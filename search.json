[{"title":"Information Systems 1- The Value of Information","url":"/2023/01/04/Information_Systems_Chapter_1/","content":"<h1 id=\"Learning-Objectives\"><a href=\"#Learning-Objectives\" class=\"headerlink\" title=\"Learning Objectives\"></a><strong>Learning Objectives</strong></h1><ul>\n<li>Describe several important emerging technologies, including 5G, IoT, and AI</li>\n<li>Compare and contrast data, information, and knowledge</li>\n<li>Explain the concepts of connectedness and usefulness as they relate to information</li>\n<li>Name the skills requird for information literacy</li>\n<li>Discuss the importance of information literacy in a businesses</li>\n<li>Compare and contrast information systems careers and information analysis careers</li>\n</ul>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"What-is-information-and-why-is-important\"><a href=\"#What-is-information-and-why-is-important\" class=\"headerlink\" title=\"What is information and why is important?\"></a>What is information and why is important?</h1><p>Information is important, so knowing about the <strong>technologies and systems</strong> that help one effectively deal with informaiton are also important.</p>\n<h2 id=\"Information-technology-vs-Information-Systems\"><a href=\"#Information-technology-vs-Information-Systems\" class=\"headerlink\" title=\"Information technology vs. Information Systems\"></a>Information technology vs. Information Systems</h2><ul>\n<li><strong>Information technology</strong>: hardware, software and media used to store, organize, retrieve and communicate information.</li>\n<li><strong>Information system</strong>: organized combination of hardware, software, infrastructure, data and people used to accomplish a specified organizational or personal bojective.</li>\n</ul>\n<h1 id=\"Information-and-Emerging-Technologies\"><a href=\"#Information-and-Emerging-Technologies\" class=\"headerlink\" title=\"Information and Emerging Technologies\"></a>Information and Emerging Technologies</h1><p>The world of technology changes rapidly, bring equally rapid changes in how we live and work. Examples include email, social media, mobile apps for ordering food, GPS, music etc.</p>\n<h2 id=\"Emering-technologies-that-are-likely-to-change-our-lives-even-more\"><a href=\"#Emering-technologies-that-are-likely-to-change-our-lives-even-more\" class=\"headerlink\" title=\"Emering technologies that are likely to change our lives even more.\"></a>Emering technologies that are likely to change our lives even more.</h2><ul>\n<li><p><strong>Fifth-generation cellular networking (5G):</strong></p>\n<ol>\n<li>It offers much faster data transmission speed, wider coverage areas, and better response times than 4G. </li>\n<li>5G’s enhanced data-handing capabilities offer many possibilities for new technology applications that depend on the ability to send and receive information rapidly. </li>\n<li>These capabilities are especially useful when combined with IoT</li>\n</ol>\n</li>\n<li><p><strong>Internet of Things (IoT):</strong></p>\n<ol>\n<li>IoT refers to an almost limitless network of connected sensors that are embedded in physical objects ranging from refrigerators to airplanes.</li>\n<li>Sensors collect data from physical objects and environment, process the data in limited ways, and transmit the data to computer through the Internet.</li>\n<li>Computers process data further and send data back to sensors, which then can send commands to other processors embeded in the physical object.</li>\n<li>Examples include: traffic sensors; smart homes (smart climate control and lighting systems, surveilance systems, video doorbells, smart refrigerators, and smart locks, among many others)</li>\n</ol>\n</li>\n<li><p><strong>Artificial intelligence (AI):</strong></p>\n<ol>\n<li>AI is used to describe a family of technologies that approximate human cognitive abilities, such as resoning, planning, learning, problem-solving, perception, and language processing.</li>\n<li>Broad applications: expert systems, machining learning, natural language processing, and intelligent agents, among others.</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"Combine-thses-Technologies-Together\"><a href=\"#Combine-thses-Technologies-Together\" class=\"headerlink\" title=\"Combine thses Technologies Together\"></a>Combine thses Technologies Together</h2><ul>\n<li><p>Information technology applications are built around the ability to <strong>gather, communicate, and process</strong> information.</p>\n</li>\n<li><p>These three capabilities align nicely with the main functions of <strong>IoT (gather), 5G (communicate), and AI (process)</strong>.</p>\n</li>\n<li><p><strong>Information</strong> has been, and continues to be, the driving element behind advances in how we apply information technologies.</p>\n</li>\n<li><p>The purpose of IoT is to gather information, the point of 5G is to communicate information faster and more effectively, and the point of AI is to use information more effectively.</p>\n</li>\n</ul>\n<h2 id=\"Interesting-Applications-of-the-Fusion\"><a href=\"#Interesting-Applications-of-the-Fusion\" class=\"headerlink\" title=\"Interesting Applications of the Fusion\"></a>Interesting Applications of the Fusion</h2><ul>\n<li><p><strong>Smart cities</strong></p>\n<ol>\n<li>The idea behind smart cities is to use IoT to collect data, which is then used to better manage resources and to more effectively provide services.</li>\n<li>Smart traffic control system: <strong>IoT-enabled sensors</strong> to conrol traffic by sensing when areas become congested and adjusting traffic lights to ease the traffic jams androute traffic to less congested routes. <strong>AI</strong> can be used to determine the optimal timing of traffic signals. <strong>5G</strong> and <strong>autonomous vehicles</strong> can further improve the efficiency and safety.</li>\n<li>Other smart city applications: environmental monitoring, energy management, intelligent transportation systems, management of public spaces, and refuse collection.</li>\n</ol>\n</li>\n<li><p><strong>Autonomous Vehicles</strong></p>\n<ol>\n<li>Automated systems alter the driver to potential hazards, such as stopped vehicle ahead. In some cases, the automated system will take over certain systems (e.g. braking system).</li>\n<li>There are 6 levels of automated driving systems. Level 0 - no automation, level 5 - full automation. Level 3 are becoming more common.</li>\n<li>Sensors – cameras, radar system, &amp; position and proximity sensors. 5G&#x2F;other network – send and receive data, communicate with traffic lights system or other vehicles. AI – use the information from IoT sensors and other information sources to take action to avoid potential collisions.</li>\n</ol>\n</li>\n<li><p><strong>VR, AR and Mixted Reality</strong></p>\n<ol>\n<li><strong>VR</strong>: Virtual reality. <strong>AR</strong>: Augmented reality. </li>\n<li>They are all similar in that they involve using digital technologies to reprsent or add to physical reality.</li>\n<li>VR is a fully immersive experience in which the technology makes you sense that you are in a different environment.</li>\n<li>AR systems overlay information on top of elements of the real world. Pokemon Go and Real Strike are examples.</li>\n<li>Mixed reality lies somewhere between VR and AR. It allows users to interact with both physical and virtual objects, which opens the possibilities for applications in many areas, such as surgery, training, retailing, real estate, and entertainment, etc.</li>\n</ol>\n</li>\n</ul>\n<h1 id=\"Data-Information-Knowledge-and-Wisdom\"><a href=\"#Data-Information-Knowledge-and-Wisdom\" class=\"headerlink\" title=\"Data, Information, Knowledge, and Wisdom\"></a>Data, Information, Knowledge, and Wisdom</h1><ul>\n<li><strong>Data</strong> are raw symbols. Data itself is meaningless.</li>\n<li><strong>Information</strong> is data that have been processed so that they are useful. In other words, <strong>Information</strong> is the original data combined with other related data and it helps us interpret the data.</li>\n<li><strong>Knowledge</strong> is when information is applied to some decision or action.</li>\n<li><strong>Wisdon</strong> involves using knowledge for the greater good. Wisdom is deeper and more uniquely human.</li>\n</ul>\n<h2 id=\"Two-reasons-bring-up-this-hierarchy\"><a href=\"#Two-reasons-bring-up-this-hierarchy\" class=\"headerlink\" title=\"Two reasons bring up this hierarchy\"></a>Two reasons bring up this hierarchy</h2><ol>\n<li><p>It gives us a way to think about different kinds of systems and how they have evolved. The hierarchy parallels how businesses have applied information technology.</p>\n<pre><code> Manage data --&gt;mamage information --&gt; manage knowledge --&gt; mamage wisdom (debatable).\n</code></pre>\n</li>\n<li><p>It helps frame two important concepts: <strong>connectedness and usefulness</strong>.</p>\n<pre><code> Data to information requires connecting data elements, and which gives the data meaning (may not be useful). \n To be useful, information is interpreted and applied leading to knowledge.\n</code></pre>\n</li>\n</ol>\n<h1 id=\"Information-Literacy\"><a href=\"#Information-Literacy\" class=\"headerlink\" title=\"Information Literacy\"></a>Information Literacy</h1><p><strong>Information Literacy</strong> is the ability to efficiently and effectively determine what information is needed and then access, evaluate, use, and manage that information in an ethical manner.</p>\n<p>Understanding how to deal with information may well have serious benefits as you move through your business career.</p>\n<h1 id=\"Use-Information\"><a href=\"#Use-Information\" class=\"headerlink\" title=\"Use Information\"></a>Use Information</h1><p>All businesses use information for three main purposes:</p>\n<ol>\n<li><p><strong>communication</strong> – Organizations much exchange information for many reasons, including sharing ideas, corrdinating actions, and transmitting information.</p>\n</li>\n<li><p><strong>process support</strong> – Many business processes are quite comples and involve various parts of business.</p>\n</li>\n<li><p><strong>decision-making</strong> – Making decision requires information about the alternatives.</p>\n</li>\n<li><p>Some businesses also use information for <strong>product</strong>. (like Google)</p>\n</li>\n</ol>\n<h1 id=\"Information-and-Your-Career\"><a href=\"#Information-and-Your-Career\" class=\"headerlink\" title=\"Information and Your Career\"></a>Information and Your Career</h1><ul>\n<li><p><strong>Information system careers</strong> – focus on the design, building, support or management of information systems.</p>\n<ul>\n<li>Examples include computer systems analyst, information systems manager, computer support specialists, etc.</li>\n</ul>\n</li>\n<li><p><strong>Information analysis careers</strong> – use systems to retrieve, report on, and analyze the information contained in the systems. </p>\n<ul>\n<li>Examples include data analyst, data scientist, business intelligence professional, etc.</li>\n</ul>\n</li>\n</ul>\n","categories":["技术杂谈","Information Systems"],"tags":["Information Systems"]},{"title":"Information Systems 4- Gaining Strategic Value from Information","url":"/2023/01/15/Information_Systems_Chapter_4/","content":"<h1 id=\"Learning-Objectives\"><a href=\"#Learning-Objectives\" class=\"headerlink\" title=\"Learning Objectives\"></a><strong>Learning Objectives</strong></h1><ul>\n<li>Present the main steps in the strategic planning process</li>\n<li>Identify competitive advantage frameworks and discuss their purpose</li>\n<li>Discuss methods for evaluating strategic initiatives</li>\n<li>Explain the concept of hypercompetition</li>\n</ul>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"Strategic-Information-Systems\"><a href=\"#Strategic-Information-Systems\" class=\"headerlink\" title=\"Strategic Information Systems\"></a>Strategic Information Systems</h1><ul>\n<li>Organizations need a variety of information systems – payroll systems, electronic mail</li>\n<li>This chapter, we are interested in <strong>strategic information systems</strong> – <strong>those information systems that are more specifically meant to provide organizations with competitive advantages.</strong></li>\n<li>It is not necessary to have unique and proprietary information technology to make an initiative strategic; it is how the IS are used that can provide the added value or strategic advantage organizations seek by implementing such initiatives.</li>\n</ul>\n<h1 id=\"Strategic-Planning-Process\"><a href=\"#Strategic-Planning-Process\" class=\"headerlink\" title=\"Strategic Planning Process\"></a>Strategic Planning Process</h1><ul>\n<li>The identification of strategic information systems should follow a structured set of steps, or <strong>strategic planning process</strong>.</li>\n<li>Example: iPhone devices came out –&gt; 1) some companies gained real advantages from increased  mobility 2) others realized the devices did not real help their employees</li>\n<li>The goal of the strategic planning effort is to identify how the organization will use and manage its resources for strategic purposes.</li>\n</ul>\n<p><img src=\"/./images/Fig_4.1.png\" alt=\"Figure 4.1\" title=\"Figure 4.1\"></p>\n<h2 id=\"Step-1-Strategic-Business-Planning\"><a href=\"#Step-1-Strategic-Business-Planning\" class=\"headerlink\" title=\"Step 1: Strategic Business Planning\"></a>Step 1: Strategic Business Planning</h2><ol>\n<li>Before deciding what IT initiatives can be used to gain a competitive advantage, it has to clearly identify what the mission of the organization is and how to achieve this mission.</li>\n<li>The strategic business planning phase is often referred to as <strong>“Know Who You Are.”</strong></li>\n<li>The <strong>outcomes</strong> of this step should include: the mission and vision of the organization, its goals for the future, and the strategies that will be used to achieve those goals.</li>\n</ol>\n<h2 id=\"Step-2-Information-System-Assessment\"><a href=\"#Step-2-Information-System-Assessment\" class=\"headerlink\" title=\"Step 2: Information System Assessment\"></a>Step 2: Information System Assessment</h2><ol>\n<li>Once managers know the main strategic goals of the organization, they need to identify the current state of IS resources in the organization.</li>\n<li>This phase is referred to as <strong>“Know Where You Start.”</strong></li>\n<li>It is important to conduct a proper assessment of resources because:<ol>\n<li>These resources could enable IS managers to meet or surpass some strategic objectives. – Example: old system already collected for a long time –&gt; great potential for new systems to use it.</li>\n<li>Conversely, it also could constrain the organization regarding what it can do. – Example: replacing the system with technology that is completely different –&gt; create disruptive situation and may even impact the profits for some time.</li>\n</ol>\n</li>\n<li>The <strong>outcome</strong> of this step is a picture of the current state of information systems resources in the organization.</li>\n<li>Depending on the assessment, it may be necessary for the organization to revise its strategic goals.</li>\n</ol>\n<p><strong>IS resources</strong> are not limited to just technology. There are three categories:</p>\n<ul>\n<li>Technical resources – hardware, software, and networks</li>\n<li>data and information resources – database</li>\n<li>human resources – the skills and personal characteristics of IS employees, the user community, and the management</li>\n</ul>\n<h2 id=\"Step-3-Information-Systems-Vision\"><a href=\"#Step-3-Information-Systems-Vision\" class=\"headerlink\" title=\"Step 3: Information Systems Vision\"></a>Step 3: Information Systems Vision</h2><ol>\n<li>Give those statements and the IS resources identified in the first two steps, IS managers must now develop a vision specifically for information system.</li>\n<li>The <strong>information systems vision</strong> should be a broad statement of how the organization should use and manage its information systems for strategic purposes.</li>\n<li>This phase is referred as <strong>Know Where They Want to Go.</strong></li>\n<li>The information systems vision has to be aligned with the organization’s mission, vision, and strategies  –&gt; require revisit the organization’s strategies.</li>\n</ol>\n<p>Example: “We will strive to offer leading-edge but tested technologies to our functional areas, provide leadership in managing external and internal data, and promote technologies that will enhance the competitive advantage of our firm.”</p>\n<ul>\n<li>For this and the following steps, the senior information systems person in the organization must gather not only employees of the information system groups, but also functional managers.<ul>\n<li>Functional managers work in other areas of the organization, such as accounting or marketing, and are likely to be the end users of the IS</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Step-4-Information-Systems-Architecture\"><a href=\"#Step-4-Information-Systems-Architecture\" class=\"headerlink\" title=\"Step 4: Information Systems Architecture\"></a>Step 4: Information Systems Architecture</h2><ol>\n<li>Information system architecture specifies how information systems resources should be used and how they should work together.</li>\n<li>It is the <strong>Know How You Are Going to Get There.</strong></li>\n<li>The development of an architecture may require to revisit the information systems vision if the architecture cannot support the vision that was established.</li>\n</ol>\n<h2 id=\"Step-5-Strategic-Initiatives-Identification\"><a href=\"#Step-5-Strategic-Initiatives-Identification\" class=\"headerlink\" title=\"Step 5: Strategic Initiatives Identification\"></a>Step 5: Strategic Initiatives Identification</h2><ol>\n<li><strong>Strategic initiatives</strong> are the means through which an organization translate its goals and visions into practice.</li>\n<li>Strategic initiatives can be about systems, but most of the time they involve much more than technology.<ul>\n<li>Example: decide to implement customer relationship management systems as new strategic direction –&gt; install hardware and software is not enough; employees must be trained to be highly customer oriented.</li>\n</ul>\n</li>\n<li>The initiatives that are identified need to be aligned with the IS vision and the strategic goals of the organization.</li>\n<li>Many frameworks that can be sued to identify the strategic information systems initiatives.</li>\n</ol>\n<h2 id=\"Advantages-of-the-IS-strategic-Planning-Process\"><a href=\"#Advantages-of-the-IS-strategic-Planning-Process\" class=\"headerlink\" title=\"Advantages of the IS strategic Planning Process\"></a>Advantages of the IS strategic Planning Process</h2><ul>\n<li><strong>Improved communication</strong>  – it allows everyone to provide input into initiatives that will potentially affect individuals in different areas of the organization.</li>\n<li><strong>Improved coordination</strong>  – various stakeholders are involved in this process, they developed a shared mental image of the initiatives, their purposes, and their advantages and disadvantages. Furthermore, each member of the planning team gets a clear picture of everyone’s responsibility.</li>\n<li><strong>Improved decision-making</strong>  – when a structured approached is used for identifying strategic initiatives, a clear set of guidelines and criteria for selection of initiatives are established. Decision making is more consistent over time with respect to which strategic initiatives are supported and, more importantly, why.</li>\n</ul>\n<h1 id=\"Frameworks-for-Strategic-Information-Systems\"><a href=\"#Frameworks-for-Strategic-Information-Systems\" class=\"headerlink\" title=\"Frameworks for Strategic Information Systems\"></a>Frameworks for Strategic Information Systems</h1><h2 id=\"Information-Systems-SWOT-Analysis\"><a href=\"#Information-Systems-SWOT-Analysis\" class=\"headerlink\" title=\"Information Systems SWOT Analysis\"></a>Information Systems SWOT Analysis</h2><ul>\n<li><strong>SWOT</strong> – strengths, weaknesses, opportunities, and threats</li>\n<li>It is important to consider factors beyond technology in the SWOT.  – Example: improve sales by providing mobile devices to sales representatives, however customers are limited to military agencies where mobile devices are not allowed on their facilities.</li>\n</ul>\n<p><img src=\"/./images/Table_4.1.png\" alt=\"Table 4.1\" title=\"Table 4.1\"></p>\n<h2 id=\"Porter’s-Five-Competitive-Forces-Model\"><a href=\"#Porter’s-Five-Competitive-Forces-Model\" class=\"headerlink\" title=\"Porter’s Five Competitive Forces Model\"></a>Porter’s Five Competitive Forces Model</h2><ul>\n<li>It is one of the most popular frameworks for analyzing a firm’s competitive position by looking at the major forces that shape an organization’s competitive environment.</li>\n<li>The original purpose of the model is to analyze how competitive an industry is and therefore determine if a particular marker could be attractive for an organization to consider.</li>\n</ul>\n<p><strong>Five forces</strong>: 1. Potential Threat of New Entrants; 2. Bargaining power of buyers; 3. Bargaining power of suppliers; 4. Potential threat of substitutes; 5. Industry competitive rivalry</p>\n<h2 id=\"Porter’s-Value-Chain-Analysis\"><a href=\"#Porter’s-Value-Chain-Analysis\" class=\"headerlink\" title=\"Porter’s Value Chain Analysis\"></a>Porter’s Value Chain Analysis</h2><ul>\n<li>In a value chain analysis, managers identify all the activities that the organization must perform to conduct its business. As each activity is performed, the organization adds value to product or service it delivers.</li>\n<li>All industries and organizations have their own value chain.</li>\n<li>Two broad categories of activities in the value chain: <strong>primary</strong> and <strong>support</strong>.<ul>\n<li>Primary activities are directly related to the creation, processing, or delivery of the product or service.</li>\n<li>Support activities are those overall tasks that make it possible for the organization to function bu that are not directly involved in the product or service.</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/./images/Fig_4.3.png\" alt=\"Figure 4.3\"></p>\n<h3 id=\"How-to-use-value-chain-analysis-to-identify-strategic-information-systems-initiatives\"><a href=\"#How-to-use-value-chain-analysis-to-identify-strategic-information-systems-initiatives\" class=\"headerlink\" title=\"How to use value chain analysis to identify strategic information systems initiatives?\"></a>How to use value chain analysis to identify strategic information systems initiatives?</h3><ol>\n<li>Lower the cost of performing an activity  – Example: companies that have cost leadership: MacDonald’s, Walmart</li>\n<li>Add more value to the final products and services in an activity  –  Example: companies that have value leadership: Apple, Starbucks</li>\n</ol>\n<p>For every activity in their value chain, manager may ask：</p>\n<ol>\n<li>How can I use IS to perform this actitity at a lower cost?  – Example: lower marketing cost –&gt; electronic marketing through social networks or email.</li>\n<li>How can I use IS to improve the value added from this activity to the final product or services?  – Example: add value to teddy bears by creating online profiles.</li>\n</ol>\n<h2 id=\"Virtual-Value-Chain\"><a href=\"#Virtual-Value-Chain\" class=\"headerlink\" title=\"Virtual Value Chain\"></a>Virtual Value Chain</h2><ul>\n<li>Instead of looking at activities that turn raw materials into a final product, as in manufacturing organizations, the <strong>virtual value chain</strong> look at activities that turn raw data into useful information.<ul>\n<li>Example 1: Google offers information to individuals through its search engine as well as information to organizations via its analytical softwares.</li>\n<li>Example 2: Consulting –&gt; Main outputs are information and knowledge-based reports and documents</li>\n</ul>\n</li>\n<li>An analysis of the virtual value chain can help identify strategic information system initiatives.</li>\n<li>Managers can ask themselves in what ways IS can make gathering, organizing, selecting, synthesizing, and distributing less expensive and add more value to the firm’s information.<ul>\n<li>Example: collecting work hours for remote employees via website applications vs. paper forms.</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"Evaluating-Strategic-Initiatives\"><a href=\"#Evaluating-Strategic-Initiatives\" class=\"headerlink\" title=\"Evaluating Strategic Initiatives\"></a>Evaluating Strategic Initiatives</h1><p>There are several tools that can be used for evaluating strategic initiatives, and we will discuss two:<strong>the critical success factors methods</strong> and <strong>the priority matrix</strong>.</p>\n<h2 id=\"Critical-Success-Factors\"><a href=\"#Critical-Success-Factors\" class=\"headerlink\" title=\"Critical Success Factors\"></a>Critical Success Factors</h2><ul>\n<li><strong>Critical success factors (CSFs)</strong> are those few important considerations that must be achieved for the organization to survive and be successful (i.e., achieve its mission).</li>\n<li>These are not about technology, but more about business objectives.</li>\n<li>The key questions asked to start the discussion are similar to these:<ul>\n<li>What needs to happen for our organization to increase its revenues?</li>\n<li>What are the most important actions we need to take to be more competitive?</li>\n<li>What is needed for us to be more successful?</li>\n</ul>\n</li>\n<li>Initiatives that do not support the CSFs should not be considered as top priorities.</li>\n</ul>\n<h2 id=\"Priority-Matrix\"><a href=\"#Priority-Matrix\" class=\"headerlink\" title=\"Priority Matrix\"></a>Priority Matrix</h2><ul>\n<li>The <strong>priority matrix</strong> allows managers to evaluate potential initiatives and prioritize them along two key dimensions<ol>\n<li>The efforts to implement the system or project</li>\n<li>the potential returns from this implementation</li>\n</ol>\n</li>\n</ul>\n<h1 id=\"Hypercompetition-Sustainability-of-Competitive-Advantage\"><a href=\"#Hypercompetition-Sustainability-of-Competitive-Advantage\" class=\"headerlink\" title=\"Hypercompetition: Sustainability of Competitive Advantage\"></a>Hypercompetition: Sustainability of Competitive Advantage</h1><p>Today the pace of change in IT and other innovations is faster than ever. This has led some individuals to question the sustainability of any competitive advantage a firm obtains through its initiatives. This is the concept of <strong>hypercompetition</strong>.</p>\n<p>D’Aveni’s 7Ss suggest:</p>\n<ul>\n<li>Every competitive advantage is eroded</li>\n<li>Sustaining an advantage can be a deadly distraction</li>\n<li>Goal of advantage should be disruption, not sustainability</li>\n<li>Initiatives are achieved through series of small steps</li>\n</ul>\n<p>7 strategic moves that organizations should consider to compete in hypercompetitive markets</p>\n<ol>\n<li>Superior stakeholder satisfaction  –  Maximizing customer satisfaction by adding value strategically.</li>\n<li>Strategic soothsaying  –  Using new knowledge to predict or create new windows of opportunity.</li>\n<li>Positioning for speed –  Preparing the organization to react as fast as possible.</li>\n<li>Positioning for suprise  –  Preparing the organization to respond to the marketplace in a manner that will surprise competitors.</li>\n<li>Shifting the rules of competition  –  Finding new ways to serve customers, transforming the industry.</li>\n<li>Signaling strategic intent  –  Communicating intentions to stall responses by competitors.</li>\n<li>Simultaneous and sequential strategic thrusts  –  Taking steps to stun and confuse competitors to disrupt or block their efforts.</li>\n</ol>\n","categories":["技术杂谈","Information Systems"],"tags":["Information Systems"]},{"title":"Information Systems 3- Evaluating Informaiton","url":"/2023/01/07/Information_Systems_Chapter_3/","content":"<h1 id=\"Learning-Objectives\"><a href=\"#Learning-Objectives\" class=\"headerlink\" title=\"Learning Objectives\"></a><strong>Learning Objectives</strong></h1><ul>\n<li>Discuss why it is important both personally and professionally to be an informed information consumer</li>\n<li>Describe information overload, its consequences, and approaches for dealing with information overload</li>\n<li>Discuss the relationship between information overload and information evaluation</li>\n<li>List and describe the dimesions of information quality</li>\n<li>List and describe the elements of an information evaluation framework</li>\n<li>Given an information-related task, evaluate information for its usefulness and believability</li>\n</ul>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"Being-a-Smart-Information-Consumer\"><a href=\"#Being-a-Smart-Information-Consumer\" class=\"headerlink\" title=\"Being a Smart Information Consumer\"></a>Being a Smart Information Consumer</h1><ul>\n<li>Online available information has both advantages and disadvantages<ul>\n<li>Advantages: easy access to information</li>\n<li>Disadvantages: no quality control.</li>\n</ul>\n</li>\n<li><strong>Information evaluation</strong> is the systematic determination of the merit and worth of information. Information evaluation skills will be important to you both personally and in your business career.<ul>\n<li><strong>Personally</strong>: sift through and evaluate many kinds of information.</li>\n<li><strong>Business Career</strong>: your reputation &amp; career success depends on the outcomes of the decisions you make, which based on better information.</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"Information-Overload-and-the-Need-to-Evaluate-Information\"><a href=\"#Information-Overload-and-the-Need-to-Evaluate-Information\" class=\"headerlink\" title=\"Information Overload and the Need to Evaluate Information\"></a>Information Overload and the Need to Evaluate Information</h1><ul>\n<li><strong>Information overload</strong> is being faced with more information than one can effectively process.</li>\n<li>Information overload reduces productivity, increases stress, and can acutally lead to physical health problems.</li>\n<li>Two major strategies for dealing with information overload are <strong>filtering and withdrawal</strong>.<ul>\n<li><strong>Withdrawal</strong> involes disconnecting from sources of information. Example: not checking email, no TV, no Internet, etc.</li>\n<li><strong>Filtering</strong> involves knowing what information we need and what information merits attention and use. Example: choose which message to open and which to delete or ignore.</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"Information-Quality\"><a href=\"#Information-Quality\" class=\"headerlink\" title=\"Information Quality\"></a>Information Quality</h1><p><strong>Information Quality</strong> The degree to which information is suitable for a particular purpose. In other words, the information with high quality is useful toward the achievement of whatever task is at hand.</p>\n<p>Wang and Strong put quality dimensions into four categories:</p>\n<ol>\n<li>Intrinsic quality  –  important regardless of the context or how it is repsrsented.</li>\n<li>Contextual quality  –  viewed differently depending on the task at hand.</li>\n<li>Representational quality  –  concerns how the information is provided to the user.</li>\n<li>Accessibility quality  –  whether authorized users can easily access the information.</li>\n</ol>\n<p>A few points regarding the classification of quality dimension</p>\n<ol>\n<li>There is considerable disagreement regarding the dimensions of information quality.</li>\n<li>It is important to consider the context when thinking about the information quality.</li>\n<li>Information quality has a cost. <strong>Sufficient quality</strong> is usually we want.<ul>\n<li>For more important, higher impact decisions, it is worthwhile to pay much more attention to information quality than for lower consequence decision. Example: buying a house vs. notebook paper.</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Evaluating-Information\"><a href=\"#Evaluating-Information\" class=\"headerlink\" title=\"Evaluating Information\"></a>Evaluating Information</h1><p>There are two questions you need to answer:</p>\n<ul>\n<li>(1) Is the information useful?</li>\n<li>(2) Is the information believable?</li>\n</ul>\n<h2 id=\"Evaluating-Usefulness\"><a href=\"#Evaluating-Usefulness\" class=\"headerlink\" title=\"Evaluating Usefulness\"></a>Evaluating Usefulness</h2><ul>\n<li><strong>Relevant</strong><ul>\n<li>Will this information help me accomplish my task?</li>\n</ul>\n</li>\n<li><strong>Appropriate</strong><ul>\n<li>Is the information suitable for your purpose?</li>\n</ul>\n</li>\n<li><strong>Current</strong><ul>\n<li>How current you need the information to be?</li>\n</ul>\n</li>\n<li>Consistent</li>\n<li>Understandable</li>\n</ul>\n<h2 id=\"Evaluating-Believability\"><a href=\"#Evaluating-Believability\" class=\"headerlink\" title=\"Evaluating Believability\"></a>Evaluating Believability</h2><ul>\n<li><strong>Credible</strong><ul>\n<li>Author’s or the information source’s reputation, influence, and experience</li>\n</ul>\n</li>\n<li><strong>Objective</strong><ul>\n<li>Whether the source of the information is relevent to or has interest conflict with the reported product or service</li>\n<li>Whether it use the persuasive or emotional lanuage</li>\n</ul>\n</li>\n<li><strong>Supported</strong><ul>\n<li>Claims without support should not be trusted</li>\n<li>When support is offered, you should evaluate the quality of the support</li>\n<li>Consider the reasonableness of the claim</li>\n<li>Think about whether the claim is testable</li>\n</ul>\n</li>\n<li><strong>Comprehensive</strong><ul>\n<li>Assessing comprehensiveness requires assessing the <strong>depth and breadth</strong> of the informaiton</li>\n<li>Breadth concern whether all aspects of a topic are covered</li>\n<li>Depth concerns the level of detail provided</li>\n</ul>\n</li>\n</ul>\n<p><strong>The more information you evaluate, the more some of this will become second nature.</strong></p>\n","categories":["技术杂谈","Information Systems"],"tags":["Information Systems"]},{"title":"Machine Learning-学习笔记-10-exercise 3 summary","url":"/2022/08/20/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-10/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 10-exercise 3 summary。</p>\n<span id=\"more\"></span>\n\n<p><strong>Programming Exercise 3: Multi-class Classification and Neural Networks</strong></p>\n<p>In this exercise, you will implement one-vs-all logistic regression and neural networks to recognize hand-written digits.</p>\n<h1 id=\"ex3-m\"><a href=\"#ex3-m\" class=\"headerlink\" title=\"ex3.m\"></a>ex3.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all</span><br><span class=\"line\"></span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">%</span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  linear exercise. You will need to complete the following functions</span><br><span class=\"line\">%  in this exericse:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     lrCostFunction.m (logistic regression cost function)</span><br><span class=\"line\">%     oneVsAll.m</span><br><span class=\"line\">%     predictOneVsAll.m</span><br><span class=\"line\">%     predict.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% Setup the parameters you will use for this part of the exercise</span><br><span class=\"line\">input_layer_size  = 400;  % 20x20 Input Images of Digits</span><br><span class=\"line\">num_labels = 10;          % 10 labels, from 1 to 10</span><br><span class=\"line\">                          % (note that we have mapped &quot;0&quot; to label 10)</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 1: Loading and Visualizing Data =============</span><br><span class=\"line\">%  We start the exercise by first loading and visualizing the dataset.</span><br><span class=\"line\">%  You will be working with a dataset that contains handwritten digits.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Load Training Data</span><br><span class=\"line\">fprintf(&#x27;Loading and Visualizing Data ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">load(&#x27;ex3data1.mat&#x27;); % training data stored in arrays X, y</span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Randomly select 100 data points to display</span><br><span class=\"line\">rand_indices = randperm(m);</span><br><span class=\"line\">sel = X(rand_indices(1:100), :);</span><br><span class=\"line\"></span><br><span class=\"line\">displayData(sel);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ============ Part 2a: Vectorize Logistic Regression ============</span><br><span class=\"line\">%  In this part of the exercise, you will reuse your logistic regression</span><br><span class=\"line\">%  code from the last exercise. You task here is to make sure that your</span><br><span class=\"line\">%  regularized logistic regression implementation is vectorized. After</span><br><span class=\"line\">%  that, you will implement one-vs-all classification for the handwritten</span><br><span class=\"line\">%  digit dataset.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Test case for lrCostFunction</span><br><span class=\"line\">fprintf(&#x27;\\nTesting lrCostFunction() with regularization&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">theta_t = [-2; -1; 1; 2];</span><br><span class=\"line\">X_t = [ones(5,1) reshape(1:15,5,3)/10];</span><br><span class=\"line\">y_t = ([1;0;1;0;1] &gt;= 0.5);</span><br><span class=\"line\">lambda_t = 3;</span><br><span class=\"line\">[J grad] = lrCostFunction(theta_t, X_t, y_t, lambda_t);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nCost: %f\\n&#x27;, J);</span><br><span class=\"line\">fprintf(&#x27;Expected cost: 2.534819\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;Gradients:\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; %f \\n&#x27;, grad);</span><br><span class=\"line\">fprintf(&#x27;Expected gradients:\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; 0.146561\\n -0.548558\\n 0.724722\\n 1.398003\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\">%% ============ Part 2b: One-vs-All Training ============</span><br><span class=\"line\">fprintf(&#x27;\\nTraining One-vs-All Logistic Regression...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">lambda = 0.1;</span><br><span class=\"line\">[all_theta] = oneVsAll(X, y, num_labels, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================ Part 3: Predict for One-Vs-All ================</span><br><span class=\"line\"></span><br><span class=\"line\">pred = predictOneVsAll(all_theta, X);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nTraining Set Accuracy: %f\\n&#x27;, mean(double(pred == y)) * 100);</span><br></pre></td></tr></table></figure>\n<h1 id=\"displayData-m\"><a href=\"#displayData-m\" class=\"headerlink\" title=\"displayData.m\"></a>displayData.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [h, display_array] = displayData(X, example_width)</span><br><span class=\"line\">%DISPLAYDATA Display 2D data in a nice grid</span><br><span class=\"line\">%   [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data</span><br><span class=\"line\">%   stored in X in a nice grid. It returns the figure handle h and the </span><br><span class=\"line\">%   displayed array if requested.</span><br><span class=\"line\"></span><br><span class=\"line\">% Set example_width automatically if not passed in</span><br><span class=\"line\">if ~exist(&#x27;example_width&#x27;, &#x27;var&#x27;) || isempty(example_width) </span><br><span class=\"line\">  example_width = round(sqrt(size(X, 2)));</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Gray Image</span><br><span class=\"line\">colormap(gray);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute rows, cols</span><br><span class=\"line\">[m n] = size(X);</span><br><span class=\"line\">example_height = (n / example_width);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute number of items to display</span><br><span class=\"line\">display_rows = floor(sqrt(m));</span><br><span class=\"line\">display_cols = ceil(m / display_rows);</span><br><span class=\"line\"></span><br><span class=\"line\">% Between images padding</span><br><span class=\"line\">pad = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">% Setup blank display</span><br><span class=\"line\">display_array = - ones(pad + display_rows * (example_height + pad), ...</span><br><span class=\"line\">                       pad + display_cols * (example_width + pad));</span><br><span class=\"line\"></span><br><span class=\"line\">% Copy each example into a patch on the display array</span><br><span class=\"line\">curr_ex = 1;</span><br><span class=\"line\">for j = 1:display_rows</span><br><span class=\"line\">  for i = 1:display_cols</span><br><span class=\"line\">    if curr_ex &gt; m, </span><br><span class=\"line\">      break; </span><br><span class=\"line\">    end</span><br><span class=\"line\">    % Copy the patch</span><br><span class=\"line\">    </span><br><span class=\"line\">    % Get the max value of the patch</span><br><span class=\"line\">    max_val = max(abs(X(curr_ex, :)));</span><br><span class=\"line\">    display_array(pad + (j - 1) * (example_height + pad) + (1:example_height), ...</span><br><span class=\"line\">                  pad + (i - 1) * (example_width + pad) + (1:example_width)) = ...</span><br><span class=\"line\">            reshape(X(curr_ex, :), example_height, example_width) / max_val;</span><br><span class=\"line\">    curr_ex = curr_ex + 1;</span><br><span class=\"line\">  end</span><br><span class=\"line\">  if curr_ex &gt; m, </span><br><span class=\"line\">    break; </span><br><span class=\"line\">  end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Display Image</span><br><span class=\"line\">h = imagesc(display_array, [-1 1]);</span><br><span class=\"line\"></span><br><span class=\"line\">% Do not show axis</span><br><span class=\"line\">axis image off</span><br><span class=\"line\"></span><br><span class=\"line\">drawnow;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"lrCostFunction-m\"><a href=\"#lrCostFunction-m\" class=\"headerlink\" title=\"lrCostFunction.m\"></a>lrCostFunction.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [J, grad] = lrCostFunction(theta, X, y, lambda)</span><br><span class=\"line\">%LRCOSTFUNCTION Compute cost and gradient for logistic regression with </span><br><span class=\"line\">%regularization</span><br><span class=\"line\">%   J = LRCOSTFUNCTION(theta, X, y, lambda) computes the cost of using</span><br><span class=\"line\">%   theta as the parameter for regularized logistic regression and the</span><br><span class=\"line\">%   gradient of the cost w.r.t. to the parameters. </span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize some useful values</span><br><span class=\"line\">m = length(y); % number of training examples</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">J = 0;</span><br><span class=\"line\">grad = zeros(size(theta));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the cost of a particular choice of theta.</span><br><span class=\"line\">%               You should set J to the cost.</span><br><span class=\"line\">%               Compute the partial derivatives and set grad to the partial</span><br><span class=\"line\">%               derivatives of the cost w.r.t. each parameter in theta</span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: The computation of the cost function and gradients can be</span><br><span class=\"line\">%       efficiently vectorized. For example, consider the computation</span><br><span class=\"line\">%</span><br><span class=\"line\">%           sigmoid(X * theta)</span><br><span class=\"line\">%</span><br><span class=\"line\">%       Each row of the resulting matrix will contain the value of the</span><br><span class=\"line\">%       prediction for that example. You can make use of this to vectorize</span><br><span class=\"line\">%       the cost function and gradient computations. </span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: When computing the gradient of the regularized cost function, </span><br><span class=\"line\">%       there&#x27;re many possible vectorized solutions, but one solution</span><br><span class=\"line\">%       looks like:</span><br><span class=\"line\">%           grad = (unregularized gradient for logistic regression)</span><br><span class=\"line\">%           temp = theta; </span><br><span class=\"line\">%           temp(1) = 0;   % because we don&#x27;t add anything for j = 0  </span><br><span class=\"line\">%           grad = grad + YOUR_CODE_HERE (using the temp variable)</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">h = sigmoid(X*theta);</span><br><span class=\"line\">reg = lambda/(2*m)*(theta&#x27;*theta-theta(1)^2);</span><br><span class=\"line\">J = 1/m*(-y&#x27;*log(h)-(1-y&#x27;)*log(1-h))+reg;</span><br><span class=\"line\"></span><br><span class=\"line\">grad = 1/m*X&#x27;*(h-y);</span><br><span class=\"line\">temp = theta;</span><br><span class=\"line\">temp(1) = 0;</span><br><span class=\"line\">grad = grad + lambda/m*temp;</span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">grad = grad(:);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"oneVsAll-m\"><a href=\"#oneVsAll-m\" class=\"headerlink\" title=\"oneVsAll.m\"></a>oneVsAll.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [all_theta] = oneVsAll(X, y, num_labels, lambda)</span><br><span class=\"line\">%ONEVSALL trains multiple logistic regression classifiers and returns all</span><br><span class=\"line\">%the classifiers in a matrix all_theta, where the i-th row of all_theta </span><br><span class=\"line\">%corresponds to the classifier for label i</span><br><span class=\"line\">%   [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels</span><br><span class=\"line\">%   logistic regression classifiers and returns each of these classifiers</span><br><span class=\"line\">%   in a matrix all_theta, where the i-th row of all_theta corresponds </span><br><span class=\"line\">%   to the classifier for label i</span><br><span class=\"line\"></span><br><span class=\"line\">% Some useful variables</span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\">n = size(X, 2);</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">all_theta = zeros(num_labels, n + 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Add ones to the X data matrix</span><br><span class=\"line\">X = [ones(m, 1) X];</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: You should complete the following code to train num_labels</span><br><span class=\"line\">%               logistic regression classifiers with regularization</span><br><span class=\"line\">%               parameter lambda. </span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: theta(:) will return a column vector.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: You can use y == c to obtain a vector of 1&#x27;s and 0&#x27;s that tell you</span><br><span class=\"line\">%       whether the ground truth is true/false for this class.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: For this assignment, we recommend using fmincg to optimize the cost</span><br><span class=\"line\">%       function. It is okay to use a for-loop (for c = 1:num_labels) to</span><br><span class=\"line\">%       loop over the different classes.</span><br><span class=\"line\">%</span><br><span class=\"line\">%       fmincg works similarly to fminunc, but is more efficient when we</span><br><span class=\"line\">%       are dealing with large number of parameters.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Example Code for fmincg:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     % Set Initial theta</span><br><span class=\"line\">%     initial_theta = zeros(n + 1, 1);</span><br><span class=\"line\">%     </span><br><span class=\"line\">%     % Set options for fminunc</span><br><span class=\"line\">%     options = optimset(&#x27;GradObj&#x27;, &#x27;on&#x27;, &#x27;MaxIter&#x27;, 50);</span><br><span class=\"line\">% </span><br><span class=\"line\">%     % Run fmincg to obtain the optimal theta</span><br><span class=\"line\">%     % This function will return theta and the cost </span><br><span class=\"line\">%     [theta] = ...</span><br><span class=\"line\">%         fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...</span><br><span class=\"line\">%                 initial_theta, options);</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">for c = 1:num_labels</span><br><span class=\"line\">  initial_theta = zeros(n + 1, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">  options = optimset(&#x27;GradObj&#x27;, &#x27;on&#x27;, &#x27;MaxIter&#x27;, 50);</span><br><span class=\"line\"></span><br><span class=\"line\">  [theta] = ...</span><br><span class=\"line\">    fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...</span><br><span class=\"line\">      initial_theta, options);</span><br><span class=\"line\">  all_theta (c,:) = [theta];</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"predictOneVsAll-m\"><a href=\"#predictOneVsAll-m\" class=\"headerlink\" title=\"predictOneVsAll.m\"></a>predictOneVsAll.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function p = predictOneVsAll(all_theta, X)</span><br><span class=\"line\">%PREDICT Predict the label for a trained one-vs-all classifier. The labels </span><br><span class=\"line\">%are in the range 1..K, where K = size(all_theta, 1). </span><br><span class=\"line\">%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions</span><br><span class=\"line\">%  for each example in the matrix X. Note that X contains the examples in</span><br><span class=\"line\">%  rows. all_theta is a matrix where the i-th row is a trained logistic</span><br><span class=\"line\">%  regression theta vector for the i-th class. You should set p to a vector</span><br><span class=\"line\">%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2</span><br><span class=\"line\">%  for 4 examples) </span><br><span class=\"line\"></span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\">num_labels = size(all_theta, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">p = zeros(size(X, 1), 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Add ones to the X data matrix</span><br><span class=\"line\">X = [ones(m, 1) X];</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Complete the following code to make predictions using</span><br><span class=\"line\">%               your learned logistic regression parameters (one-vs-all).</span><br><span class=\"line\">%               You should set p to a vector of predictions (from 1 to</span><br><span class=\"line\">%               num_labels).</span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: This code can be done all vectorized using the max function.</span><br><span class=\"line\">%       In particular, the max function can also return the index of the </span><br><span class=\"line\">%       max element, for more information see &#x27;help max&#x27;. If your examples </span><br><span class=\"line\">%       are in rows, then, you can use max(A, [], 2) to obtain the max </span><br><span class=\"line\">%       for each row.</span><br><span class=\"line\">%       </span><br><span class=\"line\"></span><br><span class=\"line\">[probability, p] = max((sigmoid(X*all_theta&#x27;)), [], 2);</span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"ex3-nn-m\"><a href=\"#ex3-nn-m\" class=\"headerlink\" title=\"ex3_nn.m\"></a>ex3_nn.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class - Exercise 3 | Part 2: Neural Networks</span><br><span class=\"line\"></span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">% </span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  linear exercise. You will need to complete the following functions </span><br><span class=\"line\">%  in this exericse:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     lrCostFunction.m (logistic regression cost function)</span><br><span class=\"line\">%     oneVsAll.m</span><br><span class=\"line\">%     predictOneVsAll.m</span><br><span class=\"line\">%     predict.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% Setup the parameters you will use for this exercise</span><br><span class=\"line\">input_layer_size  = 400;  % 20x20 Input Images of Digits</span><br><span class=\"line\">hidden_layer_size = 25;   % 25 hidden units</span><br><span class=\"line\">num_labels = 10;          % 10 labels, from 1 to 10   </span><br><span class=\"line\">                          % (note that we have mapped &quot;0&quot; to label 10)</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 1: Loading and Visualizing Data =============</span><br><span class=\"line\">%  We start the exercise by first loading and visualizing the dataset. </span><br><span class=\"line\">%  You will be working with a dataset that contains handwritten digits.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Load Training Data</span><br><span class=\"line\">fprintf(&#x27;Loading and Visualizing Data ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">load(&#x27;ex3data1.mat&#x27;);</span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Randomly select 100 data points to display</span><br><span class=\"line\">sel = randperm(size(X, 1));</span><br><span class=\"line\">sel = sel(1:100);</span><br><span class=\"line\"></span><br><span class=\"line\">displayData(X(sel, :));</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================ Part 2: Loading Pameters ================</span><br><span class=\"line\">% In this part of the exercise, we load some pre-initialized </span><br><span class=\"line\">% neural network parameters.</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nLoading Saved Neural Network Parameters ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Load the weights into variables Theta1 and Theta2</span><br><span class=\"line\">load(&#x27;ex3weights.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================= Part 3: Implement Predict =================</span><br><span class=\"line\">%  After training the neural network, we would like to use it to predict</span><br><span class=\"line\">%  the labels. You will now implement the &quot;predict&quot; function to use the</span><br><span class=\"line\">%  neural network to predict the labels of the training set. This lets</span><br><span class=\"line\">%  you compute the training set accuracy.</span><br><span class=\"line\"></span><br><span class=\"line\">pred = predict(Theta1, Theta2, X);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nTraining Set Accuracy: %f\\n&#x27;, mean(double(pred == y)) * 100);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%  To give you an idea of the network&#x27;s output, you can also run</span><br><span class=\"line\">%  through the examples one at the a time to see what it is predicting.</span><br><span class=\"line\"></span><br><span class=\"line\">%  Randomly permute examples</span><br><span class=\"line\">rp = randperm(m);</span><br><span class=\"line\"></span><br><span class=\"line\">for i = 1:m</span><br><span class=\"line\">    % Display </span><br><span class=\"line\">    fprintf(&#x27;\\nDisplaying Example Image\\n&#x27;);</span><br><span class=\"line\">    displayData(X(rp(i), :));</span><br><span class=\"line\"></span><br><span class=\"line\">    pred = predict(Theta1, Theta2, X(rp(i),:));</span><br><span class=\"line\">    fprintf(&#x27;\\nNeural Network Prediction: %d (digit %d)\\n&#x27;, pred, mod(pred, 10));</span><br><span class=\"line\">    </span><br><span class=\"line\">    % Pause with quit option</span><br><span class=\"line\">    s = input(&#x27;Paused - press enter to continue, q to exit:&#x27;,&#x27;s&#x27;);</span><br><span class=\"line\">    if s == &#x27;q&#x27;</span><br><span class=\"line\">      break</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"predict-m\"><a href=\"#predict-m\" class=\"headerlink\" title=\"predict.m\"></a>predict.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function p = predict(Theta1, Theta2, X)</span><br><span class=\"line\">%PREDICT Predict the label of an input given a trained neural network</span><br><span class=\"line\">%   p = PREDICT(Theta1, Theta2, X) outputs the predicted label of X given the</span><br><span class=\"line\">%   trained weights of a neural network (Theta1, Theta2)</span><br><span class=\"line\"></span><br><span class=\"line\">% Useful values</span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\">num_labels = size(Theta2, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">p = zeros(size(X, 1), 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Complete the following code to make predictions using</span><br><span class=\"line\">%               your learned neural network. You should set p to a </span><br><span class=\"line\">%               vector containing labels between 1 to num_labels.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: The max function might come in useful. In particular, the max</span><br><span class=\"line\">%       function can also return the index of the max element, for more</span><br><span class=\"line\">%       information see &#x27;help max&#x27;. If your examples are in rows, then, you</span><br><span class=\"line\">%       can use max(A, [], 2) to obtain the max for each row.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">X = [ones(m,1) X];</span><br><span class=\"line\">a_2 = sigmoid(X*Theta1&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">n = size(a_2, 1);</span><br><span class=\"line\">a_2 = [ones(n,1) a_2];</span><br><span class=\"line\"></span><br><span class=\"line\">[probability, p] = max((sigmoid(a_2*Theta2&#x27;)), [], 2);</span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-01-Linear Regression with One Variable","url":"/2022/08/11/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 01-单变量线性回归(Linear Regression with One Variable)。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"单变量线性回归\"><a href=\"#单变量线性回归\" class=\"headerlink\" title=\"单变量线性回归\"></a>单变量线性回归</h1><p><strong>Hypothesis:</strong><br>$$h_{\\theta}(x) &#x3D; {\\theta_0} + {\\theta_1x}$$</p>\n<p><strong>Parameters:</strong> \\({\\theta_0}, {\\theta_1}\\) </p>\n<p><strong>Cost Function:</strong><br>$$J({\\theta_0},{\\theta_1})&#x3D; \\frac{1}{2m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2$$</p>\n<p>其中，\\(h_\\theta(x^{(i)})\\)是预测值，\\(y^{(i)}\\)是真实值。Cost function越小说明我们的模型跟真实值之间的差距越小，也就是说预测会越准确。所以Meachine learning的目的是找到\\(J({\\theta_0},{\\theta_1})\\)的最小值。</p>\n<h1 id=\"当-theta-0-x3D-0-时的简化情况\"><a href=\"#当-theta-0-x3D-0-时的简化情况\" class=\"headerlink\" title=\"当\\(\\theta_0&#x3D;0\\)时的简化情况\"></a>当\\(\\theta_0&#x3D;0\\)时的简化情况</h1><p>当\\(\\theta_0&#x3D;0\\)时,hypothesis可以写为：<br>$$h_\\theta(x)&#x3D;\\theta_1x$$<br>这时我们只有一个参数\\(\\theta_1\\),此时Cost function变为：<br>$$J(\\theta_1)&#x3D;\\frac{1}{2m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2$$<br>这里由于\\(h_\\theta(x)&#x3D;\\theta_1x\\),所以cost function也可以写为：<br>$$J(\\theta_1)&#x3D;\\frac{1}{2m}\\sum_{i&#x3D;1}^{m}(\\theta_1x^{(i)}-y^{(i)})^2$$<br>这时，我们需要建立模型找到\\(J(\\theta_1)\\)的最小值。通过不断改变\\(\\theta_1\\)的值，我们就可以找到cost function\\(J(\\theta_1)\\)的最小值。或者可以通过绘制二维图形，来非常简单的找到最优解。</p>\n<h1 id=\"两个参数的情况\"><a href=\"#两个参数的情况\" class=\"headerlink\" title=\"两个参数的情况\"></a>两个参数的情况</h1><p>当有两个参数\\(\\theta_0,\\theta_1\\)时，Hypothesis的图像就变成了一个三维图像，最小值为图像的最低点。<br>找到cost function最小值的步骤为：</p>\n<ol>\n<li>从某个特定的\\(\\theta_0,\\theta_1\\)开始代入计算，比如\\(\\theta_0&#x3D;0,\\theta_1&#x3D;0\\)</li>\n<li>不断改变\\(\\theta_0,\\theta_1\\)的值来减小\\(J({\\theta_0},{\\theta_1})\\)的值，直到找到\\(J({\\theta_0},{\\theta_1})\\)的最小值。</li>\n</ol>\n<p>那么如何不断改变\\(\\theta_0,\\theta_1\\)的值呢？我们需要用到下面的公式：<br>$$\\theta_j :&#x3D; \\theta_j - \\alpha\\frac{\\partial}{\\partial{\\theta_j}}{J({\\theta_0},{\\theta_1})}\\ \\ \\ \\ (for\\ \\ j&#x3D;0\\ and\\ j&#x3D;1)$$ </p>\n<p>这里将:&#x3D;后面的值重新赋予\\(\\theta_j\\)。由于方程中出现了两个参数，改变其中一个两一个也会随之改变，所以在赋值的时候，我们需要将\\(\\theta_0,\\theta_1\\)同时赋值。</p>\n<p>通过对cost function求偏导就可以来确定我们参数改变的方向是朝着\\({J({\\theta_0},{\\theta_1})}\\)更小的方向来赋值。\\(\\alpha\\)是learning rate，用于调整我们改变参数时候的变化大小，选择合适的\\(\\alpha\\)会让我们更快更准确的找到最优解。</p>\n<p>当\\(\\alpha\\)太小的时候，方程求解的过程会十分漫长；但如果\\(\\alpha\\)选择的太大，就有可能错过最优解，从而导致无法解出方程。</p>\n<h1 id=\"对-theta-0-theta-1-求偏导\"><a href=\"#对-theta-0-theta-1-求偏导\" class=\"headerlink\" title=\"对\\(\\theta_0, \\theta_1\\)求偏导\"></a>对\\(\\theta_0, \\theta_1\\)求偏导</h1><p>上面提到了在不断对\\(\\theta_0, \\theta_1\\)赋值的过程中，我们需要对\\(\\theta_0, \\theta_1\\)求偏导，那么简化之后来看一下会得到什么样的结果吧。<br>$$<br>\\frac{\\partial}{\\partial{\\theta_j}}{J({\\theta_0},{\\theta_1})} &#x3D;<br>\\frac{\\partial}{\\partial{\\theta_j}}{\\frac{1}{2m}}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y{(i)})^2&#x3D;<br>\\frac{\\partial}{\\partial{\\theta_j}}{\\frac{1}{2m}}\\sum_{i&#x3D;1}^{m}(\\theta_0+\\theta_1x^{(i)}-y^{(i)})^2<br>$$<br>所以\\(\\theta_0, \\theta_1\\)分别为：<br>$$<br>\\theta_0\\ :\\  \\frac{\\partial}{\\partial{\\theta_j}}{J({\\theta_0},{\\theta_1})} &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})<br>$$<br>$$<br>\\theta_1\\ :\\  \\frac{\\partial}{\\partial{\\theta_j}}{J({\\theta_0},{\\theta_1})} &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{m}[(h_\\theta(x^{(i)})-y{(i)})x^{(i)}]<br>$$<br>类似的，如果我们有多个参数，对\\(\\theta_j\\)求偏导，我们会得到类似的结果：<br>$$<br>\\theta_j\\ :\\  \\frac{\\partial}{\\partial{\\theta_j}}{J({\\theta_j})} &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{m}[(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}]<br>$$</p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-11-Neural Networks:Learning","url":"/2022/08/25/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-11/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 11-神经网络的学习(Neural Networks: Learning)。</p>\n<span id=\"more\"></span>\n\n<h1 id=\"代价函数-Cost-function\"><a href=\"#代价函数-Cost-function\" class=\"headerlink\" title=\"代价函数(Cost function)\"></a>代价函数(Cost function)</h1><p>首先引入一些标记方法，以便于讨论：</p>\n<p>假设神经网络的训练样本有\\(m\\)个，每个包含一组输入信号\\(x\\)和一组输出信号\\(y\\)，\\(L\\)表示神经网络层数，\\(S_l\\)表示\\(l))层的neuron个数(不包含bias单元)。</p>\n<p>神经网络分为两类：</p>\n<ul>\n<li>二元分类：\\(y&#x3D;0\\ or\\ 1\\)；1个输出变量</li>\n<li>多元分类：\\(y\\in\\mathbb{R}^K\\)；K个输出变量</li>\n</ul>\n<p><img src=\"/../images/NeuralNetwork_1.jpg\" alt=\"NeuralNetwork_1\"></p>\n<p>逻辑回归中代价函数为：<br>$$<br>J(\\theta)&#x3D; -\\frac{1}{m}[\\sum_{i&#x3D;1}^{m}y^{(i)}log h_\\theta(x^{(i)}) + (1-y^{(i)})log(1-h_\\theta(x^{(i)}))]+\\frac{\\lambda}{2m}\\sum_{j&#x3D;1}^{n}\\theta_j^2<br>$$<br>与逻辑回归不同的是，神经网络有多个输出变量，或者说\\(h_\\Theta(x)\\)是一个维度为K的向量。因此代价函数也会更加复杂一点：<br>$$<br>J(\\Theta)&#x3D; -\\frac{1}{m}[\\sum_{i&#x3D;1}^{m}\\sum_{k&#x3D;1}^{k}y_k^{(i)}log (h_\\Theta(x^{(i)}))_k + (1-y_k^{(i)})log(1-(h_\\Theta(x^{(i)}))_k)]+\\frac{\\lambda}{2m}\\sum_{l&#x3D;1}^{L-1}\\sum_{i&#x3D;1}^{s_l}\\sum_{j&#x3D;1}^{s_l+1}(\\Theta_{ji}^{(l)})^2<br>$$</p>\n<p>其中，\\(h_\\Theta(x)\\in\\mathbb{R}^K\\)  \\((h_\\Theta(x))_i&#x3D;i^{th}\\ output\\)</p>\n<p>这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出K个预测，基本上我们可以利用循环，对每一行特征都预测K个不同结果，然后在利用循环在K个预测中选择可能性最高的一个，将其与y中的实际数据进行比较。</p>\n<p>正则化那一项只是排除了每一层的\\(\\theta_0\\)后，每一层的\\(\\theta\\)矩阵的和。</p>\n<h1 id=\"反向传播算法-Backpropagation-algorithm\"><a href=\"#反向传播算法-Backpropagation-algorithm\" class=\"headerlink\" title=\"反向传播算法(Backpropagation algorithm)\"></a>反向传播算法(Backpropagation algorithm)</h1><p>之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法，我们从第一层开始正向一层一层进行计算，直到最后一层的\\(h_\\theta(x)\\)。</p>\n<p>现在为了计算代价函数的偏导数\\(\\frac{\\partial}{\\partial\\Theta_{ij}^{(l)}}J(\\Theta)\\)，我们需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。 </p>\n<p>在不做任何正则化处理时：<br>$$<br>\\frac{\\partial}{\\partial\\Theta_{ij}^{(l)}}J(\\Theta)&#x3D;a_j^{(l)}\\delta_i^{l+1}<br>$$<br>\\(l\\)代表目前所计算的是第几层。</p>\n<p>\\(j\\)代表目前计算层中的激活单元的下标。</p>\n<p>\\(i\\)代表下一层中误差单元的下标。</p>\n<p>如果我们考虑正则化处理，并且我们的训练集是一个特征矩阵而非向量，我们需要计算每一层的误差单元来计算代价函数的偏导数。我们用\\(\\Delta_{ij}^{(l)}\\)来表示这个误差矩阵。</p>\n<p>假设我们有m个训练集，利用反向传播来计算\\(\\Delta_{ij}^{(l)}\\)的算法如下：</p>\n<p><img src=\"/../images/NeuralNetwork_2.jpg\" alt=\"NeuralNetwork_2\"></p>\n<p>在求出了\\(\\Delta_{ij}^{(l)}\\)之后，我们便可以计算代价函数的偏导数了，计算方法如下： </p>\n<p>\\(D_{ij}^{(l)}\\ :&#x3D;\\ \\frac{1}{m}\\Delta_{ij}^{(l)} + \\frac{\\lambda}{m}\\Theta_{ij}^{(l)}\\) \\(\\ \\ \\ \\ \\ \\ \\ \\  if\\ \\ \\ j\\neq 0\\) </p>\n<p>\\(D_{ij}^{(l)}\\ :&#x3D;\\ \\frac{1}{m}\\Delta_{ij}^{(l)}\\) \\(\\ \\ \\ \\ \\ \\ \\ \\  if\\ \\ \\ j&#x3D; 0\\) </p>\n<h1 id=\"展开参数\"><a href=\"#展开参数\" class=\"headerlink\" title=\"展开参数\"></a>展开参数</h1><p>在Octave 中，如果我们要使用fminuc这样的优化算法来求解求出权重矩阵，我们需要将矩阵首先展开成为向量，在利用算法求出最优解后再重新转换回矩阵。</p>\n<p>假设我们有三个权重矩阵，Theta1，Theta2 和 Theta3，尺寸分别为 10*11，10*11 和1*11， 下面的代码可以实现这样的转换：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">thetaVec = [Theta1(:) ; Theta2(:) ; Theta3(:)]</span><br><span class=\"line\"></span><br><span class=\"line\">...optimization using functions like fminuc...</span><br><span class=\"line\"></span><br><span class=\"line\">Theta1 = reshape(thetaVec(1:110, 10, 11);</span><br><span class=\"line\"></span><br><span class=\"line\">Theta2 = reshape(thetaVec(111:220, 10, 11);</span><br><span class=\"line\"></span><br><span class=\"line\">Theta1 = reshape(thetaVec(221:231, 1, 11);</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"梯度检验\"><a href=\"#梯度检验\" class=\"headerlink\" title=\"梯度检验\"></a>梯度检验</h1><p>当我们对一个较为复杂的模型（例如神经网络）使用梯度下降算法时，可能会存在一些不容易察觉的错误，意味着，虽然代价看上去在不断减小，但最终的结果可能并不是最优解。</p>\n<p>为了避免这样的问题，我们采取一种叫做梯度的数值检验（Numerical Gradient Checking）方法。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的。</p>\n<p>对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点然后计算两个点的平均值用以估计梯度。即对于某个特定的\\(\\theta\\)，我们计算出在\\(\\theta-\\epsilon\\)处和\\(\\theta+\\epsilon\\)的代价值\\((\\epsilon\\)是一个非常小的值，通常选取 0.001），然后求两个代价的平均，用以估计在\\(\\theta\\)处的代价值。</p>\n<p><img src=\"/../images/NeuralNetwork_3.jpg\" alt=\"NeuralNetwork_3\"></p>\n<p>Octave 中代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">gradApprox = (J(theta + eps) – J(theta - eps)) / (2*eps)</span><br></pre></td></tr></table></figure>\n<p>当\\(\\theta\\)是一个向量时，我们则需要对偏导数进行检验。因为代价函数的偏导数检验只针对一个参数的改变进行检验，下面是一个只针对\\(\\theta_1\\)进行检验的示例:\\(\\frac{\\partial}{\\partial\\theta_1}&#x3D;\\frac{J(\\theta_1+\\epsilon_1,\\theta_2,\\theta_3…\\theta_n)-J(\\theta_1-\\epsilon_1,\\theta_2,\\theta_3…\\theta_n)}{2\\epsilon}\\)</p>\n<p>代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">for i = 1:n</span><br><span class=\"line\">  thetaPlus = theta;</span><br><span class=\"line\">  thetaPlus(i) = thetaPlus(i) + EPSILON;</span><br><span class=\"line\">  thetaMinus = theta;</span><br><span class=\"line\">  thetaMinus(i) = thetaMinus(i) - EPSILON;</span><br><span class=\"line\">  gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*EPSILON);</span><br><span class=\"line\">end;</span><br></pre></td></tr></table></figure>\n\n<p>我们需要将通过反向传播计算出的偏导数\\(D_{ij}^{(l)}\\)转换成向量DVec，然后与gradApprox进行比较。</p>\n<h1 id=\"随机初始化\"><a href=\"#随机初始化\" class=\"headerlink\" title=\"随机初始化\"></a>随机初始化</h1><p>任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为0，这样的初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。如果我们令所有的初始参数都为0，这将意味着我们第二层的所有激活单元都会有相同的值。同理，如果我们初始所有的参数都为一个非0的数，结果也是一样的。</p>\n<p>我们通常初始参数为正负ε之间的随机值，假设我们要随机初始一个尺寸为10×11的参数矩阵，代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Theta1 = rand(10, 11) * (2*eps) - eps</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"综合起来\"><a href=\"#综合起来\" class=\"headerlink\" title=\"综合起来\"></a>综合起来</h1><p>小结一下使用神经网络时的步骤：</p>\n<ul>\n<li><p>网络结构：第一件要做的事是选择网络结构，即决定选择多少层以及决定每层分别有多少个单元。</p>\n</li>\n<li><p>第一层的单元数即我们训练集的特征数量。</p>\n</li>\n<li><p>最后一层的单元数是我们训练集的结果的类的数量。</p>\n</li>\n<li><p>如果隐藏层数大于1，确保每个隐藏层的单元个数相同，通常情况下隐藏层单元的个数越多越好。</p>\n</li>\n<li><p>我们真正要决定的是隐藏层的层数和每个中间层的单元数。</p>\n</li>\n</ul>\n<p>训练神经网络：</p>\n<ul>\n<li><p>参数的随机初始化</p>\n</li>\n<li><p>利用正向传播方法计算所有的\\(h_\\theta(x)\\)</p>\n</li>\n<li><p>编写计算代价函数J的代码</p>\n</li>\n<li><p>利用反向传播方法计算所有偏导数</p>\n</li>\n<li><p>利用数值检验方法检验这些偏导数</p>\n</li>\n<li><p>使用优化算法来最小化代价函数</p>\n</li>\n</ul>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-12-exercise 4 summary","url":"/2022/08/26/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-12/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 12-exercise 4 summary。</p>\n<span id=\"more\"></span>\n<p><strong>Programming Exercise 4: Neural Networks Learning</strong></p>\n<p>In this exercise, you will implement the backpropagation algorithm for neural networks and apply it to the task of hand-written digit recognition.</p>\n<h1 id=\"ex4-m\"><a href=\"#ex4-m\" class=\"headerlink\" title=\"ex4.m\"></a>ex4.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class - Exercise 4 Neural Network Learning</span><br><span class=\"line\"></span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">% </span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  linear exercise. You will need to complete the following functions </span><br><span class=\"line\">%  in this exericse:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     sigmoidGradient.m</span><br><span class=\"line\">%     randInitializeWeights.m</span><br><span class=\"line\">%     nnCostFunction.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% Setup the parameters you will use for this exercise</span><br><span class=\"line\">input_layer_size  = 400;  % 20x20 Input Images of Digits</span><br><span class=\"line\">hidden_layer_size = 25;   % 25 hidden units</span><br><span class=\"line\">num_labels = 10;          % 10 labels, from 1 to 10   </span><br><span class=\"line\">                          % (note that we have mapped &quot;0&quot; to label 10)</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 1: Loading and Visualizing Data =============</span><br><span class=\"line\">%  We start the exercise by first loading and visualizing the dataset. </span><br><span class=\"line\">%  You will be working with a dataset that contains handwritten digits.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Load Training Data</span><br><span class=\"line\">fprintf(&#x27;Loading and Visualizing Data ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">load(&#x27;ex4data1.mat&#x27;);</span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Randomly select 100 data points to display</span><br><span class=\"line\">sel = randperm(size(X, 1));</span><br><span class=\"line\">sel = sel(1:100);</span><br><span class=\"line\"></span><br><span class=\"line\">displayData(X(sel, :));</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================ Part 2: Loading Parameters ================</span><br><span class=\"line\">% In this part of the exercise, we load some pre-initialized </span><br><span class=\"line\">% neural network parameters.</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nLoading Saved Neural Network Parameters ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Load the weights into variables Theta1 and Theta2</span><br><span class=\"line\">load(&#x27;ex4weights.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Unroll parameters </span><br><span class=\"line\">nn_params = [Theta1(:) ; Theta2(:)];</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================ Part 3: Compute Cost (Feedforward) ================</span><br><span class=\"line\">%  To the neural network, you should first start by implementing the</span><br><span class=\"line\">%  feedforward part of the neural network that returns the cost only. You</span><br><span class=\"line\">%  should complete the code in nnCostFunction.m to return cost. After</span><br><span class=\"line\">%  implementing the feedforward to compute the cost, you can verify that</span><br><span class=\"line\">%  your implementation is correct by verifying that you get the same cost</span><br><span class=\"line\">%  as us for the fixed debugging parameters.</span><br><span class=\"line\">%</span><br><span class=\"line\">%  We suggest implementing the feedforward cost *without* regularization</span><br><span class=\"line\">%  first so that it will be easier for you to debug. Later, in part 4, you</span><br><span class=\"line\">%  will get to implement the regularized cost.</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;\\nFeedforward Using Neural Network ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Weight regularization parameter (we set this to 0 here).</span><br><span class=\"line\">lambda = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">J = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, ...</span><br><span class=\"line\">                   num_labels, X, y, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;Cost at parameters (loaded from ex4weights): %f &#x27;...</span><br><span class=\"line\">         &#x27;\\n(this value should be about 0.287629)\\n&#x27;], J);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 4: Implement Regularization ===============</span><br><span class=\"line\">%  Once your cost function implementation is correct, you should now</span><br><span class=\"line\">%  continue to implement the regularization with the cost.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nChecking Cost Function (w/ Regularization) ... \\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Weight regularization parameter (we set this to 1 here).</span><br><span class=\"line\">lambda = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">J = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, ...</span><br><span class=\"line\">                   num_labels, X, y, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;Cost at parameters (loaded from ex4weights): %f &#x27;...</span><br><span class=\"line\">         &#x27;\\n(this value should be about 0.383770)\\n&#x27;], J);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================ Part 5: Sigmoid Gradient  ================</span><br><span class=\"line\">%  Before you start implementing the neural network, you will first</span><br><span class=\"line\">%  implement the gradient for the sigmoid function. You should complete the</span><br><span class=\"line\">%  code in the sigmoidGradient.m file.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nEvaluating sigmoid gradient...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">g = sigmoidGradient([-1 -0.5 0 0.5 1]);</span><br><span class=\"line\">fprintf(&#x27;Sigmoid gradient evaluated at [-1 -0.5 0 0.5 1]:\\n  &#x27;);</span><br><span class=\"line\">fprintf(&#x27;%f &#x27;, g);</span><br><span class=\"line\">fprintf(&#x27;\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================ Part 6: Initializing Pameters ================</span><br><span class=\"line\">%  In this part of the exercise, you will be starting to implment a two</span><br><span class=\"line\">%  layer neural network that classifies digits. You will start by</span><br><span class=\"line\">%  implementing a function to initialize the weights of the neural network</span><br><span class=\"line\">%  (randInitializeWeights.m)</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nInitializing Neural Network Parameters ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size);</span><br><span class=\"line\">initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels);</span><br><span class=\"line\"></span><br><span class=\"line\">% Unroll parameters</span><br><span class=\"line\">initial_nn_params = [initial_Theta1(:) ; initial_Theta2(:)];</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 7: Implement Backpropagation ===============</span><br><span class=\"line\">%  Once your cost matches up with ours, you should proceed to implement the</span><br><span class=\"line\">%  backpropagation algorithm for the neural network. You should add to the</span><br><span class=\"line\">%  code you&#x27;ve written in nnCostFunction.m to return the partial</span><br><span class=\"line\">%  derivatives of the parameters.</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;\\nChecking Backpropagation... \\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Check gradients by running checkNNGradients</span><br><span class=\"line\">checkNNGradients;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 8: Implement Regularization ===============</span><br><span class=\"line\">%  Once your backpropagation implementation is correct, you should now</span><br><span class=\"line\">%  continue to implement the regularization with the cost and gradient.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nChecking Backpropagation (w/ Regularization) ... \\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">%  Check gradients by running checkNNGradients</span><br><span class=\"line\">lambda = 3;</span><br><span class=\"line\">checkNNGradients(lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">% Also output the costFunction debugging values</span><br><span class=\"line\">debug_J  = nnCostFunction(nn_params, input_layer_size, ...</span><br><span class=\"line\">                          hidden_layer_size, num_labels, X, y, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;\\n\\nCost at (fixed) debugging parameters (w/ lambda = %f): %f &#x27; ...</span><br><span class=\"line\">         &#x27;\\n(for lambda = 3, this value should be about 0.576051)\\n\\n&#x27;], lambda, debug_J);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =================== Part 8: Training NN ===================</span><br><span class=\"line\">%  You have now implemented all the code necessary to train a neural </span><br><span class=\"line\">%  network. To train your neural network, we will now use &quot;fmincg&quot;, which</span><br><span class=\"line\">%  is a function which works similarly to &quot;fminunc&quot;. Recall that these</span><br><span class=\"line\">%  advanced optimizers are able to train our cost functions efficiently as</span><br><span class=\"line\">%  long as we provide them with the gradient computations.</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;\\nTraining Neural Network... \\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">%  After you have completed the assignment, change the MaxIter to a larger</span><br><span class=\"line\">%  value to see how more training helps.</span><br><span class=\"line\">options = optimset(&#x27;MaxIter&#x27;, 50);</span><br><span class=\"line\"></span><br><span class=\"line\">%  You should also try different values of lambda</span><br><span class=\"line\">lambda = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">% Create &quot;short hand&quot; for the cost function to be minimized</span><br><span class=\"line\">costFunction = @(p) nnCostFunction(p, ...</span><br><span class=\"line\">                                   input_layer_size, ...</span><br><span class=\"line\">                                   hidden_layer_size, ...</span><br><span class=\"line\">                                   num_labels, X, y, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">% Now, costFunction is a function that takes in only one argument (the</span><br><span class=\"line\">% neural network parameters)</span><br><span class=\"line\">[nn_params, cost] = fmincg(costFunction, initial_nn_params, options);</span><br><span class=\"line\"></span><br><span class=\"line\">% Obtain Theta1 and Theta2 back from nn_params</span><br><span class=\"line\">Theta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)), ...</span><br><span class=\"line\">                 hidden_layer_size, (input_layer_size + 1));</span><br><span class=\"line\"></span><br><span class=\"line\">Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end), ...</span><br><span class=\"line\">                 num_labels, (hidden_layer_size + 1));</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================= Part 9: Visualize Weights =================</span><br><span class=\"line\">%  You can now &quot;visualize&quot; what the neural network is learning by </span><br><span class=\"line\">%  displaying the hidden units to see what features they are capturing in </span><br><span class=\"line\">%  the data.</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nVisualizing Neural Network... \\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">displayData(Theta1(:, 2:end));</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================= Part 10: Implement Predict =================</span><br><span class=\"line\">%  After training the neural network, we would like to use it to predict</span><br><span class=\"line\">%  the labels. You will now implement the &quot;predict&quot; function to use the</span><br><span class=\"line\">%  neural network to predict the labels of the training set. This lets</span><br><span class=\"line\">%  you compute the training set accuracy.</span><br><span class=\"line\"></span><br><span class=\"line\">pred = predict(Theta1, Theta2, X);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nTraining Set Accuracy: %f\\n&#x27;, mean(double(pred == y)) * 100);</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"displayData-m\"><a href=\"#displayData-m\" class=\"headerlink\" title=\"displayData.m\"></a>displayData.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [h, display_array] = displayData(X, example_width)</span><br><span class=\"line\">%DISPLAYDATA Display 2D data in a nice grid</span><br><span class=\"line\">%   [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data</span><br><span class=\"line\">%   stored in X in a nice grid. It returns the figure handle h and the </span><br><span class=\"line\">%   displayed array if requested.</span><br><span class=\"line\"></span><br><span class=\"line\">% Set example_width automatically if not passed in</span><br><span class=\"line\">if ~exist(&#x27;example_width&#x27;, &#x27;var&#x27;) || isempty(example_width) </span><br><span class=\"line\">  example_width = round(sqrt(size(X, 2)));</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Gray Image</span><br><span class=\"line\">colormap(gray);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute rows, cols</span><br><span class=\"line\">[m n] = size(X);</span><br><span class=\"line\">example_height = (n / example_width);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute number of items to display</span><br><span class=\"line\">display_rows = floor(sqrt(m));</span><br><span class=\"line\">display_cols = ceil(m / display_rows);</span><br><span class=\"line\"></span><br><span class=\"line\">% Between images padding</span><br><span class=\"line\">pad = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">% Setup blank display</span><br><span class=\"line\">display_array = - ones(pad + display_rows * (example_height + pad), ...</span><br><span class=\"line\">                       pad + display_cols * (example_width + pad));</span><br><span class=\"line\"></span><br><span class=\"line\">% Copy each example into a patch on the display array</span><br><span class=\"line\">curr_ex = 1;</span><br><span class=\"line\">for j = 1:display_rows</span><br><span class=\"line\">  for i = 1:display_cols</span><br><span class=\"line\">    if curr_ex &gt; m, </span><br><span class=\"line\">      break; </span><br><span class=\"line\">    end</span><br><span class=\"line\">    % Copy the patch</span><br><span class=\"line\">    </span><br><span class=\"line\">    % Get the max value of the patch</span><br><span class=\"line\">    max_val = max(abs(X(curr_ex, :)));</span><br><span class=\"line\">    display_array(pad + (j - 1) * (example_height + pad) + (1:example_height), ...</span><br><span class=\"line\">                  pad + (i - 1) * (example_width + pad) + (1:example_width)) = ...</span><br><span class=\"line\">            reshape(X(curr_ex, :), example_height, example_width) / max_val;</span><br><span class=\"line\">    curr_ex = curr_ex + 1;</span><br><span class=\"line\">  end</span><br><span class=\"line\">  if curr_ex &gt; m, </span><br><span class=\"line\">    break; </span><br><span class=\"line\">  end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Display Image</span><br><span class=\"line\">h = imagesc(display_array, [-1 1]);</span><br><span class=\"line\"></span><br><span class=\"line\">% Do not show axis</span><br><span class=\"line\">axis image off</span><br><span class=\"line\"></span><br><span class=\"line\">drawnow;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"nnCostFunction-m\"><a href=\"#nnCostFunction-m\" class=\"headerlink\" title=\"nnCostFunction.m\"></a>nnCostFunction.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [J grad] = nnCostFunction(nn_params, ...</span><br><span class=\"line\">                                   input_layer_size, ...</span><br><span class=\"line\">                                   hidden_layer_size, ...</span><br><span class=\"line\">                                   num_labels, ...</span><br><span class=\"line\">                                   X, y, lambda)</span><br><span class=\"line\">%NNCOSTFUNCTION Implements the neural network cost function for a two layer</span><br><span class=\"line\">%neural network which performs classification</span><br><span class=\"line\">%   [J grad] = NNCOSTFUNCTON(nn_params, hidden_layer_size, num_labels, ...</span><br><span class=\"line\">%   X, y, lambda) computes the cost and gradient of the neural network. The</span><br><span class=\"line\">%   parameters for the neural network are &quot;unrolled&quot; into the vector</span><br><span class=\"line\">%   nn_params and need to be converted back into the weight matrices. </span><br><span class=\"line\">% </span><br><span class=\"line\">%   The returned parameter grad should be a &quot;unrolled&quot; vector of the</span><br><span class=\"line\">%   partial derivatives of the neural network.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices</span><br><span class=\"line\">% for our 2 layer neural network</span><br><span class=\"line\">Theta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)), ...</span><br><span class=\"line\">                 hidden_layer_size, (input_layer_size + 1));</span><br><span class=\"line\"></span><br><span class=\"line\">Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end), ...</span><br><span class=\"line\">                 num_labels, (hidden_layer_size + 1));</span><br><span class=\"line\"></span><br><span class=\"line\">% Setup some useful variables</span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\">         </span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">J = 0;</span><br><span class=\"line\">Theta1_grad = zeros(size(Theta1));</span><br><span class=\"line\">Theta2_grad = zeros(size(Theta2));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: You should complete the code by working through the</span><br><span class=\"line\">%               following parts.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Part 1: Feedforward the neural network and return the cost in the</span><br><span class=\"line\">%         variable J. After implementing Part 1, you can verify that your</span><br><span class=\"line\">%         cost function computation is correct by verifying the cost</span><br><span class=\"line\">%         computed in ex4.m</span><br><span class=\"line\">%</span><br><span class=\"line\">% Part 2: Implement the backpropagation algorithm to compute the gradients</span><br><span class=\"line\">%         Theta1_grad and Theta2_grad. You should return the partial derivatives of</span><br><span class=\"line\">%         the cost function with respect to Theta1 and Theta2 in Theta1_grad and</span><br><span class=\"line\">%         Theta2_grad, respectively. After implementing Part 2, you can check</span><br><span class=\"line\">%         that your implementation is correct by running checkNNGradients</span><br><span class=\"line\">%</span><br><span class=\"line\">%         Note: The vector y passed into the function is a vector of labels</span><br><span class=\"line\">%               containing values from 1..K. You need to map this vector into a </span><br><span class=\"line\">%               binary vector of 1&#x27;s and 0&#x27;s to be used with the neural network</span><br><span class=\"line\">%               cost function.</span><br><span class=\"line\">%</span><br><span class=\"line\">%         Hint: We recommend implementing backpropagation using a for-loop</span><br><span class=\"line\">%               over the training examples if you are implementing it for the </span><br><span class=\"line\">%               first time.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Part 3: Implement regularization with the cost function and gradients.</span><br><span class=\"line\">%</span><br><span class=\"line\">%         Hint: You can implement this around the code for</span><br><span class=\"line\">%               backpropagation. That is, you can compute the gradients for</span><br><span class=\"line\">%               the regularization separately and then add them to Theta1_grad</span><br><span class=\"line\">%               and Theta2_grad from Part 2.</span><br><span class=\"line\">%</span><br><span class=\"line\">K = num_labels;</span><br><span class=\"line\"></span><br><span class=\"line\">Y = zeros(m,num_labels);</span><br><span class=\"line\"></span><br><span class=\"line\">for i = 1:m</span><br><span class=\"line\">    Y(i,y(i)) = 1;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">a1 = [ones(m,1), X]</span><br><span class=\"line\"></span><br><span class=\"line\">z2 = a1*Theta1&#x27;;</span><br><span class=\"line\">a2 = sigmoid(z2);</span><br><span class=\"line\">a2 = [ones(size(a2,1),1), a2];</span><br><span class=\"line\"></span><br><span class=\"line\">z3 = a2*Theta2&#x27;;</span><br><span class=\"line\">a3 = sigmoid(z3);</span><br><span class=\"line\"></span><br><span class=\"line\">cost = sum((-Y.*log(a3))-((1-Y).*log(1-a3)), 2);</span><br><span class=\"line\">J = 1/m*sum(cost);</span><br><span class=\"line\"></span><br><span class=\"line\">Theta1NoBias = Theta1(:, 2:end);</span><br><span class=\"line\">Theta2NoBias = Theta2(:, 2:end);</span><br><span class=\"line\"></span><br><span class=\"line\">reg = (lambda/(2*m))*(sum(sumsq(Theta1NoBias))+sum(sumsq(Theta2NoBias)));</span><br><span class=\"line\"></span><br><span class=\"line\">J = J + reg;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% -------------------------------------------------------------</span><br><span class=\"line\">% Compute gradients using back propagation</span><br><span class=\"line\"></span><br><span class=\"line\">Delta1 = 0;</span><br><span class=\"line\">Delta2 = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">for t = 1:m</span><br><span class=\"line\">    a_1 = X(t,:)&#x27;;</span><br><span class=\"line\">    a_1 = [1; a_1];</span><br><span class=\"line\"></span><br><span class=\"line\">    z_2 = Theta1* a_1;</span><br><span class=\"line\"></span><br><span class=\"line\">    a_2 = sigmoid(z_2);</span><br><span class=\"line\">    a_2 = [1; a_2];</span><br><span class=\"line\"></span><br><span class=\"line\">    z_3 = Theta2* a_2;</span><br><span class=\"line\"></span><br><span class=\"line\">    a_3 = sigmoid(z_3);</span><br><span class=\"line\"></span><br><span class=\"line\">    % Delta Output layer</span><br><span class=\"line\">    d_3 = a_3 - Y(t,:)&#x27;;</span><br><span class=\"line\"></span><br><span class=\"line\">    % Delta Hidden layer</span><br><span class=\"line\">    d_2 = (Theta2NoBias&#x27;*d_3).*sigmoidGradient(z_2);</span><br><span class=\"line\"></span><br><span class=\"line\">    % Accumulate</span><br><span class=\"line\"></span><br><span class=\"line\">    Delta2 = Delta2+(d_3*a_2&#x27;);</span><br><span class=\"line\">    Delta1 = Delta1+(d_2*a_1&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">Theta1_grad = (1/m)*Delta1;</span><br><span class=\"line\">Theta2_grad = (1/m)*Delta2;</span><br><span class=\"line\"></span><br><span class=\"line\">Theta1_grad(:, 2:end) = Theta1_grad(:, 2:end) + ((lambda/m)*Theta1NoBias);</span><br><span class=\"line\"></span><br><span class=\"line\">Theta2_grad(:, 2:end) = Theta2_grad(:, 2:end) + ((lambda/m)*Theta2NoBias);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% -------------------------------------------------------------</span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">% Unroll gradients</span><br><span class=\"line\">grad = [Theta1_grad(:) ; Theta2_grad(:)];</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"computeNumericalGradient-m\"><a href=\"#computeNumericalGradient-m\" class=\"headerlink\" title=\"computeNumericalGradient.m\"></a>computeNumericalGradient.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function numgrad = computeNumericalGradient(J, theta)</span><br><span class=\"line\">%COMPUTENUMERICALGRADIENT Computes the gradient using &quot;finite differences&quot;</span><br><span class=\"line\">%and gives us a numerical estimate of the gradient.</span><br><span class=\"line\">%   numgrad = COMPUTENUMERICALGRADIENT(J, theta) computes the numerical</span><br><span class=\"line\">%   gradient of the function J around theta. Calling y = J(theta) should</span><br><span class=\"line\">%   return the function value at theta.</span><br><span class=\"line\"></span><br><span class=\"line\">% Notes: The following code implements numerical gradient checking, and </span><br><span class=\"line\">%        returns the numerical gradient.It sets numgrad(i) to (a numerical </span><br><span class=\"line\">%        approximation of) the partial derivative of J with respect to the </span><br><span class=\"line\">%        i-th input argument, evaluated at theta. (i.e., numgrad(i) should </span><br><span class=\"line\">%        be the (approximately) the partial derivative of J with respect </span><br><span class=\"line\">%        to theta(i).)</span><br><span class=\"line\">%                </span><br><span class=\"line\"></span><br><span class=\"line\">numgrad = zeros(size(theta));</span><br><span class=\"line\">perturb = zeros(size(theta));</span><br><span class=\"line\">e = 1e-4;</span><br><span class=\"line\">for p = 1:numel(theta)</span><br><span class=\"line\">    % Set perturbation vector</span><br><span class=\"line\">    perturb(p) = e;</span><br><span class=\"line\">    loss1 = J(theta - perturb);</span><br><span class=\"line\">    loss2 = J(theta + perturb);</span><br><span class=\"line\">    % Compute Numerical Gradient</span><br><span class=\"line\">    numgrad(p) = (loss2 - loss1) / (2*e);</span><br><span class=\"line\">    perturb(p) = 0;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"checkNNGradients-m\"><a href=\"#checkNNGradients-m\" class=\"headerlink\" title=\"checkNNGradients.m\"></a>checkNNGradients.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function checkNNGradients(lambda)</span><br><span class=\"line\">%CHECKNNGRADIENTS Creates a small neural network to check the</span><br><span class=\"line\">%backpropagation gradients</span><br><span class=\"line\">%   CHECKNNGRADIENTS(lambda) Creates a small neural network to check the</span><br><span class=\"line\">%   backpropagation gradients, it will output the analytical gradients</span><br><span class=\"line\">%   produced by your backprop code and the numerical gradients (computed</span><br><span class=\"line\">%   using computeNumericalGradient). These two gradient computations should</span><br><span class=\"line\">%   result in very similar values.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">if ~exist(&#x27;lambda&#x27;, &#x27;var&#x27;) || isempty(lambda)</span><br><span class=\"line\">    lambda = 0;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">input_layer_size = 3;</span><br><span class=\"line\">hidden_layer_size = 5;</span><br><span class=\"line\">num_labels = 3;</span><br><span class=\"line\">m = 5;</span><br><span class=\"line\"></span><br><span class=\"line\">% We generate some &#x27;random&#x27; test data</span><br><span class=\"line\">Theta1 = debugInitializeWeights(hidden_layer_size, input_layer_size);</span><br><span class=\"line\">Theta2 = debugInitializeWeights(num_labels, hidden_layer_size);</span><br><span class=\"line\">% Reusing debugInitializeWeights to generate X</span><br><span class=\"line\">X  = debugInitializeWeights(m, input_layer_size - 1);</span><br><span class=\"line\">y  = 1 + mod(1:m, num_labels)&#x27;;</span><br><span class=\"line\"></span><br><span class=\"line\">% Unroll parameters</span><br><span class=\"line\">nn_params = [Theta1(:) ; Theta2(:)];</span><br><span class=\"line\"></span><br><span class=\"line\">% Short hand for cost function</span><br><span class=\"line\">costFunc = @(p) nnCostFunction(p, input_layer_size, hidden_layer_size, ...</span><br><span class=\"line\">                               num_labels, X, y, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">[cost, grad] = costFunc(nn_params);</span><br><span class=\"line\">numgrad = computeNumericalGradient(costFunc, nn_params);</span><br><span class=\"line\"></span><br><span class=\"line\">% Visually examine the two gradient computations.  The two columns</span><br><span class=\"line\">% you get should be very similar. </span><br><span class=\"line\">disp([numgrad grad]);</span><br><span class=\"line\">fprintf([&#x27;The above two columns you get should be very similar.\\n&#x27; ...</span><br><span class=\"line\">         &#x27;(Left-Your Numerical Gradient, Right-Analytical Gradient)\\n\\n&#x27;]);</span><br><span class=\"line\"></span><br><span class=\"line\">% Evaluate the norm of the difference between two solutions.  </span><br><span class=\"line\">% If you have a correct implementation, and assuming you used EPSILON = 0.0001 </span><br><span class=\"line\">% in computeNumericalGradient.m, then diff below should be less than 1e-9</span><br><span class=\"line\">diff = norm(numgrad-grad)/norm(numgrad+grad);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;If your backpropagation implementation is correct, then \\n&#x27; ...</span><br><span class=\"line\">         &#x27;the relative difference will be small (less than 1e-9). \\n&#x27; ...</span><br><span class=\"line\">         &#x27;\\nRelative Difference: %g\\n&#x27;], diff);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"randInitializaWeights-m\"><a href=\"#randInitializaWeights-m\" class=\"headerlink\" title=\"randInitializaWeights.m\"></a>randInitializaWeights.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function W = randInitializeWeights(L_in, L_out)</span><br><span class=\"line\">%RANDINITIALIZEWEIGHTS Randomly initialize the weights of a layer with L_in</span><br><span class=\"line\">%incoming connections and L_out outgoing connections</span><br><span class=\"line\">%   W = RANDINITIALIZEWEIGHTS(L_in, L_out) randomly initializes the weights </span><br><span class=\"line\">%   of a layer with L_in incoming connections and L_out outgoing </span><br><span class=\"line\">%   connections. </span><br><span class=\"line\">%</span><br><span class=\"line\">%   Note that W should be set to a matrix of size(L_out, 1 + L_in) as</span><br><span class=\"line\">%   the first column of W handles the &quot;bias&quot; terms</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">W = zeros(L_out, 1 + L_in);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Initialize W randomly so that we break the symmetry while</span><br><span class=\"line\">%               training the neural network.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: The first column of W corresponds to the parameters for the bias unit</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">espilon_init = 0.12;</span><br><span class=\"line\">W = rand(L_out, 1 + L_in)*2*espilon_init - espilon_init;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"debugInitializaWeights-m\"><a href=\"#debugInitializaWeights-m\" class=\"headerlink\" title=\"debugInitializaWeights.m\"></a>debugInitializaWeights.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function W = debugInitializeWeights(fan_out, fan_in)</span><br><span class=\"line\">%DEBUGINITIALIZEWEIGHTS Initialize the weights of a layer with fan_in</span><br><span class=\"line\">%incoming connections and fan_out outgoing connections using a fixed</span><br><span class=\"line\">%strategy, this will help you later in debugging</span><br><span class=\"line\">%   W = DEBUGINITIALIZEWEIGHTS(fan_in, fan_out) initializes the weights </span><br><span class=\"line\">%   of a layer with fan_in incoming connections and fan_out outgoing </span><br><span class=\"line\">%   connections using a fix set of values</span><br><span class=\"line\">%</span><br><span class=\"line\">%   Note that W should be set to a matrix of size(1 + fan_in, fan_out) as</span><br><span class=\"line\">%   the first row of W handles the &quot;bias&quot; terms</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Set W to zeros</span><br><span class=\"line\">W = zeros(fan_out, 1 + fan_in);</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize W using &quot;sin&quot;, this ensures that W is always of the same</span><br><span class=\"line\">% values and will be useful for debugging</span><br><span class=\"line\">W = reshape(sin(1:numel(W)), size(W)) / 10;</span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"sigmoidGradient-m\"><a href=\"#sigmoidGradient-m\" class=\"headerlink\" title=\"sigmoidGradient.m\"></a>sigmoidGradient.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function g = sigmoidGradient(z)</span><br><span class=\"line\">%SIGMOIDGRADIENT returns the gradient of the sigmoid function</span><br><span class=\"line\">%evaluated at z</span><br><span class=\"line\">%   g = SIGMOIDGRADIENT(z) computes the gradient of the sigmoid function</span><br><span class=\"line\">%   evaluated at z. This should work regardless if z is a matrix or a</span><br><span class=\"line\">%   vector. In particular, if z is a vector or matrix, you should return</span><br><span class=\"line\">%   the gradient for each element.</span><br><span class=\"line\"></span><br><span class=\"line\">g = zeros(size(z));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the gradient of the sigmoid function evaluated at</span><br><span class=\"line\">%               each value of z (z can be a matrix, vector or scalar).</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">g = sigmoid(z).*(1-sigmoid(z));</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-14-exercise 5 summary","url":"/2022/08/29/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-14/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 14-exercise 5 summary。</p>\n<span id=\"more\"></span>\n\n<p><strong>Programming Exercise 5: Regularized Linear Regression and Bias v.s. Variance</strong></p>\n<p>In this exercise, you will implement regularized linear regression and use it to<br>study models with different bias-variance properties.</p>\n<h1 id=\"ex5-m\"><a href=\"#ex5-m\" class=\"headerlink\" title=\"ex5.m\"></a>ex5.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class</span><br><span class=\"line\">%  Exercise 5 | Regularized Linear Regression and Bias-Variance</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">% </span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  exercise. You will need to complete the following functions:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     linearRegCostFunction.m</span><br><span class=\"line\">%     learningCurve.m</span><br><span class=\"line\">%     validationCurve.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 1: Loading and Visualizing Data =============</span><br><span class=\"line\">%  We start the exercise by first loading and visualizing the dataset. </span><br><span class=\"line\">%  The following code will load the dataset into your environment and plot</span><br><span class=\"line\">%  the data.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Load Training Data</span><br><span class=\"line\">fprintf(&#x27;Loading and Visualizing Data ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Load from ex5data1: </span><br><span class=\"line\">% You will have X, y, Xval, yval, Xtest, ytest in your environment</span><br><span class=\"line\">load (&#x27;ex5data1.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% m = Number of examples</span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot training data</span><br><span class=\"line\">plot(X, y, &#x27;rx&#x27;, &#x27;MarkerSize&#x27;, 10, &#x27;LineWidth&#x27;, 1.5);</span><br><span class=\"line\">xlabel(&#x27;Change in water level (x)&#x27;);</span><br><span class=\"line\">ylabel(&#x27;Water flowing out of the dam (y)&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 2: Regularized Linear Regression Cost =============</span><br><span class=\"line\">%  You should now implement the cost function for regularized linear </span><br><span class=\"line\">%  regression. </span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">theta = [1 ; 1];</span><br><span class=\"line\">J = linearRegCostFunction([ones(m, 1) X], y, theta, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;Cost at theta = [1 ; 1]: %f &#x27;...</span><br><span class=\"line\">         &#x27;\\n(this value should be about 303.993192)\\n&#x27;], J);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 3: Regularized Linear Regression Gradient =============</span><br><span class=\"line\">%  You should now implement the gradient for regularized linear </span><br><span class=\"line\">%  regression.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">theta = [1 ; 1];</span><br><span class=\"line\">[J, grad] = linearRegCostFunction([ones(m, 1) X], y, theta, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;Gradient at theta = [1 ; 1]:  [%f; %f] &#x27;...</span><br><span class=\"line\">         &#x27;\\n(this value should be about [-15.303016; 598.250744])\\n&#x27;], ...</span><br><span class=\"line\">         grad(1), grad(2));</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 4: Train Linear Regression =============</span><br><span class=\"line\">%  Once you have implemented the cost and gradient correctly, the</span><br><span class=\"line\">%  trainLinearReg function will use your cost function to train </span><br><span class=\"line\">%  regularized linear regression.</span><br><span class=\"line\">% </span><br><span class=\"line\">%  Write Up Note: The data is non-linear, so this will not give a great </span><br><span class=\"line\">%                 fit.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%  Train linear regression with lambda = 0</span><br><span class=\"line\">lambda = 0;</span><br><span class=\"line\">[theta] = trainLinearReg([ones(m, 1) X], y, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Plot fit over the data</span><br><span class=\"line\">plot(X, y, &#x27;rx&#x27;, &#x27;MarkerSize&#x27;, 10, &#x27;LineWidth&#x27;, 1.5);</span><br><span class=\"line\">xlabel(&#x27;Change in water level (x)&#x27;);</span><br><span class=\"line\">ylabel(&#x27;Water flowing out of the dam (y)&#x27;);</span><br><span class=\"line\">hold on;</span><br><span class=\"line\">plot(X, [ones(m, 1) X]*theta, &#x27;--&#x27;, &#x27;LineWidth&#x27;, 2)</span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 5: Learning Curve for Linear Regression =============</span><br><span class=\"line\">%  Next, you should implement the learningCurve function. </span><br><span class=\"line\">%</span><br><span class=\"line\">%  Write Up Note: Since the model is underfitting the data, we expect to</span><br><span class=\"line\">%                 see a graph with &quot;high bias&quot; -- Figure 3 in ex5.pdf </span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">lambda = 0;</span><br><span class=\"line\">[error_train, error_val] = ...</span><br><span class=\"line\">    learningCurve([ones(m, 1) X], y, ...</span><br><span class=\"line\">                  [ones(size(Xval, 1), 1) Xval], yval, ...</span><br><span class=\"line\">                  lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">plot(1:m, error_train, 1:m, error_val);</span><br><span class=\"line\">title(&#x27;Learning curve for linear regression&#x27;)</span><br><span class=\"line\">legend(&#x27;Train&#x27;, &#x27;Cross Validation&#x27;)</span><br><span class=\"line\">xlabel(&#x27;Number of training examples&#x27;)</span><br><span class=\"line\">ylabel(&#x27;Error&#x27;)</span><br><span class=\"line\">axis([0 13 0 150])</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;# Training Examples\\tTrain Error\\tCross Validation Error\\n&#x27;);</span><br><span class=\"line\">for i = 1:m</span><br><span class=\"line\">    fprintf(&#x27;  \\t%d\\t\\t%f\\t%f\\n&#x27;, i, error_train(i), error_val(i));</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 6: Feature Mapping for Polynomial Regression =============</span><br><span class=\"line\">%  One solution to this is to use polynomial regression. You should now</span><br><span class=\"line\">%  complete polyFeatures to map each example into its powers</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">p = 8;</span><br><span class=\"line\"></span><br><span class=\"line\">% Map X onto Polynomial Features and Normalize</span><br><span class=\"line\">X_poly = polyFeatures(X, p);</span><br><span class=\"line\">[X_poly, mu, sigma] = featureNormalize(X_poly);  % Normalize</span><br><span class=\"line\">X_poly = [ones(m, 1), X_poly];                   % Add Ones</span><br><span class=\"line\"></span><br><span class=\"line\">% Map X_poly_test and normalize (using mu and sigma)</span><br><span class=\"line\">X_poly_test = polyFeatures(Xtest, p);</span><br><span class=\"line\">X_poly_test = bsxfun(@minus, X_poly_test, mu);</span><br><span class=\"line\">X_poly_test = bsxfun(@rdivide, X_poly_test, sigma);</span><br><span class=\"line\">X_poly_test = [ones(size(X_poly_test, 1), 1), X_poly_test];         % Add Ones</span><br><span class=\"line\"></span><br><span class=\"line\">% Map X_poly_val and normalize (using mu and sigma)</span><br><span class=\"line\">X_poly_val = polyFeatures(Xval, p);</span><br><span class=\"line\">X_poly_val = bsxfun(@minus, X_poly_val, mu);</span><br><span class=\"line\">X_poly_val = bsxfun(@rdivide, X_poly_val, sigma);</span><br><span class=\"line\">X_poly_val = [ones(size(X_poly_val, 1), 1), X_poly_val];           % Add Ones</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Normalized Training Example 1:\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;  %f  \\n&#x27;, X_poly(1, :));</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 7: Learning Curve for Polynomial Regression =============</span><br><span class=\"line\">%  Now, you will get to experiment with polynomial regression with multiple</span><br><span class=\"line\">%  values of lambda. The code below runs polynomial regression with </span><br><span class=\"line\">%  lambda = 0. You should try running the code with different values of</span><br><span class=\"line\">%  lambda to see how the fit and learning curve change.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">lambda = 0;</span><br><span class=\"line\">[theta] = trainLinearReg(X_poly, y, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot training data and fit</span><br><span class=\"line\">figure(1);</span><br><span class=\"line\">plot(X, y, &#x27;rx&#x27;, &#x27;MarkerSize&#x27;, 10, &#x27;LineWidth&#x27;, 1.5);</span><br><span class=\"line\">plotFit(min(X), max(X), mu, sigma, theta, p);</span><br><span class=\"line\">xlabel(&#x27;Change in water level (x)&#x27;);</span><br><span class=\"line\">ylabel(&#x27;Water flowing out of the dam (y)&#x27;);</span><br><span class=\"line\">title (sprintf(&#x27;Polynomial Regression Fit (lambda = %f)&#x27;, lambda));</span><br><span class=\"line\"></span><br><span class=\"line\">figure(2);</span><br><span class=\"line\">[error_train, error_val] = ...</span><br><span class=\"line\">    learningCurve(X_poly, y, X_poly_val, yval, lambda);</span><br><span class=\"line\">plot(1:m, error_train, 1:m, error_val);</span><br><span class=\"line\"></span><br><span class=\"line\">title(sprintf(&#x27;Polynomial Regression Learning Curve (lambda = %f)&#x27;, lambda));</span><br><span class=\"line\">xlabel(&#x27;Number of training examples&#x27;)</span><br><span class=\"line\">ylabel(&#x27;Error&#x27;)</span><br><span class=\"line\">axis([0 13 0 100])</span><br><span class=\"line\">legend(&#x27;Train&#x27;, &#x27;Cross Validation&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Polynomial Regression (lambda = %f)\\n\\n&#x27;, lambda);</span><br><span class=\"line\">fprintf(&#x27;# Training Examples\\tTrain Error\\tCross Validation Error\\n&#x27;);</span><br><span class=\"line\">for i = 1:m</span><br><span class=\"line\">    fprintf(&#x27;  \\t%d\\t\\t%f\\t%f\\n&#x27;, i, error_train(i), error_val(i));</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 8: Validation for Selecting Lambda =============</span><br><span class=\"line\">%  You will now implement validationCurve to test various values of </span><br><span class=\"line\">%  lambda on a validation set. You will then use this to select the</span><br><span class=\"line\">%  &quot;best&quot; lambda value.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">[lambda_vec, error_train, error_val] = ...</span><br><span class=\"line\">    validationCurve(X_poly, y, X_poly_val, yval);</span><br><span class=\"line\"></span><br><span class=\"line\">close all;</span><br><span class=\"line\">plot(lambda_vec, error_train, lambda_vec, error_val);</span><br><span class=\"line\">legend(&#x27;Train&#x27;, &#x27;Cross Validation&#x27;);</span><br><span class=\"line\">xlabel(&#x27;lambda&#x27;);</span><br><span class=\"line\">ylabel(&#x27;Error&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;lambda\\t\\tTrain Error\\tValidation Error\\n&#x27;);</span><br><span class=\"line\">for i = 1:length(lambda_vec)</span><br><span class=\"line\">  fprintf(&#x27; %f\\t%f\\t%f\\n&#x27;, ...</span><br><span class=\"line\">            lambda_vec(i), error_train(i), error_val(i));</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br></pre></td></tr></table></figure>\n<h1 id=\"featureNormalize-m\"><a href=\"#featureNormalize-m\" class=\"headerlink\" title=\"featureNormalize.m\"></a>featureNormalize.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [X_norm, mu, sigma] = featureNormalize(X)</span><br><span class=\"line\">%FEATURENORMALIZE Normalizes the features in X </span><br><span class=\"line\">%   FEATURENORMALIZE(X) returns a normalized version of X where</span><br><span class=\"line\">%   the mean value of each feature is 0 and the standard deviation</span><br><span class=\"line\">%   is 1. This is often a good preprocessing step to do when</span><br><span class=\"line\">%   working with learning algorithms.</span><br><span class=\"line\"></span><br><span class=\"line\">mu = mean(X);</span><br><span class=\"line\">X_norm = bsxfun(@minus, X, mu);</span><br><span class=\"line\"></span><br><span class=\"line\">sigma = std(X_norm);</span><br><span class=\"line\">X_norm = bsxfun(@rdivide, X_norm, sigma);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% ============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"learningCurve-m\"><a href=\"#learningCurve-m\" class=\"headerlink\" title=\"learningCurve.m\"></a>learningCurve.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [error_train, error_val] = ...</span><br><span class=\"line\">    learningCurve(X, y, Xval, yval, lambda)</span><br><span class=\"line\">%LEARNINGCURVE Generates the train and cross validation set errors needed </span><br><span class=\"line\">%to plot a learning curve</span><br><span class=\"line\">%   [error_train, error_val] = ...</span><br><span class=\"line\">%       LEARNINGCURVE(X, y, Xval, yval, lambda) returns the train and</span><br><span class=\"line\">%       cross validation set errors for a learning curve. In particular, </span><br><span class=\"line\">%       it returns two vectors of the same length - error_train and </span><br><span class=\"line\">%       error_val. Then, error_train(i) contains the training error for</span><br><span class=\"line\">%       i examples (and similarly for error_val(i)).</span><br><span class=\"line\">%</span><br><span class=\"line\">%   In this function, you will compute the train and test errors for</span><br><span class=\"line\">%   dataset sizes from 1 up to m. In practice, when working with larger</span><br><span class=\"line\">%   datasets, you might want to do this in larger intervals.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Number of training examples</span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return these values correctly</span><br><span class=\"line\">error_train = zeros(m, 1);</span><br><span class=\"line\">error_val   = zeros(m, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Fill in this function to return training errors in </span><br><span class=\"line\">%               error_train and the cross validation errors in error_val. </span><br><span class=\"line\">%               i.e., error_train(i) and </span><br><span class=\"line\">%               error_val(i) should give you the errors</span><br><span class=\"line\">%               obtained after training on i examples.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: You should evaluate the training error on the first i training</span><br><span class=\"line\">%       examples (i.e., X(1:i, :) and y(1:i)).</span><br><span class=\"line\">%</span><br><span class=\"line\">%       For the cross-validation error, you should instead evaluate on</span><br><span class=\"line\">%       the _entire_ cross validation set (Xval and yval).</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: If you are using your cost function (linearRegCostFunction)</span><br><span class=\"line\">%       to compute the training and cross validation error, you should </span><br><span class=\"line\">%       call the function with the lambda argument set to 0. </span><br><span class=\"line\">%       Do note that you will still need to use lambda when running</span><br><span class=\"line\">%       the training to obtain the theta parameters.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: You can loop over the examples with the following:</span><br><span class=\"line\">%</span><br><span class=\"line\">%       for i = 1:m</span><br><span class=\"line\">%           % Compute train/cross validation errors using training examples </span><br><span class=\"line\">%           % X(1:i, :) and y(1:i), storing the result in </span><br><span class=\"line\">%           % error_train(i) and error_val(i)</span><br><span class=\"line\">%           ....</span><br><span class=\"line\">%           </span><br><span class=\"line\">%       end</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% ---------------------- Sample Solution ----------------------</span><br><span class=\"line\"></span><br><span class=\"line\">for i = 1:m</span><br><span class=\"line\">    X_train = X(1:i, :);</span><br><span class=\"line\">    y_train = y(1:i, :);</span><br><span class=\"line\">    theta = trainLinearReg(X_train, y_train, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">    error_train(i) = linearRegCostFunction(X_train, y_train, theta, 0);</span><br><span class=\"line\">    error_val(i) = linearRegCostFunction(Xval, yval, theta, 0);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% -------------------------------------------------------------</span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"linearRegCostFunction-m\"><a href=\"#linearRegCostFunction-m\" class=\"headerlink\" title=\"linearRegCostFunction.m\"></a>linearRegCostFunction.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [J, grad] = linearRegCostFunction(X, y, theta, lambda)</span><br><span class=\"line\">%LINEARREGCOSTFUNCTION Compute cost and gradient for regularized linear </span><br><span class=\"line\">%regression with multiple variables</span><br><span class=\"line\">%   [J, grad] = LINEARREGCOSTFUNCTION(X, y, theta, lambda) computes the </span><br><span class=\"line\">%   cost of using theta as the parameter for linear regression to fit the </span><br><span class=\"line\">%   data points in X and y. Returns the cost in J and the gradient in grad</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize some useful values</span><br><span class=\"line\">m = length(y); % number of training examples</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">J = 0;</span><br><span class=\"line\">grad = zeros(size(theta));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the cost and gradient of regularized linear </span><br><span class=\"line\">%               regression for a particular choice of theta.</span><br><span class=\"line\">%</span><br><span class=\"line\">%               You should set J to the cost and grad to the gradient.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">h = X*theta;</span><br><span class=\"line\"></span><br><span class=\"line\">theta_reg = [0;theta(2:end, :);];</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">J = 1/(2*m)*(h-y)&#x27;*(h-y) + lambda/(2*m)*(theta_reg&#x27;*theta_reg);</span><br><span class=\"line\"></span><br><span class=\"line\">grad = X&#x27;*(h -y)/m + lambda/m*(theta_reg);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">grad = grad(:);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"plotFit-m\"><a href=\"#plotFit-m\" class=\"headerlink\" title=\"plotFit.m\"></a>plotFit.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function plotFit(min_x, max_x, mu, sigma, theta, p)</span><br><span class=\"line\">%PLOTFIT Plots a learned polynomial regression fit over an existing figure.</span><br><span class=\"line\">%Also works with linear regression.</span><br><span class=\"line\">%   PLOTFIT(min_x, max_x, mu, sigma, theta, p) plots the learned polynomial</span><br><span class=\"line\">%   fit with power p and feature normalization (mu, sigma).</span><br><span class=\"line\"></span><br><span class=\"line\">% Hold on to the current figure</span><br><span class=\"line\">hold on;</span><br><span class=\"line\"></span><br><span class=\"line\">% We plot a range slightly bigger than the min and max values to get</span><br><span class=\"line\">% an idea of how the fit will vary outside the range of the data points</span><br><span class=\"line\">x = (min_x - 15: 0.05 : max_x + 25)&#x27;;</span><br><span class=\"line\"></span><br><span class=\"line\">% Map the X values </span><br><span class=\"line\">X_poly = polyFeatures(x, p);</span><br><span class=\"line\">X_poly = bsxfun(@minus, X_poly, mu);</span><br><span class=\"line\">X_poly = bsxfun(@rdivide, X_poly, sigma);</span><br><span class=\"line\"></span><br><span class=\"line\">% Add ones</span><br><span class=\"line\">X_poly = [ones(size(x, 1), 1) X_poly];</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot</span><br><span class=\"line\">plot(x, X_poly * theta, &#x27;--&#x27;, &#x27;LineWidth&#x27;, 2)</span><br><span class=\"line\"></span><br><span class=\"line\">% Hold off to the current figure</span><br><span class=\"line\">hold off</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"polyFeatures-m\"><a href=\"#polyFeatures-m\" class=\"headerlink\" title=\"polyFeatures.m\"></a>polyFeatures.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [X_poly] = polyFeatures(X, p)</span><br><span class=\"line\">%POLYFEATURES Maps X (1D vector) into the p-th power</span><br><span class=\"line\">%   [X_poly] = POLYFEATURES(X, p) takes a data matrix X (size m x 1) and</span><br><span class=\"line\">%   maps each example into its polynomial features where</span><br><span class=\"line\">%   X_poly(i, :) = [X(i) X(i).^2 X(i).^3 ...  X(i).^p];</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly.</span><br><span class=\"line\">X_poly = zeros(numel(X), p);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Given a vector X, return a matrix X_poly where the p-th </span><br><span class=\"line\">%               column of X contains the values of X to the p-th power.</span><br><span class=\"line\">%</span><br><span class=\"line\">% </span><br><span class=\"line\"></span><br><span class=\"line\">X_poly(:,1) = X;</span><br><span class=\"line\"></span><br><span class=\"line\">for i = 2:p</span><br><span class=\"line\">  X_poly(:, i) = X.*X_poly(:,i-1);</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"trainLinearReg-m\"><a href=\"#trainLinearReg-m\" class=\"headerlink\" title=\"trainLinearReg.m\"></a>trainLinearReg.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [theta] = trainLinearReg(X, y, lambda)</span><br><span class=\"line\">%TRAINLINEARREG Trains linear regression given a dataset (X, y) and a</span><br><span class=\"line\">%regularization parameter lambda</span><br><span class=\"line\">%   [theta] = TRAINLINEARREG (X, y, lambda) trains linear regression using</span><br><span class=\"line\">%   the dataset (X, y) and regularization parameter lambda. Returns the</span><br><span class=\"line\">%   trained parameters theta.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize Theta</span><br><span class=\"line\">initial_theta = zeros(size(X, 2), 1); </span><br><span class=\"line\"></span><br><span class=\"line\">% Create &quot;short hand&quot; for the cost function to be minimized</span><br><span class=\"line\">costFunction = @(t) linearRegCostFunction(X, y, t, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">% Now, costFunction is a function that takes in only one argument</span><br><span class=\"line\">options = optimset(&#x27;MaxIter&#x27;, 200, &#x27;GradObj&#x27;, &#x27;on&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Minimize using fmincg</span><br><span class=\"line\">theta = fmincg(costFunction, initial_theta, options);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"validationCurve-m\"><a href=\"#validationCurve-m\" class=\"headerlink\" title=\"validationCurve.m\"></a>validationCurve.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [lambda_vec, error_train, error_val] = ...</span><br><span class=\"line\">    validationCurve(X, y, Xval, yval)</span><br><span class=\"line\">%VALIDATIONCURVE Generate the train and validation errors needed to</span><br><span class=\"line\">%plot a validation curve that we can use to select lambda</span><br><span class=\"line\">%   [lambda_vec, error_train, error_val] = ...</span><br><span class=\"line\">%       VALIDATIONCURVE(X, y, Xval, yval) returns the train</span><br><span class=\"line\">%       and validation errors (in error_train, error_val)</span><br><span class=\"line\">%       for different values of lambda. You are given the training set (X,</span><br><span class=\"line\">%       y) and validation set (Xval, yval).</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Selected values of lambda (you should not change this)</span><br><span class=\"line\">lambda_vec = [0 0.001 0.003 0.01 0.03 0.1 0.3 1 3 10]&#x27;;</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return these variables correctly.</span><br><span class=\"line\">error_train = zeros(length(lambda_vec), 1);</span><br><span class=\"line\">error_val = zeros(length(lambda_vec), 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Fill in this function to return training errors in </span><br><span class=\"line\">%               error_train and the validation errors in error_val. The </span><br><span class=\"line\">%               vector lambda_vec contains the different lambda parameters </span><br><span class=\"line\">%               to use for each calculation of the errors, i.e, </span><br><span class=\"line\">%               error_train(i), and error_val(i) should give </span><br><span class=\"line\">%               you the errors obtained after training with </span><br><span class=\"line\">%               lambda = lambda_vec(i)</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: You can loop over lambda_vec with the following:</span><br><span class=\"line\">%</span><br><span class=\"line\">%       for i = 1:length(lambda_vec)</span><br><span class=\"line\">%           lambda = lambda_vec(i);</span><br><span class=\"line\">%           % Compute train / val errors when training linear </span><br><span class=\"line\">%           % regression with regularization parameter lambda</span><br><span class=\"line\">%           % You should store the result in error_train(i)</span><br><span class=\"line\">%           % and error_val(i)</span><br><span class=\"line\">%           ....</span><br><span class=\"line\">%           </span><br><span class=\"line\">%       end</span><br><span class=\"line\">%</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">for i = 1:length(lambda_vec)</span><br><span class=\"line\">    lambda = lambda_vec(i);</span><br><span class=\"line\">    theta = trainLinearReg(X, y, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">    error_train(i) = linearRegCostFunction(X, y, theta, 0);</span><br><span class=\"line\">    error_val(i) = linearRegCostFunction(Xval, yval, theta, 0);</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-13-Advice for Applying Machine Learning","url":"/2022/08/29/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-13/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 13-应用机器学习的建议(Advice for Applying Machine Learning)。</p>\n<span id=\"more\"></span>\n\n<h1 id=\"决定下一步做什么\"><a href=\"#决定下一步做什么\" class=\"headerlink\" title=\"决定下一步做什么\"></a>决定下一步做什么</h1><p>当我们运用训练好了的模型来预测未知数据的时候发现有较大的误差，我们下一步可以做什么？</p>\n<ul>\n<li>获得更多的训练样本——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。</li>\n<li>尝试减少特征的数量</li>\n<li>尝试获得更多的特征</li>\n<li>尝试增加多项式特征</li>\n<li>尝试减少正则化程度\\(\\lambda\\)</li>\n<li>尝试增加正则化程度\\(\\lambda\\)</li>\n</ul>\n<p>我这这里将会讨论怎样评估机器学习算法的性能，它们也被称为”机器学习诊断法”。“诊断法”的意思是：这是一种测试法，你通过执行这种测试，能够深入了解某种算法到底是否有用。这通常也能够告诉你，要想改进一种算法的效果，什么样的尝试，才是有意义的。</p>\n<h2 id=\"评估一个假设\"><a href=\"#评估一个假设\" class=\"headerlink\" title=\"评估一个假设\"></a>评估一个假设</h2><p>你该如何判断一个假设函数是过拟合的呢？对于这个简单的例子，我们可以对假设函数\\(h(x)\\)进行画图，然后观察图形趋势，但对于特征变量不止一个的这种一般情况，还有像有很多特征变量的问题，想要通过画出假设函数来进行观察，就会变得很难甚至是不可能实现。 因此，我们需要另一种方法来评估我们的假设函数过拟合检验。 为了检验算法是否过拟合，我们将数据分成训练集和测试集，通常用70%的数据作为训练集，用剩下30%的数据作为测试集。很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行“洗牌”，然后再分成训练集和测试集。</p>\n<p><img src=\"/../images/evaluateHypothesis.png\" alt=\"evaluateHypothesis\"></p>\n<p>测试集评估在通过训练集让我们的模型学习得出其参数后，对测试集运用该模型，我们有两种方式计算误差：</p>\n<ol>\n<li>对于线性回归模型，我们利用测试集数据(Test set)计算代价函数J。<br>$$<br>J_{test}(\\theta) &#x3D; \\frac{1}{2m_{test}}\\sum_{i&#x3D;1}^{m_{test}}(h_{\\theta}(x_{text}^{(i)})-y_{test}^{(i)})^2<br>$$</li>\n<li>对于逻辑回归模型，我们也同样可以使用Test set来计算Cost function J:<br>$$<br>J_{test}(\\theta) &#x3D; -\\frac{1}{m_{test}}\\sum_{i&#x3D;1}^{m_{test}}(y_{test}^{(i)}log h_\\theta(x_{test}^{(i)})+(1-y_{test}^{(i)})log h_\\theta(x_{test}^{(i)}))<br>$$</li>\n</ol>\n<h2 id=\"模型选择和训练、交叉验证、测试集\"><a href=\"#模型选择和训练、交叉验证、测试集\" class=\"headerlink\" title=\"模型选择和训练、交叉验证、测试集\"></a>模型选择和训练、交叉验证、测试集</h2><p>假设我们要在10个不同次数的二项式模型之间进行选择：</p>\n<p><img src=\"/../images/modelSelection.jpg\" alt=\"modelSelection\"></p>\n<p>显然越高次数的多项式模型越能够适应我们的训练数据集，但是适应训练数据集并不代表着能推广至一般情况，我们应该选择一个更能适应一般情况的模型。我们需要使用交叉验证集来帮助选择模型。 即：使用60%的数据作为训练集，使用20%的数据作为交叉验证集，使用20%的数据作为测试集。</p>\n<p><img src=\"/../images/evaluateHypothesis_2.png\" alt=\"evaluateHypothesis_2\"></p>\n<p><strong>以上10个不同次数的二项式模型选择的方法为：</strong></p>\n<ol>\n<li>使用训练集训练出10个模型</li>\n<li>用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）</li>\n<li>选取代价函数值最小的模型</li>\n<li>用步骤3中选出的模型对测试集计算得出推广误差（代价函数的值）</li>\n</ol>\n<p><strong>Training error</strong></p>\n<p>$$<br>J_{train}(\\theta) &#x3D; \\frac{1}{2m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2<br>$$</p>\n<p><strong>Cross Validation error</strong></p>\n<p>$$<br>J_{cv}(\\theta) &#x3D; \\frac{1}{2m_{cv}}\\sum_{i&#x3D;1}^{m_{cv}}(h_\\theta(x_{cv}^{(i)})-y_{cv}^{(i)})^2<br>$$</p>\n<p><strong>Test error</strong></p>\n<p>$$<br>J_{test}(\\theta) &#x3D; \\frac{1}{2m_{test}}\\sum_{i&#x3D;1}^{m_{test}}(h_\\theta(x_{test}^{(i)})-y_{test}^{(i)})^2<br>$$</p>\n<h2 id=\"诊断偏差-bias-和方差-variance\"><a href=\"#诊断偏差-bias-和方差-variance\" class=\"headerlink\" title=\"诊断偏差(bias)和方差(variance)\"></a>诊断偏差(bias)和方差(variance)</h2><p>当你运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是和两个都有关？</p>\n<p><img src=\"/../images/biasVariance.jpg\" alt=\"biasVariance\"></p>\n<p>我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：</p>\n<p><img src=\"/../images/biasVariance_2.jpg\" alt=\"biasVariance_2\"></p>\n<p>对于训练集，当d较小时，模型拟合程度更低，误差较大；随着d的增长，拟合程度提高，误差减小。 对于交叉验证集，当d较小时，模型拟合程度低，误差较大；但是随着d的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。</p>\n<h2 id=\"正则化和偏差、方差\"><a href=\"#正则化和偏差、方差\" class=\"headerlink\" title=\"正则化和偏差、方差\"></a>正则化和偏差、方差</h2><p>在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。但是我们可能会正则化的程度太高或太小了，即我们在选择λ的值时也需要思考与刚才选择多项式模型次数类似的问题。</p>\n<p><img src=\"/../images/biasVariance_3.jpg\" alt=\"biasVariance_3\"></p>\n<p>我们选择一系列的想要测试的\\(\\lambda\\)值，通常是 0-10之间的呈现2倍关系的值（如：0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10共12个）。 我们同样把数据分为训练集、交叉验证集和测试集。</p>\n<p><img src=\"/../images/regularizationBias.png\" alt=\"regularizationBias\"></p>\n<p><strong>选择\\(\\lambda\\)的方法为：</strong></p>\n<ol>\n<li>使用训练集训练出12个不同程度正则化的模型</li>\n<li>用12个模型分别对交叉验证集计算的出交叉验证误差</li>\n<li>选择得出交叉验证误差最小的模型</li>\n<li>运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：</li>\n<li>当\\(\\lambda\\)较小时，训练集误差较小（过拟合）而交叉验证集误差较大; 随着  的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加</li>\n</ol>\n<p><img src=\"/../images/regularizationBias_2.png\" alt=\"regularizationBias_2\"></p>\n<h2 id=\"学习曲线\"><a href=\"#学习曲线\" class=\"headerlink\" title=\"学习曲线\"></a>学习曲线</h2><p>学习曲线是学习算法的一个很好的合理检验（sanity check）。学习曲线是将训练集误差和交叉验证集误差作为训练集样本数量（m）的函数绘制的图表。 即，如果我们有100行数据，我们从1行数据开始，逐渐学习更多行的数据。</p>\n<p><img src=\"/../images/learningCurve_1.png\" alt=\"learningCurve_1\"></p>\n<h3 id=\"如何利用学习曲线识别高偏差-x2F-欠拟合\"><a href=\"#如何利用学习曲线识别高偏差-x2F-欠拟合\" class=\"headerlink\" title=\"如何利用学习曲线识别高偏差&#x2F;欠拟合\"></a>如何利用学习曲线识别<strong>高偏差&#x2F;欠拟合</strong></h3><p>作为例子，我们尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差都不会有太大改观：</p>\n<p><img src=\"/../images/learningCurve_2.png\" alt=\"learningCurve_2\"></p>\n<p>也就是说在高偏差&#x2F;欠拟合的情况下，增加数据到训练集不一定能有帮助。 </p>\n<h3 id=\"如何利用学习曲线识别高方差-x2F-过拟合\"><a href=\"#如何利用学习曲线识别高方差-x2F-过拟合\" class=\"headerlink\" title=\"如何利用学习曲线识别高方差&#x2F;过拟合\"></a>如何利用学习曲线识别<strong>高方差&#x2F;过拟合</strong></h3><p>假设我们使用一个非常高次的多项式模型，并且正则化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果。</p>\n<p><img src=\"/../images/learningCurve_3.png\" alt=\"learningCurve_3\"></p>\n<p>也就是说在高方差&#x2F;过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>回顾前面中提出的六种可选的下一步，让我们来看一看我们在什么情况下应该怎样选择：</p>\n<ul>\n<li>获得更多的训练样本 – 解决高方差（过拟合）</li>\n<li>尝试减少特征的数量 – 解决高方差（过拟合）</li>\n<li>尝试获得更多的特征 – 解决高偏差（欠拟合）</li>\n<li>尝试增加多项式特征 – 解决高偏差（欠拟合）</li>\n<li>尝试减少正则化程度\\(\\lambda\\) – 解决高偏差（欠拟合）</li>\n<li>尝试增加正则化程度\\(\\lambda\\) – 解决高方差（过拟合）</li>\n</ul>\n<h3 id=\"神经网络和过拟合\"><a href=\"#神经网络和过拟合\" class=\"headerlink\" title=\"神经网络和过拟合\"></a>神经网络和过拟合</h3><p>使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。</p>\n<p><strong>通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。</strong> 对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络， 然后选择交叉验证集代价最小的神经网络。</p>\n<p><img src=\"/../images/neuralNetworkOverfitting.png\" alt=\"neuralNetworkOverfitting\"></p>\n<h1 id=\"机器学习系统的设计-Machine-Learning-System-Design\"><a href=\"#机器学习系统的设计-Machine-Learning-System-Design\" class=\"headerlink\" title=\"机器学习系统的设计(Machine Learning System Design)\"></a>机器学习系统的设计(Machine Learning System Design)</h1><h2 id=\"首先要做什么：邮件分类的例子\"><a href=\"#首先要做什么：邮件分类的例子\" class=\"headerlink\" title=\"首先要做什么：邮件分类的例子\"></a>首先要做什么：邮件分类的例子</h2><p>以一个垃圾邮件分类器算法为例进行讨论。 为了解决这样一个问题，我们首先要做的决定是如何选择并表达特征向量\\(x\\)。我们可以选择一个由100个最常出现在垃圾邮件中的词所构成的列表，根据这些词是否有在邮件中出现，来获得我们的特征向量（出现为1，不出现为0），尺寸为100×1。</p>\n<p>为了构建这个分类器算法，我们可以：</p>\n<ul>\n<li>收集更多的数据，让我们有更多的垃圾邮件和非垃圾邮件的样本</li>\n<li>基于邮件的路由信息开发一系列复杂的特征</li>\n<li>基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理</li>\n<li>为探测刻意的拼写错误（把watch 写成w4tch）开发复杂的算法</li>\n</ul>\n<p>在上面这些选项中，非常难决定应该在哪一项上花费时间和精力，作出明智的选择，比随着感觉走要更好。随后讲解的误差分析，会告诉你怎样用一个更加系统性的方法，从一堆不同的方法中，选取合适的那一个。因此，你更有可能选择一个真正的好方法，能让你花上几天几周，甚至是几个月去进行深入的研究。</p>\n<h2 id=\"误差分析\"><a href=\"#误差分析\" class=\"headerlink\" title=\"误差分析\"></a>误差分析</h2><p>误差分析（Error Analysis）会帮助你更系统地做出决定。如果你准备研究机器学习的东西，或者构造机器学习应用程序，最好的实践方法不是建立一个非常复杂的系统，拥有多么复杂的变量；而是构建一个简单的算法，这样你可以很快地实现它。 然后通过交叉验证来检验数据。一旦做完，你可以画出学习曲线，通过画出学习曲线，以及检验误差，来找出你的算法是否有高偏差和高方差的问题，或者别的问题。在这样分析之后，再来决定用更多的数据训练，或者加入更多的特征变量是否有用。</p>\n<p>这么做的原因是：这在你刚接触机器学习问题时是一个很好的方法，你并不能提前知道你是否需要复杂的特征变量，或者你是否需要更多的数据，还是别的什么。提前知道你应该做什么，是非常难的，因为你缺少证据，缺少学习曲线。因此，你很难知道你应该把时间花在什么地方来提高算法的表现。但是当你实践一个非常简单即便不完美的方法时，你可以通过画出学习曲线来做出进一步的选择。</p>\n<p>除了画出学习曲线之外，一件非常有用的事是误差分析，我的意思是说：当我们在构造垃圾邮件分类器时，我会看一看我的交叉验证数据集，然后亲自看一看哪些邮件被算法错误地分类。因此，通过这些被算法错误分类的垃圾邮件与非垃圾邮件，你可以发现某些系统性的规律：什么类型的邮件总是被错误分类。经常地这样做之后，这个过程能启发你构造新的特征变量，或者告诉你：现在这个系统的短处，然后启发你如何去提高它。</p>\n<p>构建一个学习算法的推荐方法为：</p>\n<ol>\n<li>从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法</li>\n<li>绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择</li>\n<li>进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的样本，看看这些样本是否有某种系统化的趋势</li>\n</ol>\n<h2 id=\"类偏斜的误差度量\"><a href=\"#类偏斜的误差度量\" class=\"headerlink\" title=\"类偏斜的误差度量\"></a>类偏斜的误差度量</h2><p>在前面的学习中，我们提到了误差分析，以及设定误差度量值的重要性。那就是，设定某个实数来评估你的学习算法，并衡量它的表现。这里，有一件重要的事情要注意，就是使用一个合适的误差度量值，这有时会对于你的学习算法造成非常微妙的影响，这件重要的事情就是偏斜类（skewed classes）的问题。</p>\n<p>类偏斜情况表现为我们的训练集中有非常多的同一种类的样本，只有很少或没有其他类的样本。 例如我们希望用算法来预测癌症是否是恶性的，在我们的训练集中，只有0.5%的实例是恶性肿瘤。假设我们编写一个非学习而来的算法，在所有情况下都预测肿瘤是良性的，那么误差只有0.5%。然而我们通过训练而得到的神经网络算法却有1%的误差。这时，误差的大小是不能视为评判算法效果的依据的。 </p>\n<p>我们将算法预测的结果分成四种情况：</p>\n<p><img src=\"/../images/precisionRecall.PNG\" alt=\"precisionRecall\"></p>\n<p>$$<br>Precision(查准率) &#x3D; \\frac{True\\ positive}{Predicted\\ positive}&#x3D;\\frac{True\\ positive}{True\\ positive+False\\ positive}<br>$$</p>\n<p>$$<br>Recall(查全率) &#x3D; \\frac{True\\ positive}{Actual\\ positive}&#x3D;\\frac{True\\ positive}{True\\ positive+False\\ negative}<br>$$</p>\n<h2 id=\"查准率和查全率之间的权衡\"><a href=\"#查准率和查全率之间的权衡\" class=\"headerlink\" title=\"查准率和查全率之间的权衡\"></a>查准率和查全率之间的权衡</h2><p>之前我们谈到查准率和查全率，作为遇到偏斜类问题的评估度量值。在很多应用中，我们希望能够保证查准率和查全率的相对平衡。 这里将告诉你应该怎么做，同时也向你展示一些查准率和查全率作为算法评估度量值的更有效的方式。继续沿用刚才预测肿瘤性质的例子。</p>\n<p>查准率(Precision)&#x3D;TP&#x2F;(TP+FP) 例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。</p>\n<p>查全率(Recall)&#x3D;TP&#x2F;(TP+FN)例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。</p>\n<p>如果我们希望只在非常确信的情况下预测为真（肿瘤为恶性），即我们希望更高的查准率，我们可以使用比0.5更大的阀值，如0.7，0.9。这样做我们会减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。 如果我们希望提高查全率，尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地检查、诊断，我们可以使用比0.5更小的阀值，如0.3。 我们可以将不同阀值情况下，查全率与查准率的关系绘制成图表，曲线的形状根据数据的不同而不同：</p>\n<p><img src=\"/../images/precisionRecall_2.PNG\" alt=\"precisionRecall_2\"></p>\n<p>如何使用一个参数来判断是否算法更加合理呢？我们可以使用查准率和查全率的平均值，但很多时候并不能给出合理的预期。另一种更加合理的计算方法是计算他们的F1值，起计算公式为：<br>$$<br>2\\frac{PR}{P+R}<br>$$</p>\n<p><img src=\"/../images/precisionRecall_3.PNG\" alt=\"precisionRecall_3\"></p>\n<h2 id=\"机器学习的数据\"><a href=\"#机器学习的数据\" class=\"headerlink\" title=\"机器学习的数据\"></a>机器学习的数据</h2><p>在之前的一些笔记中，曾经提到我们不要盲目地花大量的时间来收集大量的数据。但事实证明，在一定条件下（后面会提到这些条件是什么），得到大量的数据并在某种类型的学习算法中进行训练，可以是一种有效的方法来获得一个具有良好性能的学习算法。</p>\n<p>我们先来看Michele Banko和Eric Brill的研究结果：</p>\n<p><img src=\"/../images/dataML.jpg\" alt=\"dataML\"></p>\n<p>通过对比不同的算法我们会发现，随着训练数据集的增大，所有算法的性能也都会对应地增强。 事实上，如果你选择任意一个算法，可能是选择了一个”劣等的”算法，如果你给这个劣等算法更多的数据，那么从这些例子中看起来的话，它看上去很有可能会其他算法更好，甚至会比”优等算法”更好。</p>\n<p>结果表明，许多不同的学习算法有时倾向于表现出非常相似的表现。真正能提高性能的，是你能够给一个算法大量的训练数据。像这样的结果，引起了一种在机器学习中的普遍共识：”取得成功的人不是拥有最好算法的人，而是拥有最多数据的人”。</p>\n<p>那么在什么条件下，更多的数据会提高我们模型的准确度呢？</p>\n<ol>\n<li>特征值中有足够的信息来预测y，比如给一个人这些信息，是否可以做出准确预测。</li>\n<li>使用的算法中有足够多的参数（比如线性回归或逻辑回归中有很多特征值，或者神经网络中有足够的hidden layer）。</li>\n<li>训练集中的数据量足够大。</li>\n</ol>\n<p>如果满足以上条件，并且收集到足够多的数据，你大概率会得到一个好性能的算法。</p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-15-Support Vector Machines","url":"/2022/08/31/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-15/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 15-支持向量(Support Vector Machines)。</p>\n<span id=\"more\"></span>\n\n<h1 id=\"优化目标\"><a href=\"#优化目标\" class=\"headerlink\" title=\"优化目标\"></a>优化目标</h1><p>与逻辑回归和神经网络相比，支持向量机(Support Vector Machine)，或者简称SVM，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。它也是我们所介绍的最后一个监督学习算法。</p>\n<p>为了描述支持向量机，事实上，我将会从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机。</p>\n<p><img src=\"/../images/SVM_1.png\" alt=\"SVM_1\"></p>\n<p>在逻辑回归中我们已经熟悉了这里的假设函数和右边的S型激励函数。简单说来，如果我们有一个y&#x3D;1的样本，如果我们想要正确的分类，就希望\\(\\theta^T x\\)远大于0。相反的，如果我们有另一个样本，y&#x3D;0，我们就会希望函数输出值接近于0。对应的，\\(\\theta^Tx\\)应当远小于0。</p>\n<p>下面我们换一种视角来看逻辑回归函数：</p>\n<p><img src=\"/../images/SVM_2.png\" alt=\"SVM_2\"></p>\n<p>在总代价函数中，y&#x3D;1时，只有左半侧函数起作用；y&#x3D;0时，只有右半侧函数起作用。</p>\n<p>近似的，如果我们用一个新的代价函数来代替，即这条从0点开始的水平直线，然后是一条斜线，像上图。那么，现在让我给这两个方程命名，左边的函数，我称之为\\(cost_1(z)\\)，同时，右边函数我称它为\\(cost_0(z)\\)。这里的下标是指在代价函数中，对应的y&#x3D;1和y&#x3D;0 的情况，拥有了这些定义后，现在，我们就开始构建支持向量机。</p>\n<p>在逻辑回归中，我们的目标是找到下面这个方程的最小值：<br>$$<br>min_\\theta\\frac{1}{m}[\\sum_{i&#x3D;1}^{m}y^{(i)}(-log h_\\theta (x^{(i)}))+(1-y^{(i)})(-log(1-h_\\theta (x^{(i)})))]+\\frac{\\lambda}{2m}\\sum_{j&#x3D;1}^{n}\\theta^2<br>$$</p>\n<p>对与支持向量机而言，形式稍微有些不同：<br>$$<br>min_\\theta C[\\sum_{i&#x3D;1}^{m}y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j&#x3D;1}^{n}\\theta^2<br>$$</p>\n<p>对比而言，两个方程有以下不同：</p>\n<ul>\n<li>去除了1&#x2F;m这一项。当然，这只是在不同函数中的不同习惯导致的，1&#x2F;m项并不会影响取得最优解。</li>\n<li>使用\\(C\\times A+B\\)来优化参数，而不是使用\\(A+\\lambda \\times B\\)。当然你也可以把这里的参数\\(C\\)考虑成\\(\\frac{1}{\\lambda}\\)，\\(C\\)同 \\(\\frac{1}{\\lambda}\\)所扮演的角色相同。</li>\n<li>有别于逻辑回归输出的概率。在这里，支持向量机所做的是它来直接预测的值等于1，还是等于0。</li>\n</ul>\n<h1 id=\"大边界的直观理解\"><a href=\"#大边界的直观理解\" class=\"headerlink\" title=\"大边界的直观理解\"></a>大边界的直观理解</h1><p>人们有时将支持向量机看作是大间距分类器。在这一部分，我将介绍其中的含义，这有助于我们直观理解SVM模型的假设是什么样的。</p>\n<p><img src=\"/../images/SVM_3.png\" alt=\"SVM_3\"></p>\n<p>如果你有一个正样本（y&#x3D;1)，我们会希望在\\(\\theta^Tx \\geq 1\\)，而不是仅仅\\(\\theta^Tx \\geq 0\\)，来使得预测函数为1。反之，如果我们有一个负样本(y&#x3D;0)，我们希望(\\theta^Tx \\leq -1\\)，而不是仅仅\\(\\theta^Tx \\leq 0\\)，来使得预测函数为0。那么我会就会用到SVM。</p>\n<p>SVM相比于逻辑回归函数的以0为分界线来说，选取的边界会大很多，对于样品的分离也更加明显。C值的选择将会影响边界的大小。</p>\n<p><img src=\"/../images/SVM_4.png\" alt=\"SVM_4\"></p>\n<p>在SVM中如果我们将C设置的非常大，决策边界会从黑线变到了粉线，但是如果C设置的小一点，则最终会得到这条黑线。也就是说，当C不是非常大的时候，它可以忽略掉一些异常点的影响，得到更好的决策界。甚至当你的数据不是线性可分的时候，支持向量机也可以给出好的结果。</p>\n<h1 id=\"Kernels-I\"><a href=\"#Kernels-I\" class=\"headerlink\" title=\"Kernels I\"></a>Kernels I</h1><p>回顾我们之前讨论过可以使用高级数的多项式模型来解决无法用直线进行分隔的分类问题：</p>\n<p><img src=\"/../images/Kernels_1.png\" alt=\"Kernels_1\"></p>\n<p>为了获得上图所示的判定边界，我们的模型可能是\\(\\theta_0+\\theta_1x_1+\\theta_2x_2+\\theta_3x_1x_2+\\theta_4x_1^2+\\theta_5x_2^2+…\\)的形式。</p>\n<p>我们可以用一系列的新的特征来替换模型中的每一项。例如令：<br>$$<br>f_1&#x3D;x_1; f_2&#x3D;x_2; f_3&#x3D;x_1x_2; f_4&#x3D;x_1^2; f_5&#x3D;x_2^2…<br>$$<br>从而得到：<br>$$<br>h_\\theta(x)&#x3D;\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n<br>$$</p>\n<p>然而，除了对原有的特征进行组合以外，有没有更好的方法来构造\\(f_1,f_2,f_3…\\)？我们可以用核函数(Kernel)来计算出新的特征。</p>\n<p>给定一个训练样本\\(x\\)，我们利用\\(x\\)的各个特征与我们预先选定的地标(landmarks)\\(l^{(1)},l^{(2)},l^{(3)}\\)的近似程度来选取新的特征\\(f_1,f_2,f_3\\)。</p>\n<p><img src=\"/../images/Kernels_2.png\" alt=\"Kernels_2\"></p>\n<p>例如：\\(f_1&#x3D;similarity(x,l^{(1)})&#x3D;e(-\\frac{||x-l^{(1)}||}{2\\sigma^2})\\)。</p>\n<p>其中\\(||x-l^{(1)}||&#x3D;\\sum_{j&#x3D;1}^n(x_j-l_j^{(1)})^2\\)，为实例x中所有特征与地标\\(l^{(1)}\\)之间的距离的和。其中的\\(f_1&#x3D;similarity(x,l^{(1)})\\)就是核函数。具体而言，是一个高斯核函数(Gaussian Kernel)。</p>\n<p>这些地标的作用是什么？如果一个训练样本\\(x\\)与地标\\(l\\)之间的距离近似于0，则新特征\\(f\\)近似于\\(e^{-0}&#x3D;1\\)，如果训练样本\\(x\\)与地标\\(l\\)之间距离较远，则\\(f\\)近似于\\(e^{-(一个较大的数)}&#x3D;0\\)。</p>\n<p>假设我们的训练样本含有两个特征值\\([x_1 x_2]\\)，给定地标\\(l^{(1)}\\)与不同的\\(\\sigma\\)值：</p>\n<p><img src=\"/../images/Kernels_3.png\" alt=\"Kernels_3\"></p>\n<p>图中水平面的坐标为\\(x_1,x_2\\)，而垂直坐标轴代表\\(f\\)。可以看出，只有当\\(x\\)与\\(l^{(1)}\\)重合时才具有最大值。随着的改变值改变的速率受到\\(\\sigma^2\\)的控制。</p>\n<p>在下图中，当样本处于洋红色的点位置处，因为其离\\(l^{(1)}\\)更近，但是离\\(l^{(2)}\\)和\\(l^{(3)}\\)较远，因此\\(f_1\\)接近1，而\\(f_2\\),\\(f_3\\)接近0。因此\\(h_\\theta(x)&#x3D;\\theta_0+\\theta_1f_1+\\theta_2f_2+\\theta_3f_3&gt;0\\)，因此预测\\(y&#x3D;1\\)。同理可以求出，对于离\\(l^{(2)}\\)较近的绿色点，也预测\\(y&#x3D;1\\)，但是对于蓝绿色的点，因为其离三个地标都较远，预测\\(y&#x3D;0\\)。</p>\n<p><img src=\"/../images/Kernels_4.png\" alt=\"Kernels_4\"></p>\n<h1 id=\"Kernels-II\"><a href=\"#Kernels-II\" class=\"headerlink\" title=\"Kernels II\"></a>Kernels II</h1><h2 id=\"如何选择地标？\"><a href=\"#如何选择地标？\" class=\"headerlink\" title=\"如何选择地标？\"></a>如何选择地标？</h2><p>我们通常是根据训练集的数量选择地标的数量，即如果训练集中有m个样本，则我们选取m个地标，并且令:\\(l^{(1)}&#x3D;x^{(1)}, l^{(2)}&#x3D;x^{(2)}, l^{(3)}&#x3D;x^{(3)}…l^{(m)}&#x3D;x^{(m)}\\)。这样做的好处在于：现在我们得到的新特征是建立在原有特征与训练集中所有其他特征之间距离的基础之上的。</p>\n<h2 id=\"向量机中使用核函数\"><a href=\"#向量机中使用核函数\" class=\"headerlink\" title=\"向量机中使用核函数\"></a>向量机中使用核函数</h2><p>下面我们将核函数运用到支持向量机中，修改我们的支持向量机假设为：<br>给定\\(x\\)，计算新的特征\\(f\\)，当\\(\\theta^T gte 0\\)时，预测\\(y&#x3D;1\\)，否则反之。</p>\n<p>相应的修改代价函数为：<br>$$<br>min_\\theta C\\sum_{i&#x3D;1}^{m}y^{(i)}cost_1(\\theta^Tf^{(i)})+(1-y^{(i)})cost_0(\\theta^Tf^{(i)})+\\frac{1}{2}\\sum_{j&#x3D;1}^{m}\\theta_j^2<br>$$</p>\n<p>在具体实施过程中，我们还需要对最后的正则化项进行些微调整。在计算时，我们用\\(\\theta^TM\\theta\\)代替\\(\\theta^T\\theta\\)，M其中是根据我们选择的核函数而不同的一个矩阵。这样做的原因是为了简化计算。</p>\n<p>理论上讲，我们也可以在逻辑回归中使用核函数，但是上面使用M来简化计算的方法不适用与逻辑回归，因此计算将非常耗费时间。</p>\n<p>另外，支持向量机也可以不使用核函数，不使用核函数又称为线性核函数(linear kernel)，当我们不采用非常复杂的函数，或者我们的训练集特征非常多而样本非常少的时候，可以采用这种不带核函数的支持向量机。</p>\n<p>下面是支持向量机的两个参数\\(C\\)和\\(\\sigma\\)的影响：</p>\n<p>\\(C&#x3D;\\frac{1}{\\lambda}\\)</p>\n<p>\\(C\\)较大时，相当于\\(\\lambda\\)较小，会导致过拟合，高方差；</p>\n<p>\\(C\\)较小时，相当于\\(\\lambda\\)较大，会导致低拟合，高偏差；</p>\n<p>\\(\\sigma\\)较大时，可能会导致低方差，高偏差；</p>\n<p>\\(\\sigma\\)较小时，可能会导致低偏差，高方差。</p>\n<h1 id=\"使用支持向量机\"><a href=\"#使用支持向量机\" class=\"headerlink\" title=\"使用支持向量机\"></a>使用支持向量机</h1><p>推荐使用SVM软件包来求解参数\\(\\theta\\)，用的比较多的两个包为：liblinear和libsvm。除了高斯核函数之外，我们还有其他一些选择，例如：</p>\n<ul>\n<li>多项式核函数(Polynomial Kernel)</li>\n<li>字符串核函数(String Kernel)</li>\n<li>卡方核函数(chi-square Kernel)</li>\n<li>直方图交集核函数(histogram intersection kernel)</li>\n</ul>\n<p>假设我们利用之前介绍的一对多方法来解决一个多类分类问题。如果一共有k个类，则我们需要k个模型，以及k个参数向量。我们同样也可以训练k个支持向量机来解决多类分类问题。但是大多数支持向量机软件包都有内置的多类分类功能，我们只要直接使用即可。</p>\n<p>尽管你不去写你自己的SVM的优化软件，但是你也需要做几件事：</p>\n<ul>\n<li>提出参数C的选择。</li>\n<li>选择内核参数或想要使用的相似函数。其中一个选择是：我们选择不需要任何内核参数，没有内核参数的理念，也叫线性核函数。因此，如果有人说他使用了线性核的SVM（支持向量机），这就意味这他使用了不带有核函数的SVM（支持向量机）。</li>\n</ul>\n<h2 id=\"逻辑回归模型-vs-支持向量机模型\"><a href=\"#逻辑回归模型-vs-支持向量机模型\" class=\"headerlink\" title=\"逻辑回归模型 vs. 支持向量机模型\"></a>逻辑回归模型 vs. 支持向量机模型</h2><p>从逻辑回归模型，我们得到了支持向量机模型，在两者之间，我们应该如何选择呢？</p>\n<p>下面是一些普遍使用的准则：<br>n为特征数，m为训练样本数。</p>\n<p>(1)如果相较于m而言，n要大许多，即训练集数据量不够支持我们训练一个复杂的非线性模型，我们选用逻辑回归模型或者不带核函数的支持向量机。</p>\n<p>(2)如果n较小，而且m大小中等，例如n在 1-1000 之间，而m在10-10000之间，使用高斯核函数的支持向量机。</p>\n<p>(3)如果n较小，而m较大，例如n在1-1000之间，而m大于50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的支持向量机。</p>\n<p>值得一提的是，神经网络在以上三种情况下都可能会有较好的表现，但是训练神经网络可能非常慢，选择支持向量机的原因主要在于它的代价函数是凸函数，不存在局部最小值。</p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-17-Unsupervised Learning","url":"/2022/09/05/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-17/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 17-无监督学习(Unsupervised Learning)。</p>\n<span id=\"more\"></span>\n\n<h1 id=\"聚类-Clustering\"><a href=\"#聚类-Clustering\" class=\"headerlink\" title=\"聚类(Clustering)\"></a>聚类(Clustering)</h1><h2 id=\"无监督学习-简介\"><a href=\"#无监督学习-简介\" class=\"headerlink\" title=\"无监督学习-简介\"></a>无监督学习-简介</h2><p>在一个典型的监督学习中，我们有一个有标签的训练集，我们的目标是找到能够区分正样本和负样本的决策边界。与此不同的是，在非监督学习中，我们的数据没有附带任何标签，我们拿到的数据就是这样的：</p>\n<p><img src=\"/../images/clustering_1.png\" alt=\"clustering_1\"></p>\n<p>在这个例子中，我们没有任何标签y。也就是说，在非监督学习中，我们需要将一系列无标签的训练数据，输入到一个算法中，然后我们告诉这个算法，去为我们找找这个数据的内在结构给定数据。</p>\n<p>图上的数据看起来可以分成两个分开的点集（称为簇），一个能够找到我圈出的这些点集的算法，就被称为聚类算法。</p>\n<p>那么聚类算法一般用来做什么呢？</p>\n<p><img src=\"/../images/clustering_2.png\" alt=\"clustering_2\"></p>\n<p>在这门课程的早些时候，我曾经列举过一些应用：比如市场分割。也许你在数据库中存储了许多客户的信息，而你希望将他们分成不同的客户群，这样你可以对不同类型的客户分别销售产品或者分别提供更适合的服务。社交网络分析：事实上有许多研究人员正在研究这样一些内容，他们关注一群人，关注社交网络，例如Facebook，Google+，或者是其他的一些信息，比如说：你经常跟哪些人联系，而这些人又经常给哪些人发邮件，由此找到关系密切的人群。另外，聚类算法可以用来更好的组织计算机集群，或者更好的管理数据中心。因为如果你知道数据中心中，哪些计算机经常协作工作。那么，你可以重新分配资源，重新布局网络。由此优化数据中心，优化数据通信。</p>\n<h2 id=\"k-均值算法\"><a href=\"#k-均值算法\" class=\"headerlink\" title=\"k-均值算法\"></a>k-均值算法</h2><p>K-均值是最普及的聚类算法，算法接受一个未标记的数据集，然后将数据聚类成不同的组。</p>\n<p>假设我们想要将数据聚类成K个组，其方法为:</p>\n<ul>\n<li>首先，选择K个随机的点，称为聚类中心（cluster centroids）</li>\n<li>对于数据集中的每一个数据，按照距离K个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类</li>\n<li>计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置</li>\n<li>重复步骤2-4直至中心点不再变化</li>\n</ul>\n<p>用\\(\\mu^1,\\mu^2,…,\\mu^k\\)来表示聚类中心，用\\(c^{(1)},c^{(2)},c^{(3)},…,c^{(m)}\\)来存储与第i个实例数据最接近的聚类中心索引，K-均值的迭代算法代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Repeat &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">for i = 1 to m</span><br><span class=\"line\"></span><br><span class=\"line\">    c(i) := index (form 1 to K) of cluster centroid closest to x(i)</span><br><span class=\"line\"></span><br><span class=\"line\">for k = 1 to K</span><br><span class=\"line\"></span><br><span class=\"line\">    μk := average (mean) of points assigned to cluster k</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>算法分为两个步骤:1)第一个for循环用于分配样例i所属的类；2)第二个for循环用于移动聚类中心，即：对于每一个类K，重新计算该类的质心。</p>\n<p>K-均值算法也可以很便利地用于将数据分为许多不同组，即使在没有非常明显区分的组群的情况下也可以。下图所示的数据集包含身高和体重两项特征构成的，利用K-均值算法将数据分为三类，用于帮助确定将要生产的T-恤衫的三种尺寸。</p>\n<p><img src=\"/../images/clustering_3.png\" alt=\"clustering_3\"></p>\n<h2 id=\"优化目标\"><a href=\"#优化目标\" class=\"headerlink\" title=\"优化目标\"></a>优化目标</h2><p>K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和，因此 K-均值的代价函数（又称畸变函数 Distortion function）为：</p>\n<p>$$<br>J(c^{(1)},…,c^{(m)},\\mu^1,…,\\mu^k) &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{m}||X^{(i)}-\\mu_{c^{(i)}}||^2<br>$$</p>\n<p>其中\\(\\mu_{c^{(i)}}\\)代表与\\(x^{(i)}\\)最近的聚类中心点。</p>\n<p>回顾刚才给出的: K-均值迭代算法，我们知道，第一个循环是用于减小\\(c^{(i)}\\)引起的代价，而第二个循环则是用于减小\\(\\mu_i\\)引起的代价。迭代的过程一定会是每一次迭代都在减小代价函数，不然便是出现了错误。</p>\n<h2 id=\"随机初始化\"><a href=\"#随机初始化\" class=\"headerlink\" title=\"随机初始化\"></a>随机初始化</h2><p>在运行K-均值算法的之前，我们首先要按照如下步骤随机初始化所有的聚类中心点：</p>\n<ul>\n<li>我们应该选择K &lt; m, 即聚类中心点的个数要小于所有训练集实例的数量</li>\n<li>随机选择K个训练实例，然后令K个聚类中心分别与这K个训练实例相等</li>\n</ul>\n<p>K-均值的一个问题在于，它有可能会停留在一个局部最小值处。</p>\n<p>为了解决这个问题，我们通常需要多次运行K-均值算法，每一次都重新进行随机初始化，最后再比较多次运行K-均值的结果，选择代价函数最小的结果。这种方法在K较小的时候（2–10）还是可行的，但是如果K较大，这么做也可能不会有明显地改善。</p>\n<h2 id=\"选择聚类数\"><a href=\"#选择聚类数\" class=\"headerlink\" title=\"选择聚类数\"></a>选择聚类数</h2><p>首先要明白一个概念，没有所谓最好的选择聚类数的方法。我们通常是根据不同的问题，人工进行选择不同的聚类数。选择的时候思考我们运用K-均值算法聚类的动机是什么，然后选择能最好服务于该目的标聚类数。</p>\n<p>选择聚类数目的方法时，有一个可能会谈及的方法叫作“肘部法则”。关于“肘部法则”，我们所需要做的是改变K值，也就是聚类类别数目的总数。然后，计算成本函数J。</p>\n<p><img src=\"/../images/clustering_4.png\" alt=\"clustering_4\"></p>\n<p>我们可能会得到一条类似于这样一个像人的肘部的曲线。你会发现随着K值增加，它的陈本函数J会迅速下降，并且在3的时候达到一个肘点。在此之后，J值就下降的非常慢，那么我们就选K&#x3D;3。当你应用“肘部法则”的时候，如果你得到了一个像上面这样的图，那么这将是一种用来选择聚类个数的合理方法。</p>\n<p>当大部分的时候，我们会得到一条如右图所示的曲线，这时候，我们就不能从这条曲线得出合理的聚类数。这时候，我们就应该选择其他的方法来选择聚类数。</p>\n<p>例如，我们的T-恤制造例子中，人们身高和体重数据是一些连续分布的点，我们就无法使用肘部曲线来进行分类。而是要根据我们的需求分类，比如，我们可以分成3个尺寸:S,M,L，也可以分成5个尺寸:XS,S,M,L,XL。这样的选择是建立在回答“聚类后我们制造的T-恤是否能较好地适合我们的客户”这个问题的基础上作出的。</p>\n<h1 id=\"降维-Dimensionality-Reduction\"><a href=\"#降维-Dimensionality-Reduction\" class=\"headerlink\" title=\"降维(Dimensionality Reduction)\"></a>降维(Dimensionality Reduction)</h1><h2 id=\"动机一：数据压缩\"><a href=\"#动机一：数据压缩\" class=\"headerlink\" title=\"动机一：数据压缩\"></a>动机一：数据压缩</h2><p>有几个不同的的原因使你可能想要做降维。一是数据压缩，数据压缩不仅允许我们使用较少的计算机内存或磁盘空间，它也能够使我们的算法计算速度更快。</p>\n<p>例如，我们未知两个的特征：\\(x_1\\)长度：用厘米表示；\\(x_2\\)：是用英寸表示同一物体的长度。我们就可以将数据减小到一个维度。</p>\n<p><img src=\"/../images/dimensionReduction_1.png\" alt=\"dimensionReduction_1\"></p>\n<p>类似的，在实际的工业运用中，有时可能有几个不同的工程团队，也许一个工程队给你二百个特征，第二工程队给你另外三百个的特征，第三工程队给你五百个特征，一千多个特征都在一起，它实际上会变得非常困难去追踪这些特征。这时，我们就需要将特征进行降维，从而更加容易的追踪它们。</p>\n<p><strong>将数据从三维降至二维</strong>： 这个例子中我们要将一个三维的特征向量降至一个二维的特征向量。过程是与上面类似的，我们将三维向量投射到一个二维的平面上，迫使所有的数据都在同一个平面上，从而降至二维的特征向量。</p>\n<p><img src=\"/../images/dimensionReduction_2.png\" alt=\"dimensionReduction_2\"></p>\n<p>我们可以将这样的处理过程应用于任何维度的数据，从而降到任何想要的维度，例如将1000维的特征降至100维。</p>\n<h2 id=\"动机二：数据可视化\"><a href=\"#动机二：数据可视化\" class=\"headerlink\" title=\"动机二：数据可视化\"></a>动机二：数据可视化</h2><p>在许多及其学习问题中，如果我们能将数据可视化，我们便能寻找到一个更好的解决方案。这时候，降维便可以帮助我们。</p>\n<p><img src=\"/../images/dimensionReduction_3.png\" alt=\"dimensionReduction_3\"></p>\n<p>假使我们有有关于许多不同国家的数据，每一个特征向量都有50个特征（如GDP，人均GDP，平均寿命等）。如果要将这个50维的数据可视化是不可能的。使用降维的方法将其降至2维，我们便可以将其可视化了。</p>\n<p><img src=\"/../images/dimensionReduction_4.png\" alt=\"dimensionReduction_4\"></p>\n<p>这样做的问题在于，降维的算法只负责减少维数，新产生的特征的意义就必须由我们自己去发现了。</p>\n<h2 id=\"主成分分析问题-Principal-Component-Analysis-Problem-Formulation\"><a href=\"#主成分分析问题-Principal-Component-Analysis-Problem-Formulation\" class=\"headerlink\" title=\"主成分分析问题(Principal Component Analysis Problem Formulation)\"></a>主成分分析问题(Principal Component Analysis Problem Formulation)</h2><p>主成分分析(PCA)是最常见的降维算法。在PCA中，我们要做的是找到一个方向向量（Vector direction），当我们把所有的数据都投射到该向量上时，我们希望投射平均均方误差能尽可能地小。方向向量是一个经过原点的向量，而投射误差是从特征向量向该方向向量作垂线的长度。</p>\n<p>PCA技术的一大好处是对数据进行降维的处理。我们可以对新求出的“主元”向量的重要性进行排序，根据需要取前面最重要的部分，将后面的维数省去，可以达到降维从而简化模型或是对数据进行压缩的效果。同时最大程度的保持了原有数据的信息。</p>\n<h2 id=\"主成分分析算法-Principal-Component-Analysis-Algorithm\"><a href=\"#主成分分析算法-Principal-Component-Analysis-Algorithm\" class=\"headerlink\" title=\"主成分分析算法(Principal Component Analysis Algorithm)\"></a>主成分分析算法(Principal Component Analysis Algorithm)</h2><p>PCA将n维数据降维到k维的步骤：</p>\n<ul>\n<li>均值归一化：我们需要计算出所有特征的均值，然后令\\(x_j&#x3D;x_j-\\mu_j\\)。如果特征是在不同的数量级上，我们还需要将其除以标准差\\(\\sigma^2\\)。</li>\n<li>计算协方差矩阵(covariance matrix)。\\(\\sum &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{n}(x^{(i)})(x^{(i)})^T\\)。</li>\n<li>计算协方差矩阵(covariance matrix)\\(\\sum\\)的特征向量(eigenvectors)：<ul>\n<li>在Octave中可以利用奇异值分解(singular value decomposition)来求解</li>\n<li>其函数为[U,S,V]&#x3D;svd(sigma)</li>\n</ul>\n</li>\n</ul>\n<p>对于一个\\(n\\times n\\)维度的矩阵，上式中的U是一个具有与数据之间最小投射误差的方向向量构成的矩阵。如果我们希望将数据从n维降至k维，我们只需要从U中选取前k个向量，从而获得一个\\(n\\times k\\)维度的矩阵，我们用\\(U_{reduce}\\)来表示，然后通过如下计算获得新的特征向量\\(z^{(i)}\\)：<br>$$<br>z^{(i)} &#x3D; U_{reduce}^T * x^{(i)}<br>$$</p>\n<h2 id=\"选择主成分的数量-Choosing-the-Number-of-Principal-Components\"><a href=\"#选择主成分的数量-Choosing-the-Number-of-Principal-Components\" class=\"headerlink\" title=\"选择主成分的数量(Choosing the Number of Principal Components)\"></a>选择主成分的数量(Choosing the Number of Principal Components)</h2><p><strong>我们希望在平均均方误差与训练集方差的比例尽可能小的情况下选择尽可能小的k值</strong>。</p>\n<p>投射的平均均方误差：\\(\\frac{1}{m}\\sum_{i&#x3D;1}^{m}||x^{(i)}-x_{approx}^{(i)}||^2\\)</p>\n<p>训练集的方差为:\\(\\frac{1}{m}\\sum_{i&#x3D;1}^{m}||x^{(i)}||^2\\)</p>\n<p>如果我们希望这个比例小于1%，就意味着原本数据的偏差有99%都保留下来了。</p>\n<p>我们可以先令\\(k&#x3D;1\\)，然后进行主要成分分析，获得\\(U_{reduce}\\)和\\(z\\)，然后计算比例是否小于1%。如果不是的话再令\\(k&#x3D;2\\)，如此类推，直到找到可以使得比例小于1%的最小k值。</p>\n<p>我们还可以使用Octave的svd函数([U, S, V] &#x3D; svd(sigma))中的返回的第二个参数S来快速的得到k值。</p>\n<p>这里S是一个\\(n\\times n\\)的矩阵，只有对角线上有值，而其它单元都是0。</p>\n<p><img src=\"/../images/dimensionReduction_5.png\" alt=\"dimensionReduction_5\"></p>\n<p>计算平均均方误差与训练集方差的比例的方法如下：<br>$$<br>\\frac{\\frac{1}{m}\\sum_{i&#x3D;1}^{m}||x^{(i)}-x_{approx}^{(i)}||^2}{\\frac{1}{m}\\sum_{i&#x3D;1}^{m}||x^{(i)}||^2}&#x3D;1-\\frac{\\sum_{i&#x3D;1}{k}S_{ii}}{\\sum_{i&#x3D;1}{m}S_{ii}} \\leq 1%<br>$$</p>\n<p>在压缩过数据后，我们可以采用如下方法来近似地获得原有的特征：\\(x_{approax}^{(i)}&#x3D;U_{reduce}z^{(i)}\\)</p>\n<h2 id=\"主成分分析法的应用建议-Advice-for-Applying-PCA\"><a href=\"#主成分分析法的应用建议-Advice-for-Applying-PCA\" class=\"headerlink\" title=\"主成分分析法的应用建议(Advice for Applying PCA)\"></a>主成分分析法的应用建议(Advice for Applying PCA)</h2><p>假使我们正在针对一张 100×100像素的图片进行某个计算机视觉的机器学习，即总共有10000 个特征。</p>\n<ol>\n<li>第一步是运用主要成分分析将数据压缩至1000个特征</li>\n<li>然后对训练集运行学习算法</li>\n<li>在预测时，采用之前学习而来的\\(U_{reduce}\\)将输入的特征\\(x\\)转换成特征向量\\(z\\)，然后再进行预测</li>\n</ol>\n<p><strong>错误的主要成分分析情况</strong>：</p>\n<ul>\n<li>用于减少过拟合–原因在于主要成分分析只是近似地丢弃掉一些特征，它并不考虑任何与结果变量有关的信息，因此可能会丢失非常重要的特征。</li>\n<li>默认地将主要成分分析作为学习过程中的一部分–这虽然很多时候有效果，最好还是从所有原始特征开始，只在有必要的时候（算法运行太慢或者占用太多内存）才考虑采用主要成分分析。</li>\n</ul>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-16-exercise 6 summuary","url":"/2022/09/02/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-16/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 16-exercise 6 summuary。</p>\n<span id=\"more\"></span>\n<p><strong>Programming Exercise 6: Support Vector Machines</strong></p>\n<p>In this exercise, you will be using support vector machines (SVMs) to build<br>a spam classiifier.</p>\n<h1 id=\"ex6-m\"><a href=\"#ex6-m\" class=\"headerlink\" title=\"ex6.m\"></a>ex6.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class</span><br><span class=\"line\">%  Exercise 6 | Support Vector Machines</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">% </span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  exercise. You will need to complete the following functions:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     gaussianKernel.m</span><br><span class=\"line\">%     dataset3Params.m</span><br><span class=\"line\">%     processEmail.m</span><br><span class=\"line\">%     emailFeatures.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 1: Loading and Visualizing Data ================</span><br><span class=\"line\">%  We start the exercise by first loading and visualizing the dataset. </span><br><span class=\"line\">%  The following code will load the dataset into your environment and plot</span><br><span class=\"line\">%  the data.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Loading and Visualizing Data ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Load from ex6data1: </span><br><span class=\"line\">% You will have X, y in your environment</span><br><span class=\"line\">load(&#x27;ex6data1.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot training data</span><br><span class=\"line\">plotData(X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ==================== Part 2: Training Linear SVM ====================</span><br><span class=\"line\">%  The following code will train a linear SVM on the dataset and plot the</span><br><span class=\"line\">%  decision boundary learned.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Load from ex6data1: </span><br><span class=\"line\">% You will have X, y in your environment</span><br><span class=\"line\">load(&#x27;ex6data1.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nTraining Linear SVM ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% You should try to change the C value below and see how the decision</span><br><span class=\"line\">% boundary varies (e.g., try C = 1000)</span><br><span class=\"line\">C = 1;</span><br><span class=\"line\">model = svmTrain(X, y, C, @linearKernel, 1e-3, 20);</span><br><span class=\"line\">visualizeBoundaryLinear(X, y, model);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 3: Implementing Gaussian Kernel ===============</span><br><span class=\"line\">%  You will now implement the Gaussian kernel to use</span><br><span class=\"line\">%  with the SVM. You should complete the code in gaussianKernel.m</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;\\nEvaluating the Gaussian Kernel ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">x1 = [1 2 1]; x2 = [0 4 -1]; sigma = 2;</span><br><span class=\"line\">sim = gaussianKernel(x1, x2, sigma);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;Gaussian Kernel between x1 = [1; 2; 1], x2 = [0; 4; -1], sigma = %f :&#x27; ...</span><br><span class=\"line\">         &#x27;\\n\\t%f\\n(for sigma = 2, this value should be about 0.324652)\\n&#x27;], sigma, sim);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 4: Visualizing Dataset 2 ================</span><br><span class=\"line\">%  The following code will load the next dataset into your environment and </span><br><span class=\"line\">%  plot the data. </span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Loading and Visualizing Data ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Load from ex6data2: </span><br><span class=\"line\">% You will have X, y in your environment</span><br><span class=\"line\">load(&#x27;ex6data2.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot training data</span><br><span class=\"line\">plotData(X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ========== Part 5: Training SVM with RBF Kernel (Dataset 2) ==========</span><br><span class=\"line\">%  After you have implemented the kernel, we can now use it to train the </span><br><span class=\"line\">%  SVM classifier.</span><br><span class=\"line\">% </span><br><span class=\"line\">fprintf(&#x27;\\nTraining SVM with RBF Kernel (this may take 1 to 2 minutes) ...\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Load from ex6data2: </span><br><span class=\"line\">% You will have X, y in your environment</span><br><span class=\"line\">load(&#x27;ex6data2.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% SVM Parameters</span><br><span class=\"line\">C = 1; sigma = 0.1;</span><br><span class=\"line\"></span><br><span class=\"line\">% We set the tolerance and max_passes lower here so that the code will run</span><br><span class=\"line\">% faster. However, in practice, you will want to run the training to</span><br><span class=\"line\">% convergence.</span><br><span class=\"line\">model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma)); </span><br><span class=\"line\">visualizeBoundary(X, y, model);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 6: Visualizing Dataset 3 ================</span><br><span class=\"line\">%  The following code will load the next dataset into your environment and </span><br><span class=\"line\">%  plot the data. </span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Loading and Visualizing Data ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Load from ex6data3: </span><br><span class=\"line\">% You will have X, y in your environment</span><br><span class=\"line\">load(&#x27;ex6data3.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot training data</span><br><span class=\"line\">plotData(X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ========== Part 7: Training SVM with RBF Kernel (Dataset 3) ==========</span><br><span class=\"line\"></span><br><span class=\"line\">%  This is a different dataset that you can use to experiment with. Try</span><br><span class=\"line\">%  different values of C and sigma here.</span><br><span class=\"line\">% </span><br><span class=\"line\"></span><br><span class=\"line\">% Load from ex6data3: </span><br><span class=\"line\">% You will have X, y in your environment</span><br><span class=\"line\">load(&#x27;ex6data3.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Try different SVM Parameters here</span><br><span class=\"line\">[C, sigma] = dataset3Params(X, y, Xval, yval);</span><br><span class=\"line\"></span><br><span class=\"line\">% Train the SVM</span><br><span class=\"line\">model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma));</span><br><span class=\"line\">visualizeBoundary(X, y, model);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"gaussianKernel-m\"><a href=\"#gaussianKernel-m\" class=\"headerlink\" title=\"gaussianKernel.m\"></a>gaussianKernel.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function sim = gaussianKernel(x1, x2, sigma)</span><br><span class=\"line\">%RBFKERNEL returns a radial basis function kernel between x1 and x2</span><br><span class=\"line\">%   sim = gaussianKernel(x1, x2) returns a gaussian kernel between x1 and x2</span><br><span class=\"line\">%   and returns the value in sim</span><br><span class=\"line\"></span><br><span class=\"line\">% Ensure that x1 and x2 are column vectors</span><br><span class=\"line\">x1 = x1(:); x2 = x2(:);</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly.</span><br><span class=\"line\">sim = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Fill in this function to return the similarity between x1</span><br><span class=\"line\">%               and x2 computed using a Gaussian kernel with bandwidth</span><br><span class=\"line\">%               sigma</span><br><span class=\"line\">%</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">sim = exp(-(x1-x2)&#x27;*(x1-x2)/(2*sigma^2));</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\">    </span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"svmTrain-m\"><a href=\"#svmTrain-m\" class=\"headerlink\" title=\"svmTrain.m\"></a>svmTrain.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [model] = svmTrain(X, Y, C, kernelFunction, ...</span><br><span class=\"line\">                            tol, max_passes)</span><br><span class=\"line\">%SVMTRAIN Trains an SVM classifier using a simplified version of the SMO </span><br><span class=\"line\">%algorithm. </span><br><span class=\"line\">%   [model] = SVMTRAIN(X, Y, C, kernelFunction, tol, max_passes) trains an</span><br><span class=\"line\">%   SVM classifier and returns trained model. X is the matrix of training </span><br><span class=\"line\">%   examples.  Each row is a training example, and the jth column holds the </span><br><span class=\"line\">%   jth feature.  Y is a column matrix containing 1 for positive examples </span><br><span class=\"line\">%   and 0 for negative examples.  C is the standard SVM regularization </span><br><span class=\"line\">%   parameter.  tol is a tolerance value used for determining equality of </span><br><span class=\"line\">%   floating point numbers. max_passes controls the number of iterations</span><br><span class=\"line\">%   over the dataset (without changes to alpha) before the algorithm quits.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: This is a simplified version of the SMO algorithm for training</span><br><span class=\"line\">%       SVMs. In practice, if you want to train an SVM classifier, we</span><br><span class=\"line\">%       recommend using an optimized package such as:  </span><br><span class=\"line\">%</span><br><span class=\"line\">%           LIBSVM   (http://www.csie.ntu.edu.tw/~cjlin/libsvm/)</span><br><span class=\"line\">%           SVMLight (http://svmlight.joachims.org/)</span><br><span class=\"line\">%</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">if ~exist(&#x27;tol&#x27;, &#x27;var&#x27;) || isempty(tol)</span><br><span class=\"line\">    tol = 1e-3;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">if ~exist(&#x27;max_passes&#x27;, &#x27;var&#x27;) || isempty(max_passes)</span><br><span class=\"line\">    max_passes = 5;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Data parameters</span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\">n = size(X, 2);</span><br><span class=\"line\"></span><br><span class=\"line\">% Map 0 to -1</span><br><span class=\"line\">Y(Y==0) = -1;</span><br><span class=\"line\"></span><br><span class=\"line\">% Variables</span><br><span class=\"line\">alphas = zeros(m, 1);</span><br><span class=\"line\">b = 0;</span><br><span class=\"line\">E = zeros(m, 1);</span><br><span class=\"line\">passes = 0;</span><br><span class=\"line\">eta = 0;</span><br><span class=\"line\">L = 0;</span><br><span class=\"line\">H = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">% Pre-compute the Kernel Matrix since our dataset is small</span><br><span class=\"line\">% (in practice, optimized SVM packages that handle large datasets</span><br><span class=\"line\">%  gracefully will _not_ do this)</span><br><span class=\"line\">% </span><br><span class=\"line\">% We have implemented optimized vectorized version of the Kernels here so</span><br><span class=\"line\">% that the svm training will run faster.</span><br><span class=\"line\">if strcmp(func2str(kernelFunction), &#x27;linearKernel&#x27;)</span><br><span class=\"line\">    % Vectorized computation for the Linear Kernel</span><br><span class=\"line\">    % This is equivalent to computing the kernel on every pair of examples</span><br><span class=\"line\">    K = X*X&#x27;;</span><br><span class=\"line\">elseif strfind(func2str(kernelFunction), &#x27;gaussianKernel&#x27;)</span><br><span class=\"line\">    % Vectorized RBF Kernel</span><br><span class=\"line\">    % This is equivalent to computing the kernel on every pair of examples</span><br><span class=\"line\">    X2 = sum(X.^2, 2);</span><br><span class=\"line\">    K = bsxfun(@plus, X2, bsxfun(@plus, X2&#x27;, - 2 * (X * X&#x27;)));</span><br><span class=\"line\">    K = kernelFunction(1, 0) .^ K;</span><br><span class=\"line\">else</span><br><span class=\"line\">    % Pre-compute the Kernel Matrix</span><br><span class=\"line\">    % The following can be slow due to the lack of vectorization</span><br><span class=\"line\">    K = zeros(m);</span><br><span class=\"line\">    for i = 1:m</span><br><span class=\"line\">        for j = i:m</span><br><span class=\"line\">             K(i,j) = kernelFunction(X(i,:)&#x27;, X(j,:)&#x27;);</span><br><span class=\"line\">             K(j,i) = K(i,j); %the matrix is symmetric</span><br><span class=\"line\">        end</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Train</span><br><span class=\"line\">fprintf(&#x27;\\nTraining ...&#x27;);</span><br><span class=\"line\">dots = 12;</span><br><span class=\"line\">while passes &lt; max_passes,</span><br><span class=\"line\">            </span><br><span class=\"line\">    num_changed_alphas = 0;</span><br><span class=\"line\">    for i = 1:m,</span><br><span class=\"line\">        </span><br><span class=\"line\">        % Calculate Ei = f(x(i)) - y(i) using (2). </span><br><span class=\"line\">        % E(i) = b + sum (X(i, :) * (repmat(alphas.*Y,1,n).*X)&#x27;) - Y(i);</span><br><span class=\"line\">        E(i) = b + sum (alphas.*Y.*K(:,i)) - Y(i);</span><br><span class=\"line\">        </span><br><span class=\"line\">        if ((Y(i)*E(i) &lt; -tol &amp;&amp; alphas(i) &lt; C) || (Y(i)*E(i) &gt; tol &amp;&amp; alphas(i) &gt; 0)),</span><br><span class=\"line\">            </span><br><span class=\"line\">            % In practice, there are many heuristics one can use to select</span><br><span class=\"line\">            % the i and j. In this simplified code, we select them randomly.</span><br><span class=\"line\">            j = ceil(m * rand());</span><br><span class=\"line\">            while j == i,  % Make sure i \\neq j</span><br><span class=\"line\">                j = ceil(m * rand());</span><br><span class=\"line\">            end</span><br><span class=\"line\"></span><br><span class=\"line\">            % Calculate Ej = f(x(j)) - y(j) using (2).</span><br><span class=\"line\">            E(j) = b + sum (alphas.*Y.*K(:,j)) - Y(j);</span><br><span class=\"line\"></span><br><span class=\"line\">            % Save old alphas</span><br><span class=\"line\">            alpha_i_old = alphas(i);</span><br><span class=\"line\">            alpha_j_old = alphas(j);</span><br><span class=\"line\">            </span><br><span class=\"line\">            % Compute L and H by (10) or (11). </span><br><span class=\"line\">            if (Y(i) == Y(j)),</span><br><span class=\"line\">                L = max(0, alphas(j) + alphas(i) - C);</span><br><span class=\"line\">                H = min(C, alphas(j) + alphas(i));</span><br><span class=\"line\">            else</span><br><span class=\"line\">                L = max(0, alphas(j) - alphas(i));</span><br><span class=\"line\">                H = min(C, C + alphas(j) - alphas(i));</span><br><span class=\"line\">            end</span><br><span class=\"line\">           </span><br><span class=\"line\">            if (L == H),</span><br><span class=\"line\">                % continue to next i. </span><br><span class=\"line\">                continue;</span><br><span class=\"line\">            end</span><br><span class=\"line\"></span><br><span class=\"line\">            % Compute eta by (14).</span><br><span class=\"line\">            eta = 2 * K(i,j) - K(i,i) - K(j,j);</span><br><span class=\"line\">            if (eta &gt;= 0),</span><br><span class=\"line\">                % continue to next i. </span><br><span class=\"line\">                continue;</span><br><span class=\"line\">            end</span><br><span class=\"line\">            </span><br><span class=\"line\">            % Compute and clip new value for alpha j using (12) and (15).</span><br><span class=\"line\">            alphas(j) = alphas(j) - (Y(j) * (E(i) - E(j))) / eta;</span><br><span class=\"line\">            </span><br><span class=\"line\">            % Clip</span><br><span class=\"line\">            alphas(j) = min (H, alphas(j));</span><br><span class=\"line\">            alphas(j) = max (L, alphas(j));</span><br><span class=\"line\">            </span><br><span class=\"line\">            % Check if change in alpha is significant</span><br><span class=\"line\">            if (abs(alphas(j) - alpha_j_old) &lt; tol),</span><br><span class=\"line\">                % continue to next i. </span><br><span class=\"line\">                % replace anyway</span><br><span class=\"line\">                alphas(j) = alpha_j_old;</span><br><span class=\"line\">                continue;</span><br><span class=\"line\">            end</span><br><span class=\"line\">            </span><br><span class=\"line\">            % Determine value for alpha i using (16). </span><br><span class=\"line\">            alphas(i) = alphas(i) + Y(i)*Y(j)*(alpha_j_old - alphas(j));</span><br><span class=\"line\">            </span><br><span class=\"line\">            % Compute b1 and b2 using (17) and (18) respectively. </span><br><span class=\"line\">            b1 = b - E(i) ...</span><br><span class=\"line\">                 - Y(i) * (alphas(i) - alpha_i_old) *  K(i,j)&#x27; ...</span><br><span class=\"line\">                 - Y(j) * (alphas(j) - alpha_j_old) *  K(i,j)&#x27;;</span><br><span class=\"line\">            b2 = b - E(j) ...</span><br><span class=\"line\">                 - Y(i) * (alphas(i) - alpha_i_old) *  K(i,j)&#x27; ...</span><br><span class=\"line\">                 - Y(j) * (alphas(j) - alpha_j_old) *  K(j,j)&#x27;;</span><br><span class=\"line\"></span><br><span class=\"line\">            % Compute b by (19). </span><br><span class=\"line\">            if (0 &lt; alphas(i) &amp;&amp; alphas(i) &lt; C),</span><br><span class=\"line\">                b = b1;</span><br><span class=\"line\">            elseif (0 &lt; alphas(j) &amp;&amp; alphas(j) &lt; C),</span><br><span class=\"line\">                b = b2;</span><br><span class=\"line\">            else</span><br><span class=\"line\">                b = (b1+b2)/2;</span><br><span class=\"line\">            end</span><br><span class=\"line\"></span><br><span class=\"line\">            num_changed_alphas = num_changed_alphas + 1;</span><br><span class=\"line\"></span><br><span class=\"line\">        end</span><br><span class=\"line\">        </span><br><span class=\"line\">    end</span><br><span class=\"line\">    </span><br><span class=\"line\">    if (num_changed_alphas == 0),</span><br><span class=\"line\">        passes = passes + 1;</span><br><span class=\"line\">    else</span><br><span class=\"line\">        passes = 0;</span><br><span class=\"line\">    end</span><br><span class=\"line\"></span><br><span class=\"line\">    fprintf(&#x27;.&#x27;);</span><br><span class=\"line\">    dots = dots + 1;</span><br><span class=\"line\">    if dots &gt; 78</span><br><span class=\"line\">        dots = 0;</span><br><span class=\"line\">        fprintf(&#x27;\\n&#x27;);</span><br><span class=\"line\">    end</span><br><span class=\"line\">    if exist(&#x27;OCTAVE_VERSION&#x27;)</span><br><span class=\"line\">        fflush(stdout);</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br><span class=\"line\">fprintf(&#x27; Done! \\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Save the model</span><br><span class=\"line\">idx = alphas &gt; 0;</span><br><span class=\"line\">model.X= X(idx,:);</span><br><span class=\"line\">model.y= Y(idx);</span><br><span class=\"line\">model.kernelFunction = kernelFunction;</span><br><span class=\"line\">model.b= b;</span><br><span class=\"line\">model.alphas= alphas(idx);</span><br><span class=\"line\">model.w = ((alphas.*Y)&#x27;*X)&#x27;;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"svmPredict-m\"><a href=\"#svmPredict-m\" class=\"headerlink\" title=\"svmPredict.m\"></a>svmPredict.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function pred = svmPredict(model, X)</span><br><span class=\"line\">%SVMPREDICT returns a vector of predictions using a trained SVM model</span><br><span class=\"line\">%(svmTrain). </span><br><span class=\"line\">%   pred = SVMPREDICT(model, X) returns a vector of predictions using a </span><br><span class=\"line\">%   trained SVM model (svmTrain). X is a mxn matrix where there each </span><br><span class=\"line\">%   example is a row. model is a svm model returned from svmTrain.</span><br><span class=\"line\">%   predictions pred is a m x 1 column of predictions of &#123;0, 1&#125; values.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Check if we are getting a column vector, if so, then assume that we only</span><br><span class=\"line\">% need to do prediction for a single example</span><br><span class=\"line\">if (size(X, 2) == 1)</span><br><span class=\"line\">    % Examples should be in rows</span><br><span class=\"line\">    X = X&#x27;;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Dataset </span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\">p = zeros(m, 1);</span><br><span class=\"line\">pred = zeros(m, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">if strcmp(func2str(model.kernelFunction), &#x27;linearKernel&#x27;)</span><br><span class=\"line\">    % We can use the weights and bias directly if working with the </span><br><span class=\"line\">    % linear kernel</span><br><span class=\"line\">    p = X * model.w + model.b;</span><br><span class=\"line\">elseif strfind(func2str(model.kernelFunction), &#x27;gaussianKernel&#x27;)</span><br><span class=\"line\">    % Vectorized RBF Kernel</span><br><span class=\"line\">    % This is equivalent to computing the kernel on every pair of examples</span><br><span class=\"line\">    X1 = sum(X.^2, 2);</span><br><span class=\"line\">    X2 = sum(model.X.^2, 2)&#x27;;</span><br><span class=\"line\">    K = bsxfun(@plus, X1, bsxfun(@plus, X2, - 2 * X * model.X&#x27;));</span><br><span class=\"line\">    K = model.kernelFunction(1, 0) .^ K;</span><br><span class=\"line\">    K = bsxfun(@times, model.y&#x27;, K);</span><br><span class=\"line\">    K = bsxfun(@times, model.alphas&#x27;, K);</span><br><span class=\"line\">    p = sum(K, 2);</span><br><span class=\"line\">else</span><br><span class=\"line\">    % Other Non-linear kernel</span><br><span class=\"line\">    for i = 1:m</span><br><span class=\"line\">        prediction = 0;</span><br><span class=\"line\">        for j = 1:size(model.X, 1)</span><br><span class=\"line\">            prediction = prediction + ...</span><br><span class=\"line\">                model.alphas(j) * model.y(j) * ...</span><br><span class=\"line\">                model.kernelFunction(X(i,:)&#x27;, model.X(j,:)&#x27;);</span><br><span class=\"line\">        end</span><br><span class=\"line\">        p(i) = prediction + model.b;</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Convert predictions into 0 / 1</span><br><span class=\"line\">pred(p &gt;= 0) =  1;</span><br><span class=\"line\">pred(p &lt;  0) =  0;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"visualizeBoundary-m\"><a href=\"#visualizeBoundary-m\" class=\"headerlink\" title=\"visualizeBoundary.m\"></a>visualizeBoundary.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function pred = svmPredict(model, X)</span><br><span class=\"line\">%SVMPREDICT returns a vector of predictions using a trained SVM model</span><br><span class=\"line\">%(svmTrain). </span><br><span class=\"line\">%   pred = SVMPREDICT(model, X) returns a vector of predictions using a </span><br><span class=\"line\">%   trained SVM model (svmTrain). X is a mxn matrix where there each </span><br><span class=\"line\">%   example is a row. model is a svm model returned from svmTrain.</span><br><span class=\"line\">%   predictions pred is a m x 1 column of predictions of &#123;0, 1&#125; values.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Check if we are getting a column vector, if so, then assume that we only</span><br><span class=\"line\">% need to do prediction for a single example</span><br><span class=\"line\">if (size(X, 2) == 1)</span><br><span class=\"line\">    % Examples should be in rows</span><br><span class=\"line\">    X = X&#x27;;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Dataset </span><br><span class=\"line\">m = size(X, 1);</span><br><span class=\"line\">p = zeros(m, 1);</span><br><span class=\"line\">pred = zeros(m, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">if strcmp(func2str(model.kernelFunction), &#x27;linearKernel&#x27;)</span><br><span class=\"line\">    % We can use the weights and bias directly if working with the </span><br><span class=\"line\">    % linear kernel</span><br><span class=\"line\">    p = X * model.w + model.b;</span><br><span class=\"line\">elseif strfind(func2str(model.kernelFunction), &#x27;gaussianKernel&#x27;)</span><br><span class=\"line\">    % Vectorized RBF Kernel</span><br><span class=\"line\">    % This is equivalent to computing the kernel on every pair of examples</span><br><span class=\"line\">    X1 = sum(X.^2, 2);</span><br><span class=\"line\">    X2 = sum(model.X.^2, 2)&#x27;;</span><br><span class=\"line\">    K = bsxfun(@plus, X1, bsxfun(@plus, X2, - 2 * X * model.X&#x27;));</span><br><span class=\"line\">    K = model.kernelFunction(1, 0) .^ K;</span><br><span class=\"line\">    K = bsxfun(@times, model.y&#x27;, K);</span><br><span class=\"line\">    K = bsxfun(@times, model.alphas&#x27;, K);</span><br><span class=\"line\">    p = sum(K, 2);</span><br><span class=\"line\">else</span><br><span class=\"line\">    % Other Non-linear kernel</span><br><span class=\"line\">    for i = 1:m</span><br><span class=\"line\">        prediction = 0;</span><br><span class=\"line\">        for j = 1:size(model.X, 1)</span><br><span class=\"line\">            prediction = prediction + ...</span><br><span class=\"line\">                model.alphas(j) * model.y(j) * ...</span><br><span class=\"line\">                model.kernelFunction(X(i,:)&#x27;, model.X(j,:)&#x27;);</span><br><span class=\"line\">        end</span><br><span class=\"line\">        p(i) = prediction + model.b;</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Convert predictions into 0 / 1</span><br><span class=\"line\">pred(p &gt;= 0) =  1;</span><br><span class=\"line\">pred(p &lt;  0) =  0;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"dataset3Params-m\"><a href=\"#dataset3Params-m\" class=\"headerlink\" title=\"dataset3Params.m\"></a>dataset3Params.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [C, sigma] = dataset3Params(X, y, Xval, yval)</span><br><span class=\"line\">%DATASET3PARAMS returns your choice of C and sigma for Part 3 of the exercise</span><br><span class=\"line\">%where you select the optimal (C, sigma) learning parameters to use for SVM</span><br><span class=\"line\">%with RBF kernel</span><br><span class=\"line\">%   [C, sigma] = DATASET3PARAMS(X, y, Xval, yval) returns your choice of C and </span><br><span class=\"line\">%   sigma. You should complete this function to return the optimal C and </span><br><span class=\"line\">%   sigma based on a cross-validation set.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly.</span><br><span class=\"line\">C = 1;</span><br><span class=\"line\">sigma = 0.3;</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Fill in this function to return the optimal C and sigma</span><br><span class=\"line\">%               learning parameters found using the cross validation set.</span><br><span class=\"line\">%               You can use svmPredict to predict the labels on the cross</span><br><span class=\"line\">%               validation set. For example, </span><br><span class=\"line\">%                   predictions = svmPredict(model, Xval);</span><br><span class=\"line\">%               will return the predictions on the cross validation set.</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Note: You can compute the prediction error using </span><br><span class=\"line\">%        mean(double(predictions ~= yval))</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">error_min = inf;</span><br><span class=\"line\"></span><br><span class=\"line\">for C = [0.01 0.03 0.1 0.3 1 3 10 30]</span><br><span class=\"line\">  for sigma = [0.01 0.03 0.1 0.3 1 3 10 30]</span><br><span class=\"line\">    model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma));</span><br><span class=\"line\">    predictions = svmPredict(model, Xval);</span><br><span class=\"line\">    error = mean(double(predictions ~= yval));</span><br><span class=\"line\">    if(error &lt;= error_min)</span><br><span class=\"line\">      C_final = C;</span><br><span class=\"line\">      sigma_final = sigma;</span><br><span class=\"line\">      error_min = error;</span><br><span class=\"line\">    end </span><br><span class=\"line\">  end </span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">C = C_final;</span><br><span class=\"line\">sigma = sigma_final;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"ex6-spam-m\"><a href=\"#ex6-spam-m\" class=\"headerlink\" title=\"ex6_spam.m\"></a>ex6_spam.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class</span><br><span class=\"line\">%  Exercise 6 | Spam Classification with SVMs</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">% </span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  exercise. You will need to complete the following functions:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     gaussianKernel.m</span><br><span class=\"line\">%     dataset3Params.m</span><br><span class=\"line\">%     processEmail.m</span><br><span class=\"line\">%     emailFeatures.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% ==================== Part 1: Email Preprocessing ====================</span><br><span class=\"line\">%  To use an SVM to classify emails into Spam v.s. Non-Spam, you first need</span><br><span class=\"line\">%  to convert each email into a vector of features. In this part, you will</span><br><span class=\"line\">%  implement the preprocessing steps for each email. You should</span><br><span class=\"line\">%  complete the code in processEmail.m to produce a word indices vector</span><br><span class=\"line\">%  for a given email.</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nPreprocessing sample email (emailSample1.txt)\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Extract Features</span><br><span class=\"line\">file_contents = readFile(&#x27;emailSample1.txt&#x27;);</span><br><span class=\"line\">word_indices  = processEmail(file_contents);</span><br><span class=\"line\"></span><br><span class=\"line\">% Print Stats</span><br><span class=\"line\">fprintf(&#x27;Word Indices: \\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; %d&#x27;, word_indices);</span><br><span class=\"line\">fprintf(&#x27;\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ==================== Part 2: Feature Extraction ====================</span><br><span class=\"line\">%  Now, you will convert each email into a vector of features in R^n. </span><br><span class=\"line\">%  You should complete the code in emailFeatures.m to produce a feature</span><br><span class=\"line\">%  vector for a given email.</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nExtracting features from sample email (emailSample1.txt)\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Extract Features</span><br><span class=\"line\">file_contents = readFile(&#x27;emailSample1.txt&#x27;);</span><br><span class=\"line\">word_indices  = processEmail(file_contents);</span><br><span class=\"line\">features      = emailFeatures(word_indices);</span><br><span class=\"line\"></span><br><span class=\"line\">% Print Stats</span><br><span class=\"line\">fprintf(&#x27;Length of feature vector: %d\\n&#x27;, length(features));</span><br><span class=\"line\">fprintf(&#x27;Number of non-zero entries: %d\\n&#x27;, sum(features &gt; 0));</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 3: Train Linear SVM for Spam Classification ========</span><br><span class=\"line\">%  In this section, you will train a linear classifier to determine if an</span><br><span class=\"line\">%  email is Spam or Not-Spam.</span><br><span class=\"line\"></span><br><span class=\"line\">% Load the Spam Email dataset</span><br><span class=\"line\">% You will have X, y in your environment</span><br><span class=\"line\">load(&#x27;spamTrain.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nTraining Linear SVM (Spam Classification)\\n&#x27;)</span><br><span class=\"line\">fprintf(&#x27;(this may take 1 to 2 minutes) ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">C = 0.1;</span><br><span class=\"line\">model = svmTrain(X, y, C, @linearKernel);</span><br><span class=\"line\"></span><br><span class=\"line\">p = svmPredict(model, X);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Training Accuracy: %f\\n&#x27;, mean(double(p == y)) * 100);</span><br><span class=\"line\"></span><br><span class=\"line\">%% =================== Part 4: Test Spam Classification ================</span><br><span class=\"line\">%  After training the classifier, we can evaluate it on a test set. We have</span><br><span class=\"line\">%  included a test set in spamTest.mat</span><br><span class=\"line\"></span><br><span class=\"line\">% Load the test dataset</span><br><span class=\"line\">% You will have Xtest, ytest in your environment</span><br><span class=\"line\">load(&#x27;spamTest.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nEvaluating the trained Linear SVM on a test set ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">p = svmPredict(model, Xtest);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Test Accuracy: %f\\n&#x27;, mean(double(p == ytest)) * 100);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================= Part 5: Top Predictors of Spam ====================</span><br><span class=\"line\">%  Since the model we are training is a linear SVM, we can inspect the</span><br><span class=\"line\">%  weights learned by the model to understand better how it is determining</span><br><span class=\"line\">%  whether an email is spam or not. The following code finds the words with</span><br><span class=\"line\">%  the highest weights in the classifier. Informally, the classifier</span><br><span class=\"line\">%  &#x27;thinks&#x27; that these words are the most likely indicators of spam.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Sort the weights and obtin the vocabulary list</span><br><span class=\"line\">[weight, idx] = sort(model.w, &#x27;descend&#x27;);</span><br><span class=\"line\">vocabList = getVocabList();</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nTop predictors of spam: \\n&#x27;);</span><br><span class=\"line\">for i = 1:15</span><br><span class=\"line\">    fprintf(&#x27; %-15s (%f) \\n&#x27;, vocabList&#123;idx(i)&#125;, weight(i));</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\n\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =================== Part 6: Try Your Own Emails =====================</span><br><span class=\"line\">%  Now that you&#x27;ve trained the spam classifier, you can use it on your own</span><br><span class=\"line\">%  emails! In the starter code, we have included spamSample1.txt,</span><br><span class=\"line\">%  spamSample2.txt, emailSample1.txt and emailSample2.txt as examples. </span><br><span class=\"line\">%  The following code reads in one of these emails and then uses your </span><br><span class=\"line\">%  learned SVM classifier to determine whether the email is Spam or </span><br><span class=\"line\">%  Not Spam</span><br><span class=\"line\"></span><br><span class=\"line\">% Set the file to be read in (change this to spamSample2.txt,</span><br><span class=\"line\">% emailSample1.txt or emailSample2.txt to see different predictions on</span><br><span class=\"line\">% different emails types). Try your own emails as well!</span><br><span class=\"line\">filename = &#x27;spamSample1.txt&#x27;;</span><br><span class=\"line\"></span><br><span class=\"line\">% Read and predict</span><br><span class=\"line\">file_contents = readFile(filename);</span><br><span class=\"line\">word_indices  = processEmail(file_contents);</span><br><span class=\"line\">x             = emailFeatures(word_indices);</span><br><span class=\"line\">p = svmPredict(model, x);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProcessed %s\\n\\nSpam Classification: %d\\n&#x27;, filename, p);</span><br><span class=\"line\">fprintf(&#x27;(1 indicates spam, 0 indicates not spam)\\n\\n&#x27;);</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"readFile-m\"><a href=\"#readFile-m\" class=\"headerlink\" title=\"readFile.m\"></a>readFile.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function file_contents = readFile(filename)</span><br><span class=\"line\">%READFILE reads a file and returns its entire contents </span><br><span class=\"line\">%   file_contents = READFILE(filename) reads a file and returns its entire</span><br><span class=\"line\">%   contents in file_contents</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Load File</span><br><span class=\"line\">fid = fopen(filename);</span><br><span class=\"line\">if fid</span><br><span class=\"line\">    file_contents = fscanf(fid, &#x27;%c&#x27;, inf);</span><br><span class=\"line\">    fclose(fid);</span><br><span class=\"line\">else</span><br><span class=\"line\">    file_contents = &#x27;&#x27;;</span><br><span class=\"line\">    fprintf(&#x27;Unable to open %s\\n&#x27;, filename);</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"processEmail-m\"><a href=\"#processEmail-m\" class=\"headerlink\" title=\"processEmail.m\"></a>processEmail.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function word_indices = processEmail(email_contents)</span><br><span class=\"line\">%PROCESSEMAIL preprocesses a the body of an email and</span><br><span class=\"line\">%returns a list of word_indices </span><br><span class=\"line\">%   word_indices = PROCESSEMAIL(email_contents) preprocesses </span><br><span class=\"line\">%   the body of an email and returns a list of indices of the </span><br><span class=\"line\">%   words contained in the email. </span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Load Vocabulary</span><br><span class=\"line\">vocabList = getVocabList();</span><br><span class=\"line\"></span><br><span class=\"line\">% Init return value</span><br><span class=\"line\">word_indices = [];</span><br><span class=\"line\"></span><br><span class=\"line\">% ========================== Preprocess Email ===========================</span><br><span class=\"line\"></span><br><span class=\"line\">% Find the Headers ( \\n\\n and remove )</span><br><span class=\"line\">% Uncomment the following lines if you are working with raw emails with the</span><br><span class=\"line\">% full headers</span><br><span class=\"line\"></span><br><span class=\"line\">% hdrstart = strfind(email_contents, ([char(10) char(10)]));</span><br><span class=\"line\">% email_contents = email_contents(hdrstart(1):end);</span><br><span class=\"line\"></span><br><span class=\"line\">% Lower case</span><br><span class=\"line\">email_contents = lower(email_contents);</span><br><span class=\"line\"></span><br><span class=\"line\">% Strip all HTML</span><br><span class=\"line\">% Looks for any expression that starts with &lt; and ends with &gt; and replace</span><br><span class=\"line\">% and does not have any &lt; or &gt; in the tag it with a space</span><br><span class=\"line\">email_contents = regexprep(email_contents, &#x27;&lt;[^&lt;&gt;]+&gt;&#x27;, &#x27; &#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Handle Numbers</span><br><span class=\"line\">% Look for one or more characters between 0-9</span><br><span class=\"line\">email_contents = regexprep(email_contents, &#x27;[0-9]+&#x27;, &#x27;number&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Handle URLS</span><br><span class=\"line\">% Look for strings starting with http:// or https://</span><br><span class=\"line\">email_contents = regexprep(email_contents, ...</span><br><span class=\"line\">                           &#x27;(http|https)://[^\\s]*&#x27;, &#x27;httpaddr&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Handle Email Addresses</span><br><span class=\"line\">% Look for strings with @ in the middle</span><br><span class=\"line\">email_contents = regexprep(email_contents, &#x27;[^\\s]+@[^\\s]+&#x27;, &#x27;emailaddr&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Handle $ sign</span><br><span class=\"line\">email_contents = regexprep(email_contents, &#x27;[$]+&#x27;, &#x27;dollar&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% ========================== Tokenize Email ===========================</span><br><span class=\"line\"></span><br><span class=\"line\">% Output the email to screen as well</span><br><span class=\"line\">fprintf(&#x27;\\n==== Processed Email ====\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Process file</span><br><span class=\"line\">l = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">while ~isempty(email_contents)</span><br><span class=\"line\"></span><br><span class=\"line\">    % Tokenize and also get rid of any punctuation</span><br><span class=\"line\">    [str, email_contents] = ...</span><br><span class=\"line\">       strtok(email_contents, ...</span><br><span class=\"line\">              [&#x27; @$/#.-:&amp;*+=[]?!()&#123;&#125;,&#x27;&#x27;&quot;&gt;_&lt;;%&#x27; char(10) char(13)]);</span><br><span class=\"line\">   </span><br><span class=\"line\">    % Remove any non alphanumeric characters</span><br><span class=\"line\">    str = regexprep(str, &#x27;[^a-zA-Z0-9]&#x27;, &#x27;&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">    % Stem the word </span><br><span class=\"line\">    % (the porterStemmer sometimes has issues, so we use a try catch block)</span><br><span class=\"line\">    try str = porterStemmer(strtrim(str)); </span><br><span class=\"line\">    catch str = &#x27;&#x27;; continue;</span><br><span class=\"line\">    end;</span><br><span class=\"line\"></span><br><span class=\"line\">    % Skip the word if it is too short</span><br><span class=\"line\">    if length(str) &lt; 1</span><br><span class=\"line\">       continue;</span><br><span class=\"line\">    end</span><br><span class=\"line\"></span><br><span class=\"line\">    % Look up the word in the dictionary and add to word_indices if</span><br><span class=\"line\">    % found</span><br><span class=\"line\">    % ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">    % Instructions: Fill in this function to add the index of str to</span><br><span class=\"line\">    %               word_indices if it is in the vocabulary. At this point</span><br><span class=\"line\">    %               of the code, you have a stemmed word from the email in</span><br><span class=\"line\">    %               the variable str. You should look up str in the</span><br><span class=\"line\">    %               vocabulary list (vocabList). If a match exists, you</span><br><span class=\"line\">    %               should add the index of the word to the word_indices</span><br><span class=\"line\">    %               vector. Concretely, if str = &#x27;action&#x27;, then you should</span><br><span class=\"line\">    %               look up the vocabulary list to find where in vocabList</span><br><span class=\"line\">    %               &#x27;action&#x27; appears. For example, if vocabList&#123;18&#125; =</span><br><span class=\"line\">    %               &#x27;action&#x27;, then, you should add 18 to the word_indices </span><br><span class=\"line\">    %               vector (e.g., word_indices = [word_indices ; 18]; ).</span><br><span class=\"line\">    % </span><br><span class=\"line\">    % Note: vocabList&#123;idx&#125; returns a the word with index idx in the</span><br><span class=\"line\">    %       vocabulary list.</span><br><span class=\"line\">    % </span><br><span class=\"line\">    % Note: You can use strcmp(str1, str2) to compare two strings (str1 and</span><br><span class=\"line\">    %       str2). It will return 1 only if the two strings are equivalent.</span><br><span class=\"line\">    %</span><br><span class=\"line\">    </span><br><span class=\"line\">    for i = 1:length(vocabList)</span><br><span class=\"line\">        if(strcmp(str, vocabList&#123;i&#125;))</span><br><span class=\"line\">            word_indices = [word_indices; i];</span><br><span class=\"line\">        end</span><br><span class=\"line\">    end    </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    % =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    % Print to screen, ensuring that the output lines are not too long</span><br><span class=\"line\">    if (l + length(str) + 1) &gt; 78</span><br><span class=\"line\">        fprintf(&#x27;\\n&#x27;);</span><br><span class=\"line\">        l = 0;</span><br><span class=\"line\">    end</span><br><span class=\"line\">    fprintf(&#x27;%s &#x27;, str);</span><br><span class=\"line\">    l = l + length(str) + 1;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Print footer</span><br><span class=\"line\">fprintf(&#x27;\\n\\n=========================\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"emailFeatures-m\"><a href=\"#emailFeatures-m\" class=\"headerlink\" title=\"emailFeatures.m\"></a>emailFeatures.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function word_indices = processEmail(email_contents)</span><br><span class=\"line\">%PROCESSEMAIL preprocesses a the body of an email and</span><br><span class=\"line\">%returns a list of word_indices </span><br><span class=\"line\">%   word_indices = PROCESSEMAIL(email_contents) preprocesses </span><br><span class=\"line\">%   the body of an email and returns a list of indices of the </span><br><span class=\"line\">%   words contained in the email. </span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Load Vocabulary</span><br><span class=\"line\">vocabList = getVocabList();</span><br><span class=\"line\"></span><br><span class=\"line\">% Init return value</span><br><span class=\"line\">word_indices = [];</span><br><span class=\"line\"></span><br><span class=\"line\">% ========================== Preprocess Email ===========================</span><br><span class=\"line\"></span><br><span class=\"line\">% Find the Headers ( \\n\\n and remove )</span><br><span class=\"line\">% Uncomment the following lines if you are working with raw emails with the</span><br><span class=\"line\">% full headers</span><br><span class=\"line\"></span><br><span class=\"line\">% hdrstart = strfind(email_contents, ([char(10) char(10)]));</span><br><span class=\"line\">% email_contents = email_contents(hdrstart(1):end);</span><br><span class=\"line\"></span><br><span class=\"line\">% Lower case</span><br><span class=\"line\">email_contents = lower(email_contents);</span><br><span class=\"line\"></span><br><span class=\"line\">% Strip all HTML</span><br><span class=\"line\">% Looks for any expression that starts with &lt; and ends with &gt; and replace</span><br><span class=\"line\">% and does not have any &lt; or &gt; in the tag it with a space</span><br><span class=\"line\">email_contents = regexprep(email_contents, &#x27;&lt;[^&lt;&gt;]+&gt;&#x27;, &#x27; &#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Handle Numbers</span><br><span class=\"line\">% Look for one or more characters between 0-9</span><br><span class=\"line\">email_contents = regexprep(email_contents, &#x27;[0-9]+&#x27;, &#x27;number&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Handle URLS</span><br><span class=\"line\">% Look for strings starting with http:// or https://</span><br><span class=\"line\">email_contents = regexprep(email_contents, ...</span><br><span class=\"line\">                           &#x27;(http|https)://[^\\s]*&#x27;, &#x27;httpaddr&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Handle Email Addresses</span><br><span class=\"line\">% Look for strings with @ in the middle</span><br><span class=\"line\">email_contents = regexprep(email_contents, &#x27;[^\\s]+@[^\\s]+&#x27;, &#x27;emailaddr&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Handle $ sign</span><br><span class=\"line\">email_contents = regexprep(email_contents, &#x27;[$]+&#x27;, &#x27;dollar&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% ========================== Tokenize Email ===========================</span><br><span class=\"line\"></span><br><span class=\"line\">% Output the email to screen as well</span><br><span class=\"line\">fprintf(&#x27;\\n==== Processed Email ====\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Process file</span><br><span class=\"line\">l = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">while ~isempty(email_contents)</span><br><span class=\"line\"></span><br><span class=\"line\">    % Tokenize and also get rid of any punctuation</span><br><span class=\"line\">    [str, email_contents] = ...</span><br><span class=\"line\">       strtok(email_contents, ...</span><br><span class=\"line\">              [&#x27; @$/#.-:&amp;*+=[]?!()&#123;&#125;,&#x27;&#x27;&quot;&gt;_&lt;;%&#x27; char(10) char(13)]);</span><br><span class=\"line\">   </span><br><span class=\"line\">    % Remove any non alphanumeric characters</span><br><span class=\"line\">    str = regexprep(str, &#x27;[^a-zA-Z0-9]&#x27;, &#x27;&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">    % Stem the word </span><br><span class=\"line\">    % (the porterStemmer sometimes has issues, so we use a try catch block)</span><br><span class=\"line\">    try str = porterStemmer(strtrim(str)); </span><br><span class=\"line\">    catch str = &#x27;&#x27;; continue;</span><br><span class=\"line\">    end;</span><br><span class=\"line\"></span><br><span class=\"line\">    % Skip the word if it is too short</span><br><span class=\"line\">    if length(str) &lt; 1</span><br><span class=\"line\">       continue;</span><br><span class=\"line\">    end</span><br><span class=\"line\"></span><br><span class=\"line\">    % Look up the word in the dictionary and add to word_indices if</span><br><span class=\"line\">    % found</span><br><span class=\"line\">    % ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">    % Instructions: Fill in this function to add the index of str to</span><br><span class=\"line\">    %               word_indices if it is in the vocabulary. At this point</span><br><span class=\"line\">    %               of the code, you have a stemmed word from the email in</span><br><span class=\"line\">    %               the variable str. You should look up str in the</span><br><span class=\"line\">    %               vocabulary list (vocabList). If a match exists, you</span><br><span class=\"line\">    %               should add the index of the word to the word_indices</span><br><span class=\"line\">    %               vector. Concretely, if str = &#x27;action&#x27;, then you should</span><br><span class=\"line\">    %               look up the vocabulary list to find where in vocabList</span><br><span class=\"line\">    %               &#x27;action&#x27; appears. For example, if vocabList&#123;18&#125; =</span><br><span class=\"line\">    %               &#x27;action&#x27;, then, you should add 18 to the word_indices </span><br><span class=\"line\">    %               vector (e.g., word_indices = [word_indices ; 18]; ).</span><br><span class=\"line\">    % </span><br><span class=\"line\">    % Note: vocabList&#123;idx&#125; returns a the word with index idx in the</span><br><span class=\"line\">    %       vocabulary list.</span><br><span class=\"line\">    % </span><br><span class=\"line\">    % Note: You can use strcmp(str1, str2) to compare two strings (str1 and</span><br><span class=\"line\">    %       str2). It will return 1 only if the two strings are equivalent.</span><br><span class=\"line\">    %</span><br><span class=\"line\">    </span><br><span class=\"line\">    for i = 1:length(vocabList)</span><br><span class=\"line\">        if(strcmp(str, vocabList&#123;i&#125;))</span><br><span class=\"line\">            word_indices = [word_indices; i];</span><br><span class=\"line\">        end</span><br><span class=\"line\">    end    </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    % =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    % Print to screen, ensuring that the output lines are not too long</span><br><span class=\"line\">    if (l + length(str) + 1) &gt; 78</span><br><span class=\"line\">        fprintf(&#x27;\\n&#x27;);</span><br><span class=\"line\">        l = 0;</span><br><span class=\"line\">    end</span><br><span class=\"line\">    fprintf(&#x27;%s &#x27;, str);</span><br><span class=\"line\">    l = l + length(str) + 1;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Print footer</span><br><span class=\"line\">fprintf(&#x27;\\n\\n=========================\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"getVocabList-m\"><a href=\"#getVocabList-m\" class=\"headerlink\" title=\"getVocabList.m\"></a>getVocabList.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function vocabList = getVocabList()</span><br><span class=\"line\">%GETVOCABLIST reads the fixed vocabulary list in vocab.txt and returns a</span><br><span class=\"line\">%cell array of the words</span><br><span class=\"line\">%   vocabList = GETVOCABLIST() reads the fixed vocabulary list in vocab.txt </span><br><span class=\"line\">%   and returns a cell array of the words in vocabList.</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% Read the fixed vocabulary list</span><br><span class=\"line\">fid = fopen(&#x27;vocab.txt&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Store all dictionary words in cell array vocab&#123;&#125;</span><br><span class=\"line\">n = 1899;  % Total number of words in the dictionary</span><br><span class=\"line\"></span><br><span class=\"line\">% For ease of implementation, we use a struct to map the strings =&gt; integers</span><br><span class=\"line\">% In practice, you&#x27;ll want to use some form of hashmap</span><br><span class=\"line\">vocabList = cell(n, 1);</span><br><span class=\"line\">for i = 1:n</span><br><span class=\"line\">    % Word Index (can ignore since it will be = i)</span><br><span class=\"line\">    fscanf(fid, &#x27;%d&#x27;, 1);</span><br><span class=\"line\">    % Actual Word</span><br><span class=\"line\">    vocabList&#123;i&#125; = fscanf(fid, &#x27;%s&#x27;, 1);</span><br><span class=\"line\">end</span><br><span class=\"line\">fclose(fid);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"linearKernel-m\"><a href=\"#linearKernel-m\" class=\"headerlink\" title=\"linearKernel.m\"></a>linearKernel.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function sim = linearKernel(x1, x2)</span><br><span class=\"line\">%LINEARKERNEL returns a linear kernel between x1 and x2</span><br><span class=\"line\">%   sim = linearKernel(x1, x2) returns a linear kernel between x1 and x2</span><br><span class=\"line\">%   and returns the value in sim</span><br><span class=\"line\"></span><br><span class=\"line\">% Ensure that x1 and x2 are column vectors</span><br><span class=\"line\">x1 = x1(:); x2 = x2(:);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute the kernel</span><br><span class=\"line\">sim = x1&#x27; * x2;  % dot product</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"visulizeBoundaryLinear-m\"><a href=\"#visulizeBoundaryLinear-m\" class=\"headerlink\" title=\"visulizeBoundaryLinear.m\"></a>visulizeBoundaryLinear.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function visualizeBoundaryLinear(X, y, model)</span><br><span class=\"line\">%VISUALIZEBOUNDARYLINEAR plots a linear decision boundary learned by the</span><br><span class=\"line\">%SVM</span><br><span class=\"line\">%   VISUALIZEBOUNDARYLINEAR(X, y, model) plots a linear decision boundary </span><br><span class=\"line\">%   learned by the SVM and overlays the data on it</span><br><span class=\"line\"></span><br><span class=\"line\">w = model.w;</span><br><span class=\"line\">b = model.b;</span><br><span class=\"line\">xp = linspace(min(X(:,1)), max(X(:,1)), 100);</span><br><span class=\"line\">yp = - (w(1)*xp + b)/w(2);</span><br><span class=\"line\">plotData(X, y);</span><br><span class=\"line\">hold on;</span><br><span class=\"line\">plot(xp, yp, &#x27;-b&#x27;); </span><br><span class=\"line\">hold off</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"plotData-m\"><a href=\"#plotData-m\" class=\"headerlink\" title=\"plotData.m\"></a>plotData.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function plotData(X, y)</span><br><span class=\"line\">%PLOTDATA Plots the data points X and y into a new figure </span><br><span class=\"line\">%   PLOTDATA(x,y) plots the data points with + for the positive examples</span><br><span class=\"line\">%   and o for the negative examples. X is assumed to be a Mx2 matrix.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: This was slightly modified such that it expects y = 1 or y = 0</span><br><span class=\"line\"></span><br><span class=\"line\">% Find Indices of Positive and Negative Examples</span><br><span class=\"line\">pos = find(y == 1); neg = find(y == 0);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot Examples</span><br><span class=\"line\">plot(X(pos, 1), X(pos, 2), &#x27;k+&#x27;,&#x27;LineWidth&#x27;, 1, &#x27;MarkerSize&#x27;, 7)</span><br><span class=\"line\">hold on;</span><br><span class=\"line\">plot(X(neg, 1), X(neg, 2), &#x27;ko&#x27;, &#x27;MarkerFaceColor&#x27;, &#x27;y&#x27;, &#x27;MarkerSize&#x27;, 7)</span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"porterStemmer-m\"><a href=\"#porterStemmer-m\" class=\"headerlink\" title=\"porterStemmer.m\"></a>porterStemmer.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function plotData(X, y)</span><br><span class=\"line\">%PLOTDATA Plots the data points X and y into a new figure </span><br><span class=\"line\">%   PLOTDATA(x,y) plots the data points with + for the positive examples</span><br><span class=\"line\">%   and o for the negative examples. X is assumed to be a Mx2 matrix.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: This was slightly modified such that it expects y = 1 or y = 0</span><br><span class=\"line\"></span><br><span class=\"line\">% Find Indices of Positive and Negative Examples</span><br><span class=\"line\">pos = find(y == 1); neg = find(y == 0);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot Examples</span><br><span class=\"line\">plot(X(pos, 1), X(pos, 2), &#x27;k+&#x27;,&#x27;LineWidth&#x27;, 1, &#x27;MarkerSize&#x27;, 7)</span><br><span class=\"line\">hold on;</span><br><span class=\"line\">plot(X(neg, 1), X(neg, 2), &#x27;ko&#x27;, &#x27;MarkerFaceColor&#x27;, &#x27;y&#x27;, &#x27;MarkerSize&#x27;, 7)</span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-02-Linear Algebra Review","url":"/2022/08/12/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 02-线性代数回顾(Linear Algebra Review)。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"矩阵和向量-Matrices-and-Vectors\"><a href=\"#矩阵和向量-Matrices-and-Vectors\" class=\"headerlink\" title=\"矩阵和向量(Matrices and Vectors)\"></a>矩阵和向量(Matrices and Vectors)</h1><p><strong>矩阵</strong>： 矩阵(Matrix)是一个按照长方阵列排列的复数或实数集合。例如：<br>$$<br>\\begin{bmatrix}<br>1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9<br>\\end{bmatrix}<br>$$<br><strong>向量</strong>：向量(Vector)是一个维度为nx1的矩阵。比如：<br>$$<br>\\begin{bmatrix}<br>1 \\\\ 2 \\\\ 3<br>\\end{bmatrix}<br>$$</p>\n<h1 id=\"矩阵的加法-Matrix-Addition\"><a href=\"#矩阵的加法-Matrix-Addition\" class=\"headerlink\" title=\"矩阵的加法(Matrix Addition)\"></a>矩阵的加法(Matrix Addition)</h1><p>只有维度相同的矩阵才可以做加法，相加时把对应的元素相加即可。例如：<br>$$<br>\\begin{bmatrix}<br>1&amp;0 \\\\ 2&amp;5 \\\\ 3&amp;1<br>\\end{bmatrix}+ \\begin{bmatrix}<br>4&amp;0.5 \\\\ 2&amp;5 \\\\ 0&amp;1<br>\\end{bmatrix}<br>&#x3D; \\begin{bmatrix}<br>5&amp;0.5 \\\\ 4&amp;10 \\\\ 3&amp;2<br>\\end{bmatrix}<br>$$</p>\n<h1 id=\"标量乘法-Scalar-Multiplication\"><a href=\"#标量乘法-Scalar-Multiplication\" class=\"headerlink\" title=\"标量乘法(Scalar Multiplication)\"></a>标量乘法(Scalar Multiplication)</h1><p>$$<br>3\\times\\begin{bmatrix}<br>1 \\\\ 4 \\\\ 2<br>\\end{bmatrix}<br>&#x3D;\\begin{bmatrix}<br>3 \\\\ 12 \\\\ 6<br>\\end{bmatrix}<br>$$</p>\n<h1 id=\"矩阵乘法-Matrix-matrix-Multiplication\"><a href=\"#矩阵乘法-Matrix-matrix-Multiplication\" class=\"headerlink\" title=\"矩阵乘法(Matrix-matrix Multiplication)\"></a>矩阵乘法(Matrix-matrix Multiplication)</h1><p>设A为\\(m\\times p\\)的矩阵，B为\\(p\\times n\\)的矩阵，那么称\\(m\\times n\\)的矩阵C为矩阵A与B的乘积，记作\\(C&#x3D;A\\times B\\)，其中矩阵C中的第i行第j列元素可以表示为：<br>$$ (AB)_{ij} &#x3D; \\sum_{k&#x3D;1}^{p}(a_{ik}b_{kj})&#x3D;a_{i1}b_{1j}+a_{i2}b_{2j}+…+a_{ip}b_{pj}$$<br>例如：<br>$$<br>\\begin{bmatrix}<br>1 &amp;3&amp;2\\\\ 4&amp;0&amp;1<br>\\end{bmatrix}\\times<br>\\begin{bmatrix}<br>1 &amp;3\\\\ 0&amp;1 \\\\5&amp;2<br>\\end{bmatrix}<br>&#x3D;\\begin{bmatrix}<br>1\\times 1+3\\times 0+2\\times 5 &amp; 1\\times 3+3\\times 1+2\\times 2\\\\ 4\\times 1+0\\times 0+1\\times 5 &amp; 4\\times 3+0\\times 1+1\\times 2<br>\\end{bmatrix}<br>&#x3D;\\begin{bmatrix}<br>11 &amp;10 \\\\ 9 &amp;14<br>\\end{bmatrix}<br>$$<br>注意：</p>\n<ol>\n<li>当矩阵A的列数（column）等于矩阵B的行数（row）时，A与B可以相乘。</li>\n<li>矩阵C的行数等于矩阵A的行数，C的列数等于B的列数。</li>\n<li>乘积C的第m行第n列的元素等于矩阵A的第m行的元素与矩阵B的第n列对应元素乘积之和。</li>\n</ol>\n<h1 id=\"矩阵乘法的基本性质\"><a href=\"#矩阵乘法的基本性质\" class=\"headerlink\" title=\"矩阵乘法的基本性质\"></a>矩阵乘法的基本性质</h1><ul>\n<li>乘法结合律： \\((AB)C&#x3D;A(BC)\\)．</li>\n<li>乘法左分配律：\\((A+B)C&#x3D;AC+BC\\)</li>\n<li>乘法右分配律：\\(C(A+B)&#x3D;CA+CB\\)</li>\n<li>对数乘的结合性<em>k</em>\\((AB)\\)&#x3D;(<em>k</em>\\(A)B\\)&#x3D;\\(A(\\)<em>k</em>\\(B)\\)．</li>\n<li>转置 \\((AB)^T\\)&#x3D;\\(B^TA^T\\)．</li>\n</ul>\n<p>通常情况下，矩阵乘法不可以使用交换律，也就是：<br>$$A\\times B \\neq B\\times A $$</p>\n<p>但在以下两种情况下满足交换律。</p>\n<ul>\n<li>\\(AA^*&#x3D;A^*A\\)，A和伴随矩阵相乘满足交换律。</li>\n<li>\\(AI&#x3D;IA\\)，A和单位矩阵或数量矩阵满足交换律。</li>\n</ul>\n<h1 id=\"单位矩阵-Identity-Matrix\"><a href=\"#单位矩阵-Identity-Matrix\" class=\"headerlink\" title=\"单位矩阵(Identity Matrix)\"></a>单位矩阵(Identity Matrix)</h1><p>在矩阵的乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的1，这种矩阵被称为单位矩阵。 它是个方阵，从左上角到右下角的对角线（称为主对角线）上的元素均为1。 除此以外全都为0。单位矩阵使用\\(I\\)或者\\(I_{n\\times n}\\)来表示。例如：<br>$$<br>\\begin{bmatrix}<br>1 &amp;0&amp;0\\\\ 0&amp;1&amp;0\\\\ 0&amp;0&amp;1<br>\\end{bmatrix}<br>$$</p>\n<h1 id=\"转置矩阵-Matrix-Transpose-和逆矩阵-Matrix-Inverse\"><a href=\"#转置矩阵-Matrix-Transpose-和逆矩阵-Matrix-Inverse\" class=\"headerlink\" title=\"转置矩阵(Matrix Transpose)和逆矩阵(Matrix Inverse)\"></a>转置矩阵(Matrix Transpose)和逆矩阵(Matrix Inverse)</h1><p><strong>转置矩阵</strong>：将矩阵的行列互换得到的新矩阵称为转置矩阵。例如：<br>$$<br>A&#x3D;\\begin{bmatrix}<br>1&amp;2&amp;0\\\\3&amp;5&amp;9<br>\\end{bmatrix}<br>\\ \\ \\ \\ \\ \\<br>B&#x3D;A^T&#x3D;\\begin{bmatrix}<br>1&amp;3\\\\2&amp;5\\\\0&amp;9<br>\\end{bmatrix}<br>$$<br>则B为A的转置矩阵。</p>\n<p><strong>逆矩阵</strong>：实数有倒数，逆矩阵也是相同的概念，当我们把矩阵与其逆矩阵相乘，得到的是单位矩阵。例如：<br>$$A\\times A^{-1}&#x3D;I$$<br>这里我们用\\(A^{-1}\\)来表示A的逆矩阵。举例如下：<br>$$<br>A&#x3D;\\begin{bmatrix}<br>3&amp;4\\\\2&amp;16<br>\\end{bmatrix}<br>\\ \\ \\ \\ \\ \\<br>B&#x3D;A^{-1}&#x3D;\\begin{bmatrix}<br>0.4&amp;-0.1\\\\-0.05&amp;0.075<br>\\end{bmatrix}<br>$$</p>\n<p>$$<br>A\\times B &#x3D; A\\times A^{-1} &#x3D;<br>\\begin{bmatrix}<br>1&amp;0\\\\0&amp;1<br>\\end{bmatrix}<br>$$</p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-18-exercise 7 summuary","url":"/2022/09/06/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-18/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 18-exercise 7 summuary。</p>\n<span id=\"more\"></span>\n<p><strong>Programming Exercise 7: K-means Clustering and Principal Component Analysis</strong></p>\n<p>In this exercise, you will implement the K-means clustering algorithm and apply it to compress an image. </p>\n<p>In the second part, you will use principal component analysis to find a low-dimensional representation of face images.</p>\n<h1 id=\"ex7-m\"><a href=\"#ex7-m\" class=\"headerlink\" title=\"ex7.m\"></a>ex7.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class</span><br><span class=\"line\">%  Exercise 7 | Principle Component Analysis and K-Means Clustering</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">%</span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  exercise. You will need to complete the following functions:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     pca.m</span><br><span class=\"line\">%     projectData.m</span><br><span class=\"line\">%     recoverData.m</span><br><span class=\"line\">%     computeCentroids.m</span><br><span class=\"line\">%     findClosestCentroids.m</span><br><span class=\"line\">%     kMeansInitCentroids.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================= Part 1: Find Closest Centroids ====================</span><br><span class=\"line\">%  To help you implement K-Means, we have divided the learning algorithm </span><br><span class=\"line\">%  into two functions -- findClosestCentroids and computeCentroids. In this</span><br><span class=\"line\">%  part, you should complete the code in the findClosestCentroids function. </span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;Finding closest centroids.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Load an example dataset that we will be using</span><br><span class=\"line\">load(&#x27;ex7data2.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Select an initial set of centroids</span><br><span class=\"line\">K = 3; % 3 Centroids</span><br><span class=\"line\">initial_centroids = [3 3; 6 2; 8 5];</span><br><span class=\"line\"></span><br><span class=\"line\">% Find the closest centroids for the examples using the</span><br><span class=\"line\">% initial_centroids</span><br><span class=\"line\">idx = findClosestCentroids(X, initial_centroids);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Closest centroids for the first 3 examples: \\n&#x27;)</span><br><span class=\"line\">fprintf(&#x27; %d&#x27;, idx(1:3));</span><br><span class=\"line\">fprintf(&#x27;\\n(the closest centroids should be 1, 3, 2 respectively)\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ===================== Part 2: Compute Means =========================</span><br><span class=\"line\">%  After implementing the closest centroids function, you should now</span><br><span class=\"line\">%  complete the computeCentroids function.</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;\\nComputing centroids means.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Compute means based on the closest centroids found in the previous part.</span><br><span class=\"line\">centroids = computeCentroids(X, idx, K);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Centroids computed after initial finding of closest centroids: \\n&#x27;)</span><br><span class=\"line\">fprintf(&#x27; %f %f \\n&#x27; , centroids&#x27;);</span><br><span class=\"line\">fprintf(&#x27;\\n(the centroids should be\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;   [ 2.428301 3.157924 ]\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;   [ 5.813503 2.633656 ]\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;   [ 7.119387 3.616684 ]\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =================== Part 3: K-Means Clustering ======================</span><br><span class=\"line\">%  After you have completed the two functions computeCentroids and</span><br><span class=\"line\">%  findClosestCentroids, you have all the necessary pieces to run the</span><br><span class=\"line\">%  kMeans algorithm. In this part, you will run the K-Means algorithm on</span><br><span class=\"line\">%  the example dataset we have provided. </span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;\\nRunning K-Means clustering on example dataset.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Load an example dataset</span><br><span class=\"line\">load(&#x27;ex7data2.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Settings for running K-Means</span><br><span class=\"line\">K = 3;</span><br><span class=\"line\">max_iters = 10;</span><br><span class=\"line\"></span><br><span class=\"line\">% For consistency, here we set centroids to specific values</span><br><span class=\"line\">% but in practice you want to generate them automatically, such as by</span><br><span class=\"line\">% settings them to be random examples (as can be seen in</span><br><span class=\"line\">% kMeansInitCentroids).</span><br><span class=\"line\">initial_centroids = [3 3; 6 2; 8 5];</span><br><span class=\"line\"></span><br><span class=\"line\">% Run K-Means algorithm. The &#x27;true&#x27; at the end tells our function to plot</span><br><span class=\"line\">% the progress of K-Means</span><br><span class=\"line\">[centroids, idx] = runkMeans(X, initial_centroids, max_iters, true);</span><br><span class=\"line\">fprintf(&#x27;\\nK-Means Done.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ============= Part 4: K-Means Clustering on Pixels ===============</span><br><span class=\"line\">%  In this exercise, you will use K-Means to compress an image. To do this,</span><br><span class=\"line\">%  you will first run K-Means on the colors of the pixels in the image and</span><br><span class=\"line\">%  then you will map each pixel onto its closest centroid.</span><br><span class=\"line\">%  </span><br><span class=\"line\">%  You should now complete the code in kMeansInitCentroids.m</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nRunning K-Means clustering on pixels from an image.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Load an image of a bird</span><br><span class=\"line\">A = double(imread(&#x27;bird_small.png&#x27;));</span><br><span class=\"line\"></span><br><span class=\"line\">% If imread does not work for you, you can try instead</span><br><span class=\"line\">%   load (&#x27;bird_small.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">A = A / 255; % Divide by 255 so that all values are in the range 0 - 1</span><br><span class=\"line\"></span><br><span class=\"line\">% Size of the image</span><br><span class=\"line\">img_size = size(A);</span><br><span class=\"line\"></span><br><span class=\"line\">% Reshape the image into an Nx3 matrix where N = number of pixels.</span><br><span class=\"line\">% Each row will contain the Red, Green and Blue pixel values</span><br><span class=\"line\">% This gives us our dataset matrix X that we will use K-Means on.</span><br><span class=\"line\">X = reshape(A, img_size(1) * img_size(2), 3);</span><br><span class=\"line\"></span><br><span class=\"line\">% Run your K-Means algorithm on this data</span><br><span class=\"line\">% You should try different values of K and max_iters here</span><br><span class=\"line\">K = 16; </span><br><span class=\"line\">max_iters = 10;</span><br><span class=\"line\"></span><br><span class=\"line\">% When using K-Means, it is important the initialize the centroids</span><br><span class=\"line\">% randomly. </span><br><span class=\"line\">% You should complete the code in kMeansInitCentroids.m before proceeding</span><br><span class=\"line\">initial_centroids = kMeansInitCentroids(X, K);</span><br><span class=\"line\"></span><br><span class=\"line\">% Run K-Means</span><br><span class=\"line\">[centroids, idx] = runkMeans(X, initial_centroids, max_iters);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================= Part 5: Image Compression ======================</span><br><span class=\"line\">%  In this part of the exercise, you will use the clusters of K-Means to</span><br><span class=\"line\">%  compress an image. To do this, we first find the closest clusters for</span><br><span class=\"line\">%  each example. After that, we </span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nApplying K-Means to compress an image.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Find closest cluster members</span><br><span class=\"line\">idx = findClosestCentroids(X, centroids);</span><br><span class=\"line\"></span><br><span class=\"line\">% Essentially, now we have represented the image X as in terms of the</span><br><span class=\"line\">% indices in idx. </span><br><span class=\"line\"></span><br><span class=\"line\">% We can now recover the image from the indices (idx) by mapping each pixel</span><br><span class=\"line\">% (specified by its index in idx) to the centroid value</span><br><span class=\"line\">X_recovered = centroids(idx,:);</span><br><span class=\"line\"></span><br><span class=\"line\">% Reshape the recovered image into proper dimensions</span><br><span class=\"line\">X_recovered = reshape(X_recovered, img_size(1), img_size(2), 3);</span><br><span class=\"line\"></span><br><span class=\"line\">% Display the original image </span><br><span class=\"line\">subplot(1, 2, 1);</span><br><span class=\"line\">imagesc(A); </span><br><span class=\"line\">title(&#x27;Original&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Display compressed image side by side</span><br><span class=\"line\">subplot(1, 2, 2);</span><br><span class=\"line\">imagesc(X_recovered)</span><br><span class=\"line\">title(sprintf(&#x27;Compressed, with %d colors.&#x27;, K));</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"findClosestCentroids-m\"><a href=\"#findClosestCentroids-m\" class=\"headerlink\" title=\"findClosestCentroids.m\"></a>findClosestCentroids.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function idx = findClosestCentroids(X, centroids)</span><br><span class=\"line\">%FINDCLOSESTCENTROIDS computes the centroid memberships for every example</span><br><span class=\"line\">%   idx = FINDCLOSESTCENTROIDS (X, centroids) returns the closest centroids</span><br><span class=\"line\">%   in idx for a dataset X where each row is a single example. idx = m x 1 </span><br><span class=\"line\">%   vector of centroid assignments (i.e. each entry in range [1..K])</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Set K</span><br><span class=\"line\">K = size(centroids, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly.</span><br><span class=\"line\">idx = zeros(size(X,1), 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Go over every example, find its closest centroid, and store</span><br><span class=\"line\">%               the index inside idx at the appropriate location.</span><br><span class=\"line\">%               Concretely, idx(i) should contain the index of the centroid</span><br><span class=\"line\">%               closest to example i. Hence, it should be a value in the </span><br><span class=\"line\">%               range 1..K</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: You can use a for-loop over the examples to compute this.</span><br><span class=\"line\">%</span><br><span class=\"line\">m = size(X,1);</span><br><span class=\"line\"></span><br><span class=\"line\">for i = 1:m</span><br><span class=\"line\">  for j = 1:K</span><br><span class=\"line\">    dist(j) = sum((X(i,:)-centroids(j,:)).^2);</span><br><span class=\"line\">  end</span><br><span class=\"line\">  [d(i),idx(i)] = min(dist);</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"computeCentroids-m\"><a href=\"#computeCentroids-m\" class=\"headerlink\" title=\"computeCentroids.m\"></a>computeCentroids.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function centroids = computeCentroids(X, idx, K)</span><br><span class=\"line\">%COMPUTECENTROIDS returns the new centroids by computing the means of the </span><br><span class=\"line\">%data points assigned to each centroid.</span><br><span class=\"line\">%   centroids = COMPUTECENTROIDS(X, idx, K) returns the new centroids by </span><br><span class=\"line\">%   computing the means of the data points assigned to each centroid. It is</span><br><span class=\"line\">%   given a dataset X where each row is a single data point, a vector</span><br><span class=\"line\">%   idx of centroid assignments (i.e. each entry in range [1..K]) for each</span><br><span class=\"line\">%   example, and K, the number of centroids. You should return a matrix</span><br><span class=\"line\">%   centroids, where each row of centroids is the mean of the data points</span><br><span class=\"line\">%   assigned to it.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Useful variables</span><br><span class=\"line\">[m n] = size(X);</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly.</span><br><span class=\"line\">centroids = zeros(K, n);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Go over every centroid and compute mean of all points that</span><br><span class=\"line\">%               belong to it. Concretely, the row vector centroids(i, :)</span><br><span class=\"line\">%               should contain the mean of the data points assigned to</span><br><span class=\"line\">%               centroid i.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: You can use a for-loop over the centroids to compute this.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">Y = zeros(K,n);</span><br><span class=\"line\">a = zeros(K,1);</span><br><span class=\"line\"></span><br><span class=\"line\">for i = 1:m</span><br><span class=\"line\">  for j = 1:K</span><br><span class=\"line\">    if idx(i) == j</span><br><span class=\"line\">      Y(j,:) = Y(j,:) + X(i,:);</span><br><span class=\"line\">      a(j) = a(j)+1;</span><br><span class=\"line\">    centroids(j,:) = Y(j,:)./a(j);</span><br><span class=\"line\">    end</span><br><span class=\"line\">  end</span><br><span class=\"line\">end </span><br><span class=\"line\"></span><br><span class=\"line\">% Alternative solution</span><br><span class=\"line\"></span><br><span class=\"line\">% for i = 1:K</span><br><span class=\"line\">%    X_i = X(idx == i, :);</span><br><span class=\"line\">%    centroids(i,:) = mean(X_i, 1);</span><br><span class=\"line\">% end</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"runkMeans-m\"><a href=\"#runkMeans-m\" class=\"headerlink\" title=\"runkMeans.m\"></a>runkMeans.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [centroids, idx] = runkMeans(X, initial_centroids, ...</span><br><span class=\"line\">                                      max_iters, plot_progress)</span><br><span class=\"line\">%RUNKMEANS runs the K-Means algorithm on data matrix X, where each row of X</span><br><span class=\"line\">%is a single example</span><br><span class=\"line\">%   [centroids, idx] = RUNKMEANS(X, initial_centroids, max_iters, ...</span><br><span class=\"line\">%   plot_progress) runs the K-Means algorithm on data matrix X, where each </span><br><span class=\"line\">%   row of X is a single example. It uses initial_centroids used as the</span><br><span class=\"line\">%   initial centroids. max_iters specifies the total number of interactions </span><br><span class=\"line\">%   of K-Means to execute. plot_progress is a true/false flag that </span><br><span class=\"line\">%   indicates if the function should also plot its progress as the </span><br><span class=\"line\">%   learning happens. This is set to false by default. runkMeans returns </span><br><span class=\"line\">%   centroids, a Kxn matrix of the computed centroids and idx, a m x 1 </span><br><span class=\"line\">%   vector of centroid assignments (i.e. each entry in range [1..K])</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Set default value for plot progress</span><br><span class=\"line\">if ~exist(&#x27;plot_progress&#x27;, &#x27;var&#x27;) || isempty(plot_progress)</span><br><span class=\"line\">    plot_progress = false;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot the data if we are plotting progress</span><br><span class=\"line\">if plot_progress</span><br><span class=\"line\">    figure;</span><br><span class=\"line\">    hold on;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize values</span><br><span class=\"line\">[m n] = size(X);</span><br><span class=\"line\">K = size(initial_centroids, 1);</span><br><span class=\"line\">centroids = initial_centroids;</span><br><span class=\"line\">previous_centroids = centroids;</span><br><span class=\"line\">idx = zeros(m, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Run K-Means</span><br><span class=\"line\">for i=1:max_iters</span><br><span class=\"line\">    </span><br><span class=\"line\">    % Output progress</span><br><span class=\"line\">    fprintf(&#x27;K-Means iteration %d/%d...\\n&#x27;, i, max_iters);</span><br><span class=\"line\">    if exist(&#x27;OCTAVE_VERSION&#x27;)</span><br><span class=\"line\">        fflush(stdout);</span><br><span class=\"line\">    end</span><br><span class=\"line\">    </span><br><span class=\"line\">    % For each example in X, assign it to the closest centroid</span><br><span class=\"line\">    idx = findClosestCentroids(X, centroids);</span><br><span class=\"line\">    </span><br><span class=\"line\">    % Optionally, plot progress here</span><br><span class=\"line\">    if plot_progress</span><br><span class=\"line\">        plotProgresskMeans(X, centroids, previous_centroids, idx, K, i);</span><br><span class=\"line\">        previous_centroids = centroids;</span><br><span class=\"line\">        fprintf(&#x27;Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">        pause;</span><br><span class=\"line\">    end</span><br><span class=\"line\">    </span><br><span class=\"line\">    % Given the memberships, compute new centroids</span><br><span class=\"line\">    centroids = computeCentroids(X, idx, K);</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Hold off if we are plotting progress</span><br><span class=\"line\">if plot_progress</span><br><span class=\"line\">    hold off;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"featureNormalize-m\"><a href=\"#featureNormalize-m\" class=\"headerlink\" title=\"featureNormalize.m\"></a>featureNormalize.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [X_norm, mu, sigma] = featureNormalize(X)</span><br><span class=\"line\">%FEATURENORMALIZE Normalizes the features in X </span><br><span class=\"line\">%   FEATURENORMALIZE(X) returns a normalized version of X where</span><br><span class=\"line\">%   the mean value of each feature is 0 and the standard deviation</span><br><span class=\"line\">%   is 1. This is often a good preprocessing step to do when</span><br><span class=\"line\">%   working with learning algorithms.</span><br><span class=\"line\"></span><br><span class=\"line\">mu = mean(X);</span><br><span class=\"line\">X_norm = bsxfun(@minus, X, mu);</span><br><span class=\"line\"></span><br><span class=\"line\">sigma = std(X_norm);</span><br><span class=\"line\">X_norm = bsxfun(@rdivide, X_norm, sigma);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% ============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"kMeansInitCentroids-m\"><a href=\"#kMeansInitCentroids-m\" class=\"headerlink\" title=\"kMeansInitCentroids.m\"></a>kMeansInitCentroids.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function centroids = kMeansInitCentroids(X, K)</span><br><span class=\"line\">%KMEANSINITCENTROIDS This function initializes K centroids that are to be </span><br><span class=\"line\">%used in K-Means on the dataset X</span><br><span class=\"line\">%   centroids = KMEANSINITCENTROIDS(X, K) returns K initial centroids to be</span><br><span class=\"line\">%   used with the K-Means on the dataset X</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% You should return this values correctly</span><br><span class=\"line\">centroids = zeros(K, size(X, 2));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: You should set centroids to randomly chosen examples from</span><br><span class=\"line\">%               the dataset X</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize the centroids to be random examples</span><br><span class=\"line\">% Randomly reorder the indices of examples</span><br><span class=\"line\"></span><br><span class=\"line\">randidx = randperm(size(X, 1));</span><br><span class=\"line\"></span><br><span class=\"line\">% Take the first K examples as centroids</span><br><span class=\"line\"></span><br><span class=\"line\">centroids = X(randidx(1:K), :);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"ex7-pca-m\"><a href=\"#ex7-pca-m\" class=\"headerlink\" title=\"ex7_pca.m\"></a>ex7_pca.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class</span><br><span class=\"line\">%  Exercise 7 | Principle Component Analysis and K-Means Clustering</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">%</span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  exercise. You will need to complete the following functions:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     pca.m</span><br><span class=\"line\">%     projectData.m</span><br><span class=\"line\">%     recoverData.m</span><br><span class=\"line\">%     computeCentroids.m</span><br><span class=\"line\">%     findClosestCentroids.m</span><br><span class=\"line\">%     kMeansInitCentroids.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================== Part 1: Load Example Dataset  ===================</span><br><span class=\"line\">%  We start this exercise by using a small dataset that is easily to</span><br><span class=\"line\">%  visualize</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;Visualizing example dataset for PCA.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  The following command loads the dataset. You should now have the </span><br><span class=\"line\">%  variable X in your environment</span><br><span class=\"line\">load (&#x27;ex7data1.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Visualize the example dataset</span><br><span class=\"line\">plot(X(:, 1), X(:, 2), &#x27;bo&#x27;);</span><br><span class=\"line\">axis([0.5 6.5 2 8]); axis square;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 2: Principal Component Analysis ===============</span><br><span class=\"line\">%  You should now implement PCA, a dimension reduction technique. You</span><br><span class=\"line\">%  should complete the code in pca.m</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;\\nRunning PCA on example dataset.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Before running PCA, it is important to first normalize X</span><br><span class=\"line\">[X_norm, mu, sigma] = featureNormalize(X);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Run PCA</span><br><span class=\"line\">[U, S] = pca(X_norm);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Compute mu, the mean of the each feature</span><br><span class=\"line\"></span><br><span class=\"line\">%  Draw the eigenvectors centered at mean of data. These lines show the</span><br><span class=\"line\">%  directions of maximum variations in the dataset.</span><br><span class=\"line\">hold on;</span><br><span class=\"line\">drawLine(mu, mu + 1.5 * S(1,1) * U(:,1)&#x27;, &#x27;-k&#x27;, &#x27;LineWidth&#x27;, 2);</span><br><span class=\"line\">drawLine(mu, mu + 1.5 * S(2,2) * U(:,2)&#x27;, &#x27;-k&#x27;, &#x27;LineWidth&#x27;, 2);</span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Top eigenvector: \\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; U(:,1) = %f %f \\n&#x27;, U(1,1), U(2,1));</span><br><span class=\"line\">fprintf(&#x27;\\n(you should expect to see -0.707107 -0.707107)\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =================== Part 3: Dimension Reduction ===================</span><br><span class=\"line\">%  You should now implement the projection step to map the data onto the </span><br><span class=\"line\">%  first k eigenvectors. The code will then plot the data in this reduced </span><br><span class=\"line\">%  dimensional space.  This will show you what the data looks like when </span><br><span class=\"line\">%  using only the corresponding eigenvectors to reconstruct it.</span><br><span class=\"line\">%</span><br><span class=\"line\">%  You should complete the code in projectData.m</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;\\nDimension reduction on example dataset.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Plot the normalized dataset (returned from pca)</span><br><span class=\"line\">plot(X_norm(:, 1), X_norm(:, 2), &#x27;bo&#x27;);</span><br><span class=\"line\">axis([-4 3 -4 3]); axis square</span><br><span class=\"line\"></span><br><span class=\"line\">%  Project the data onto K = 1 dimension</span><br><span class=\"line\">K = 1;</span><br><span class=\"line\">Z = projectData(X_norm, U, K);</span><br><span class=\"line\">fprintf(&#x27;Projection of the first example: %f\\n&#x27;, Z(1));</span><br><span class=\"line\">fprintf(&#x27;\\n(this value should be about 1.481274)\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">X_rec  = recoverData(Z, U, K);</span><br><span class=\"line\">fprintf(&#x27;Approximation of the first example: %f %f\\n&#x27;, X_rec(1, 1), X_rec(1, 2));</span><br><span class=\"line\">fprintf(&#x27;\\n(this value should be about  -1.047419 -1.047419)\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Draw lines connecting the projected points to the original points</span><br><span class=\"line\">hold on;</span><br><span class=\"line\">plot(X_rec(:, 1), X_rec(:, 2), &#x27;ro&#x27;);</span><br><span class=\"line\">for i = 1:size(X_norm, 1)</span><br><span class=\"line\">    drawLine(X_norm(i,:), X_rec(i,:), &#x27;--k&#x27;, &#x27;LineWidth&#x27;, 1);</span><br><span class=\"line\">end</span><br><span class=\"line\">hold off</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 4: Loading and Visualizing Face Data =============</span><br><span class=\"line\">%  We start the exercise by first loading and visualizing the dataset.</span><br><span class=\"line\">%  The following code will load the dataset into your environment</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;\\nLoading face dataset.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Load Face dataset</span><br><span class=\"line\">load (&#x27;ex7faces.mat&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">%  Display the first 100 faces in the dataset</span><br><span class=\"line\">displayData(X(1:100, :));</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 5: PCA on Face Data: Eigenfaces  ===================</span><br><span class=\"line\">%  Run PCA and visualize the eigenvectors which are in this case eigenfaces</span><br><span class=\"line\">%  We display the first 36 eigenfaces.</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf([&#x27;\\nRunning PCA on face dataset.\\n&#x27; ...</span><br><span class=\"line\">         &#x27;(this might take a minute or two ...)\\n\\n&#x27;]);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Before running PCA, it is important to first normalize X by subtracting </span><br><span class=\"line\">%  the mean value from each feature</span><br><span class=\"line\">[X_norm, mu, sigma] = featureNormalize(X);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Run PCA</span><br><span class=\"line\">[U, S] = pca(X_norm);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Visualize the top 36 eigenvectors found</span><br><span class=\"line\">displayData(U(:, 1:36)&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ============= Part 6: Dimension Reduction for Faces =================</span><br><span class=\"line\">%  Project images to the eigen space using the top k eigenvectors </span><br><span class=\"line\">%  If you are applying a machine learning algorithm </span><br><span class=\"line\">fprintf(&#x27;\\nDimension reduction for face dataset.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">K = 100;</span><br><span class=\"line\">Z = projectData(X_norm, U, K);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;The projected data Z has a size of: &#x27;)</span><br><span class=\"line\">fprintf(&#x27;%d &#x27;, size(Z));</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\n\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ==== Part 7: Visualization of Faces after PCA Dimension Reduction ====</span><br><span class=\"line\">%  Project images to the eigen space using the top K eigen vectors and </span><br><span class=\"line\">%  visualize only using those K dimensions</span><br><span class=\"line\">%  Compare to the original input, which is also displayed</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nVisualizing the projected (reduced dimension) faces.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">K = 100;</span><br><span class=\"line\">X_rec  = recoverData(Z, U, K);</span><br><span class=\"line\"></span><br><span class=\"line\">% Display normalized data</span><br><span class=\"line\">subplot(1, 2, 1);</span><br><span class=\"line\">displayData(X_norm(1:100,:));</span><br><span class=\"line\">title(&#x27;Original faces&#x27;);</span><br><span class=\"line\">axis square;</span><br><span class=\"line\"></span><br><span class=\"line\">% Display reconstructed data from only k eigenfaces</span><br><span class=\"line\">subplot(1, 2, 2);</span><br><span class=\"line\">displayData(X_rec(1:100,:));</span><br><span class=\"line\">title(&#x27;Recovered faces&#x27;);</span><br><span class=\"line\">axis square;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% === Part 8(a): Optional (ungraded) Exercise: PCA for Visualization ===</span><br><span class=\"line\">%  One useful application of PCA is to use it to visualize high-dimensional</span><br><span class=\"line\">%  data. In the last K-Means exercise you ran K-Means on 3-dimensional </span><br><span class=\"line\">%  pixel colors of an image. We first visualize this output in 3D, and then</span><br><span class=\"line\">%  apply PCA to obtain a visualization in 2D.</span><br><span class=\"line\"></span><br><span class=\"line\">close all; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">% Reload the image from the previous exercise and run K-Means on it</span><br><span class=\"line\">% For this to work, you need to complete the K-Means assignment first</span><br><span class=\"line\">A = double(imread(&#x27;bird_small.png&#x27;));</span><br><span class=\"line\"></span><br><span class=\"line\">% If imread does not work for you, you can try instead</span><br><span class=\"line\">%   load (&#x27;bird_small.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">A = A / 255;</span><br><span class=\"line\">img_size = size(A);</span><br><span class=\"line\">X = reshape(A, img_size(1) * img_size(2), 3);</span><br><span class=\"line\">K = 16; </span><br><span class=\"line\">max_iters = 10;</span><br><span class=\"line\">initial_centroids = kMeansInitCentroids(X, K);</span><br><span class=\"line\">[centroids, idx] = runkMeans(X, initial_centroids, max_iters);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Sample 1000 random indexes (since working with all the data is</span><br><span class=\"line\">%  too expensive. If you have a fast computer, you may increase this.</span><br><span class=\"line\">sel = floor(rand(1000, 1) * size(X, 1)) + 1;</span><br><span class=\"line\"></span><br><span class=\"line\">%  Setup Color Palette</span><br><span class=\"line\">palette = hsv(K);</span><br><span class=\"line\">colors = palette(idx(sel), :);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Visualize the data and centroid memberships in 3D</span><br><span class=\"line\">figure;</span><br><span class=\"line\">scatter3(X(sel, 1), X(sel, 2), X(sel, 3), 10, colors);</span><br><span class=\"line\">title(&#x27;Pixel dataset plotted in 3D. Color shows centroid memberships&#x27;);</span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% === Part 8(b): Optional (ungraded) Exercise: PCA for Visualization ===</span><br><span class=\"line\">% Use PCA to project this cloud to 2D for visualization</span><br><span class=\"line\"></span><br><span class=\"line\">% Subtract the mean to use PCA</span><br><span class=\"line\">[X_norm, mu, sigma] = featureNormalize(X);</span><br><span class=\"line\"></span><br><span class=\"line\">% PCA and project the data to 2D</span><br><span class=\"line\">[U, S] = pca(X_norm);</span><br><span class=\"line\">Z = projectData(X_norm, U, 2);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot in 2D</span><br><span class=\"line\">figure;</span><br><span class=\"line\">plotDataPoints(Z(sel, :), idx(sel), K);</span><br><span class=\"line\">title(&#x27;Pixel dataset plotted in 2D, using PCA for dimensionality reduction&#x27;);</span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br></pre></td></tr></table></figure>\n<h1 id=\"displayData-m\"><a href=\"#displayData-m\" class=\"headerlink\" title=\"displayData.m\"></a>displayData.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [h, display_array] = displayData(X, example_width)</span><br><span class=\"line\">%DISPLAYDATA Display 2D data in a nice grid</span><br><span class=\"line\">%   [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data</span><br><span class=\"line\">%   stored in X in a nice grid. It returns the figure handle h and the </span><br><span class=\"line\">%   displayed array if requested.</span><br><span class=\"line\"></span><br><span class=\"line\">% Set example_width automatically if not passed in</span><br><span class=\"line\">if ~exist(&#x27;example_width&#x27;, &#x27;var&#x27;) || isempty(example_width) </span><br><span class=\"line\">  example_width = round(sqrt(size(X, 2)));</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Gray Image</span><br><span class=\"line\">colormap(gray);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute rows, cols</span><br><span class=\"line\">[m n] = size(X);</span><br><span class=\"line\">example_height = (n / example_width);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute number of items to display</span><br><span class=\"line\">display_rows = floor(sqrt(m));</span><br><span class=\"line\">display_cols = ceil(m / display_rows);</span><br><span class=\"line\"></span><br><span class=\"line\">% Between images padding</span><br><span class=\"line\">pad = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">% Setup blank display</span><br><span class=\"line\">display_array = - ones(pad + display_rows * (example_height + pad), ...</span><br><span class=\"line\">                       pad + display_cols * (example_width + pad));</span><br><span class=\"line\"></span><br><span class=\"line\">% Copy each example into a patch on the display array</span><br><span class=\"line\">curr_ex = 1;</span><br><span class=\"line\">for j = 1:display_rows</span><br><span class=\"line\">  for i = 1:display_cols</span><br><span class=\"line\">    if curr_ex &gt; m, </span><br><span class=\"line\">      break; </span><br><span class=\"line\">    end</span><br><span class=\"line\">    % Copy the patch</span><br><span class=\"line\">    </span><br><span class=\"line\">    % Get the max value of the patch</span><br><span class=\"line\">    max_val = max(abs(X(curr_ex, :)));</span><br><span class=\"line\">    display_array(pad + (j - 1) * (example_height + pad) + (1:example_height), ...</span><br><span class=\"line\">                  pad + (i - 1) * (example_width + pad) + (1:example_width)) = ...</span><br><span class=\"line\">            reshape(X(curr_ex, :), example_height, example_width) / max_val;</span><br><span class=\"line\">    curr_ex = curr_ex + 1;</span><br><span class=\"line\">  end</span><br><span class=\"line\">  if curr_ex &gt; m, </span><br><span class=\"line\">    break; </span><br><span class=\"line\">  end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Display Image</span><br><span class=\"line\">h = imagesc(display_array, [-1 1]);</span><br><span class=\"line\"></span><br><span class=\"line\">% Do not show axis</span><br><span class=\"line\">axis image off</span><br><span class=\"line\"></span><br><span class=\"line\">drawnow;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"drawLine-m\"><a href=\"#drawLine-m\" class=\"headerlink\" title=\"drawLine.m\"></a>drawLine.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function drawLine(p1, p2, varargin)</span><br><span class=\"line\">%DRAWLINE Draws a line from point p1 to point p2</span><br><span class=\"line\">%   DRAWLINE(p1, p2) Draws a line from point p1 to point p2 and holds the</span><br><span class=\"line\">%   current figure</span><br><span class=\"line\"></span><br><span class=\"line\">plot([p1(1) p2(1)], [p1(2) p2(2)], varargin&#123;:&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"pca-m\"><a href=\"#pca-m\" class=\"headerlink\" title=\"pca.m\"></a>pca.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [U, S] = pca(X)</span><br><span class=\"line\">%PCA Run principal component analysis on the dataset X</span><br><span class=\"line\">%   [U, S, X] = pca(X) computes eigenvectors of the covariance matrix of X</span><br><span class=\"line\">%   Returns the eigenvectors U, the eigenvalues (on diagonal) in S</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Useful values</span><br><span class=\"line\">[m, n] = size(X);</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly.</span><br><span class=\"line\">U = zeros(n);</span><br><span class=\"line\">S = zeros(n);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: You should first compute the covariance matrix. Then, you</span><br><span class=\"line\">%               should use the &quot;svd&quot; function to compute the eigenvectors</span><br><span class=\"line\">%               and eigenvalues of the covariance matrix. </span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: When computing the covariance matrix, remember to divide by m (the</span><br><span class=\"line\">%       number of examples).</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">sigma = 1/m*X&#x27;*X;</span><br><span class=\"line\">[U, S, V] = svd(sigma);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"plotDataPoints-m\"><a href=\"#plotDataPoints-m\" class=\"headerlink\" title=\"plotDataPoints.m\"></a>plotDataPoints.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function plotDataPoints(X, idx, K)</span><br><span class=\"line\">%PLOTDATAPOINTS plots data points in X, coloring them so that those with the same</span><br><span class=\"line\">%index assignments in idx have the same color</span><br><span class=\"line\">%   PLOTDATAPOINTS(X, idx, K) plots data points in X, coloring them so that those </span><br><span class=\"line\">%   with the same index assignments in idx have the same color</span><br><span class=\"line\"></span><br><span class=\"line\">% Create palette</span><br><span class=\"line\">palette = hsv(K + 1);</span><br><span class=\"line\">colors = palette(idx, :);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot the data</span><br><span class=\"line\">scatter(X(:,1), X(:,2), 15, colors);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"plotProgresskMeans-m\"><a href=\"#plotProgresskMeans-m\" class=\"headerlink\" title=\"plotProgresskMeans.m\"></a>plotProgresskMeans.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function plotProgresskMeans(X, centroids, previous, idx, K, i)</span><br><span class=\"line\">%PLOTPROGRESSKMEANS is a helper function that displays the progress of </span><br><span class=\"line\">%k-Means as it is running. It is intended for use only with 2D data.</span><br><span class=\"line\">%   PLOTPROGRESSKMEANS(X, centroids, previous, idx, K, i) plots the data</span><br><span class=\"line\">%   points with colors assigned to each centroid. With the previous</span><br><span class=\"line\">%   centroids, it also plots a line between the previous locations and</span><br><span class=\"line\">%   current locations of the centroids.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot the examples</span><br><span class=\"line\">plotDataPoints(X, idx, K);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot the centroids as black x&#x27;s</span><br><span class=\"line\">plot(centroids(:,1), centroids(:,2), &#x27;x&#x27;, ...</span><br><span class=\"line\">     &#x27;MarkerEdgeColor&#x27;,&#x27;k&#x27;, ...</span><br><span class=\"line\">     &#x27;MarkerSize&#x27;, 10, &#x27;LineWidth&#x27;, 3);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot the history of the centroids with lines</span><br><span class=\"line\">for j=1:size(centroids,1)</span><br><span class=\"line\">    drawLine(centroids(j, :), previous(j, :));</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">% Title</span><br><span class=\"line\">title(sprintf(&#x27;Iteration number %d&#x27;, i))</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"projectData-m\"><a href=\"#projectData-m\" class=\"headerlink\" title=\"projectData.m\"></a>projectData.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function Z = projectData(X, U, K)</span><br><span class=\"line\">%PROJECTDATA Computes the reduced data representation when projecting only </span><br><span class=\"line\">%on to the top k eigenvectors</span><br><span class=\"line\">%   Z = projectData(X, U, K) computes the projection of </span><br><span class=\"line\">%   the normalized inputs X into the reduced dimensional space spanned by</span><br><span class=\"line\">%   the first K columns of U. It returns the projected examples in Z.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly.</span><br><span class=\"line\">Z = zeros(size(X, 1), K);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the projection of the data using only the top K </span><br><span class=\"line\">%               eigenvectors in U (first K columns). </span><br><span class=\"line\">%               For the i-th example X(i,:), the projection on to the k-th </span><br><span class=\"line\">%               eigenvector is given as follows:</span><br><span class=\"line\">%                    x = X(i, :)&#x27;;</span><br><span class=\"line\">%                    projection_k = x&#x27; * U(:, k);</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">U_reduce = U(:,1:K);</span><br><span class=\"line\"></span><br><span class=\"line\">Z = X*U_reduce;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"recoverData-m\"><a href=\"#recoverData-m\" class=\"headerlink\" title=\"recoverData.m\"></a>recoverData.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function X_rec = recoverData(Z, U, K)</span><br><span class=\"line\">%RECOVERDATA Recovers an approximation of the original data when using the </span><br><span class=\"line\">%projected data</span><br><span class=\"line\">%   X_rec = RECOVERDATA(Z, U, K) recovers an approximation the </span><br><span class=\"line\">%   original data that has been reduced to K dimensions. It returns the</span><br><span class=\"line\">%   approximate reconstruction in X_rec.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly.</span><br><span class=\"line\">X_rec = zeros(size(Z, 1), size(U, 1));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the approximation of the data by projecting back</span><br><span class=\"line\">%               onto the original space using the top K eigenvectors in U.</span><br><span class=\"line\">%</span><br><span class=\"line\">%               For the i-th example Z(i,:), the (approximate)</span><br><span class=\"line\">%               recovered data for dimension j is given as follows:</span><br><span class=\"line\">%                    v = Z(i, :)&#x27;;</span><br><span class=\"line\">%                    recovered_j = v&#x27; * U(j, 1:K)&#x27;;</span><br><span class=\"line\">%</span><br><span class=\"line\">%               Notice that U(j, 1:K) is a row vector.</span><br><span class=\"line\">%               </span><br><span class=\"line\"></span><br><span class=\"line\">U_reduce = U(:,1:K);</span><br><span class=\"line\">X_rec = Z*U_reduce&#x27;;</span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-19-Anomaly Detection","url":"/2022/09/11/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-19/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 19-异常检测(Anomaly Detection)。</p>\n<span id=\"more\"></span>\n\n<h1 id=\"问题的动机\"><a href=\"#问题的动机\" class=\"headerlink\" title=\"问题的动机\"></a>问题的动机</h1><h2 id=\"什么是异常检测？\"><a href=\"#什么是异常检测？\" class=\"headerlink\" title=\"什么是异常检测？\"></a>什么是异常检测？</h2><p>异常检测(Anomaly Detection)问题是机器学习算法的一个常见的应用。这种算法的一个有趣之处在于：它虽然主要用于非监督学习问题，但从某些角度看，它又类似于一些监督学习问题。</p>\n<p>我们来举例说明：</p>\n<p>假想你是一个飞机引擎制造商，当你生产的飞机引擎从生产线上流出时，你需要进行QA(质量控制测试)，而作为这个测试的一部分，你测量了飞机引擎的一些特征变量，比如引擎运转时产生的热量，或者引擎的振动等等。这样一来，你就有了一个数据集，从\\(x^{(1)}\\)到\\(x^{(m)}\\)，你将这些数据绘制成图表，看起来就是这个样子：</p>\n<p><img src=\"/../images/anomalyDetection_1.png\" alt=\"anomalyDetection_1\"></p>\n<p>这里的每个数据点都是无标签的数据。异常检测问题可以定义如下：我们假设后来有一天，你有一个新的飞机引擎从生产线上流出，而你的新飞机引擎有特征变量\\(x_{test}\\)。我们希望通过对现有数据的分析知道这个新的飞机引擎是否有某种异常，而不需要进一步的测试。</p>\n<p>假使给定的数据集\\(x^{(1)},x^{(2)},…x^{(m)}\\)是正常的，我们需要知道新的数据\\(x_{test}\\)是不是正常的。我们可以把这个问题转化为测试该数据不属于给定数据集的几率如何。我们所构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的概率\\(p(x)\\)。</p>\n<p><img src=\"/../images/anomalyDetection_2.png\" alt=\"anomalyDetection_2\"></p>\n<p>上图中，在蓝色圈内的数据属于该组数据的可能性较高，而越是偏远的数据，其属于该组数据的可能性就越低。这种方法称为密度估计，表达如下：</p>\n<p>$$<br>if\\ \\ p(x)<br>\\begin{cases}<br>&lt; &amp; \\epsilon &amp; anomaly \\\\<br>\\geq &amp; \\epsilon &amp; normal<br>\\end{cases}<br>$$</p>\n<h2 id=\"异常检测例子\"><a href=\"#异常检测例子\" class=\"headerlink\" title=\"异常检测例子\"></a>异常检测例子</h2><h3 id=\"欺诈检测\"><a href=\"#欺诈检测\" class=\"headerlink\" title=\"欺诈检测\"></a>欺诈检测</h3><p>异常检测主要用来识别欺骗。例如在线采集而来的有关用户的数据，一个特征向量中可能会包含如：用户多久登录一次，访问过的页面，在论坛发布的帖子数量，甚至是打字速度等。尝试根据这些特征构建一个模型，可以用这个模型来识别那些不符合该模式的用户。</p>\n<ul>\n<li>通过建模来计算\\(p(x)\\)</li>\n<li>检测\\(p(x)&lt;\\epsilon\\)来确定非正常用户。</li>\n</ul>\n<h3 id=\"生产制造残次品检测\"><a href=\"#生产制造残次品检测\" class=\"headerlink\" title=\"生产制造残次品检测\"></a>生产制造残次品检测</h3><p>例如我们上面提到的飞机引擎的例子</p>\n<h3 id=\"数据中心监测\"><a href=\"#数据中心监测\" class=\"headerlink\" title=\"数据中心监测\"></a>数据中心监测</h3><p>再一个例子是检测一个数据中心，特征可能包含：内存使用情况，被访问的磁盘数量，CPU的负载，网络的通信量等。根据这些特征可以构建一个模型，用来判断某些计算机是不是有可能出错了。</p>\n<h1 id=\"高斯分布\"><a href=\"#高斯分布\" class=\"headerlink\" title=\"高斯分布\"></a>高斯分布</h1><p>高斯分布，也称为正态分布。先回顾以下高斯分布的基本知识：</p>\n<p>通常如果我们认为变量\\(x\\)符合高斯分布\\(x~N(\\mu, \\sigma^2)\\)则其概率密度函数为：<br>$$<br>p(x;\\mu,\\sigma^2)&#x3D;\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})<br>$$</p>\n<p>我们可以利用已有的数据来预测总体中的\\(\\mu\\)和\\(\\sigma^2\\),计算方法如下： </p>\n<p>$$<br>\\mu &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{m}x^{(i)}<br>$$</p>\n<p>$$<br>\\sigma^2 &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{m}(x^{(i)}-\\mu)^2<br>$$</p>\n<p><img src=\"/../images/Gaussian_1.png\" alt=\"Gaussian_1\"></p>\n<p>注：机器学习中对于方差我们通常只除以m而非统计学中的(m-1)。这两个版本的公式在理论特性和数学特性上稍有不同，但是在实际使用中，他们的区别甚小，几乎可以忽略不计。</p>\n<h1 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h1><h2 id=\"异常检测算法\"><a href=\"#异常检测算法\" class=\"headerlink\" title=\"异常检测算法\"></a>异常检测算法</h2><p>对于给定的数据集\\(x^{(1)},x^{(2)},…x^{(m)}\\)，我们要针对每一个特征计算\\(\\mu\\)和\\(\\sigma^2\\)的估计值。<br>$$<br>\\mu &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{m}x_j^{(i)}<br>$$</p>\n<p>$$<br>\\sigma^2 &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{m}(x_j^{(i)}-\\mu_j)^2<br>$$</p>\n<p>一旦我们获得了平均值和方差的估计值，给定新的一个训练实例，根据模型计算\\(p(x)\\)：<br>$$<br>p(x) &#x3D; \\Pi_{j&#x3D;1}^{n}p(x_j;\\mu_j,\\sigma^2)&#x3D;\\Pi_{j&#x3D;1}^{1}\\frac{1}{\\sqrt{2\\pi}\\sigma_j}exp(-\\frac{(x_j-\\mu_j)^2}{2\\sigma_j^2})<br>$$</p>\n<p>当\\(p(x) &lt; \\epsilon\\)时为异常。</p>\n<p>例如下图是一个由两个特征的训练集，以及特征的分布情况：</p>\n<p><img src=\"/../images/anomalyDetection_3.png\" alt=\"anomalyDetection_3\"></p>\n<p>下面的三维图表表示的是密度估计函数，z轴为根据两个特征的值所估计的\\(p(x)\\)值：</p>\n<p><img src=\"/../images/anomalyDetection_4.png\" alt=\"anomalyDetection_4\"></p>\n<p>我们需要选择一个\\(\\epsilon\\)，将\\(p(x)&#x3D;\\epsilon\\)作为我们的判定边界，当时预测数据\\(p(x)&gt;\\epsilon\\)为正常数据，否则为异常。</p>\n<h2 id=\"开发和评价一个异常检测系统\"><a href=\"#开发和评价一个异常检测系统\" class=\"headerlink\" title=\"开发和评价一个异常检测系统\"></a>开发和评价一个异常检测系统</h2><p>异常检测算法是一个非监督学习算法，意味着我们无法根据结果变量y的值来告诉我们数据是否真的是异常的。我们需要另一种方法来帮助检验算法是否有效。</p>\n<p>当我们开发一个异常检测系统时，我们从带标记（异常或正常）的数据着手，我们从其中选择一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集。</p>\n<p>例如：我们有10000台正常引擎的数据，有20台异常引擎的数据。 我们这样分配数据：</p>\n<ul>\n<li><p>6000台正常引擎的数据作为训练集</p>\n</li>\n<li><p>2000台正常引擎和10台异常引擎的数据作为交叉检验集</p>\n</li>\n<li><p>2000台正常引擎和10台异常引擎的数据作为测试集</p>\n</li>\n</ul>\n<p>具体的评价方法如下：</p>\n<ul>\n<li>根据测试集数据，我们估计特征的平均值和方差并构建\\(p(x)\\)函数</li>\n<li>对交叉检验集，我们尝试使用不同的\\(\\epsilon\\)值作为阀值，并预测数据是否异常，根据F1值或者查准率与查全率的比例来选择 \\(\\epsilon\\)</li>\n<li>选出\\(\\epsilon\\)后，针对测试集进行预测，计算异常检验系统的F1值，或者查准率与查全率之比</li>\n</ul>\n<h1 id=\"异常检测与监督学习对比\"><a href=\"#异常检测与监督学习对比\" class=\"headerlink\" title=\"异常检测与监督学习对比\"></a>异常检测与监督学习对比</h1><p>之前我们构建的异常检测系统也使用了带标记的数据，与监督学习有些相似，下面的对比有助于选择采用监督学习还是异常检测。</p>\n<table>\n<thead>\n<tr>\n<th>异常检测</th>\n<th>监督学习</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>非常少量的正向类（异常数据y&#x3D;1）, 大量的负向类（y&#x3D;0）</td>\n<td>同时有大量的正向类和负向类</td>\n</tr>\n<tr>\n<td>许多不同种类的异常。对于任何算法来说，根据非常少量的正向类数据来进行训练什么是异常都是非常困难的</td>\n<td>有足够多的正向类实例，足够用于训练 算法，未来遇到的正向类实例可能与训练集中的非常近似</td>\n</tr>\n<tr>\n<td>未来遇到的异常可能与已掌握的异常、非常的不同</td>\n<td></td>\n</tr>\n<tr>\n<td>例如： 欺诈行为检测 生产（例如飞机引擎）检测数据中心的计算机运行状况</td>\n<td>例如：邮件过滤器 天气预报 肿瘤分类</td>\n</tr>\n</tbody></table>\n<h1 id=\"选择特征\"><a href=\"#选择特征\" class=\"headerlink\" title=\"选择特征\"></a>选择特征</h1><p>对于异常检测算法，我们使用的特征是至关重要的，下面谈谈如何选择特征：</p>\n<h2 id=\"高斯分布转换\"><a href=\"#高斯分布转换\" class=\"headerlink\" title=\"高斯分布转换\"></a>高斯分布转换</h2><p>异常检测假设特征符合高斯分布，如果数据的分布不是高斯分布，异常检测算法也能够工作，但是最好还是将数据转换成高斯分布。</p>\n<p>例如使用对数函数：\\(x&#x3D;log(x+c)\\)，其中\\(c\\)为非负常数； 或者\\(x&#x3D;x^c\\)，\\(c\\)为 0-1 之间的一个分数，等方法。</p>\n<p><img src=\"/../images/anomalyDetection_5.png\" alt=\"anomalyDetection_5\"></p>\n<h2 id=\"误差分析\"><a href=\"#误差分析\" class=\"headerlink\" title=\"误差分析\"></a>误差分析</h2><p>我们异常检测系统希望得到的结果:</p>\n<ul>\n<li>对于正常样品，我们希望获得较大的p(x)值</li>\n<li>对于异常样品，我们希望获得较小的p(x)值</li>\n</ul>\n<p>但在异常检测问题中一个常见的问题就是，对于正常和异常样品，我们获得的p(x)值比较接近，从而无法真正把异常样品挑选出来。</p>\n<p><img src=\"/../images/anomalyDetection_6.png\" alt=\"anomalyDetection_6\"></p>\n<p>我们通常可以通过将一些相关的特征进行组合，来获得一些新的更好的特征（异常数据的该特征值异常地大或小），例如，在检测数据中心的计算机状况的例子中，我们可以用CPU负载与网络通信量的比例作为一个新的特征，如果该值异常地大，便有可能意味着该服务器是陷入了一些问题中。</p>\n<h1 id=\"多元高斯分布\"><a href=\"#多元高斯分布\" class=\"headerlink\" title=\"多元高斯分布\"></a>多元高斯分布</h1><p>假使我们有两个相关的特征，而且这两个特征的值域范围比较宽，这种情况下，一般的高斯分布模型可能不能很好地识别异常数据。其原因在于，一般的高斯分布模型尝试的是去同时抓住两个特征的偏差，因此创造出一个比较大的判定边界。</p>\n<p>下图中是两个相关特征，洋红色的线（根据ε的不同其范围可大可小）是一般的高斯分布模型获得的判定边界，很明显绿色的X所代表的数据点很可能是异常值，但是其p(x)值却仍然在正常范围内。多元高斯分布将创建像图中蓝色曲线所示的判定边界。</p>\n<p><img src=\"/../images/anomalyDetection_7.png\" alt=\"anomalyDetection_7\"></p>\n<p>在一般的高斯分布模型中，我们计算p(x)的方法是： 通过分别计算每个特征对应的几率然后将其累乘起来，在多元高斯分布模型中，我们将构建特征的协方差矩阵，用所有的特征一起来计算p(x)。</p>\n<p>$$<br>\\mu&#x3D;\\frac{1}{m}\\sum_{i&#x3D;1}^{m}x^{(i)}<br>$$<br>$$<br>\\Sigma &#x3D; \\frac{1}{m}(x^{(i)}-\\mu)(x^{(i)}-\\mu)^T&#x3D;\\frac{1}{m}(X-\\mu)^T(X-\\mu)<br>$$</p>\n<p>其中，\\(\\mu\\)是一个向量，其每一个单元都是原特征矩阵中一行数据的均值。</p>\n<p>最后我们计算多元高斯分布的p(x):<br>$$<br>p(x;\\mu,\\Sigma)&#x3D;\\frac{1}{(2\\pi)^{n&#x2F;2}|\\Sigma|^{1&#x2F;2}}exp(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu))<br>$$</p>\n<p>其中\\(|\\Sigma|\\)是定矩阵，在Octave中用det(sigma)计算。</p>\n<p>下面我们来看看协方差矩阵是如何影响模型的：</p>\n<p><img src=\"/../images/anomalyDetection_8.png\" alt=\"anomalyDetection_8\"></p>\n<p>上图是5个不同的模型，从左往右依次分析：</p>\n<ol>\n<li>是一个一般的高斯分布模型</li>\n<li>通过协方差矩阵，令特征1拥有较小的偏差，同时保持特征2的偏差</li>\n<li>通过协方差矩阵，令特征2拥有较大的偏差，同时保持特征1的偏差</li>\n<li>通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的正相关性</li>\n<li>通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的负相关性</li>\n</ol>\n<h2 id=\"原高斯分布模型和多元高斯分布模型的比较：\"><a href=\"#原高斯分布模型和多元高斯分布模型的比较：\" class=\"headerlink\" title=\"原高斯分布模型和多元高斯分布模型的比较：\"></a>原高斯分布模型和多元高斯分布模型的比较：</h2><table>\n<thead>\n<tr>\n<th>原高斯分布模型</th>\n<th>多元高斯分布模型</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>不能捕捉特征之间的相关性 但可以通过将特征进行组合的方法来解决</td>\n<td>自动捕捉特征之间的相关性</td>\n</tr>\n<tr>\n<td>计算代价低，能适应大规模的特征</td>\n<td>计算代价较高；训练集较小时也同样适用</td>\n</tr>\n<tr>\n<td>m较小的情况也可以使用</td>\n<td>必须要有m&gt;n，不然的话协方差矩阵不可逆，通常需要m&gt;10n另外特征冗余也会导致协方差矩阵不可逆</td>\n</tr>\n</tbody></table>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-20-Recommender Systems","url":"/2022/09/11/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-20/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 20-推荐系统(Recommender Systems)。</p>\n<span id=\"more\"></span>\n\n<h1 id=\"为什么学习推荐系统\"><a href=\"#为什么学习推荐系统\" class=\"headerlink\" title=\"为什么学习推荐系统\"></a>为什么学习推荐系统</h1><ol>\n<li>推荐系统是机器学习中的一个重要的应用。如果你考虑网站像亚马逊，或网飞公司或易趣，或iTunes Genius，有很多的网站或系统试图推荐新产品给用户。如，亚马逊推荐新书给你，网飞公司试图推荐新电影给你，等等。这些推荐系统，根据浏览你过去买过什么书，或过去评价过什么电影来判断。这些系统会带来很大一部分收入，比如为亚马逊和像网飞这样的公司。因此，对推荐系统性能的改善，将对这些企业的有实质性和直接的影响。</li>\n<li>通过推荐系统，我们将领略一小部分特征学习的思想。对机器学习来说，特征是很重要的，你所选择的特征，将对你学习算法的性能有很大的影响。因此，在机器学习中有一种大思想，它针对一些问题(可能并不是所有的问题)，有些现有的算法可以为你自动学习一套好的特征。</li>\n</ol>\n<h1 id=\"问题形式化\"><a href=\"#问题形式化\" class=\"headerlink\" title=\"问题形式化\"></a>问题形式化</h1><p>我们从一个例子开始定义推荐系统的问题。</p>\n<p>假使我们是一个电影供应商，我们有 5 部电影和 4 个用户，我们要求用户为电影打分。</p>\n<p><img src=\"/../images/recommenderSys_1.png\" alt=\"recommenderSys_1\"></p>\n<p>前三部电影是爱情片，后两部则是动作片，我们可以看出Alice和Bob似乎更倾向与爱情片， 而 Carol 和 Dave 似乎更倾向与动作片。并且没有一个用户给所有的电影都打过分。我们希望构建一个算法来预测他们每个人可能会给他们没看过的电影打多少分，并以此作为推荐的依据。</p>\n<p>下面引入一些标记：</p>\n<ul>\n<li>\\(n_u\\)代表用户的数量</li>\n<li>\\(n_m\\)代表电影的数量</li>\n<li>\\(r(i,j)\\) 如果用户\\(j\\)给电影\\(i\\)评过分则\\(r(i,j)&#x3D;1\\)</li>\n<li>\\(y^{(i,j)}\\)代表用户\\(j\\)给电影\\(i\\)的评分</li>\n<li>\\(m_j\\)代表用户\\(j\\)评过分的电影的总数</li>\n</ul>\n<h1 id=\"基于内容的推荐系统\"><a href=\"#基于内容的推荐系统\" class=\"headerlink\" title=\"基于内容的推荐系统\"></a>基于内容的推荐系统</h1><p>在我们的例子中，我们可以假设每部电影都有两个特征，如\\(x_1\\)代表电影的浪漫程度，\\(x_2\\)代表电影的动作程度。</p>\n<p><img src=\"/../images/recommenderSys_2.png\" alt=\"recommenderSys_2\"></p>\n<p>则每部电影都有一个特征向量，如\\(x^{(1)}\\)是第一部电影的特征向量为[0.9 0]。</p>\n<p>下面我们要基于这些特征来构建一个推荐系统算法。 假设我们采用线性回归模型，我们可以针对每一个用户都训练一个线性回归模型，如\\(\\theta^{(1)}\\)是第一个用户的模型的参数。 于是我们有：</p>\n<ul>\n<li>\\(\\theta^{(j)}\\)：用户\\(j\\)的参数向量</li>\n<li>\\(x^{(i)}\\)：电影\\(i\\)的特征向量</li>\n<li>对于用户\\(j\\)和电影\\(i\\)，我们的预测评分为\\((\\theta^{(j)})^Tx^{(i)}\\)</li>\n</ul>\n<p><strong>代价函数</strong><br>$$<br>J(\\theta^{(j)})&#x3D;\\frac{1}{2}\\sum_{i:r(i,j)&#x3D;1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2}\\sum_{k&#x3D;1}^n(\\theta_k^{(j)})^2<br>$$<br>其中\\(i:r(i,j)&#x3D;1\\)表示我们只计算那些用户\\(j\\)评过分的电影。在一般的线性回归模型中，误差项和正则项应该都是乘以\\(\\frac{1}{2m}\\)，在这里我们将m去掉。并且我们不对方差项\\(\\theta_0\\)进行正则化处理。</p>\n<p>上面的代价函数只是针对一个用户的，为了学习所有用户，我们将所有用户的代价函数求和：<br>$$<br>J(\\theta^{(1)},…,\\theta^{(n_u)})&#x3D;\\frac{1}{2}\\sum_{j&#x3D;1}^{n_u}\\sum_{i:r(i,j)&#x3D;1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2}\\sum_{j&#x3D;1}^{n_u}\\sum_{k&#x3D;1}^n(\\theta_k^{(j)})^2<br>$$</p>\n<p><strong>梯度下降求解公式</strong></p>\n<p>如果我们要用梯度下降法来求解最优解，我们计算代价函数的偏导数后得到梯度下降的更新公式如下：</p>\n<p>for \\(k&#x3D;0\\):<br>$$<br>\\theta_k^{(j)}:&#x3D;\\theta_k^{(j)}-\\alpha\\sum_{i:r(i,j)&#x3D;1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}<br>$$</p>\n<p>for \\(k \\neq 0\\):<br>$$<br>\\theta_k^{(j)}:&#x3D;\\theta_k^{(j)}-\\alpha(\\sum_{i:r(i,j)&#x3D;1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)} + \\lambda\\theta_k^{(j)})<br>$$</p>\n<h1 id=\"协同过滤\"><a href=\"#协同过滤\" class=\"headerlink\" title=\"协同过滤\"></a>协同过滤</h1><p>在之前的基于内容的推荐系统中，对于每一部电影，我们都掌握了可用的特征，使用这些特征训练出了每一个用户的参数。相反地，如果我们拥有用户的参数，我们可以学习得出电影的特征。</p>\n<p><img src=\"/../images/recommenderSys_3.png\" alt=\"recommenderSys_3\"></p>\n<p>但是如果我们既没有用户的参数，也没有电影的特征，这两种方法都不可行了。协同过滤算法可以同时学习这两者。我们的优化目标便改为同时针对\\(x\\)和\\(\\theta\\)进行。<br>$$<br>J(x^{(1)},…,x^{(n_m)},\\theta^{(1)},…,\\theta^{(n_u)}) &#x3D; \\frac{1}{2}\\sum_{j&#x3D;1}^{n_u}\\sum_{(i,j):r(i,j)&#x3D;1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2}\\sum_{i&#x3D;1}^{n_m}\\sum_{k&#x3D;1}^n(x_k^{(i)})^2+\\frac{\\lambda}{2}\\sum_{j&#x3D;1}^{n_u}\\sum_{k&#x3D;1}^n(\\theta_k^{(j)})^2<br>$$<br>对代价函数求偏导数的结果如下：<br>$$<br>x_k^{(i)}:&#x3D;x_k^{(i)}-\\alpha(\\sum_{j:r(i,j)&#x3D;1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})\\theta_k^{(i)} + \\lambda x_k^{(j)})<br>$$</p>\n<p>$$<br>\\theta_k^{(j)}:&#x3D;\\theta_k^{(j)}-\\alpha(\\sum_{i:r(i,j)&#x3D;1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)} + \\lambda\\theta_k^{(j)})<br>$$</p>\n<p>协同过滤算法使用步骤如下：</p>\n<ul>\n<li>初始\\(x^{(1)},…,x^{(n_m),\\theta^{(1)},…,\\theta^{(n_u)}\\)为一些小的随机值</li>\n<li>使用梯度下降算法最小化代价函数</li>\n<li>在训练完算法后，我们预测\\((\\theta^{(j)})^Tx^{(i)}\\)为用户\\(j\\)给电影\\(i\\)的评分</li>\n</ul>\n<h1 id=\"向量化：低秩矩阵分解\"><a href=\"#向量化：低秩矩阵分解\" class=\"headerlink\" title=\"向量化：低秩矩阵分解\"></a>向量化：低秩矩阵分解</h1><p>这里将会讲到有关协同过滤算法的向量化实现，以及说说有关该算法你可以做的其他事情，例如：</p>\n<ol>\n<li>当给出一件产品时，你能否找到与之相关的其它产品。</li>\n<li>一位用户最近看上一件产品，有没有其它相关的产品，你可以推荐给他。</li>\n</ol>\n<h2 id=\"向量化\"><a href=\"#向量化\" class=\"headerlink\" title=\"向量化\"></a>向量化</h2><p>我们有关于五部电影的数据集，我将要做的是，将这些用户的电影评分，进行分组并存到一个矩阵中。</p>\n<p>我们有五部电影，以及四位用户，那么 这个矩阵Y就是一个5行4列的矩阵，它将这些电影的用户评分数据都存在矩阵里：</p>\n<p><img src=\"/../images/recommenderSys_4.png\" alt=\"recommenderSys_4\"></p>\n<p>使用协同过滤算法，我们就可以找到特征向量X，以及参数\\(\\Theta\\)。从而，推导出预测的评分\\(X\\Theta^T\\)</p>\n<p><img src=\"/../images/recommenderSys_5.png\" alt=\"recommenderSys_5\"></p>\n<h2 id=\"找到相似产品\"><a href=\"#找到相似产品\" class=\"headerlink\" title=\"找到相似产品\"></a>找到相似产品</h2><p>当用户在看某部电影  的时候，如果你想找5部与电影非常相似的电影，为了能给用户推荐5部新电影，你需要做的是找出电影\\(j\\)与我们要找的电影\\(i\\)的距离最小，这样你就能给你的用户推荐几部不同的电影了。</p>\n<p><img src=\"/../images/recommenderSys_6.png\" alt=\"recommenderSys_6\"></p>\n<h1 id=\"均值归一化\"><a href=\"#均值归一化\" class=\"headerlink\" title=\"均值归一化\"></a>均值归一化</h1><p>让我们来看下面的用户评分数据：</p>\n<p><img src=\"/../images/recommenderSys_7.png\" alt=\"recommenderSys_7\"></p>\n<p>如果我们新增一个用户 Eve，并且 Eve 没有为任何电影评分，那么我们以什么为依据为Eve推荐电影呢？</p>\n<p>我们首先需要对结果 矩阵进行均值归一化处理，将每一个用户对某一部电影的评分减去所有用户对该电影评分的平均值：</p>\n<p><img src=\"/../images/recommenderSys_8.png\" alt=\"recommenderSys_8\"></p>\n<p>然后我们利用这个新的Y矩阵来训练算法。 如果我们要用新训练出的算法来预测评分，则需要将平均值重新加回去，预测\\((\\theta^{(j)})^Tx^{(i)}+\\mu_i\\)，对于Eve，我们的新模型会认为她给每部电影的评分都是该电影的平均分。</p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-23-Application example:Photo OCR","url":"/2022/09/13/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-23/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 22-应用实例：图片文字识别(Application example:Photo OCR)。</p>\n<span id=\"more\"></span>\n\n<h1 id=\"问题描述和流程图-Problem-description-and-pipeline\"><a href=\"#问题描述和流程图-Problem-description-and-pipeline\" class=\"headerlink\" title=\"问题描述和流程图(Problem description and pipeline)\"></a>问题描述和流程图(Problem description and pipeline)</h1><p>图像文字识别应用所作的事是，从一张给定的图片中识别文字。这比从一份扫描文档中识别文字要复杂的多。</p>\n<p>为了完成这样的工作，需要采取如下步骤：</p>\n<ul>\n<li>文字侦测（Text detection）——将图片上的文字与其他环境对象分离开来</li>\n<li>字符切分（Character segmentation）——将文字分割成一个个单一的字符</li>\n<li>字符分类（Character classification）——确定每一个字符是什么</li>\n</ul>\n<p>我们可以用任务流程图来表达这个问题，每一项任务可以由一个单独的小队来负责解决。</p>\n<p><img src=\"/../images/OCR_1.png\" alt=\"OCR_1\"></p>\n<h1 id=\"滑动窗口-Sliding-windows\"><a href=\"#滑动窗口-Sliding-windows\" class=\"headerlink\" title=\"滑动窗口(Sliding windows)\"></a>滑动窗口(Sliding windows)</h1><p>滑动窗口是一项用来从图像中抽取对象的技术。假使我们需要在一张图片中识别行人，首先要做的是用许多固定尺寸的图片来训练一个能够准确识别行人的模型。然后我们用之前训练识别行人的模型时所采用的图片尺寸在我们要进行行人识别的图片上进行剪裁，然后将剪裁得到的切片交给模型，让模型判断是否为行人，然后在图片上滑动剪裁区域重新进行剪裁，将新剪裁的切片也交给模型进行判断，如此循环直至将图片全部检测完。</p>\n<p>一旦完成后，我们按比例放大剪裁的区域，再以新的尺寸对图片进行剪裁，将新剪裁的切片按比例缩小至模型所采纳的尺寸，交给模型进行判断，如此循环。</p>\n<p><img src=\"/../images/OCR_2.png\" alt=\"OCR_2\"></p>\n<p>滑动窗口技术也被用于文字识别，首先训练模型能够区分字符与非字符，然后，运用滑动窗口技术识别字符，一旦完成了字符的识别，我们将识别得出的区域进行一些扩展，然后将重叠的区域进行合并。接着我们以宽高比作为过滤条件，过滤掉高度比宽度更大的区域（认为单词的长度通常比高度要大）。下图中绿色的区域是经过这些步骤后被认为是文字的区域，而红色的区域是被忽略的。</p>\n<p><img src=\"/../images/OCR_3.png\" alt=\"OCR_3\"></p>\n<p>以上便是文字侦测阶段。下一步是训练一个模型来完成将文字分割成一个个字符的任务，需要的训练集由单个字符的图片和两个相连字符之间的图片来训练模型。</p>\n<p><img src=\"/../images/OCR_4.png\" alt=\"OCR_4\"></p>\n<p>模型训练完后，我们仍然是使用滑动窗口技术来进行字符识别。</p>\n<p>以上便是字符切分阶段。 最后一个阶段是字符分类阶段，利用神经网络、支持向量机或者逻辑回归算法训练一个分类器即可。</p>\n<h1 id=\"获取大量数据和人工数据-Getting-lots-of-data-Artificial-data-synthesis\"><a href=\"#获取大量数据和人工数据-Getting-lots-of-data-Artificial-data-synthesis\" class=\"headerlink\" title=\"获取大量数据和人工数据(Getting lots of data: Artificial data synthesis)\"></a>获取大量数据和人工数据(Getting lots of data: Artificial data synthesis)</h1><p>如果我们的模型是低方差的，那么获得更多的数据用于训练模型，是能够有更好的效果的。问题在于，我们怎样获得数据，数据不总是可以直接获得的，我们有可能需要人工地创造一些数据。</p>\n<p>以我们的文字识别应用为例，我们可以字体网站下载各种字体，然后利用这些不同的字体配上各种不同的随机背景图片创造出一些用于训练的实例，这让我们能够获得一个无限大的训练集。这是从零开始创造实例。</p>\n<p>另一种方法是，利用已有的数据，然后对其进行修改，例如将已有的字符图片进行一些扭曲、旋转、模糊处理。只要我们认为实际数据有可能和经过这样处理后的数据类似，我们便可以用这样的方法来创造大量的数据。</p>\n<p>有关获得更多数据的几种方法：</p>\n<ul>\n<li>人工数据合成</li>\n<li>手动收集、标记数据</li>\n<li>众包 (E.g. Amazon Mechanical Turk)</li>\n</ul>\n<h1 id=\"上限分析：哪部分管道值得去进一步提升-Ceiling-analysis-What-part-of-the-pipeline-to-work-on-next\"><a href=\"#上限分析：哪部分管道值得去进一步提升-Ceiling-analysis-What-part-of-the-pipeline-to-work-on-next\" class=\"headerlink\" title=\"上限分析：哪部分管道值得去进一步提升(Ceiling analysis: What part of the pipeline to work on next)\"></a>上限分析：哪部分管道值得去进一步提升(Ceiling analysis: What part of the pipeline to work on next)</h1><p>在机器学习的应用中，我们通常需要通过几个步骤才能进行最终的预测，我们如何能够知道哪一部分最值得我们花时间和精力去改善呢？这个问题可以通过上限分析来回答。</p>\n<p>回到我们的文字识别应用中，我们的流程图如下：</p>\n<p><img src=\"/../images/OCR_1.png\" alt=\"OCR_1\"></p>\n<p>流程图中每一部分的输出都是下一部分的输入，上限分析中，我们选取一部分，手工提供100%正确的输出结果，然后看应用的整体效果提升了多少。假使我们的例子中总体效果为72%的正确率。</p>\n<p>如果我们令文字侦测部分输出的结果100%正确，发现系统的总体效果从72%提高到了89%。这意味着我们很可能会希望投入时间精力来提高我们的文字侦测部分。</p>\n<p>接着我们手动选择数据，让字符切分输出的结果100%正确，发现系统的总体效果只提升了1%，这意味着，我们的字符切分部分可能已经足够好了。</p>\n<p>最后我们手工选择数据，让字符分类输出的结果100%正确，系统的总体效果又提升了10%，这意味着我们可能也会应该投入更多的时间和精力来提高应用的总体表现。</p>\n<p><img src=\"/../images/OCR_5.png\" alt=\"OCR_5\"></p>\n<h1 id=\"个人课程总结\"><a href=\"#个人课程总结\" class=\"headerlink\" title=\"个人课程总结\"></a>个人课程总结</h1><p>终于学习完了这门课程的所有内容，最后简单总结一下。总体来说，这门课质量真的不错，无论是课程安排还是编程作业，都值得我花更多的时间来继续挖掘和研究。上完这门课之后，个人感觉收获也非常大。</p>\n<p>其实，在好几年前就对Machine Learning比较感兴趣，也听朋友说起它在我们生活中的种种应用。但由于读博期间科研工作比较繁忙，一直没有下定决心要好好研究一下。</p>\n<p>直到2019年，终于决定要挤出时间系统的学习下Machine Learning。刚好听说了Andrew Ng在Course上面开设的这门课，而且评价非常高。就花钱在Course上面报了名，但只坚持了大概五个星期，就无法再继续学下去了。首先，是当时计算机基础太薄弱，对于里面的编程部分非常吃力。每次都要花上非常久的时间才能写出个大概。其次，还是上面提到的科研工作比较繁忙，压力也比较大，很难抽出大块时间花在这门课程上。还有就是，当时是断断续续的学习，把战线拉得比较长。往往在还没有完全吃透前面章节的前提下，就开始了后面的课程，导致后面课程理解难度越来越大。就这样，最终不得不把学习计划暂时搁浅。</p>\n<p>这一放就是三年，三年期间忙着结婚、生子、博士毕业、找工作等等这些事情。虽然没有继续学习Machine Learning，但这期间还是学习了很多计算机相关知识，提升了编程能力。工作之后，由于是大学老师的工作，时间比较自由，刚好这学期课业压力也不算特别大。有了一些时间之后，就想着继续把之前放弃的课程学完，所以从八月份开始就重新把这门课从头学起。在学习的同时，每一个章节都写了博客，来帮助梳理和记忆。发现这种方法非常好，极大的提升了学习效率。大概花了一个月左右时间，终于学完了所有的课程。</p>\n<p>个人感觉，学完课程只算是基本入门，如果想要应用在生活和工作中，还是有很多地方需要学习和思考的。希望与各位共勉，活到老学到老。</p>\n<p>最后，分享一下我的结业证书：）</p>\n<p><img src=\"/../images/Certificate.PNG\" alt=\"Certificate\"></p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-22-Large Scale Machine Learning","url":"/2022/09/13/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-22/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 22-大规模机器学习(Large Scale Machine Learning)。</p>\n<span id=\"more\"></span>\n<h1 id=\"大型数据集的学习\"><a href=\"#大型数据集的学习\" class=\"headerlink\" title=\"大型数据集的学习\"></a>大型数据集的学习</h1><p>如果我们有一个低方差的模型，增加数据集的规模可以帮助你获得更好的结果。我们应该怎样应对一个有100万条记录的训练集？</p>\n<p>以线性回归模型为例，每一次梯度下降迭代，我们都需要计算这100万条记录的误差的平方和，如果我们的学习算法需要有20次迭代，这便已经是非常大的计算代价。</p>\n<p>所以，我们首先应该做的事是去检查一个这么大规模的训练集是否真的必要，也许我们只用1000个训练集也能获得较好的效果，我们可以绘制学习曲线来帮助判断。</p>\n<p><img src=\"/../images/largeScaleML_1.png\" alt=\"largeScaleML_1\"></p>\n<h1 id=\"随机梯度下降法-Stochastic-gradient-descent\"><a href=\"#随机梯度下降法-Stochastic-gradient-descent\" class=\"headerlink\" title=\"随机梯度下降法(Stochastic gradient descent)\"></a>随机梯度下降法(Stochastic gradient descent)</h1><p>如果我们一定需要一个大规模的训练集，我们可以尝试使用随机梯度下降法(Stochastic gradient descent)来代替批量梯度下降法。</p>\n<p>在随机梯度下降法中，我们定义代价函数为一个单一训练实例的代价：</p>\n<p>$$<br>cost(\\theta,(x^{(i)},y^{(i)})) &#x3D; \\frac{1}{2}(h_\\theta(x^{(i)})-y^{(i)})^2<br>$$<br>随机梯度下降算法为：</p>\n<ul>\n<li>对训练集随机“洗牌”</li>\n<li>重复以下循环1到10次：<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Repeat&#123;</span><br><span class=\"line\">  for i=1:m&#123; </span><br><span class=\"line\">    theta := theta_j - alpha(h_theta(x_i)-y_i)</span><br><span class=\"line\">    (for j = 0:n)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n随机梯度下降算法在每一次计算之后便更新参数\\(\\theta\\)，而不需要首先将所有的训练集求和，在梯度下降算法还没有完成一次迭代时，随机梯度下降算法便已经走出了很远。但是这样的算法存在的问题是，不是每一步都是朝着”正确”的方向迈出的。因此算法虽然会逐渐走向全局最小值的位置，但是可能无法站到那个最小值的那一点，而是在最小值点附近徘徊。</li>\n</ul>\n<p><img src=\"/../images/largeScaleML_2.png\" alt=\"largeScaleML_2\"></p>\n<h1 id=\"小批量梯度下降-Mini-batch-gradient-descent\"><a href=\"#小批量梯度下降-Mini-batch-gradient-descent\" class=\"headerlink\" title=\"小批量梯度下降(Mini-batch gradient descent)\"></a>小批量梯度下降(Mini-batch gradient descent)</h1><p>小批量梯度下降算法是介于批量梯度下降算法和随机梯度下降算法之间的算法，每计算常数b次训练实例，便更新一次参数\\(\\theta\\)。</p>\n<p>Repeat{</p>\n<p><img src=\"/../images/largeScaleML_3.png\" alt=\"largeScaleML_3\"></p>\n<p>通常我们会令b在 2-100 之间。这样做的好处在于，我们可以用向量化的方式来循环b个训练实例，如果我们用的线性代数函数库比较好，能够支持平行处理，那么算法的总体表现将不受影响（与随机梯度下降相同）。</p>\n<h1 id=\"随机梯度下降收敛-Stochastic-gradient-descent-convergence\"><a href=\"#随机梯度下降收敛-Stochastic-gradient-descent-convergence\" class=\"headerlink\" title=\"随机梯度下降收敛(Stochastic gradient descent convergence)\"></a>随机梯度下降收敛(Stochastic gradient descent convergence)</h1><p>在批量梯度下降中，我们可以令代价函数J为迭代次数的函数，绘制图表，根据图表来判断梯度下降是否收敛。但是，在大规模的训练集的情况下，这是不现实的，因为计算代价太大了。</p>\n<p>在随机梯度下降中，我们在每一次更新\\(\\theta\\)之前都计算一次代价，然后每x次迭代后，求出这x次对训练实例计算代价的平均值，然后绘制这些平均值与x次迭代的次数之间的函数图表。</p>\n<p><img src=\"/../images/largeScaleML_4.png\" alt=\"largeScaleML_4\"></p>\n<p>当我们绘制这样的图表时，可能会得到一个颠簸不平但是不会明显减少的函数图像（如上面左下图中蓝线所示）。我们可以增加\\(\\alpha\\)来使得函数更加平缓，也许便能看出下降的趋势了（如上面左下图中红线所示）；或者可能函数图表仍然是颠簸不平且不下降的（如洋红色线所示），那么我们的模型本身可能存在一些错误。</p>\n<p>如果我们得到的曲线如上面右下方所示，不断地上升，那么说明我们选择的\\(\\alpha\\)太大，我们可能会需要选择一个较小的学习率\\(\\alpha\\)。</p>\n<p>我们也可以令学习率随着迭代次数的增加而减小，例如令：</p>\n<p>$$<br>\\alpha&#x3D;\\frac{const1}{iterationNumber + const2}<br>$$</p>\n<p>随着我们不断地靠近全局最小值，通过减小学习率，我们迫使算法收敛而非在最小值附近徘徊。 但是通常我们不需要这样做便能有非常好的效果了，对\\(alpha\\)进行调整所耗费的计算通常不值得。</p>\n<p><img src=\"/../images/largeScaleML_5.png\" alt=\"largeScaleML_5\"></p>\n<h1 id=\"在线学习-Online-learning\"><a href=\"#在线学习-Online-learning\" class=\"headerlink\" title=\"在线学习(Online learning)\"></a>在线学习(Online learning)</h1><p>如果你有一个由连续的用户流引发的连续的数据流，进入你的网站，你能做的是使用一个在线学习机制，从数据流中学习用户的偏好，然后使用这些信息来优化一些关于网站的决策。</p>\n<p>许多在线网站都有持续不断的用户流，对于每一个用户，网站希望能在不将数据存储到数据库中便顺利地进行算法学习。</p>\n<p>假使我们正在经营一家物流公司，每当一个用户询问从地点A至地点B的快递费用时，我们给用户一个报价，该用户可能选择接受（y&#x3D;1）或不接受（y&#x3D;0）。</p>\n<p>现在，我们希望构建一个模型，来预测用户接受报价使用我们的物流服务的可能性。因此报价 是我们的一个特征，其他特征为距离，起始地点，目标地点以及特定的用户数据。模型的输出是:\\(p(y&#x3D;1)\\)。</p>\n<p>在线学习的算法与随机梯度下降算法有些类似，我们对单一的实例进行学习，而非对一个提前定义的训练集进行循环。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Repeat forever (as long as the website is running) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  Get (x,y) corresponding to the current user</span><br><span class=\"line\"></span><br><span class=\"line\">  theta := theta_j- alpha(h_theta(x)-y)</span><br><span class=\"line\">  (for j=0:n)</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>一旦对一个数据的学习完成了，我们便可以丢弃该数据，不需要再存储它了。这种方式的好处在于，我们的算法可以很好的适应用户的倾向性，算法可以针对用户的当前行为不断地更新模型以适应该用户。</p>\n<p>每次交互事件并不只产生一个数据集，例如，我们一次给用户提供3个物流选项，用户选择2项，我们实际上可以获得3个新的训练实例，因而我们的算法可以一次从3个实例中学习并更新模型。</p>\n<p>我们所使用的这个算法与随机梯度下降算法非常类似，唯一的区别的是，我们不会使用一个固定的数据集，我们会做的是获取一个用户样本，从那个样本中学习，然后丢弃那个样本并继续下去。尤其是，如果你对某一种应用有一个连续的数据流，这样的算法会非常值得认真考虑。在线学习的一个优点就是，如果你有一个变化的用户群，又或者你在尝试预测的事情，在缓慢变化 （就像你的用户的品味在缓慢变化），在线学习算法，可以慢慢地调试你所学习到的假设，将其调节更新到最新的用户行为。</p>\n<h1 id=\"映射化简和数据并行-Map-reduce-and-data-parallelism\"><a href=\"#映射化简和数据并行-Map-reduce-and-data-parallelism\" class=\"headerlink\" title=\"映射化简和数据并行(Map-reduce and data parallelism)\"></a>映射化简和数据并行(Map-reduce and data parallelism)</h1><p>映射化简和数据并行对于大规模机器学习问题而言是非常重要的概念。之前提到，如果我们用批量梯度下降算法来求解大规模数据集的最优解，我们需要对整个训练集进行循环，计算偏导数和代价，再求和，计算代价非常大。如果我们能够将我们的数据集分配给不多台计算机，让每一台计算机处理数据集的一个子集，然后我们将计所的结果汇总在求和。这样的方法叫做映射简化。</p>\n<p>具体而言，如果任何学习算法能够表达为，对训练集的函数的求和，那么便能将这个任务分配给多台计算机（或者同一台计算机的不同CPU 核心），以达到加速处理的目的。</p>\n<p>例如，我们有400个训练实例，我们可以将批量梯度下降的求和任务分配给4台计算机进行处理：</p>\n<p><img src=\"/../images/largeScaleML_6.png\" alt=\"largeScaleML_6\"></p>\n<p>很多高级的线性代数函数库已经能够利用多核CPU的多个核心来并行地处理矩阵运算，这也是算法的向量化实现如此重要的缘故（比调用循环快）。</p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-Linear Regression with Multiple Variables","url":"/2022/08/14/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-4/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 04-多变量线性回归(Linear Regression with Multiple Variables)。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"多维特征-Multiple-Features\"><a href=\"#多维特征-Multiple-Features\" class=\"headerlink\" title=\"多维特征(Multiple Features)\"></a>多维特征(Multiple Features)</h1><p>对于一个要度量的对象，一般来说会有不同维度的多个特征。比如之前的房屋价格预测例子中，除了房屋的面积大小，可能还有房屋的年限、房屋的层数等等其他特征：</p>\n<table>\n<thead>\n<tr>\n<th>Size (\\(feet^2\\))</th>\n<th>Number of bedrooms</th>\n<th>Number of floors</th>\n<th>Aage of home (years)</th>\n<th>Price ($1000)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2104</td>\n<td>5</td>\n<td>1</td>\n<td>45</td>\n<td>460</td>\n</tr>\n<tr>\n<td>1416</td>\n<td>3</td>\n<td>2</td>\n<td>40</td>\n<td>232</td>\n</tr>\n<tr>\n<td>1534</td>\n<td>3</td>\n<td>2</td>\n<td>30</td>\n<td>315</td>\n</tr>\n<tr>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n</tr>\n</tbody></table>\n<p>由于有多个特征，引入了一些新的记号：</p>\n<ul>\n<li><p>n &#x3D; 特征的总数</p>\n</li>\n<li><p>\\(x^{(i)}\\) &#x3D; 代表样本矩阵中的第i行，也就是第i个训练实例。</p>\n</li>\n<li><p>\\(x_j^{(i)}\\) &#x3D;  代表样本矩阵中第i行的第j列，也就是第i个训练实例的第j个特征。</p>\n</li>\n</ul>\n<p>例如上面的例子：<br>$$<br>x^{(2)}&#x3D;<br>\\begin{bmatrix}<br>1416\\\\3\\\\2\\\\40\\\\<br>\\end{bmatrix},<br>x_1^{(2)}&#x3D;1416<br>$$<br>多变量假设函数表示为：<br>$$<br>h_\\theta(x)&#x3D;\\theta_0+\\theta_1x_1+\\theta_2x_2+…+\\theta_nx_n<br>$$<br>在添加一个特征向量\\(x_0\\)之后，可以将假设函数简化为：</p>\n<p>$$<br>h_\\theta(x)&#x3D;<br>\\begin{bmatrix}<br>\\theta_0&amp;\\theta_1&amp;…&amp;\\theta_n<br>\\end{bmatrix}<br>\\begin{bmatrix}<br>x_0\\\\x_1\\\\…\\\\x_n<br>\\end{bmatrix}<br>$$</p>\n<h1 id=\"多变量梯度下降-Gradient-Descent-for-Multiple-Variables\"><a href=\"#多变量梯度下降-Gradient-Descent-for-Multiple-Variables\" class=\"headerlink\" title=\"多变量梯度下降(Gradient Descent for Multiple Variables)\"></a>多变量梯度下降(Gradient Descent for Multiple Variables)</h1><p>多变量cost function类似于单变量cost function，即：<br>$$<br>J(\\theta_0,\\theta_1,\\theta_2…,\\theta_n) &#x3D; \\frac{1}{2m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2<br>$$<br>多变量下梯度下降公式：<br>Repeat {<br>$$<br>\\theta_j :&#x3D;\\theta_j- \\alpha\\frac{\\partial}{\\partial{\\theta_j}}{J({\\theta_0,\\theta_1,\\theta_2…,\\theta_n}})<br>$$<br>}</p>\n<p>解出偏导得到：<br>$$<br>\\theta_j :&#x3D;\\theta_j- \\alpha\\frac{1}{m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}<br>$$</p>\n<h1 id=\"梯度下降实践1-特征缩放-Feature-Scaling\"><a href=\"#梯度下降实践1-特征缩放-Feature-Scaling\" class=\"headerlink\" title=\"梯度下降实践1-特征缩放(Feature Scaling)\"></a>梯度下降实践1-特征缩放(Feature Scaling)</h1><p>在应用梯度下降算法实践时，由于各特征值的范围不一，可能会影响代价函数收敛速度。为了优化梯度下降的收敛速度，采用特征缩放的技巧，使各特征值的范围尽量一致。</p>\n<p>除了人工选择并除以一个参数的方式，均值归一化(Mean normalization)方法更为便捷，可采用它来对所有特征值统一缩放：</p>\n<p>$$<br>x_i &#x3D; \\frac{x_i-average(x)}{max(x)-min(x)}, 从而使得 x_i\\in(-1,1)<br>$$<br>或者可以使用标准方差来代替\\(max(x)-min(x)\\)，也就是：<br>$$<br>x_i &#x3D; \\frac{x_i-average(x)}{std(x)}, 从而使得 x_i\\in(-1,1)<br>$$</p>\n<p>但不一定必须\\(-1\\leq x\\leq1\\)，类似于\\(1\\leq x\\leq3\\)也是可以的。</p>\n<h1 id=\"梯度下降实践2-学习速率-Learning-Rate\"><a href=\"#梯度下降实践2-学习速率-Learning-Rate\" class=\"headerlink\" title=\"梯度下降实践2-学习速率(Learning Rate)\"></a>梯度下降实践2-学习速率(Learning Rate)</h1><p>对于学习速率，如果\\(\\alpha\\)过大，代价函数(Cost Function)无法收敛，如果过小，代价函数(Cost Function)收敛的太慢。当然， 足够小时，代价函数在每轮迭代后一定会减少。</p>\n<p>通过不断改变\\(\\alpha\\)值，绘制并观察图像，并以此来确定合适的学习速率。 尝试时可取\\(\\alpha\\)如: …0.001, 0.003, 0.01, 0.03, 0.1,…</p>\n<h1 id=\"特征和多项式回归-Features-and-Polynomial-Regression\"><a href=\"#特征和多项式回归-Features-and-Polynomial-Regression\" class=\"headerlink\" title=\"特征和多项式回归(Features and Polynomial Regression)\"></a>特征和多项式回归(Features and Polynomial Regression)</h1><p>在特征选取时，我们也可以自己归纳总结，定义一个新的特征，用来取代或拆分旧的一个或多个特征。比如，对于房屋面积特征来说，我们可以将其拆分为长度和宽度两个特征，反之，我们也可以合并长度和宽度这两个特征为面积这一个特征。</p>\n<p>线性回归只能以直线来对数据进行拟合，有时候需要使用曲线来对数据进行拟合，即多项式回归(Polynomial Regression)。</p>\n<p>比如一个二次方模型：\\(h_\\theta(x)&#x3D;\\theta_0+\\theta_1x_1+\\theta_2x_2^2\\)</p>\n<p>或者三次方模型： \\(h_\\theta(x)&#x3D;\\theta_0+\\theta_1x_1+\\theta_2x_2^2+\\theta_3x_3^3\\)</p>\n<p>或者平方根模型： \\(h_\\theta(x)&#x3D;\\theta_0+\\theta_1x_1+\\theta_2x_2^2+\\theta_3\\sqrt{(x_3)}\\)</p>\n<p>在使用多项式回归时，要记住非常有必要进行特征缩放，比如\\(x_1\\)的范围为 1-1000，那么\\(x_1^2\\)的范围则为 1- 1000000，不适用特征缩放的话，范围更有不一致，也更易影响效率。</p>\n<h1 id=\"正规方程-Normal-Equation\"><a href=\"#正规方程-Normal-Equation\" class=\"headerlink\" title=\"正规方程(Normal Equation)\"></a>正规方程(Normal Equation)</h1><p>正规方程法，即令\\(\\frac{\\partial}{\\partial{\\theta_j}}J({\\theta_j})&#x3D;0\\)，通过解析函数的方式直接计算得出参数向量的值。</p>\n<p>$$<br>\\theta &#x3D; (X^TX)^-1X^Ty<br>$$</p>\n<p>Octave&#x2F;Matlab代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">theta = pinv(X&#x27;*X)*X&#x27;*y</span><br></pre></td></tr></table></figure>\n<p>下表列出了正规方程法与梯度下降算法的对比</p>\n<table>\n<thead>\n<tr>\n<th>条件</th>\n<th>梯度下降</th>\n<th>正规方程</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>是否需要选取\\(\\alpha\\)</td>\n<td>是</td>\n<td>否</td>\n</tr>\n<tr>\n<td>是否需要迭代运算</td>\n<td>是</td>\n<td>否</td>\n</tr>\n<tr>\n<td>特征量大时是否适用</td>\n<td>是，\\(O(kn^2)\\)</td>\n<td>否，\\(O(n^3)\\)</td>\n</tr>\n<tr>\n<td>适用范围</td>\n<td>各类模型</td>\n<td>只适用线性模型，且矩阵需可逆</td>\n</tr>\n</tbody></table>\n<h1 id=\"不可逆性正规方程-Normal-Equation-Noninvertibility-Optional\"><a href=\"#不可逆性正规方程-Normal-Equation-Noninvertibility-Optional\" class=\"headerlink\" title=\"不可逆性正规方程(Normal Equation Noninvertibility (Optional))\"></a>不可逆性正规方程(Normal Equation Noninvertibility (Optional))</h1><p>正规方程无法应用于不可逆的矩阵，发生这种问题的概率很小，通常由于:</p>\n<ul>\n<li>特征之间线性相关</li>\n<li>特征数量大于训练集的数量。</li>\n</ul>\n<p>如果发现\\(X^TX\\)的结果不可逆，可尝试:</p>\n<ul>\n<li>减少多余&#x2F;重复特征</li>\n<li>增加训练集数量</li>\n<li>使用正则化（后文）</li>\n</ul>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-21-execrise 8 summary","url":"/2022/09/12/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-21/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 21-execrise 8 summary。</p>\n<span id=\"more\"></span>\n<p><strong>Programming Exercise 8: Anomaly Detection and Recommender Systems</strong></p>\n<p>In this exercise, you will implement the anomaly detection algorithm and<br>apply it to detect failing servers on a network. In the second part, you will<br>use collaborative filtering to build a recommender system for movies.</p>\n<h1 id=\"exe8-m\"><a href=\"#exe8-m\" class=\"headerlink\" title=\"exe8.m\"></a>exe8.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class</span><br><span class=\"line\">%  Exercise 8 | Anomaly Detection and Collaborative Filtering</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">%</span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  exercise. You will need to complete the following functions:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     estimateGaussian.m</span><br><span class=\"line\">%     selectThreshold.m</span><br><span class=\"line\">%     cofiCostFunc.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================== Part 1: Load Example Dataset  ===================</span><br><span class=\"line\">%  We start this exercise by using a small dataset that is easy to</span><br><span class=\"line\">%  visualize.</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Our example case consists of 2 network server statistics across</span><br><span class=\"line\">%  several machines: the latency and throughput of each machine.</span><br><span class=\"line\">%  This exercise will help us find possibly faulty (or very fast) machines.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Visualizing example dataset for outlier detection.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  The following command loads the dataset. You should now have the</span><br><span class=\"line\">%  variables X, Xval, yval in your environment</span><br><span class=\"line\">load(&#x27;ex8data1.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Visualize the example dataset</span><br><span class=\"line\">plot(X(:, 1), X(:, 2), &#x27;bx&#x27;);</span><br><span class=\"line\">axis([0 30 0 30]);</span><br><span class=\"line\">xlabel(&#x27;Latency (ms)&#x27;);</span><br><span class=\"line\">ylabel(&#x27;Throughput (mb/s)&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================== Part 2: Estimate the dataset statistics ===================</span><br><span class=\"line\">%  For this exercise, we assume a Gaussian distribution for the dataset.</span><br><span class=\"line\">%</span><br><span class=\"line\">%  We first estimate the parameters of our assumed Gaussian distribution, </span><br><span class=\"line\">%  then compute the probabilities for each of the points and then visualize </span><br><span class=\"line\">%  both the overall distribution and where each of the points falls in </span><br><span class=\"line\">%  terms of that distribution.</span><br><span class=\"line\">%</span><br><span class=\"line\">fprintf(&#x27;Visualizing Gaussian fit.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Estimate my and sigma2</span><br><span class=\"line\">[mu sigma2] = estimateGaussian(X);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Returns the density of the multivariate normal at each data point (row) </span><br><span class=\"line\">%  of X</span><br><span class=\"line\">p = multivariateGaussian(X, mu, sigma2);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Visualize the fit</span><br><span class=\"line\">visualizeFit(X,  mu, sigma2);</span><br><span class=\"line\">xlabel(&#x27;Latency (ms)&#x27;);</span><br><span class=\"line\">ylabel(&#x27;Throughput (mb/s)&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================== Part 3: Find Outliers ===================</span><br><span class=\"line\">%  Now you will find a good epsilon threshold using a cross-validation set</span><br><span class=\"line\">%  probabilities given the estimated Gaussian distribution</span><br><span class=\"line\">% </span><br><span class=\"line\"></span><br><span class=\"line\">pval = multivariateGaussian(Xval, mu, sigma2);</span><br><span class=\"line\"></span><br><span class=\"line\">[epsilon F1] = selectThreshold(yval, pval);</span><br><span class=\"line\">fprintf(&#x27;Best epsilon found using cross-validation: %e\\n&#x27;, epsilon);</span><br><span class=\"line\">fprintf(&#x27;Best F1 on Cross Validation Set:  %f\\n&#x27;, F1);</span><br><span class=\"line\">fprintf(&#x27;   (you should see a value epsilon of about 8.99e-05)\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;   (you should see a Best F1 value of  0.875000)\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Find the outliers in the training set and plot the</span><br><span class=\"line\">outliers = find(p &lt; epsilon);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Draw a red circle around those outliers</span><br><span class=\"line\">hold on</span><br><span class=\"line\">plot(X(outliers, 1), X(outliers, 2), &#x27;ro&#x27;, &#x27;LineWidth&#x27;, 2, &#x27;MarkerSize&#x27;, 10);</span><br><span class=\"line\">hold off</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================== Part 4: Multidimensional Outliers ===================</span><br><span class=\"line\">%  We will now use the code from the previous part and apply it to a </span><br><span class=\"line\">%  harder problem in which more features describe each datapoint and only </span><br><span class=\"line\">%  some features indicate whether a point is an outlier.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%  Loads the second dataset. You should now have the</span><br><span class=\"line\">%  variables X, Xval, yval in your environment</span><br><span class=\"line\">load(&#x27;ex8data2.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Apply the same steps to the larger dataset</span><br><span class=\"line\">[mu sigma2] = estimateGaussian(X);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Training set </span><br><span class=\"line\">p = multivariateGaussian(X, mu, sigma2);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Cross-validation set</span><br><span class=\"line\">pval = multivariateGaussian(Xval, mu, sigma2);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Find the best threshold</span><br><span class=\"line\">[epsilon F1] = selectThreshold(yval, pval);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Best epsilon found using cross-validation: %e\\n&#x27;, epsilon);</span><br><span class=\"line\">fprintf(&#x27;Best F1 on Cross Validation Set:  %f\\n&#x27;, F1);</span><br><span class=\"line\">fprintf(&#x27;   (you should see a value epsilon of about 1.38e-18)\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;   (you should see a Best F1 value of 0.615385)\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;# Outliers found: %d\\n\\n&#x27;, sum(p &lt; epsilon));</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"estimateGaussian-m\"><a href=\"#estimateGaussian-m\" class=\"headerlink\" title=\"estimateGaussian.m\"></a>estimateGaussian.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [mu sigma2] = estimateGaussian(X)</span><br><span class=\"line\">%ESTIMATEGAUSSIAN This function estimates the parameters of a </span><br><span class=\"line\">%Gaussian distribution using the data in X</span><br><span class=\"line\">%   [mu sigma2] = estimateGaussian(X), </span><br><span class=\"line\">%   The input X is the dataset with each n-dimensional data point in one row</span><br><span class=\"line\">%   The output is an n-dimensional vector mu, the mean of the data set</span><br><span class=\"line\">%   and the variances sigma^2, an n x 1 vector</span><br><span class=\"line\">% </span><br><span class=\"line\"></span><br><span class=\"line\">% Useful variables</span><br><span class=\"line\">[m, n] = size(X);</span><br><span class=\"line\"></span><br><span class=\"line\">% You should return these values correctly</span><br><span class=\"line\">mu = zeros(n, 1);</span><br><span class=\"line\">sigma2 = zeros(n, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the mean of the data and the variances</span><br><span class=\"line\">%               In particular, mu(i) should contain the mean of</span><br><span class=\"line\">%               the data for the i-th feature and sigma2(i)</span><br><span class=\"line\">%               should contain variance of the i-th feature.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">mu = sum(X,1)/m;</span><br><span class=\"line\"></span><br><span class=\"line\">sigma2 = sum((X-mu).^2,1)/m;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"multivariateGaussian-m\"><a href=\"#multivariateGaussian-m\" class=\"headerlink\" title=\"multivariateGaussian.m\"></a>multivariateGaussian.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function p = multivariateGaussian(X, mu, Sigma2)</span><br><span class=\"line\">%MULTIVARIATEGAUSSIAN Computes the probability density function of the</span><br><span class=\"line\">%multivariate gaussian distribution.</span><br><span class=\"line\">%    p = MULTIVARIATEGAUSSIAN(X, mu, Sigma2) Computes the probability </span><br><span class=\"line\">%    density function of the examples X under the multivariate gaussian </span><br><span class=\"line\">%    distribution with parameters mu and Sigma2. If Sigma2 is a matrix, it is</span><br><span class=\"line\">%    treated as the covariance matrix. If Sigma2 is a vector, it is treated</span><br><span class=\"line\">%    as the \\sigma^2 values of the variances in each dimension (a diagonal</span><br><span class=\"line\">%    covariance matrix)</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">k = length(mu);</span><br><span class=\"line\"></span><br><span class=\"line\">if (size(Sigma2, 2) == 1) || (size(Sigma2, 1) == 1)</span><br><span class=\"line\">    Sigma2 = diag(Sigma2);</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">X = bsxfun(@minus, X, mu(:)&#x27;);</span><br><span class=\"line\">p = (2 * pi) ^ (- k / 2) * det(Sigma2) ^ (-0.5) * ...</span><br><span class=\"line\">    exp(-0.5 * sum(bsxfun(@times, X * pinv(Sigma2), X), 2));</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"selectThreshold-m\"><a href=\"#selectThreshold-m\" class=\"headerlink\" title=\"selectThreshold.m\"></a>selectThreshold.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [bestEpsilon bestF1] = selectThreshold(yval, pval)</span><br><span class=\"line\">%SELECTTHRESHOLD Find the best threshold (epsilon) to use for selecting</span><br><span class=\"line\">%outliers</span><br><span class=\"line\">%   [bestEpsilon bestF1] = SELECTTHRESHOLD(yval, pval) finds the best</span><br><span class=\"line\">%   threshold to use for selecting outliers based on the results from a</span><br><span class=\"line\">%   validation set (pval) and the ground truth (yval).</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">bestEpsilon = 0;</span><br><span class=\"line\">bestF1 = 0;</span><br><span class=\"line\">F1 = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">stepsize = (max(pval) - min(pval)) / 1000;</span><br><span class=\"line\">for epsilon = min(pval):stepsize:max(pval)</span><br><span class=\"line\">    </span><br><span class=\"line\">    % ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">    % Instructions: Compute the F1 score of choosing epsilon as the</span><br><span class=\"line\">    %               threshold and place the value in F1. The code at the</span><br><span class=\"line\">    %               end of the loop will compare the F1 score for this</span><br><span class=\"line\">    %               choice of epsilon and set it to be the best epsilon if</span><br><span class=\"line\">    %               it is better than the current choice of epsilon.</span><br><span class=\"line\">    %               </span><br><span class=\"line\">    % Note: You can use predictions = (pval &lt; epsilon) to get a binary vector</span><br><span class=\"line\">    %       of 0&#x27;s and 1&#x27;s of the outlier predictions</span><br><span class=\"line\"></span><br><span class=\"line\">    predictions = (pval &lt; epsilon);</span><br><span class=\"line\"></span><br><span class=\"line\">    fp = sum((predictions ==1) &amp; (yval == 0));</span><br><span class=\"line\">    tp = sum((predictions ==1) &amp; (yval == 1));</span><br><span class=\"line\">    fn = sum((predictions ==0) &amp; (yval == 1));</span><br><span class=\"line\"></span><br><span class=\"line\">    prec = tp/(tp+fp);</span><br><span class=\"line\">    rec = tp/(tp+fn);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    F1 = 2*(prec*rec)/(prec+rec);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    % =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">    if F1 &gt; bestF1</span><br><span class=\"line\">       bestF1 = F1;</span><br><span class=\"line\">       bestEpsilon = epsilon;</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"visualizeFit-m\"><a href=\"#visualizeFit-m\" class=\"headerlink\" title=\"visualizeFit.m\"></a>visualizeFit.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function visualizeFit(X, mu, sigma2)</span><br><span class=\"line\">%VISUALIZEFIT Visualize the dataset and its estimated distribution.</span><br><span class=\"line\">%   VISUALIZEFIT(X, p, mu, sigma2) This visualization shows you the </span><br><span class=\"line\">%   probability density function of the Gaussian distribution. Each example</span><br><span class=\"line\">%   has a location (x1, x2) that depends on its feature values.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">[X1,X2] = meshgrid(0:.5:35); </span><br><span class=\"line\">Z = multivariateGaussian([X1(:) X2(:)],mu,sigma2);</span><br><span class=\"line\">Z = reshape(Z,size(X1));</span><br><span class=\"line\"></span><br><span class=\"line\">plot(X(:, 1), X(:, 2),&#x27;bx&#x27;);</span><br><span class=\"line\">hold on;</span><br><span class=\"line\">% Do not plot if there are infinities</span><br><span class=\"line\">if (sum(isinf(Z)) == 0)</span><br><span class=\"line\">    contour(X1, X2, Z, 10.^(-20:3:0)&#x27;);</span><br><span class=\"line\">end</span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"ex8-cofi-m\"><a href=\"#ex8-cofi-m\" class=\"headerlink\" title=\"ex8_cofi.m\"></a>ex8_cofi.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class</span><br><span class=\"line\">%  Exercise 8 | Anomaly Detection and Collaborative Filtering</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">%</span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  exercise. You will need to complete the following functions:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     estimateGaussian.m</span><br><span class=\"line\">%     selectThreshold.m</span><br><span class=\"line\">%     cofiCostFunc.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% =============== Part 1: Loading movie ratings dataset ================</span><br><span class=\"line\">%  You will start by loading the movie ratings dataset to understand the</span><br><span class=\"line\">%  structure of the data.</span><br><span class=\"line\">%  </span><br><span class=\"line\">fprintf(&#x27;Loading movie ratings dataset.\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Load data</span><br><span class=\"line\">load (&#x27;ex8_movies.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Y is a 1682x943 matrix, containing ratings (1-5) of 1682 movies on </span><br><span class=\"line\">%  943 users</span><br><span class=\"line\">%</span><br><span class=\"line\">%  R is a 1682x943 matrix, where R(i,j) = 1 if and only if user j gave a</span><br><span class=\"line\">%  rating to movie i</span><br><span class=\"line\"></span><br><span class=\"line\">%  From the matrix, we can compute statistics like average rating.</span><br><span class=\"line\">fprintf(&#x27;Average rating for movie 1 (Toy Story): %f / 5\\n\\n&#x27;, ...</span><br><span class=\"line\">        mean(Y(1, R(1, :))));</span><br><span class=\"line\"></span><br><span class=\"line\">%  We can &quot;visualize&quot; the ratings matrix by plotting it with imagesc</span><br><span class=\"line\">imagesc(Y);</span><br><span class=\"line\">ylabel(&#x27;Movies&#x27;);</span><br><span class=\"line\">xlabel(&#x27;Users&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ============ Part 2: Collaborative Filtering Cost Function ===========</span><br><span class=\"line\">%  You will now implement the cost function for collaborative filtering.</span><br><span class=\"line\">%  To help you debug your cost function, we have included set of weights</span><br><span class=\"line\">%  that we trained on that. Specifically, you should complete the code in </span><br><span class=\"line\">%  cofiCostFunc.m to return J.</span><br><span class=\"line\"></span><br><span class=\"line\">%  Load pre-trained weights (X, Theta, num_users, num_movies, num_features)</span><br><span class=\"line\">load (&#x27;ex8_movieParams.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Reduce the data set size so that this runs faster</span><br><span class=\"line\">num_users = 4; num_movies = 5; num_features = 3;</span><br><span class=\"line\">X = X(1:num_movies, 1:num_features);</span><br><span class=\"line\">Theta = Theta(1:num_users, 1:num_features);</span><br><span class=\"line\">Y = Y(1:num_movies, 1:num_users);</span><br><span class=\"line\">R = R(1:num_movies, 1:num_users);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Evaluate cost function</span><br><span class=\"line\">J = cofiCostFunc([X(:) ; Theta(:)], Y, R, num_users, num_movies, ...</span><br><span class=\"line\">               num_features, 0);</span><br><span class=\"line\">           </span><br><span class=\"line\">fprintf([&#x27;Cost at loaded parameters: %f &#x27;...</span><br><span class=\"line\">         &#x27;\\n(this value should be about 22.22)\\n&#x27;], J);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ============== Part 3: Collaborative Filtering Gradient ==============</span><br><span class=\"line\">%  Once your cost function matches up with ours, you should now implement </span><br><span class=\"line\">%  the collaborative filtering gradient function. Specifically, you should </span><br><span class=\"line\">%  complete the code in cofiCostFunc.m to return the grad argument.</span><br><span class=\"line\">%  </span><br><span class=\"line\">fprintf(&#x27;\\nChecking Gradients (without regularization) ... \\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Check gradients by running checkNNGradients</span><br><span class=\"line\">checkCostFunction;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ========= Part 4: Collaborative Filtering Cost Regularization ========</span><br><span class=\"line\">%  Now, you should implement regularization for the cost function for </span><br><span class=\"line\">%  collaborative filtering. You can implement it by adding the cost of</span><br><span class=\"line\">%  regularization to the original cost computation.</span><br><span class=\"line\">%  </span><br><span class=\"line\"></span><br><span class=\"line\">%  Evaluate cost function</span><br><span class=\"line\">J = cofiCostFunc([X(:) ; Theta(:)], Y, R, num_users, num_movies, ...</span><br><span class=\"line\">               num_features, 1.5);</span><br><span class=\"line\">           </span><br><span class=\"line\">fprintf([&#x27;Cost at loaded parameters (lambda = 1.5): %f &#x27;...</span><br><span class=\"line\">         &#x27;\\n(this value should be about 31.34)\\n&#x27;], J);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ======= Part 5: Collaborative Filtering Gradient Regularization ======</span><br><span class=\"line\">%  Once your cost matches up with ours, you should proceed to implement </span><br><span class=\"line\">%  regularization for the gradient. </span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%  </span><br><span class=\"line\">fprintf(&#x27;\\nChecking Gradients (with regularization) ... \\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Check gradients by running checkNNGradients</span><br><span class=\"line\">checkCostFunction(1.5);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ============== Part 6: Entering ratings for a new user ===============</span><br><span class=\"line\">%  Before we will train the collaborative filtering model, we will first</span><br><span class=\"line\">%  add ratings that correspond to a new user that we just observed. This</span><br><span class=\"line\">%  part of the code will also allow you to put in your own ratings for the</span><br><span class=\"line\">%  movies in our dataset!</span><br><span class=\"line\">%</span><br><span class=\"line\">movieList = loadMovieList();</span><br><span class=\"line\"></span><br><span class=\"line\">%  Initialize my ratings</span><br><span class=\"line\">my_ratings = zeros(1682, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Check the file movie_idx.txt for id of each movie in our dataset</span><br><span class=\"line\">% For example, Toy Story (1995) has ID 1, so to rate it &quot;4&quot;, you can set</span><br><span class=\"line\">my_ratings(1) = 4;</span><br><span class=\"line\"></span><br><span class=\"line\">% Or suppose did not enjoy Silence of the Lambs (1991), you can set</span><br><span class=\"line\">my_ratings(98) = 2;</span><br><span class=\"line\"></span><br><span class=\"line\">% We have selected a few movies we liked / did not like and the ratings we</span><br><span class=\"line\">% gave are as follows:</span><br><span class=\"line\">my_ratings(7) = 3;</span><br><span class=\"line\">my_ratings(12)= 5;</span><br><span class=\"line\">my_ratings(54) = 4;</span><br><span class=\"line\">my_ratings(64)= 5;</span><br><span class=\"line\">my_ratings(66)= 3;</span><br><span class=\"line\">my_ratings(69) = 5;</span><br><span class=\"line\">my_ratings(183) = 4;</span><br><span class=\"line\">my_ratings(226) = 5;</span><br><span class=\"line\">my_ratings(355)= 5;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\n\\nNew user ratings:\\n&#x27;);</span><br><span class=\"line\">for i = 1:length(my_ratings)</span><br><span class=\"line\">    if my_ratings(i) &gt; 0 </span><br><span class=\"line\">        fprintf(&#x27;Rated %d for %s\\n&#x27;, my_ratings(i), ...</span><br><span class=\"line\">                 movieList&#123;i&#125;);</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================== Part 7: Learning Movie Ratings ====================</span><br><span class=\"line\">%  Now, you will train the collaborative filtering model on a movie rating </span><br><span class=\"line\">%  dataset of 1682 movies and 943 users</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nTraining collaborative filtering...\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Load data</span><br><span class=\"line\">load(&#x27;ex8_movies.mat&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Y is a 1682x943 matrix, containing ratings (1-5) of 1682 movies by </span><br><span class=\"line\">%  943 users</span><br><span class=\"line\">%</span><br><span class=\"line\">%  R is a 1682x943 matrix, where R(i,j) = 1 if and only if user j gave a</span><br><span class=\"line\">%  rating to movie i</span><br><span class=\"line\"></span><br><span class=\"line\">%  Add our own ratings to the data matrix</span><br><span class=\"line\">Y = [my_ratings Y];</span><br><span class=\"line\">R = [(my_ratings ~= 0) R];</span><br><span class=\"line\"></span><br><span class=\"line\">%  Normalize Ratings</span><br><span class=\"line\">[Ynorm, Ymean] = normalizeRatings(Y, R);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Useful Values</span><br><span class=\"line\">num_users = size(Y, 2);</span><br><span class=\"line\">num_movies = size(Y, 1);</span><br><span class=\"line\">num_features = 10;</span><br><span class=\"line\"></span><br><span class=\"line\">% Set Initial Parameters (Theta, X)</span><br><span class=\"line\">X = randn(num_movies, num_features);</span><br><span class=\"line\">Theta = randn(num_users, num_features);</span><br><span class=\"line\"></span><br><span class=\"line\">initial_parameters = [X(:); Theta(:)];</span><br><span class=\"line\"></span><br><span class=\"line\">% Set options for fmincg</span><br><span class=\"line\">options = optimset(&#x27;GradObj&#x27;, &#x27;on&#x27;, &#x27;MaxIter&#x27;, 100);</span><br><span class=\"line\"></span><br><span class=\"line\">% Set Regularization</span><br><span class=\"line\">lambda = 10;</span><br><span class=\"line\">theta = fmincg (@(t)(cofiCostFunc(t, Ynorm, R, num_users, num_movies, ...</span><br><span class=\"line\">                                num_features, lambda)), ...</span><br><span class=\"line\">                initial_parameters, options);</span><br><span class=\"line\"></span><br><span class=\"line\">% Unfold the returned theta back into U and W</span><br><span class=\"line\">X = reshape(theta(1:num_movies*num_features), num_movies, num_features);</span><br><span class=\"line\">Theta = reshape(theta(num_movies*num_features+1:end), ...</span><br><span class=\"line\">                num_users, num_features);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Recommender system learning completed.\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================== Part 8: Recommendation for you ====================</span><br><span class=\"line\">%  After training the model, you can now make recommendations by computing</span><br><span class=\"line\">%  the predictions matrix.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">p = X * Theta&#x27;;</span><br><span class=\"line\">my_predictions = p(:,1) + Ymean;</span><br><span class=\"line\"></span><br><span class=\"line\">movieList = loadMovieList();</span><br><span class=\"line\"></span><br><span class=\"line\">[r, ix] = sort(my_predictions, &#x27;descend&#x27;);</span><br><span class=\"line\">fprintf(&#x27;\\nTop recommendations for you:\\n&#x27;);</span><br><span class=\"line\">for i=1:10</span><br><span class=\"line\">    j = ix(i);</span><br><span class=\"line\">    fprintf(&#x27;Predicting rating %.1f for movie %s\\n&#x27;, my_predictions(j), ...</span><br><span class=\"line\">            movieList&#123;j&#125;);</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\n\\nOriginal ratings provided:\\n&#x27;);</span><br><span class=\"line\">for i = 1:length(my_ratings)</span><br><span class=\"line\">    if my_ratings(i) &gt; 0 </span><br><span class=\"line\">        fprintf(&#x27;Rated %d for %s\\n&#x27;, my_ratings(i), ...</span><br><span class=\"line\">                 movieList&#123;i&#125;);</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"cofiCostFunc-m\"><a href=\"#cofiCostFunc-m\" class=\"headerlink\" title=\"cofiCostFunc.m\"></a>cofiCostFunc.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [J, grad] = cofiCostFunc(params, Y, R, num_users, num_movies, ...</span><br><span class=\"line\">                                  num_features, lambda)</span><br><span class=\"line\">%COFICOSTFUNC Collaborative filtering cost function</span><br><span class=\"line\">%   [J, grad] = COFICOSTFUNC(params, Y, R, num_users, num_movies, ...</span><br><span class=\"line\">%   num_features, lambda) returns the cost and gradient for the</span><br><span class=\"line\">%   collaborative filtering problem.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Unfold the U and W matrices from params</span><br><span class=\"line\">X = reshape(params(1:num_movies*num_features), num_movies, num_features);</span><br><span class=\"line\">Theta = reshape(params(num_movies*num_features+1:end), ...</span><br><span class=\"line\">                num_users, num_features);</span><br><span class=\"line\"></span><br><span class=\"line\">            </span><br><span class=\"line\">% You need to return the following values correctly</span><br><span class=\"line\">J = 0;</span><br><span class=\"line\">X_grad = zeros(size(X));</span><br><span class=\"line\">Theta_grad = zeros(size(Theta));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the cost function and gradient for collaborative</span><br><span class=\"line\">%               filtering. Concretely, you should first implement the cost</span><br><span class=\"line\">%               function (without regularization) and make sure it is</span><br><span class=\"line\">%               matches our costs. After that, you should implement the </span><br><span class=\"line\">%               gradient and use the checkCostFunction routine to check</span><br><span class=\"line\">%               that the gradient is correct. Finally, you should implement</span><br><span class=\"line\">%               regularization.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Notes: X - num_movies  x num_features matrix of movie features</span><br><span class=\"line\">%        Theta - num_users  x num_features matrix of user features</span><br><span class=\"line\">%        Y - num_movies x num_users matrix of user ratings of movies</span><br><span class=\"line\">%        R - num_movies x num_users matrix, where R(i, j) = 1 if the </span><br><span class=\"line\">%            i-th movie was rated by the j-th user</span><br><span class=\"line\">%</span><br><span class=\"line\">% You should set the following variables correctly:</span><br><span class=\"line\">%</span><br><span class=\"line\">%        X_grad - num_movies x num_features matrix, containing the </span><br><span class=\"line\">%                 partial derivatives w.r.t. to each element of X</span><br><span class=\"line\">%        Theta_grad - num_users x num_features matrix, containing the </span><br><span class=\"line\">%                     partial derivatives w.r.t. to each element of Theta</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">J = 1/2*sum(sum((X*Theta&#x27;-Y).^2.*R));</span><br><span class=\"line\"></span><br><span class=\"line\">c_regular = 0;</span><br><span class=\"line\">c_regular = (lambda/2)*sum(sum(Theta.^2)) + (lambda/2)*sum(sum(X.^2));</span><br><span class=\"line\"></span><br><span class=\"line\">J = J + c_regular;</span><br><span class=\"line\"></span><br><span class=\"line\">X_grad = ((X*Theta&#x27;-Y).*R)*Theta;</span><br><span class=\"line\">Theta_grad = ((X*Theta&#x27;-Y).*R)&#x27;*X;</span><br><span class=\"line\"></span><br><span class=\"line\">X_grad_regular = lambda*X;</span><br><span class=\"line\">Theta_grad_regular = lambda*Theta;</span><br><span class=\"line\"></span><br><span class=\"line\">X_grad = X_grad + X_grad_regular;</span><br><span class=\"line\">Theta_grad = Theta_grad + Theta_grad_regular;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">grad = [X_grad(:); Theta_grad(:)];</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"checkCostFunction-m\"><a href=\"#checkCostFunction-m\" class=\"headerlink\" title=\"checkCostFunction.m\"></a>checkCostFunction.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function checkCostFunction(lambda)</span><br><span class=\"line\">%CHECKCOSTFUNCTION Creates a collaborative filering problem </span><br><span class=\"line\">%to check your cost function and gradients</span><br><span class=\"line\">%   CHECKCOSTFUNCTION(lambda) Creates a collaborative filering problem </span><br><span class=\"line\">%   to check your cost function and gradients, it will output the </span><br><span class=\"line\">%   analytical gradients produced by your code and the numerical gradients </span><br><span class=\"line\">%   (computed using computeNumericalGradient). These two gradient </span><br><span class=\"line\">%   computations should result in very similar values.</span><br><span class=\"line\"></span><br><span class=\"line\">% Set lambda</span><br><span class=\"line\">if ~exist(&#x27;lambda&#x27;, &#x27;var&#x27;) || isempty(lambda)</span><br><span class=\"line\">    lambda = 0;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">%% Create small problem</span><br><span class=\"line\">X_t = rand(4, 3);</span><br><span class=\"line\">Theta_t = rand(5, 3);</span><br><span class=\"line\"></span><br><span class=\"line\">% Zap out most entries</span><br><span class=\"line\">Y = X_t * Theta_t&#x27;;</span><br><span class=\"line\">Y(rand(size(Y)) &gt; 0.5) = 0;</span><br><span class=\"line\">R = zeros(size(Y));</span><br><span class=\"line\">R(Y ~= 0) = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">%% Run Gradient Checking</span><br><span class=\"line\">X = randn(size(X_t));</span><br><span class=\"line\">Theta = randn(size(Theta_t));</span><br><span class=\"line\">num_users = size(Y, 2);</span><br><span class=\"line\">num_movies = size(Y, 1);</span><br><span class=\"line\">num_features = size(Theta_t, 2);</span><br><span class=\"line\"></span><br><span class=\"line\">numgrad = computeNumericalGradient( ...</span><br><span class=\"line\">                @(t) cofiCostFunc(t, Y, R, num_users, num_movies, ...</span><br><span class=\"line\">                                num_features, lambda), [X(:); Theta(:)]);</span><br><span class=\"line\"></span><br><span class=\"line\">[cost, grad] = cofiCostFunc([X(:); Theta(:)],  Y, R, num_users, ...</span><br><span class=\"line\">                          num_movies, num_features, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">disp([numgrad grad]);</span><br><span class=\"line\">fprintf([&#x27;The above two columns you get should be very similar.\\n&#x27; ...</span><br><span class=\"line\">         &#x27;(Left-Your Numerical Gradient, Right-Analytical Gradient)\\n\\n&#x27;]);</span><br><span class=\"line\"></span><br><span class=\"line\">diff = norm(numgrad-grad)/norm(numgrad+grad);</span><br><span class=\"line\">fprintf([&#x27;If your cost function implementation is correct, then \\n&#x27; ...</span><br><span class=\"line\">         &#x27;the relative difference will be small (less than 1e-9). \\n&#x27; ...</span><br><span class=\"line\">         &#x27;\\nRelative Difference: %g\\n&#x27;], diff);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"computeNumericalGradient-m\"><a href=\"#computeNumericalGradient-m\" class=\"headerlink\" title=\"computeNumericalGradient.m\"></a>computeNumericalGradient.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function numgrad = computeNumericalGradient(J, theta)</span><br><span class=\"line\">%COMPUTENUMERICALGRADIENT Computes the gradient using &quot;finite differences&quot;</span><br><span class=\"line\">%and gives us a numerical estimate of the gradient.</span><br><span class=\"line\">%   numgrad = COMPUTENUMERICALGRADIENT(J, theta) computes the numerical</span><br><span class=\"line\">%   gradient of the function J around theta. Calling y = J(theta) should</span><br><span class=\"line\">%   return the function value at theta.</span><br><span class=\"line\"></span><br><span class=\"line\">% Notes: The following code implements numerical gradient checking, and </span><br><span class=\"line\">%        returns the numerical gradient.It sets numgrad(i) to (a numerical </span><br><span class=\"line\">%        approximation of) the partial derivative of J with respect to the </span><br><span class=\"line\">%        i-th input argument, evaluated at theta. (i.e., numgrad(i) should </span><br><span class=\"line\">%        be the (approximately) the partial derivative of J with respect </span><br><span class=\"line\">%        to theta(i).)</span><br><span class=\"line\">%                </span><br><span class=\"line\"></span><br><span class=\"line\">numgrad = zeros(size(theta));</span><br><span class=\"line\">perturb = zeros(size(theta));</span><br><span class=\"line\">e = 1e-4;</span><br><span class=\"line\">for p = 1:numel(theta)</span><br><span class=\"line\">    % Set perturbation vector</span><br><span class=\"line\">    perturb(p) = e;</span><br><span class=\"line\">    loss1 = J(theta - perturb);</span><br><span class=\"line\">    loss2 = J(theta + perturb);</span><br><span class=\"line\">    % Compute Numerical Gradient</span><br><span class=\"line\">    numgrad(p) = (loss2 - loss1) / (2*e);</span><br><span class=\"line\">    perturb(p) = 0;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"loadMovieList-m\"><a href=\"#loadMovieList-m\" class=\"headerlink\" title=\"loadMovieList.m\"></a>loadMovieList.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function movieList = loadMovieList()</span><br><span class=\"line\">%GETMOVIELIST reads the fixed movie list in movie.txt and returns a</span><br><span class=\"line\">%cell array of the words</span><br><span class=\"line\">%   movieList = GETMOVIELIST() reads the fixed movie list in movie.txt </span><br><span class=\"line\">%   and returns a cell array of the words in movieList.</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% Read the fixed movieulary list</span><br><span class=\"line\">fid = fopen(&#x27;movie_ids.txt&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Store all movies in cell array movie&#123;&#125;</span><br><span class=\"line\">n = 1682;  % Total number of movies </span><br><span class=\"line\"></span><br><span class=\"line\">movieList = cell(n, 1);</span><br><span class=\"line\">for i = 1:n</span><br><span class=\"line\">    % Read line</span><br><span class=\"line\">    line = fgets(fid);</span><br><span class=\"line\">    % Word Index (can ignore since it will be = i)</span><br><span class=\"line\">    [idx, movieName] = strtok(line, &#x27; &#x27;);</span><br><span class=\"line\">    % Actual Word</span><br><span class=\"line\">    movieList&#123;i&#125; = strtrim(movieName);</span><br><span class=\"line\">end</span><br><span class=\"line\">fclose(fid);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"normalizeRatings-m\"><a href=\"#normalizeRatings-m\" class=\"headerlink\" title=\"normalizeRatings.m\"></a>normalizeRatings.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [Ynorm, Ymean] = normalizeRatings(Y, R)</span><br><span class=\"line\">%NORMALIZERATINGS Preprocess data by subtracting mean rating for every </span><br><span class=\"line\">%movie (every row)</span><br><span class=\"line\">%   [Ynorm, Ymean] = NORMALIZERATINGS(Y, R) normalized Y so that each movie</span><br><span class=\"line\">%   has a rating of 0 on average, and returns the mean rating in Ymean.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">[m, n] = size(Y);</span><br><span class=\"line\">Ymean = zeros(m, 1);</span><br><span class=\"line\">Ynorm = zeros(size(Y));</span><br><span class=\"line\">for i = 1:m</span><br><span class=\"line\">    idx = find(R(i, :) == 1);</span><br><span class=\"line\">    Ymean(i) = mean(Y(i, idx));</span><br><span class=\"line\">    Ynorm(i, idx) = Y(i, idx) - Ymean(i);</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"fmincg-m\"><a href=\"#fmincg-m\" class=\"headerlink\" title=\"fmincg.m\"></a>fmincg.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)</span><br><span class=\"line\">% Minimize a continuous differentialble multivariate function. Starting point</span><br><span class=\"line\">% is given by &quot;X&quot; (D by 1), and the function named in the string &quot;f&quot;, must</span><br><span class=\"line\">% return a function value and a vector of partial derivatives. The Polack-</span><br><span class=\"line\">% Ribiere flavour of conjugate gradients is used to compute search directions,</span><br><span class=\"line\">% and a line search using quadratic and cubic polynomial approximations and the</span><br><span class=\"line\">% Wolfe-Powell stopping criteria is used together with the slope ratio method</span><br><span class=\"line\">% for guessing initial step sizes. Additionally a bunch of checks are made to</span><br><span class=\"line\">% make sure that exploration is taking place and that extrapolation will not</span><br><span class=\"line\">% be unboundedly large. The &quot;length&quot; gives the length of the run: if it is</span><br><span class=\"line\">% positive, it gives the maximum number of line searches, if negative its</span><br><span class=\"line\">% absolute gives the maximum allowed number of function evaluations. You can</span><br><span class=\"line\">% (optionally) give &quot;length&quot; a second component, which will indicate the</span><br><span class=\"line\">% reduction in function value to be expected in the first line-search (defaults</span><br><span class=\"line\">% to 1.0). The function returns when either its length is up, or if no further</span><br><span class=\"line\">% progress can be made (ie, we are at a minimum, or so close that due to</span><br><span class=\"line\">% numerical problems, we cannot get any closer). If the function terminates</span><br><span class=\"line\">% within a few iterations, it could be an indication that the function value</span><br><span class=\"line\">% and derivatives are not consistent (ie, there may be a bug in the</span><br><span class=\"line\">% implementation of your &quot;f&quot; function). The function returns the found</span><br><span class=\"line\">% solution &quot;X&quot;, a vector of function values &quot;fX&quot; indicating the progress made</span><br><span class=\"line\">% and &quot;i&quot; the number of iterations (line searches or function evaluations,</span><br><span class=\"line\">% depending on the sign of &quot;length&quot;) used.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Usage: [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)</span><br><span class=\"line\">%</span><br><span class=\"line\">% See also: checkgrad </span><br><span class=\"line\">%</span><br><span class=\"line\">% Copyright (C) 2001 and 2002 by Carl Edward Rasmussen. Date 2002-02-13</span><br><span class=\"line\">%</span><br><span class=\"line\">%</span><br><span class=\"line\">% (C) Copyright 1999, 2000 &amp; 2001, Carl Edward Rasmussen</span><br><span class=\"line\">% </span><br><span class=\"line\">% Permission is granted for anyone to copy, use, or modify these</span><br><span class=\"line\">% programs and accompanying documents for purposes of research or</span><br><span class=\"line\">% education, provided this copyright notice is retained, and note is</span><br><span class=\"line\">% made of any changes that have been made.</span><br><span class=\"line\">% </span><br><span class=\"line\">% These programs and documents are distributed without any warranty,</span><br><span class=\"line\">% express or implied.  As the programs were written for research</span><br><span class=\"line\">% purposes only, they have not been tested to the degree that would be</span><br><span class=\"line\">% advisable in any important application.  All use of these programs is</span><br><span class=\"line\">% entirely at the user&#x27;s own risk.</span><br><span class=\"line\">%</span><br><span class=\"line\">% [ml-class] Changes Made:</span><br><span class=\"line\">% 1) Function name and argument specifications</span><br><span class=\"line\">% 2) Output display</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Read options</span><br><span class=\"line\">if exist(&#x27;options&#x27;, &#x27;var&#x27;) &amp;&amp; ~isempty(options) &amp;&amp; isfield(options, &#x27;MaxIter&#x27;)</span><br><span class=\"line\">    length = options.MaxIter;</span><br><span class=\"line\">else</span><br><span class=\"line\">    length = 100;</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">RHO = 0.01;                            % a bunch of constants for line searches</span><br><span class=\"line\">SIG = 0.5;       % RHO and SIG are the constants in the Wolfe-Powell conditions</span><br><span class=\"line\">INT = 0.1;    % don&#x27;t reevaluate within 0.1 of the limit of the current bracket</span><br><span class=\"line\">EXT = 3.0;                    % extrapolate maximum 3 times the current bracket</span><br><span class=\"line\">MAX = 20;                         % max 20 function evaluations per line search</span><br><span class=\"line\">RATIO = 100;                                      % maximum allowed slope ratio</span><br><span class=\"line\"></span><br><span class=\"line\">argstr = [&#x27;feval(f, X&#x27;];                      % compose string used to call function</span><br><span class=\"line\">for i = 1:(nargin - 3)</span><br><span class=\"line\">  argstr = [argstr, &#x27;,P&#x27;, int2str(i)];</span><br><span class=\"line\">end</span><br><span class=\"line\">argstr = [argstr, &#x27;)&#x27;];</span><br><span class=\"line\"></span><br><span class=\"line\">if max(size(length)) == 2, red=length(2); length=length(1); else red=1; end</span><br><span class=\"line\">S=[&#x27;Iteration &#x27;];</span><br><span class=\"line\"></span><br><span class=\"line\">i = 0;                                            % zero the run length counter</span><br><span class=\"line\">ls_failed = 0;                             % no previous line search has failed</span><br><span class=\"line\">fX = [];</span><br><span class=\"line\">[f1 df1] = eval(argstr);                      % get function value and gradient</span><br><span class=\"line\">i = i + (length&lt;0);                                            % count epochs?!</span><br><span class=\"line\">s = -df1;                                        % search direction is steepest</span><br><span class=\"line\">d1 = -s&#x27;*s;                                                 % this is the slope</span><br><span class=\"line\">z1 = red/(1-d1);                                  % initial step is red/(|s|+1)</span><br><span class=\"line\"></span><br><span class=\"line\">while i &lt; abs(length)                                      % while not finished</span><br><span class=\"line\">  i = i + (length&gt;0);                                      % count iterations?!</span><br><span class=\"line\"></span><br><span class=\"line\">  X0 = X; f0 = f1; df0 = df1;                   % make a copy of current values</span><br><span class=\"line\">  X = X + z1*s;                                             % begin line search</span><br><span class=\"line\">  [f2 df2] = eval(argstr);</span><br><span class=\"line\">  i = i + (length&lt;0);                                          % count epochs?!</span><br><span class=\"line\">  d2 = df2&#x27;*s;</span><br><span class=\"line\">  f3 = f1; d3 = d1; z3 = -z1;             % initialize point 3 equal to point 1</span><br><span class=\"line\">  if length&gt;0, M = MAX; else M = min(MAX, -length-i); end</span><br><span class=\"line\">  success = 0; limit = -1;                     % initialize quanteties</span><br><span class=\"line\">  while 1</span><br><span class=\"line\">    while ((f2 &gt; f1+z1*RHO*d1) || (d2 &gt; -SIG*d1)) &amp;&amp; (M &gt; 0) </span><br><span class=\"line\">      limit = z1;                                         % tighten the bracket</span><br><span class=\"line\">      if f2 &gt; f1</span><br><span class=\"line\">        z2 = z3 - (0.5*d3*z3*z3)/(d3*z3+f2-f3);                 % quadratic fit</span><br><span class=\"line\">      else</span><br><span class=\"line\">        A = 6*(f2-f3)/z3+3*(d2+d3);                                 % cubic fit</span><br><span class=\"line\">        B = 3*(f3-f2)-z3*(d3+2*d2);</span><br><span class=\"line\">        z2 = (sqrt(B*B-A*d2*z3*z3)-B)/A;       % numerical error possible - ok!</span><br><span class=\"line\">      end</span><br><span class=\"line\">      if isnan(z2) || isinf(z2)</span><br><span class=\"line\">        z2 = z3/2;                  % if we had a numerical problem then bisect</span><br><span class=\"line\">      end</span><br><span class=\"line\">      z2 = max(min(z2, INT*z3),(1-INT)*z3);  % don&#x27;t accept too close to limits</span><br><span class=\"line\">      z1 = z1 + z2;                                           % update the step</span><br><span class=\"line\">      X = X + z2*s;</span><br><span class=\"line\">      [f2 df2] = eval(argstr);</span><br><span class=\"line\">      M = M - 1; i = i + (length&lt;0);                           % count epochs?!</span><br><span class=\"line\">      d2 = df2&#x27;*s;</span><br><span class=\"line\">      z3 = z3-z2;                    % z3 is now relative to the location of z2</span><br><span class=\"line\">    end</span><br><span class=\"line\">    if f2 &gt; f1+z1*RHO*d1 || d2 &gt; -SIG*d1</span><br><span class=\"line\">      break;                                                % this is a failure</span><br><span class=\"line\">    elseif d2 &gt; SIG*d1</span><br><span class=\"line\">      success = 1; break;                                             % success</span><br><span class=\"line\">    elseif M == 0</span><br><span class=\"line\">      break;                                                          % failure</span><br><span class=\"line\">    end</span><br><span class=\"line\">    A = 6*(f2-f3)/z3+3*(d2+d3);                      % make cubic extrapolation</span><br><span class=\"line\">    B = 3*(f3-f2)-z3*(d3+2*d2);</span><br><span class=\"line\">    z2 = -d2*z3*z3/(B+sqrt(B*B-A*d2*z3*z3));        % num. error possible - ok!</span><br><span class=\"line\">    if ~isreal(z2) || isnan(z2) || isinf(z2) || z2 &lt; 0 % num prob or wrong sign?</span><br><span class=\"line\">      if limit &lt; -0.5                               % if we have no upper limit</span><br><span class=\"line\">        z2 = z1 * (EXT-1);                 % the extrapolate the maximum amount</span><br><span class=\"line\">      else</span><br><span class=\"line\">        z2 = (limit-z1)/2;                                   % otherwise bisect</span><br><span class=\"line\">      end</span><br><span class=\"line\">    elseif (limit &gt; -0.5) &amp;&amp; (z2+z1 &gt; limit)         % extraplation beyond max?</span><br><span class=\"line\">      z2 = (limit-z1)/2;                                               % bisect</span><br><span class=\"line\">    elseif (limit &lt; -0.5) &amp;&amp; (z2+z1 &gt; z1*EXT)       % extrapolation beyond limit</span><br><span class=\"line\">      z2 = z1*(EXT-1.0);                           % set to extrapolation limit</span><br><span class=\"line\">    elseif z2 &lt; -z3*INT</span><br><span class=\"line\">      z2 = -z3*INT;</span><br><span class=\"line\">    elseif (limit &gt; -0.5) &amp;&amp; (z2 &lt; (limit-z1)*(1.0-INT))  % too close to limit?</span><br><span class=\"line\">      z2 = (limit-z1)*(1.0-INT);</span><br><span class=\"line\">    end</span><br><span class=\"line\">    f3 = f2; d3 = d2; z3 = -z2;                  % set point 3 equal to point 2</span><br><span class=\"line\">    z1 = z1 + z2; X = X + z2*s;                      % update current estimates</span><br><span class=\"line\">    [f2 df2] = eval(argstr);</span><br><span class=\"line\">    M = M - 1; i = i + (length&lt;0);                             % count epochs?!</span><br><span class=\"line\">    d2 = df2&#x27;*s;</span><br><span class=\"line\">  end                                                      % end of line search</span><br><span class=\"line\"></span><br><span class=\"line\">  if success                                         % if line search succeeded</span><br><span class=\"line\">    f1 = f2; fX = [fX&#x27; f1]&#x27;;</span><br><span class=\"line\">    fprintf(&#x27;%s %4i | Cost: %4.6e\\r&#x27;, S, i, f1);</span><br><span class=\"line\">    s = (df2&#x27;*df2-df1&#x27;*df2)/(df1&#x27;*df1)*s - df2;      % Polack-Ribiere direction</span><br><span class=\"line\">    tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives</span><br><span class=\"line\">    d2 = df1&#x27;*s;</span><br><span class=\"line\">    if d2 &gt; 0                                      % new slope must be negative</span><br><span class=\"line\">      s = -df1;                              % otherwise use steepest direction</span><br><span class=\"line\">      d2 = -s&#x27;*s;    </span><br><span class=\"line\">    end</span><br><span class=\"line\">    z1 = z1 * min(RATIO, d1/(d2-realmin));          % slope ratio but max RATIO</span><br><span class=\"line\">    d1 = d2;</span><br><span class=\"line\">    ls_failed = 0;                              % this line search did not fail</span><br><span class=\"line\">  else</span><br><span class=\"line\">    X = X0; f1 = f0; df1 = df0;  % restore point from before failed line search</span><br><span class=\"line\">    if ls_failed || i &gt; abs(length)          % line search failed twice in a row</span><br><span class=\"line\">      break;                             % or we ran out of time, so we give up</span><br><span class=\"line\">    end</span><br><span class=\"line\">    tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives</span><br><span class=\"line\">    s = -df1;                                                    % try steepest</span><br><span class=\"line\">    d1 = -s&#x27;*s;</span><br><span class=\"line\">    z1 = 1/(1-d1);                     </span><br><span class=\"line\">    ls_failed = 1;                                    % this line search failed</span><br><span class=\"line\">  end</span><br><span class=\"line\">  if exist(&#x27;OCTAVE_VERSION&#x27;)</span><br><span class=\"line\">    fflush(stdout);</span><br><span class=\"line\">  end</span><br><span class=\"line\">end</span><br><span class=\"line\">fprintf(&#x27;\\n&#x27;);</span><br></pre></td></tr></table></figure>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Machine Learning-学习笔记-03-MATLAB/Octave toturial","url":"/2022/08/13/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 03-MATLAB&#x2F;Octave toturial。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"基本操作-Basic-Operations\"><a href=\"#基本操作-Basic-Operations\" class=\"headerlink\" title=\"基本操作(Basic Operations)\"></a>基本操作(Basic Operations)</h1><h2 id=\"改变提示字符串：\"><a href=\"#改变提示字符串：\" class=\"headerlink\" title=\"改变提示字符串：\"></a>改变提示字符串：</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">octave:1&gt; PS1(&#x27;&gt;&gt;&#x27;);</span><br><span class=\"line\">&gt;&gt;</span><br></pre></td></tr></table></figure>\n<h2 id=\"退出Octave\"><a href=\"#退出Octave\" class=\"headerlink\" title=\"退出Octave\"></a>退出Octave</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;quit</span><br></pre></td></tr></table></figure>\n<p>or</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;exit</span><br></pre></td></tr></table></figure>\n<h2 id=\"清除页面\"><a href=\"#清除页面\" class=\"headerlink\" title=\"清除页面\"></a>清除页面</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;clc</span><br></pre></td></tr></table></figure>\n<h2 id=\"基本数学运算\"><a href=\"#基本数学运算\" class=\"headerlink\" title=\"基本数学运算\"></a>基本数学运算</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;3+5</span><br><span class=\"line\">ans = 8</span><br><span class=\"line\">&gt;&gt;5-3</span><br><span class=\"line\">ans = 2</span><br><span class=\"line\">&gt;&gt;6*3</span><br><span class=\"line\">ans = 18</span><br><span class=\"line\">&gt;&gt;6/2</span><br><span class=\"line\">ans = 3</span><br><span class=\"line\">&gt;&gt;3^2</span><br><span class=\"line\">ans = 9</span><br><span class=\"line\">&gt;&gt;sqrt(9)</span><br><span class=\"line\">ans = 3</span><br></pre></td></tr></table></figure>\n<h2 id=\"逻辑运算\"><a href=\"#逻辑运算\" class=\"headerlink\" title=\"逻辑运算\"></a>逻辑运算</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;1==2</span><br><span class=\"line\">ans = 0  %返回值0代表false</span><br><span class=\"line\">&gt;&gt;1~=2</span><br><span class=\"line\">ans = 1  %返回值1代表true</span><br><span class=\"line\">&gt;&gt;1&amp;&amp;0</span><br><span class=\"line\">ans = 0</span><br><span class=\"line\">&gt;&gt;1||0</span><br><span class=\"line\">ans = 1</span><br></pre></td></tr></table></figure>\n<p>这里注意，不等于符号的写法是这个波浪线加上等于符号 ( ~&#x3D; )，而不是等于感叹号加等号 ( !&#x3D; )，这是和其他一些编程语言中不太一样的地方。</p>\n<h2 id=\"结果显示\"><a href=\"#结果显示\" class=\"headerlink\" title=\"结果显示\"></a>结果显示</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;a=pi</span><br><span class=\"line\">a = 3.1416</span><br><span class=\"line\">&gt;&gt;disp(a)</span><br><span class=\"line\">3.1416</span><br><span class=\"line\">&gt;&gt;disp(sprintf(&#x27;2 decimals: %0.2f&#x27;,a))</span><br><span class=\"line\">2 decimals: 3.14</span><br></pre></td></tr></table></figure>\n<h2 id=\"矩阵和向量\"><a href=\"#矩阵和向量\" class=\"headerlink\" title=\"矩阵和向量\"></a>矩阵和向量</h2><h3 id=\"定义一个矩阵：\"><a href=\"#定义一个矩阵：\" class=\"headerlink\" title=\"定义一个矩阵：\"></a>定义一个矩阵：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A = [1 2; 3 4; 5 6]</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   3   4</span><br><span class=\"line\">   5   6</span><br></pre></td></tr></table></figure>\n<p>也可以用以下方式来定义一个矩阵：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A = [1 2;</span><br><span class=\"line\">&gt; 3 4;</span><br><span class=\"line\">&gt; 5 6]</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   3   4</span><br><span class=\"line\">   5   6</span><br></pre></td></tr></table></figure>\n<h3 id=\"定义一个向量：\"><a href=\"#定义一个向量：\" class=\"headerlink\" title=\"定义一个向量：\"></a>定义一个向量：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;v = [1 2 3]</span><br><span class=\"line\">v =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2   3</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;v = [1; 2; 3]</span><br><span class=\"line\">v =</span><br><span class=\"line\"></span><br><span class=\"line\">   1</span><br><span class=\"line\">   2</span><br><span class=\"line\">   3</span><br></pre></td></tr></table></figure>\n<h3 id=\"全一矩阵-Matrix-of-ones\"><a href=\"#全一矩阵-Matrix-of-ones\" class=\"headerlink\" title=\"全一矩阵(Matrix of ones)\"></a>全一矩阵(Matrix of ones)</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;ones(2,3)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   1   1</span><br><span class=\"line\">   1   1   1</span><br></pre></td></tr></table></figure>\n<p>类似的，如果想定义一个全是2的矩阵：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;C = 2*ones(2,3)</span><br><span class=\"line\">C =</span><br><span class=\"line\"></span><br><span class=\"line\">   2   2   2</span><br><span class=\"line\">   2   2   2</span><br></pre></td></tr></table></figure>\n<h3 id=\"零矩阵-Zero-matrix\"><a href=\"#零矩阵-Zero-matrix\" class=\"headerlink\" title=\"零矩阵(Zero matrix)\"></a>零矩阵(Zero matrix)</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;zeros(1,3)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   0   0   0</span><br></pre></td></tr></table></figure>\n<h3 id=\"随机数矩阵\"><a href=\"#随机数矩阵\" class=\"headerlink\" title=\"随机数矩阵\"></a>随机数矩阵</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;randn(2,3)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   0.3765   1.0025   0.3219</span><br><span class=\"line\">   1.4467   0.7443   1.3480</span><br></pre></td></tr></table></figure>\n\n<p>注意在MATLAB或者Octave中还有另外一个类似的随机数函数rand()。区别在于，rand是0-1的均匀随机分布，而randn是均值为0方差为1的正态分布。让我们将他们plot出来：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;q = -6 + sqrt(10)*(randn(1,10000));</span><br><span class=\"line\">&gt;&gt;hist(q)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/../images/hist.svg\" alt=\"hist of randn\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;w = -6 + sqrt(10)*(rand(1,10000));</span><br><span class=\"line\">&gt;&gt;hist(w)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/../images/hist_rand.svg\" alt=\"hist of randn\"></p>\n<h3 id=\"单位矩阵\"><a href=\"#单位矩阵\" class=\"headerlink\" title=\"单位矩阵\"></a>单位矩阵</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;eye(4)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">Diagonal Matrix</span><br><span class=\"line\"></span><br><span class=\"line\">   1   0   0   0</span><br><span class=\"line\">   0   1   0   0</span><br><span class=\"line\">   0   0   1   0</span><br><span class=\"line\">   0   0   0   1</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"移动数据\"><a href=\"#移动数据\" class=\"headerlink\" title=\"移动数据\"></a>移动数据</h1><h2 id=\"矩阵维度\"><a href=\"#矩阵维度\" class=\"headerlink\" title=\"矩阵维度\"></a>矩阵维度</h2><h3 id=\"size\"><a href=\"#size\" class=\"headerlink\" title=\"size()\"></a>size()</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   3   4</span><br><span class=\"line\">   5   6</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;size(A)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   3   2</span><br></pre></td></tr></table></figure>\n<p>另外我们可以显示使用如下命令来显示行数和列数：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;size(A,1)</span><br><span class=\"line\">ans = 3</span><br><span class=\"line\">&gt;&gt;size(A,2)</span><br><span class=\"line\">ans = 2</span><br></pre></td></tr></table></figure>\n<h3 id=\"length\"><a href=\"#length\" class=\"headerlink\" title=\"length()\"></a>length()</h3><p>length()函数可以用来显示矩阵的较长的维度（行或者列）</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;v = [1 2 3 4]</span><br><span class=\"line\">v =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2   3   4</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;length(v)</span><br><span class=\"line\">ans = 4</span><br><span class=\"line\">&gt;&gt;length(A)</span><br><span class=\"line\">ans = 3</span><br></pre></td></tr></table></figure>\n<h2 id=\"加载数据\"><a href=\"#加载数据\" class=\"headerlink\" title=\"加载数据\"></a>加载数据</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;load featuresX.dat</span><br></pre></td></tr></table></figure>\n<h2 id=\"显示内存中的变量\"><a href=\"#显示内存中的变量\" class=\"headerlink\" title=\"显示内存中的变量\"></a>显示内存中的变量</h2><h3 id=\"who\"><a href=\"#who\" class=\"headerlink\" title=\"who\"></a>who</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;who</span><br><span class=\"line\">Variables visible from the current scope:</span><br><span class=\"line\"></span><br><span class=\"line\">A    C    a    ans  q    v    w</span><br></pre></td></tr></table></figure>\n<h3 id=\"whos用于显示更加详细的信息\"><a href=\"#whos用于显示更加详细的信息\" class=\"headerlink\" title=\"whos用于显示更加详细的信息\"></a>whos用于显示更加详细的信息</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;whos</span><br><span class=\"line\">Variables visible from the current scope:</span><br><span class=\"line\"></span><br><span class=\"line\">variables in scope: top scope</span><br><span class=\"line\"></span><br><span class=\"line\">  Attr   Name        Size                     Bytes  Class</span><br><span class=\"line\">  ====   ====        ====                     =====  =====</span><br><span class=\"line\">         A           3x2                         48  double</span><br><span class=\"line\">         C           2x3                         48  double</span><br><span class=\"line\">         a           1x1                          8  double</span><br><span class=\"line\">         ans         1x1                          8  double</span><br><span class=\"line\">         q           1x10000                  80000  double</span><br><span class=\"line\">         v           1x4                         32  double</span><br><span class=\"line\">         w           1x10000                  80000  double</span><br><span class=\"line\"></span><br><span class=\"line\">Total is 20018 elements using 160144 bytes</span><br></pre></td></tr></table></figure>\n<h2 id=\"清除内存中的变量\"><a href=\"#清除内存中的变量\" class=\"headerlink\" title=\"清除内存中的变量\"></a>清除内存中的变量</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;clear A</span><br><span class=\"line\">&gt;&gt;who</span><br><span class=\"line\">Variables visible from the current scope:</span><br><span class=\"line\"></span><br><span class=\"line\">C    a    ans  q    v    w</span><br></pre></td></tr></table></figure>\n<h2 id=\"数据存储\"><a href=\"#数据存储\" class=\"headerlink\" title=\"数据存储\"></a>数据存储</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;C</span><br><span class=\"line\">C =</span><br><span class=\"line\"></span><br><span class=\"line\">   2   2   2</span><br><span class=\"line\">   2   2   2</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;save myData.txt C;</span><br></pre></td></tr></table></figure>\n<p>查看当前目录，我们就会发现新建了一个名为myData.txt的文件，内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># Created by Octave 7.2.0, Sat Aug 13 14:16:13 2022 GMT &lt;unknown@Shi-Lap&gt;</span><br><span class=\"line\"># name: C</span><br><span class=\"line\"># type: matrix</span><br><span class=\"line\"># rows: 2</span><br><span class=\"line\"># columns: 3</span><br><span class=\"line\"> 2 2 2</span><br><span class=\"line\"> 2 2 2</span><br></pre></td></tr></table></figure>\n<p>我们也可以加上ascii使得文件只显示数据：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;save myData.txt C -ascii</span><br></pre></td></tr></table></figure>\n<p>文件内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">2.00000000e+00 2.00000000e+00 2.00000000e+00</span><br><span class=\"line\">2.00000000e+00 2.00000000e+00 2.00000000e+00</span><br></pre></td></tr></table></figure>\n<h2 id=\"操作数据\"><a href=\"#操作数据\" class=\"headerlink\" title=\"操作数据\"></a>操作数据</h2><h3 id=\"数据索引\"><a href=\"#数据索引\" class=\"headerlink\" title=\"数据索引\"></a>数据索引</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A=[1 2; 3 4; 5 6]</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   3   4</span><br><span class=\"line\">   5   6</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;A(3,2)</span><br><span class=\"line\">ans = 6</span><br><span class=\"line\">&gt;&gt;A(2,:)  %获取第二行的所有内容</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   3   4</span><br><span class=\"line\">&gt;&gt;A(:,2)  %获取第二列的所有内容</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   2</span><br><span class=\"line\">   4</span><br><span class=\"line\">   6</span><br><span class=\"line\">&gt;&gt;A([1 3],:)  %获取第一行和第三行的内容</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   5   6</span><br></pre></td></tr></table></figure>\n<h3 id=\"改写数据\"><a href=\"#改写数据\" class=\"headerlink\" title=\"改写数据\"></a>改写数据</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   3   4</span><br><span class=\"line\">   5   6</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;A(:,2)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   2</span><br><span class=\"line\">   4</span><br><span class=\"line\">   6</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;A(:,2)=[10; 11; 12]</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">    1   10</span><br><span class=\"line\">    3   11</span><br><span class=\"line\">    5   12</span><br></pre></td></tr></table></figure>\n<h3 id=\"追加数据\"><a href=\"#追加数据\" class=\"headerlink\" title=\"追加数据\"></a>追加数据</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">      1   10</span><br><span class=\"line\">      3   11</span><br><span class=\"line\">      5   12</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;A=[A,[100; 101; 102]]</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">     1    10   100</span><br><span class=\"line\">     3    11   101</span><br><span class=\"line\">     5    12   102</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"将所有数据放入一个向量\"><a href=\"#将所有数据放入一个向量\" class=\"headerlink\" title=\"将所有数据放入一个向量\"></a>将所有数据放入一个向量</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A(:)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">     1</span><br><span class=\"line\">     3</span><br><span class=\"line\">     5</span><br><span class=\"line\">    10</span><br><span class=\"line\">    11</span><br><span class=\"line\">    12</span><br><span class=\"line\">   100</span><br><span class=\"line\">   101</span><br><span class=\"line\">   102</span><br></pre></td></tr></table></figure>\n<h3 id=\"合并矩阵\"><a href=\"#合并矩阵\" class=\"headerlink\" title=\"合并矩阵\"></a>合并矩阵</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A = [1 2; 3 4; 5 6];</span><br><span class=\"line\">&gt;&gt;B = [11 12; 13 14; 15 16];</span><br><span class=\"line\">&gt;&gt;A</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   3   4</span><br><span class=\"line\">   5   6</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;B</span><br><span class=\"line\">B =</span><br><span class=\"line\"></span><br><span class=\"line\">   11   12</span><br><span class=\"line\">   13   14</span><br><span class=\"line\">   15   16</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;C = [A B]</span><br><span class=\"line\">C =</span><br><span class=\"line\"></span><br><span class=\"line\">    1    2   11   12</span><br><span class=\"line\">    3    4   13   14</span><br><span class=\"line\">    5    6   15   16</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;C = [A; B]</span><br><span class=\"line\">C =</span><br><span class=\"line\"></span><br><span class=\"line\">    1    2</span><br><span class=\"line\">    3    4</span><br><span class=\"line\">    5    6</span><br><span class=\"line\">   11   12</span><br><span class=\"line\">   13   14</span><br><span class=\"line\">   15   16</span><br></pre></td></tr></table></figure>\n<h1 id=\"计算数据\"><a href=\"#计算数据\" class=\"headerlink\" title=\"计算数据\"></a>计算数据</h1><h2 id=\"矩阵乘法\"><a href=\"#矩阵乘法\" class=\"headerlink\" title=\"矩阵乘法\"></a>矩阵乘法</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   3   4</span><br><span class=\"line\">   5   6</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;B</span><br><span class=\"line\">B =</span><br><span class=\"line\"></span><br><span class=\"line\">   11   12</span><br><span class=\"line\">   13   14</span><br><span class=\"line\">   15   16</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;C = [1 1; 2 2]</span><br><span class=\"line\">C =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   1</span><br><span class=\"line\">   2   2</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;A*C</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">    5    5</span><br><span class=\"line\">   11   11</span><br><span class=\"line\">   17   17</span><br></pre></td></tr></table></figure>\n<h2 id=\"矩阵点乘运算\"><a href=\"#矩阵点乘运算\" class=\"headerlink\" title=\"矩阵点乘运算\"></a>矩阵点乘运算</h2><p>两个矩阵A和B做点乘运算(A.*B)是将对应元素相乘，例如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A.*B</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   11   24</span><br><span class=\"line\">   39   56</span><br><span class=\"line\">   75   96</span><br></pre></td></tr></table></figure>\n<p>同样的点次方，点除等运算：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A.^2</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">    1    4</span><br><span class=\"line\">    9   16</span><br><span class=\"line\">   25   36</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;1./A</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   1.0000   0.5000</span><br><span class=\"line\">   0.3333   0.2500</span><br><span class=\"line\">   0.2000   0.1667</span><br></pre></td></tr></table></figure>\n<h2 id=\"转置\"><a href=\"#转置\" class=\"headerlink\" title=\"转置\"></a>转置</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   3   4</span><br><span class=\"line\">   5   6</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;A&#x27;</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   3   5</span><br><span class=\"line\">   2   4   6</span><br></pre></td></tr></table></figure>\n<h2 id=\"数值比较\"><a href=\"#数值比较\" class=\"headerlink\" title=\"数值比较\"></a>数值比较</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;a&lt;3</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">  1  0  1  1  %0表示false, 1表示true</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;find(a&lt;3)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   3   4  %所有小于3的值的Index number</span><br></pre></td></tr></table></figure>\n<h2 id=\"常用函数\"><a href=\"#常用函数\" class=\"headerlink\" title=\"常用函数\"></a>常用函数</h2><h3 id=\"magic\"><a href=\"#magic\" class=\"headerlink\" title=\"magic()\"></a>magic()</h3><p>magic函数可以生成一个行和列相加的和为一个定值的矩阵，比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A = magic(3)</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   8   1   6</span><br><span class=\"line\">   3   5   7</span><br><span class=\"line\">   4   9   2</span><br></pre></td></tr></table></figure>\n<h3 id=\"sum\"><a href=\"#sum\" class=\"headerlink\" title=\"sum()\"></a>sum()</h3><p>求和</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;a</span><br><span class=\"line\">a =</span><br><span class=\"line\"></span><br><span class=\"line\">    1.0000   15.0000    2.0000    0.5000</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;sum(a)</span><br><span class=\"line\">ans = 18.500</span><br></pre></td></tr></table></figure>\n<h3 id=\"prod\"><a href=\"#prod\" class=\"headerlink\" title=\"prod()\"></a>prod()</h3><p>求乘积</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;prod(a)</span><br><span class=\"line\">ans = 15</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"floor\"><a href=\"#floor\" class=\"headerlink\" title=\"floor()\"></a>floor()</h3><p>向下四舍五入</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;floor(a)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">    1   15    2    0</span><br></pre></td></tr></table></figure>\n<h3 id=\"ceil\"><a href=\"#ceil\" class=\"headerlink\" title=\"ceil()\"></a>ceil()</h3><p>向上四舍五入</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;ceil(a)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">    1   15    2    1</span><br></pre></td></tr></table></figure>\n<h2 id=\"max\"><a href=\"#max\" class=\"headerlink\" title=\"max()\"></a>max()</h2><p>求最大值</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;val = max(a)</span><br><span class=\"line\">val = 15</span><br></pre></td></tr></table></figure>\n<p>每一列的最大值</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;A</span><br><span class=\"line\">A =</span><br><span class=\"line\"></span><br><span class=\"line\">   8   1   6</span><br><span class=\"line\">   3   5   7</span><br><span class=\"line\">   4   9   2</span><br><span class=\"line\">&gt;&gt;max(A,[],1)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   8   9   7</span><br></pre></td></tr></table></figure>\n<p>每一行的最大值</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;max(A,[],2)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   8</span><br><span class=\"line\">   7</span><br><span class=\"line\">   9</span><br></pre></td></tr></table></figure>\n<p>类似的，我们可以对矩阵进行每列或者每行求和和求积：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;sum(A,1)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   15   15   15</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;sum(A,2)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   15</span><br><span class=\"line\">   15</span><br><span class=\"line\">   15</span><br></pre></td></tr></table></figure>\n<h2 id=\"矩阵对角线求和\"><a href=\"#矩阵对角线求和\" class=\"headerlink\" title=\"矩阵对角线求和\"></a>矩阵对角线求和</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;eye(3)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">Diagonal Matrix</span><br><span class=\"line\"></span><br><span class=\"line\">   1   0   0</span><br><span class=\"line\">   0   1   0</span><br><span class=\"line\">   0   0   1</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;A.*eye(3)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   8   0   0</span><br><span class=\"line\">   0   5   0</span><br><span class=\"line\">   0   0   2</span><br><span class=\"line\">&gt;&gt;sum(sum(A.*eye(3)))</span><br><span class=\"line\">ans = 15</span><br></pre></td></tr></table></figure>\n<h2 id=\"矩阵求逆\"><a href=\"#矩阵求逆\" class=\"headerlink\" title=\"矩阵求逆\"></a>矩阵求逆</h2><p>pinv()函数可以计算矩阵的逆矩阵</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;pinv(A)</span><br><span class=\"line\">ans =</span><br><span class=\"line\"></span><br><span class=\"line\">   0.147222  -0.144444   0.063889</span><br><span class=\"line\">  -0.061111   0.022222   0.105556</span><br><span class=\"line\">  -0.019444   0.188889  -0.102778</span><br></pre></td></tr></table></figure>\n<h1 id=\"绘制数据\"><a href=\"#绘制数据\" class=\"headerlink\" title=\"绘制数据\"></a>绘制数据</h1><h2 id=\"使用plot-函数快速绘图\"><a href=\"#使用plot-函数快速绘图\" class=\"headerlink\" title=\"使用plot()函数快速绘图\"></a>使用plot()函数快速绘图</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;t = [0:0.01:0.98];</span><br><span class=\"line\">&gt;&gt;y1 = sin(2*pi*4*t);</span><br><span class=\"line\">&gt;&gt;plot(t,y1)</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用hold-on函数保存旧图\"><a href=\"#使用hold-on函数保存旧图\" class=\"headerlink\" title=\"使用hold on函数保存旧图\"></a>使用hold on函数保存旧图</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;t = [0:0.01:0.98];</span><br><span class=\"line\">&gt;&gt;y1 = sin(2*pi*4*t);</span><br><span class=\"line\">&gt;&gt;y2 = cos(2*pi*4*t);</span><br><span class=\"line\">&gt;&gt;plot(t,y1)</span><br><span class=\"line\">&gt;&gt;hold on;</span><br><span class=\"line\">&gt;&gt;plot(t,y2)</span><br></pre></td></tr></table></figure>\n<p>这样新的图像就会绘制在旧的之上。</p>\n<h2 id=\"改变颜色\"><a href=\"#改变颜色\" class=\"headerlink\" title=\"改变颜色\"></a>改变颜色</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;plot(t,y2,&#x27;k&#x27;)</span><br></pre></td></tr></table></figure>\n<p>常用颜色：r–red; g–green; y–yellow;b–blue;k–black</p>\n<h2 id=\"添加坐标轴label\"><a href=\"#添加坐标轴label\" class=\"headerlink\" title=\"添加坐标轴label\"></a>添加坐标轴label</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;xlabel(&#x27;time&#x27;)</span><br><span class=\"line\">&gt;&gt;ylabel(&#x27;value&#x27;)</span><br></pre></td></tr></table></figure>\n<h2 id=\"添加legend\"><a href=\"#添加legend\" class=\"headerlink\" title=\"添加legend\"></a>添加legend</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;legend(&#x27;sin&#x27;,&#x27;cos&#x27;)</span><br></pre></td></tr></table></figure>\n<h2 id=\"添加title\"><a href=\"#添加title\" class=\"headerlink\" title=\"添加title\"></a>添加title</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;title(&#x27;my plot&#x27;)</span><br></pre></td></tr></table></figure>\n<h2 id=\"保存图片\"><a href=\"#保存图片\" class=\"headerlink\" title=\"保存图片\"></a>保存图片</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;print -dpng &#x27;myplot.png&#x27;</span><br></pre></td></tr></table></figure>\n<h2 id=\"关闭图片\"><a href=\"#关闭图片\" class=\"headerlink\" title=\"关闭图片\"></a>关闭图片</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;close</span><br></pre></td></tr></table></figure>\n<p>最终绘制的图像如下：</p>\n<p><img src=\"/../images/myplot.png\" alt=\"myplot\"></p>\n<h2 id=\"图像标号\"><a href=\"#图像标号\" class=\"headerlink\" title=\"图像标号\"></a>图像标号</h2><p>Octave&#x2F;MATLAB也可以让你为图像标号。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;figure(1);plot(t,y1);</span><br><span class=\"line\">&gt;&gt;figure(2);plot(t,y2);</span><br></pre></td></tr></table></figure>\n<p>这时你的电脑上将会显示名为’Figure 1’和’Figure 2’的两张不同的图片。</p>\n<h2 id=\"subplot\"><a href=\"#subplot\" class=\"headerlink\" title=\"subplot()\"></a>subplot()</h2><p>subplot命令可以让我们在一张图中展示多个plot。比如，我们使用subplot(1,2,1)命令，可以将图像分为一个 1*2 的格子，也就是前两个参数，然后它使用第一个格子，也就是最后一个参数1的意思。同样的，我们也可以使用subplot(1,2,2)命令来使用第二个格子。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;subplot(1,2,1)</span><br><span class=\"line\">&gt;&gt;plot(t,y1)</span><br><span class=\"line\">&gt;&gt;subplot(1,2,2)</span><br><span class=\"line\">&gt;&gt;plot(t,y2)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"设置坐标轴范围\"><a href=\"#设置坐标轴范围\" class=\"headerlink\" title=\"设置坐标轴范围\"></a>设置坐标轴范围</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;axis([0.5 1 -1 1])  %x轴坐标0.5到1;y轴坐标-1到1</span><br></pre></td></tr></table></figure>\n<p>新绘制的图像如下：</p>\n<p><img src=\"/../images/subplot.png\" alt=\"subplot\"></p>\n<h2 id=\"清除图像\"><a href=\"#清除图像\" class=\"headerlink\" title=\"清除图像\"></a>清除图像</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;clf;</span><br></pre></td></tr></table></figure>\n<h2 id=\"可视化矩阵\"><a href=\"#可视化矩阵\" class=\"headerlink\" title=\"可视化矩阵\"></a>可视化矩阵</h2><p>使用 imagesc(A)命令，它将会绘制一个彩色格图，不同的颜色对应矩阵中的不同值。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;imagesc(A)</span><br></pre></td></tr></table></figure>\n<p>还可以使用colorbar和colormap gray来对图像进行进一步调整。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;imagesc(magic(15))，colorbar，colormap gray</span><br></pre></td></tr></table></figure>\n<p>运行以上代码，可以得到一个如下所示的15*15的彩格图。</p>\n<p><img src=\"/../images/colormap.png\" alt=\"colormap\"></p>\n<h2 id=\"同时使用多条命令\"><a href=\"#同时使用多条命令\" class=\"headerlink\" title=\"同时使用多条命令\"></a>同时使用多条命令</h2><p>上面的例子中，我们使用的逗号连接函数调用。如果我键入a&#x3D;1,b&#x3D;2,c&#x3D;3然后按Enter键，其实这是将这三个命令同时执行，或者是将三个命令一个接一个执行，它将输出所有这三个结果。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;a=1,b=2,c=3</span><br><span class=\"line\">a = 1</span><br><span class=\"line\">b = 2</span><br><span class=\"line\">c = 3</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"控制语句：for-while-if\"><a href=\"#控制语句：for-while-if\" class=\"headerlink\" title=\"控制语句：for, while, if\"></a>控制语句：for, while, if</h1><h2 id=\"for循环\"><a href=\"#for循环\" class=\"headerlink\" title=\"for循环\"></a>for循环</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;v=zeros(10,1)</span><br><span class=\"line\">v =</span><br><span class=\"line\"></span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;for i=1:10,</span><br><span class=\"line\">&gt; v(i)=2^i;</span><br><span class=\"line\">&gt; end;</span><br><span class=\"line\">&gt;&gt;v</span><br><span class=\"line\">v =</span><br><span class=\"line\"></span><br><span class=\"line\">      2</span><br><span class=\"line\">      4</span><br><span class=\"line\">      8</span><br><span class=\"line\">     16</span><br><span class=\"line\">     32</span><br><span class=\"line\">     64</span><br><span class=\"line\">    128</span><br><span class=\"line\">    256</span><br><span class=\"line\">    512</span><br><span class=\"line\">   1024</span><br></pre></td></tr></table></figure>\n<h2 id=\"while循环\"><a href=\"#while循环\" class=\"headerlink\" title=\"while循环\"></a>while循环</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt; i = 1;</span><br><span class=\"line\">&gt;&gt; while i&lt;= 5,</span><br><span class=\"line\">&gt; v(i)=100;</span><br><span class=\"line\">&gt; i=i+1;</span><br><span class=\"line\">&gt; end;</span><br><span class=\"line\">&gt;&gt; v</span><br><span class=\"line\">v =</span><br><span class=\"line\"></span><br><span class=\"line\">    100</span><br><span class=\"line\">    100</span><br><span class=\"line\">    100</span><br><span class=\"line\">    100</span><br><span class=\"line\">    100</span><br><span class=\"line\">     64</span><br><span class=\"line\">    128</span><br><span class=\"line\">    256</span><br><span class=\"line\">    512</span><br><span class=\"line\">   1024</span><br></pre></td></tr></table></figure>\n<h2 id=\"if…else…\"><a href=\"#if…else…\" class=\"headerlink\" title=\"if…else…\"></a>if…else…</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt; v(1) = 2;</span><br><span class=\"line\">&gt;&gt; if v(1)==1,</span><br><span class=\"line\">&gt;   disp(&#x27;The value is one&#x27;);</span><br><span class=\"line\">&gt; elseif v(1)==2,</span><br><span class=\"line\">&gt;   disp(&#x27;The value is two&#x27;);</span><br><span class=\"line\">&gt; else</span><br><span class=\"line\">&gt;   disp(&#x27;The value is not one or two.&#x27;);</span><br><span class=\"line\">&gt; end;</span><br><span class=\"line\">The value is two</span><br></pre></td></tr></table></figure>\n<h2 id=\"定义函数\"><a href=\"#定义函数\" class=\"headerlink\" title=\"定义函数\"></a>定义函数</h2><p>例如，我们可以在当前目录定义一个函数squareThisNumber.m来返回一个数值的平方数，函数内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function y = squareThisNumber(x)</span><br><span class=\"line\">y = x^2;</span><br></pre></td></tr></table></figure>\n<p>在Octave中就可以这样调用刚才定义的函数：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt; squareThisNumber(5)</span><br><span class=\"line\">ans = 25</span><br></pre></td></tr></table></figure>\n<p>我们还可以定义一个返回两个数值的函数squareAndCubeThisNumber.m，用于返回一个数值的平方数以及立方数，函数内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [y1,y2] = squareAndCubeThisNumber(x)</span><br><span class=\"line\">y1 = x^2;</span><br><span class=\"line\">y2 = x^3;</span><br></pre></td></tr></table></figure>\n<p>同样的我们可以调用刚才定义的函数：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt; [a,b]=squareAndCubeThisNumber(5);</span><br><span class=\"line\">&gt;&gt; a</span><br><span class=\"line\">a = 25</span><br><span class=\"line\">&gt;&gt; b</span><br><span class=\"line\">b = 125</span><br></pre></td></tr></table></figure>\n<h2 id=\"定义Cost-Function\"><a href=\"#定义Cost-Function\" class=\"headerlink\" title=\"定义Cost Function\"></a>定义Cost Function</h2><p>可以用上面提到的定义函数的方法来定义Cost Function J。新建一个名为costFunctionJ.m的函数，并且包含如下内容：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function J = costFunctionJ(X, y, theta)</span><br><span class=\"line\"></span><br><span class=\"line\">% X is the &quot;design matrix&quot; containing our training examples.</span><br><span class=\"line\">% y is the class labels</span><br><span class=\"line\"></span><br><span class=\"line\">m = size(X, 1);         % number of training examples</span><br><span class=\"line\">predictions = X*theta;  % predictions of hypothesis on all m examples</span><br><span class=\"line\">sqrErrors = (predictions-y).^2; % squared errors</span><br><span class=\"line\"></span><br><span class=\"line\">J = 1/(2*m)*sum(sqrErrors);</span><br></pre></td></tr></table></figure>\n\n<p>下面是使用costFunctionJ的两个例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt; X = [1 1; 1 2; 1 3]</span><br><span class=\"line\">X =</span><br><span class=\"line\"></span><br><span class=\"line\">   1   1</span><br><span class=\"line\">   1   2</span><br><span class=\"line\">   1   3</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt; y = [1; 2; 3]</span><br><span class=\"line\">y =</span><br><span class=\"line\"></span><br><span class=\"line\">   1</span><br><span class=\"line\">   2</span><br><span class=\"line\">   3</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt; theta = [0; 1]</span><br><span class=\"line\">theta =</span><br><span class=\"line\"></span><br><span class=\"line\">   0</span><br><span class=\"line\">   1</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt; j = costFunctionJ(X, y, theta)</span><br><span class=\"line\">j = 0</span><br><span class=\"line\">&gt;&gt; theta = [0; 0]</span><br><span class=\"line\">theta =</span><br><span class=\"line\"></span><br><span class=\"line\">   0</span><br><span class=\"line\">   0</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt; j = costFunctionJ(X, y, theta)</span><br><span class=\"line\">j = 2.3333</span><br></pre></td></tr></table></figure>\n<h1 id=\"向量化-Vectorization\"><a href=\"#向量化-Vectorization\" class=\"headerlink\" title=\"向量化(Vectorization)\"></a>向量化(Vectorization)</h1><p>使用向量计算可以使计算速度变得更快，而且可以使代码更加简洁。</p>\n<h2 id=\"假设函数-h-theta-x-的向量化计算\"><a href=\"#假设函数-h-theta-x-的向量化计算\" class=\"headerlink\" title=\"假设函数\\(h_{\\theta}(x)\\)的向量化计算\"></a>假设函数\\(h_{\\theta}(x)\\)的向量化计算</h2><h3 id=\"tehta-0\"><a href=\"#tehta-0\" class=\"headerlink\" title=\"\\(\\tehta_0\\)\"></a>\\(\\tehta_0\\)</h3><p>$$<br>h_{\\theta}(x)&#x3D;\\sum_{j&#x3D;0}^n\\theta_jx_j&#x3D;\\theta^Tx<br>$$<br>我们分别使用循环和向量化两种方式来对上面的例子进行计算。</p>\n<p>不使用向量化：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">prediction = 0.0;</span><br><span class=\"line\">for j = 1:n+1</span><br><span class=\"line\">  predition = prediction + theta(j)*x(j)</span><br><span class=\"line\">end;</span><br></pre></td></tr></table></figure>\n<p>使用向量化：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">prediction = theta&#x27; * x;</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用向量化来更新线性回归梯度下降的-theta-j\"><a href=\"#使用向量化来更新线性回归梯度下降的-theta-j\" class=\"headerlink\" title=\"使用向量化来更新线性回归梯度下降的\\(\\theta_j\\)\"></a>使用向量化来更新线性回归梯度下降的\\(\\theta_j\\)</h2><p>$$<br>\\theta_0 :&#x3D; \\theta_0-\\alpha\\frac{1}{m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y{(i)})x_0^{(i)}<br>$$<br>$$<br>\\theta_1 :&#x3D; \\theta_1-\\alpha\\frac{1}{m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y{(i)})x_1^{(i)}<br>$$<br>$$<br>\\theta_2 :&#x3D; \\theta_2-\\alpha\\frac{1}{m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y{(i)})x_2^{(i)}<br>(n&#x3D;2)<br>$$<br>这里我们可以将这些方程等价为：<br>$$<br>\\theta :&#x3D; \\theta - \\alpha\\delta<br>$$<br>$$<br>\\delta&#x3D;\\frac{1}{m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}<br>$$<br>其中，\\(\\theta,\\delta\\)为n+1维度的向量，\\(\\alpha\\)为实数，这样我们就把上面的方程等价为了向量计算。</p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能","Octave","MATLAB"]},{"title":"Machine Learning-学习笔记-5-exercise 1 summary","url":"/2022/08/16/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-5/","content":"<p><strong>Programming Exercise 1: Linear Regression</strong></p>\n<p>In this exercise, you will implement linear regression and get to see it work on data.</p>\n<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 05-exercise 1 summary。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"ex1-m\"><a href=\"#ex1-m\" class=\"headerlink\" title=\"ex1.m\"></a>ex1.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class - Exercise 1: Linear Regression</span><br><span class=\"line\"></span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">%</span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  linear exercise. You will need to complete the following functions</span><br><span class=\"line\">%  in this exericse:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     warmUpExercise.m</span><br><span class=\"line\">%     plotData.m</span><br><span class=\"line\">%     gradientDescent.m</span><br><span class=\"line\">%     computeCost.m</span><br><span class=\"line\">%     gradientDescentMulti.m</span><br><span class=\"line\">%     computeCostMulti.m</span><br><span class=\"line\">%     featureNormalize.m</span><br><span class=\"line\">%     normalEqn.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\">% x refers to the population size in 10,000s</span><br><span class=\"line\">% y refers to the profit in $10,000s</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% ==================== Part 1: Basic Function ====================</span><br><span class=\"line\">% Complete warmUpExercise.m</span><br><span class=\"line\">fprintf(&#x27;Running warmUpExercise ... \\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;5x5 Identity Matrix: \\n&#x27;);</span><br><span class=\"line\">warmUpExercise()</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ======================= Part 2: Plotting =======================</span><br><span class=\"line\">fprintf(&#x27;Plotting Data ...\\n&#x27;)</span><br><span class=\"line\">data = load(&#x27;ex1data1.txt&#x27;);</span><br><span class=\"line\">X = data(:, 1); y = data(:, 2);</span><br><span class=\"line\">m = length(y); % number of training examples</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot Data</span><br><span class=\"line\">% Note: You have to complete the code in plotData.m</span><br><span class=\"line\">plotData(X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% =================== Part 3: Cost and Gradient descent ===================</span><br><span class=\"line\"></span><br><span class=\"line\">X = [ones(m, 1), data(:,1)]; % Add a column of ones to x</span><br><span class=\"line\">theta = zeros(2, 1); % initialize fitting parameters</span><br><span class=\"line\"></span><br><span class=\"line\">% Some gradient descent settings</span><br><span class=\"line\">iterations = 1500;</span><br><span class=\"line\">alpha = 0.01;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nTesting the cost function ...\\n&#x27;)</span><br><span class=\"line\">% compute and display initial cost</span><br><span class=\"line\">J = computeCost(X, y, theta);</span><br><span class=\"line\">fprintf(&#x27;With theta = [0 ; 0]\\nCost computed = %f\\n&#x27;, J);</span><br><span class=\"line\">fprintf(&#x27;Expected cost value (approx) 32.07\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% further testing of the cost function</span><br><span class=\"line\">J = computeCost(X, y, [-1 ; 2]);</span><br><span class=\"line\">fprintf(&#x27;\\nWith theta = [-1 ; 2]\\nCost computed = %f\\n&#x27;, J);</span><br><span class=\"line\">fprintf(&#x27;Expected cost value (approx) 54.24\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nRunning Gradient Descent ...\\n&#x27;)</span><br><span class=\"line\">% run gradient descent</span><br><span class=\"line\">theta = gradientDescent(X, y, theta, alpha, iterations);</span><br><span class=\"line\"></span><br><span class=\"line\">% print theta to screen</span><br><span class=\"line\">fprintf(&#x27;Theta found by gradient descent:\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;%f\\n&#x27;, theta);</span><br><span class=\"line\">fprintf(&#x27;Expected theta values (approx)\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; -3.6303\\n  1.1664\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot the linear fit</span><br><span class=\"line\">hold on; % keep previous plot visible</span><br><span class=\"line\">plot(X(:,2), X*theta, &#x27;-&#x27;)</span><br><span class=\"line\">legend(&#x27;Training data&#x27;, &#x27;Linear regression&#x27;)</span><br><span class=\"line\">hold off % don&#x27;t overlay any more plots on this figure</span><br><span class=\"line\"></span><br><span class=\"line\">% Predict values for population sizes of 35,000 and 70,000</span><br><span class=\"line\">predict1 = [1, 3.5] *theta;</span><br><span class=\"line\">fprintf(&#x27;For population = 35,000, we predict a profit of %f\\n&#x27;,...</span><br><span class=\"line\">    predict1*10000);</span><br><span class=\"line\">predict2 = [1, 7] * theta;</span><br><span class=\"line\">fprintf(&#x27;For population = 70,000, we predict a profit of %f\\n&#x27;,...</span><br><span class=\"line\">    predict2*10000);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ============= Part 4: Visualizing J(theta_0, theta_1) =============</span><br><span class=\"line\">fprintf(&#x27;Visualizing J(theta_0, theta_1) ...\\n&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Grid over which we will calculate J</span><br><span class=\"line\">theta0_vals = linspace(-10, 10, 100);</span><br><span class=\"line\">theta1_vals = linspace(-1, 4, 100);</span><br><span class=\"line\"></span><br><span class=\"line\">% initialize J_vals to a matrix of 0&#x27;s</span><br><span class=\"line\">J_vals = zeros(length(theta0_vals), length(theta1_vals));</span><br><span class=\"line\"></span><br><span class=\"line\">% Fill out J_vals</span><br><span class=\"line\">for i = 1:length(theta0_vals)</span><br><span class=\"line\">    for j = 1:length(theta1_vals)</span><br><span class=\"line\">    t = [theta0_vals(i); theta1_vals(j)];</span><br><span class=\"line\">    J_vals(i,j) = computeCost(X, y, t);</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% Because of the way meshgrids work in the surf command, we need to</span><br><span class=\"line\">% transpose J_vals before calling surf, or else the axes will be flipped</span><br><span class=\"line\">J_vals = J_vals&#x27;;</span><br><span class=\"line\">% Surface plot</span><br><span class=\"line\">figure;</span><br><span class=\"line\">surf(theta0_vals, theta1_vals, J_vals)</span><br><span class=\"line\">xlabel(&#x27;\\theta_0&#x27;); ylabel(&#x27;\\theta_1&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Contour plot</span><br><span class=\"line\">figure;</span><br><span class=\"line\">% Plot J_vals as 15 contours spaced logarithmically between 0.01 and 100</span><br><span class=\"line\">contour(theta0_vals, theta1_vals, J_vals, logspace(-2, 3, 20))</span><br><span class=\"line\">xlabel(&#x27;\\theta_0&#x27;); ylabel(&#x27;\\theta_1&#x27;);</span><br><span class=\"line\">hold on;</span><br><span class=\"line\">plot(theta(1), theta(2), &#x27;rx&#x27;, &#x27;MarkerSize&#x27;, 10, &#x27;LineWidth&#x27;, 2);</span><br></pre></td></tr></table></figure>\n<h1 id=\"warmUpExercise-m\"><a href=\"#warmUpExercise-m\" class=\"headerlink\" title=\"warmUpExercise.m\"></a>warmUpExercise.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function A = warmUpExercise()</span><br><span class=\"line\">%WARMUPEXERCISE Example function in octave</span><br><span class=\"line\">%   A = WARMUPEXERCISE() is an example function that returns the 5x5 identity matrix</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% ============= YOUR CODE HERE ==============</span><br><span class=\"line\">% Instructions: Return the 5x5 identity matrix</span><br><span class=\"line\">%               In octave, we return values by defining which variables</span><br><span class=\"line\">%               represent the return values (at the top of the file)</span><br><span class=\"line\">%               and then set them accordingly.</span><br><span class=\"line\"></span><br><span class=\"line\">A = eye(5);</span><br><span class=\"line\"></span><br><span class=\"line\">% ===========================================</span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"plotData-m\"><a href=\"#plotData-m\" class=\"headerlink\" title=\"plotData.m\"></a>plotData.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function plotData(x, y)</span><br><span class=\"line\">%PLOTDATA Plots the data points x and y into a new figure</span><br><span class=\"line\">%   PLOTDATA(x,y) plots the data points and gives the figure axes labels of</span><br><span class=\"line\">%   population and profit.</span><br><span class=\"line\"></span><br><span class=\"line\">figure; % open a new figure window</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Plot the training data into a figure using the</span><br><span class=\"line\">%               &quot;figure&quot; and &quot;plot&quot; commands. Set the axes labels using</span><br><span class=\"line\">%               the &quot;xlabel&quot; and &quot;ylabel&quot; commands. Assume the</span><br><span class=\"line\">%               population and revenue data have been passed in</span><br><span class=\"line\">%               as the x and y arguments of this function.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: You can use the &#x27;rx&#x27; option with plot to have the markers</span><br><span class=\"line\">%       appear as red crosses. Furthermore, you can make the</span><br><span class=\"line\">%       markers larger by using plot(..., &#x27;rx&#x27;, &#x27;MarkerSize&#x27;, 10);</span><br><span class=\"line\"></span><br><span class=\"line\">  plot(x,y,&#x27;rx&#x27;,&#x27;MarkerSize&#x27;,10);</span><br><span class=\"line\">  ylabel(&#x27;Profit in $10,000s&#x27;)</span><br><span class=\"line\">  xlabel(&#x27;Population of City in 10,000s&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% ============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"cumputeCost-m\"><a href=\"#cumputeCost-m\" class=\"headerlink\" title=\"cumputeCost.m\"></a>cumputeCost.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function J = computeCost(X, y, theta)</span><br><span class=\"line\">%COMPUTECOST Compute cost for linear regression</span><br><span class=\"line\">%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the</span><br><span class=\"line\">%   parameter for linear regression to fit the data points in X and y</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize some useful values</span><br><span class=\"line\">m = length(y); % number of training examples</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly</span><br><span class=\"line\">J = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the cost of a particular choice of theta</span><br><span class=\"line\">%               You should set J to the cost.</span><br><span class=\"line\"></span><br><span class=\"line\">J=(X*theta-y)&#x27;*(X*theta-y)/(2*m);</span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"gradientDescent-m\"><a href=\"#gradientDescent-m\" class=\"headerlink\" title=\"gradientDescent.m\"></a>gradientDescent.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)</span><br><span class=\"line\">%GRADIENTDESCENT Performs gradient descent to learn theta</span><br><span class=\"line\">%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by </span><br><span class=\"line\">%   taking num_iters gradient steps with learning rate alpha</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize some useful values</span><br><span class=\"line\">m = length(y); % number of training examples</span><br><span class=\"line\">J_history = zeros(num_iters, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">for iter = 1:num_iters</span><br><span class=\"line\"></span><br><span class=\"line\">    % ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">    % Instructions: Perform a single gradient step on the parameter vector</span><br><span class=\"line\">    %               theta. </span><br><span class=\"line\">    %</span><br><span class=\"line\">    % Hint: While debugging, it can be useful to print out the values</span><br><span class=\"line\">    %       of the cost function (computeCost) and gradient here.</span><br><span class=\"line\">    %</span><br><span class=\"line\"></span><br><span class=\"line\">    error = X*theta-y;</span><br><span class=\"line\">    theta_change = alpha/m*(X&#x27;*error);</span><br><span class=\"line\">    theta = theta - theta_change;</span><br><span class=\"line\"></span><br><span class=\"line\">    % ============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">    % Save the cost J in every iteration    </span><br><span class=\"line\">    J_history(iter) = computeCost(X, y, theta);</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"ex1-multi-m\"><a href=\"#ex1-multi-m\" class=\"headerlink\" title=\"ex1_multi.m\"></a>ex1_multi.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class</span><br><span class=\"line\">%  Exercise 1: Linear regression with multiple variables</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">% </span><br><span class=\"line\">%  This file contains code that helps you get started on the</span><br><span class=\"line\">%  linear regression exercise. </span><br><span class=\"line\">%</span><br><span class=\"line\">%  You will need to complete the following functions in this </span><br><span class=\"line\">%  exericse:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     warmUpExercise.m</span><br><span class=\"line\">%     plotData.m</span><br><span class=\"line\">%     gradientDescent.m</span><br><span class=\"line\">%     computeCost.m</span><br><span class=\"line\">%     gradientDescentMulti.m</span><br><span class=\"line\">%     computeCostMulti.m</span><br><span class=\"line\">%     featureNormalize.m</span><br><span class=\"line\">%     normalEqn.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this part of the exercise, you will need to change some</span><br><span class=\"line\">%  parts of the code below for various experiments (e.g., changing</span><br><span class=\"line\">%  learning rates).</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================ Part 1: Feature Normalization ================</span><br><span class=\"line\"></span><br><span class=\"line\">%% Clear and Close Figures</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Loading data ...\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">%% Load Data</span><br><span class=\"line\">data = load(&#x27;ex1data2.txt&#x27;);</span><br><span class=\"line\">X = data(:, 1:2);</span><br><span class=\"line\">y = data(:, 3);</span><br><span class=\"line\">m = length(y);</span><br><span class=\"line\"></span><br><span class=\"line\">% Print out some data points</span><br><span class=\"line\">fprintf(&#x27;First 10 examples from the dataset: \\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; x = [%.0f %.0f], y = %.0f \\n&#x27;, [X(1:10,:) y(1:10,:)]&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">% Scale features and set them to zero mean</span><br><span class=\"line\">fprintf(&#x27;Normalizing Features ...\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">[X mu sigma] = featureNormalize(X);</span><br><span class=\"line\"></span><br><span class=\"line\">% Add intercept term to X</span><br><span class=\"line\">X = [ones(m, 1) X];</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ================ Part 2: Gradient Descent ================</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: We have provided you with the following starter</span><br><span class=\"line\">%               code that runs gradient descent with a particular</span><br><span class=\"line\">%               learning rate (alpha). </span><br><span class=\"line\">%</span><br><span class=\"line\">%               Your task is to first make sure that your functions - </span><br><span class=\"line\">%               computeCost and gradientDescent already work with </span><br><span class=\"line\">%               this starter code and support multiple variables.</span><br><span class=\"line\">%</span><br><span class=\"line\">%               After that, try running gradient descent with </span><br><span class=\"line\">%               different values of alpha and see which one gives</span><br><span class=\"line\">%               you the best result.</span><br><span class=\"line\">%</span><br><span class=\"line\">%               Finally, you should complete the code at the end</span><br><span class=\"line\">%               to predict the price of a 1650 sq-ft, 3 br house.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: By using the &#x27;hold on&#x27; command, you can plot multiple</span><br><span class=\"line\">%       graphs on the same figure.</span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: At prediction, make sure you do the same feature normalization.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Running gradient descent ...\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Choose some alpha value</span><br><span class=\"line\">alpha = 0.01;</span><br><span class=\"line\">num_iters = 400;</span><br><span class=\"line\"></span><br><span class=\"line\">% Init Theta and Run Gradient Descent </span><br><span class=\"line\">theta = zeros(3, 1);</span><br><span class=\"line\">[theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot the convergence graph</span><br><span class=\"line\">figure;</span><br><span class=\"line\">plot(1:numel(J_history), J_history, &#x27;-b&#x27;, &#x27;LineWidth&#x27;, 2);</span><br><span class=\"line\">xlabel(&#x27;Number of iterations&#x27;);</span><br><span class=\"line\">ylabel(&#x27;Cost J&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Display gradient descent&#x27;s result</span><br><span class=\"line\">fprintf(&#x27;Theta computed from gradient descent: \\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; %f \\n&#x27;, theta);</span><br><span class=\"line\">fprintf(&#x27;\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Estimate the price of a 1650 sq-ft, 3 br house</span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Recall that the first column of X is all-ones. Thus, it does</span><br><span class=\"line\">% not need to be normalized.</span><br><span class=\"line\">price = 0; % You should change this</span><br><span class=\"line\">X = [1 1650 3];</span><br><span class=\"line\">price = X*theta;</span><br><span class=\"line\"></span><br><span class=\"line\">% ============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;Predicted price of a 1650 sq-ft, 3 br house &#x27; ...</span><br><span class=\"line\">         &#x27;(using gradient descent):\\n $%f\\n&#x27;], price);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Program paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ================ Part 3: Normal Equations ================</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Solving with normal equations...\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: The following code computes the closed form </span><br><span class=\"line\">%               solution for linear regression using the normal</span><br><span class=\"line\">%               equations. You should complete the code in </span><br><span class=\"line\">%               normalEqn.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%               After doing so, you should complete this code </span><br><span class=\"line\">%               to predict the price of a 1650 sq-ft, 3 br house.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Load Data</span><br><span class=\"line\">data = csvread(&#x27;ex1data2.txt&#x27;);</span><br><span class=\"line\">X = data(:, 1:2);</span><br><span class=\"line\">y = data(:, 3);</span><br><span class=\"line\">m = length(y);</span><br><span class=\"line\"></span><br><span class=\"line\">% Add intercept term to X</span><br><span class=\"line\">X = [ones(m, 1) X];</span><br><span class=\"line\"></span><br><span class=\"line\">% Calculate the parameters from the normal equation</span><br><span class=\"line\">theta = normalEqn(X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">% Display normal equation&#x27;s result</span><br><span class=\"line\">fprintf(&#x27;Theta computed from the normal equations: \\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; %f \\n&#x27;, theta);</span><br><span class=\"line\">fprintf(&#x27;\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% Estimate the price of a 1650 sq-ft, 3 br house</span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">price = 0; % You should change this</span><br><span class=\"line\">X = [1 1650 3];</span><br><span class=\"line\">price = X*theta;</span><br><span class=\"line\"></span><br><span class=\"line\">% ============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;Predicted price of a 1650 sq-ft, 3 br house &#x27; ...</span><br><span class=\"line\">         &#x27;(using normal equations):\\n $%f\\n&#x27;], price);</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"featureNormalize-m\"><a href=\"#featureNormalize-m\" class=\"headerlink\" title=\"featureNormalize.m\"></a>featureNormalize.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [X_norm, mu, sigma] = featureNormalize(X)</span><br><span class=\"line\">%FEATURENORMALIZE Normalizes the features in X </span><br><span class=\"line\">%   FEATURENORMALIZE(X) returns a normalized version of X where</span><br><span class=\"line\">%   the mean value of each feature is 0 and the standard deviation</span><br><span class=\"line\">%   is 1. This is often a good preprocessing step to do when</span><br><span class=\"line\">%   working with learning algorithms.</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to set these values correctly</span><br><span class=\"line\">X_norm = X;</span><br><span class=\"line\">mu = zeros(1, size(X, 2));</span><br><span class=\"line\">sigma = zeros(1, size(X, 2));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: First, for each feature dimension, compute the mean</span><br><span class=\"line\">%               of the feature and subtract it from the dataset,</span><br><span class=\"line\">%               storing the mean value in mu. Next, compute the </span><br><span class=\"line\">%               standard deviation of each feature and divide</span><br><span class=\"line\">%               each feature by it&#x27;s standard deviation, storing</span><br><span class=\"line\">%               the standard deviation in sigma. </span><br><span class=\"line\">%</span><br><span class=\"line\">%               Note that X is a matrix where each column is a </span><br><span class=\"line\">%               feature and each row is an example. You need </span><br><span class=\"line\">%               to perform the normalization separately for </span><br><span class=\"line\">%               each feature. </span><br><span class=\"line\">%</span><br><span class=\"line\">% Hint: You might find the &#x27;mean&#x27; and &#x27;std&#x27; functions useful.</span><br><span class=\"line\">%       </span><br><span class=\"line\"></span><br><span class=\"line\">mu = mean(X);</span><br><span class=\"line\"></span><br><span class=\"line\">sigma = std(X);</span><br><span class=\"line\"></span><br><span class=\"line\">X_norm = (X-mu)./sigma;</span><br><span class=\"line\"></span><br><span class=\"line\">% ============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"normalEqn-m\"><a href=\"#normalEqn-m\" class=\"headerlink\" title=\"normalEqn.m\"></a>normalEqn.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [theta] = normalEqn(X, y)</span><br><span class=\"line\">%NORMALEQN Computes the closed-form solution to linear regression </span><br><span class=\"line\">%   NORMALEQN(X,y) computes the closed-form solution to linear </span><br><span class=\"line\">%   regression using the normal equations.</span><br><span class=\"line\"></span><br><span class=\"line\">theta = zeros(size(X, 2), 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Complete the code to compute the closed form solution</span><br><span class=\"line\">%               to linear regression and put the result in theta.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% ---------------------- Sample Solution ----------------------</span><br><span class=\"line\"></span><br><span class=\"line\">theta = pinv(X&#x27;*X)*X&#x27;*y;</span><br><span class=\"line\"></span><br><span class=\"line\">% -------------------------------------------------------------</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% ============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能","Octave","MATLAB"]},{"title":"Machine Learning-学习笔记-06-Logistic Regression","url":"/2022/08/17/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-6/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 06-逻辑回归(Logistic Regression)。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"分类问题\"><a href=\"#分类问题\" class=\"headerlink\" title=\"分类问题\"></a>分类问题</h1><p>在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问的例子有：</p>\n<ul>\n<li>判断一封电子邮件是否是垃圾邮件？</li>\n<li>判断一次金融交易是否是欺诈？</li>\n<li>区别一个肿瘤是恶性的还是良性的？</li>\n</ul>\n<p>$$<br>y\\in{0,1}<br>$$<br>0: 负向类（例如，表示良性肿瘤）<br>1：正向类（例如，表示恶性肿瘤）</p>\n<p><strong>线性回归解决分类问题的难点</strong>：假设函数的输出值可能远大于1，或者远小于 0。<br>$$<br>h_\\theta(x)\\ can\\ be\\ &gt;1\\ or\\ &lt;0<br>$$</p>\n<p><strong>逻辑回归(Logistic Regression)</strong> ：它的输出值永远在 0 到 1 之间。<br>$$<br>0\\leq h_\\theta(x)\\leq 1<br>$$</p>\n<h1 id=\"假说表示\"><a href=\"#假说表示\" class=\"headerlink\" title=\"假说表示\"></a>假说表示</h1><p>线性回归模型，因为其预测的值可以超越[0,1]的范围，并不适合解决分类问题。</p>\n<p>我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在 0 和 1 之间。 逻辑 回归模型的假设是：<br>$$<br>h_\\theta(x)&#x3D;g(\\theta^Tx)<br>$$</p>\n<p>X表示特征向量，g表示逻辑函数(Logistic Function)。</p>\n<p>一个常用的逻辑函数为Sigmoid function，公式为：<br>$$<br>h_\\theta(x)&#x3D;\\frac{1}{1+e^{-\\theta^Tx}}<br>$$<br>其图形为：</p>\n<p><img src=\"/../images/SigmoidFunction.svg\" alt=\"sigmoid fuction\"></p>\n<p>\\(h_\\theta(x)\\)函数的意义为：对于给定的输入变量，计算输出变量 &#x3D;1的概率</p>\n<p>例如：如果对于给定的x，通过已经确定的参数计算得出\\(h_\\theta(x)&#x3D;0.7\\)，则表示有70%的几率y为正向类，相应地y为负向类的几率为 1-0.7&#x3D;0.3。</p>\n<p>$$<br>P(y&#x3D;0|x;\\theta) &#x3D; 1 - P(y&#x3D;1|x;\\theta)<br>$$</p>\n<h1 id=\"判定边界\"><a href=\"#判定边界\" class=\"headerlink\" title=\"判定边界\"></a>判定边界</h1><p>决策边界(decision boundary)这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么。</p>\n<p>在上面的逻辑回归的Sigmoid函数模型中，</p>\n<p>当\\(h_\\theta&lt;0.5\\)时，也就是\\(\\theta^Tx&lt;0\\)时，预测”y &#x3D; 0”；</p>\n<p>当\\(h_\\theta \\geq 0.5\\)时，也就是\\(\\theta^Tx \\geq 0\\)时，预测”y &#x3D; 1”；</p>\n<p>现在假设我们有如下模型，并且\\(\\theta_0&#x3D;-3, \\theta_1&#x3D;1, \\theta_2&#x3D;1\\)：</p>\n<p><img src=\"/../images/boundary.png\" alt=\"boundary\"></p>\n<p>当\\(-3+x_1+x_2 \\geq 0\\)，即\\(x_1+x_2 \\geq 3\\)时，模型将预测y&#x3D;1。我们可以绘制直线\\(x_1+x_2&#x3D;3\\)作为模型的分界线，将预测为1的区域和预测为0的区域分隔开。</p>\n<p><img src=\"/../images/boundary_2.png\" alt=\"boundary_2\"></p>\n<p>同样的，我们可以用半径为1，圆心在原点的圆将如下的模型分隔开。</p>\n<p><img src=\"/../images/boundary_3.png\" alt=\"boundary_3\"></p>\n<p>也就是\\(h_\\theta(x) &#x3D; g(\\theta_0 +\\theta_1x_1 + \\theta_2x_2 +\\theta_3x_2^2 + \\theta_4x_2^2）\\)，其中\\(\\theta\\)为[-1 0 0 1 1]。</p>\n<h1 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h1><p>假设我们有如下training sets，如何使用逻辑回归模型来找到代价函数的最优解呢？</p>\n<p><img src=\"/../images/costFunction_1.png\" alt=\"costFunction_1\"></p>\n<p>在之前的线性回归模型中，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将\\(h_\\theta(x)&#x3D;\\frac{1}{1+e^{-\\theta^Tx}}\\)代入之后，我们得到的代价函数将是一个非凸函数(non-convexfunction)。这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。!</p>\n<p><img src=\"/../images/costFunction_2.png\" alt=\"costFunction_2\"></p>\n<p>所以，我们重新定义逻辑回归的代价函数为：<br>$$<br>Cost(h_\\theta(x), y) &#x3D; \\begin{cases}<br>-log(h_\\theta(x))&amp; if\\ \\ y &#x3D; 1\\\\<br>-log(1-h_\\theta(x))&amp; if\\ \\ y &#x3D; 0<br>\\end{cases}<br>$$<br>\\(h_\\theta(x)\\)与\\(Cost(h_\\theta(x), y))\\)之间的关系如下：</p>\n<p><img src=\"/../images/costFunction_3.png\" alt=\"costFunction_3\"></p>\n<p><strong>左图</strong>：</p>\n<p>在当实际的\\(y&#x3D;1\\)，且\\(h_\\theta(x)\\)也为1时,误差Cost为0；</p>\n<p>但是，如果\\(h_\\theta(x)\\)趋向于0的时候，Cost就会趋向于\\(\\infty\\)。</p>\n<p><strong>右图</strong>：</p>\n<p>当实际的\\(y&#x3D;0\\)，且\\(h_\\theta(x)\\)也为0时,误差Cost为0；</p>\n<p>但是，如果\\(h_\\theta(x)\\)趋向于1的时候，Cost就会趋向于\\(\\infty\\)。</p>\n<p>简化之后的cost function如下：</p>\n<p>$$<br>J(\\theta) &#x3D; \\frac{1}{m}\\sum_{i&#x3D;1}^{m}Cost(h_\\theta(x^{(i)}), y^{(i)})\\\\<br>&#x3D; -\\frac{1}{m}[\\sum_{i&#x3D;1}^{m}y^{(i)}log h_\\theta(x^{(i)}) + (1-y^{(i)})log(1-h_\\theta(x^{(i)}))]<br>$$</p>\n<p>这样，无论y&#x3D;0还是y&#x3D;1，我们都可以使用这个方程。</p>\n<h1 id=\"梯度下降-gradient-descent\"><a href=\"#梯度下降-gradient-descent\" class=\"headerlink\" title=\"梯度下降 (gradient descent)\"></a>梯度下降 (gradient descent)</h1><p>在得到上面的Cost Function之后，我们就可以使用梯度下降的算法来求得能使代价函数最小的\\(\\theta\\)参数值了。具体算法为：<br>$$<br>\\theta_j :&#x3D; \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)<br>$$</p>\n<p>求导后得到：</p>\n<p>$$<br>\\theta_j :&#x3D; \\theta_j - \\alpha\\frac{1}{m}\\sum_{i&#x3D;1}^m(h_\\theta(x^{i})-y^{(i)})x_j^{(i)}<br>$$</p>\n<p>注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的\\(h_\\theta(x)&#x3D;g(\\theta^TX)\\)与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。</p>\n<h1 id=\"算法优化\"><a href=\"#算法优化\" class=\"headerlink\" title=\"算法优化\"></a>算法优化</h1><p>一些梯度下降算法之外的选择： 除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：共轭梯度（Conjugate Gradient），局部优化法(Broyden fletcher goldfarb shann,BFGS)和有限内存局部优化法(LBFGS) ，fminunc是 matlab和octave 中都带的一个最小值优化函数，使用时我们需要提供代价函数和每个参数的求导，下面是 octave 中使用 fminunc 函数的代码示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [jVal, gradient] = costFunction(theta)</span><br><span class=\"line\"></span><br><span class=\"line\">    jVal = [...code to compute J(theta)...];</span><br><span class=\"line\">    gradient = [...code to compute derivative of J(theta)...];</span><br><span class=\"line\">    </span><br><span class=\"line\">end</span><br><span class=\"line\">    </span><br><span class=\"line\">options = optimset(&#x27;GradObj&#x27;, &#x27;on&#x27;, &#x27;MaxIter&#x27;, &#x27;100&#x27;);</span><br><span class=\"line\">    </span><br><span class=\"line\">initialTheta = zeros(2,1);</span><br><span class=\"line\">    </span><br><span class=\"line\">[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"多类别分类：一对多\"><a href=\"#多类别分类：一对多\" class=\"headerlink\" title=\"多类别分类：一对多\"></a>多类别分类：一对多</h1><p>多类别分类的例子：</p>\n<ul>\n<li>邮件标签： 工作、朋友、家庭、爱好</li>\n<li>医学诊断： 没有生病、感冒、流感</li>\n<li>天气：晴朗、多云、下雨、下雪</li>\n</ul>\n<p>二元分类和多类别分类数据的区别：</p>\n<p><img src=\"/../images/multiClass.png\" alt=\"MultiClass\"></p>\n<p>我们可以将多个类中的一个类标记为正向类（y&#x3D;1），然后将其他所有类都标记为负向类，这个模型记作\\(h_\\theta^{(1)}(x)\\)。接着，类似地第我们选择另一个类标记为正向类（y&#x3D;2），再将其它类都标记为负向类，将这个模型记作\\(h_\\theta^{(2)}(x)\\),依此类推。 最后我们得到一系列的模型简记为\\(h_\\theta^{(i)}(x)&#x3D;P(y&#x3D;i|x;\\theta)\\)： 其中：i &#x3D; (1,2,3)</p>\n<p>最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。</p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Hexo博客主题的选择和优化","url":"/2022/07/15/Hexo%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A2%98%E7%9A%84%E9%80%89%E6%8B%A9%E5%92%8C%E4%BC%98%E5%8C%96/","content":"<p>在搭建完网站的主体框架之后，我们就要对我们的网站进行“内部装修”工作了，也就是主题的选择和优化。这样我们就能拥有我们喜欢的博客样式了。在这篇文章中，我将分享我是怎么安装主题，以及怎么对主题进行优化的。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"一、主题的选择\"><a href=\"#一、主题的选择\" class=\"headerlink\" title=\"一、主题的选择\"></a><strong>一、主题的选择</strong></h1><p>第一个问题，怎么样选择适合自己的主题呢？Hexo的官方主题页展示了三百多个主题的样式，大家可以逐个浏览，找到自己心仪的主题。官网地址如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://hexo.io/themes/</span><br></pre></td></tr></table></figure>\n<p>在选择好主题之后，就可以进行安装了。这里以我选择的Next主题为例进行讲解。在github中搜索hexo next theme，就可以找到与这个主题相关的项目文件。然后在本地计算机Hexo的文件中使用如下git命令，对主题进行下载：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n<p>其中，<a href=\"https://github.com/theme-next/hexo-theme-next\">https://github.com/theme-next/hexo-theme-next</a> 为这个项目所对应的地址，themes&#x2F;next为本地计算机的存储目录。</p>\n<p>一般来说，都有主题说明文件README.md，注意仔细阅读此文档，并且按照文件配置主题信息即可。</p>\n<h1 id=\"二、主题的启用\"><a href=\"#二、主题的启用\" class=\"headerlink\" title=\"二、主题的启用\"></a><strong>二、主题的启用</strong></h1><p>在下载好主题之后，我们要对Hexo根目录下的配置文件_config.yml进行修改，从而启用我们的主题。搜索并找到theme，然后在后面填写主题的名称。比如我选的Next主题配置好之后的相关代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># Extensions</span><br><span class=\"line\">## Plugins: https://hexo.io/plugins/</span><br><span class=\"line\">## Themes: https://hexo.io/themes/</span><br><span class=\"line\">theme: next</span><br></pre></td></tr></table></figure>\n<p>保存这个文件，然后同样使用下面的三联git命令来对网站进行更新和部署：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">hexo c</span><br><span class=\"line\">hexo g</span><br><span class=\"line\">hexo d</span><br></pre></td></tr></table></figure>\n<p>这时候如果查看我们的网站，就会发现主题已经成功启用。</p>\n<h1 id=\"三、主题的优化\"><a href=\"#三、主题的优化\" class=\"headerlink\" title=\"三、主题的优化\"></a><strong>三、主题的优化</strong></h1><p>虽然主题已经成功启动，但对于追求完美的我们来说，我们还远远不能满足。我们还需要对主体进行进一步的优化，从而满足我们的个性化需求。在这里，我给大家分享一下我都做了哪些修改吧。</p>\n<p>Hexo对主题的优化，完全是以代码形式来呈现的。所以，首先我们要找到这个主题的配置文件。这个文件的路径为Hexo&#x2F;themes&#x2F;next&#x2F;_config.yml。一般来说，里面的注释会非常详细的解释每一部分代码的功能，我们只需要根据提示来做出相应的修改就可以了。这里还以我所使用的next主题为例来进行讲解。</p>\n<h2 id=\"1-修改网站的logo\"><a href=\"#1-修改网站的logo\" class=\"headerlink\" title=\"1. 修改网站的logo\"></a>1. 修改网站的logo</h2><p>网站logo最好使用Adobe Illustrator来制作矢量图，这样文件会比较小，容易加载，清晰度还比较高。在制作完成之后，输出为合适的分辨率和格式即可。我使用Adobe Illustrator制作了logo，并且输出了分率为16×16, 32×32的不同大小的png格式图片，以及SVG格式的矢量图。<br>然后将图片储存在Hexo\\themes\\next\\source\\images文件夹中，并且将相应的文件名复制到主题配置文件中相应的地方来对这些图片进行链接。我的配置如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># ---------------------------------------------------------------</span><br><span class=\"line\"># Site Information Settings</span><br><span class=\"line\"># See: https://theme-next.org/docs/getting-started/</span><br><span class=\"line\"># ---------------------------------------------------------------</span><br><span class=\"line\"></span><br><span class=\"line\">favicon:</span><br><span class=\"line\">  small: /images/favicon-16x16-Shi.png</span><br><span class=\"line\">  medium: /images/favicon-32x32-Shi.png</span><br><span class=\"line\">  apple_touch_icon: /images/apple-touch-icon-next.png</span><br><span class=\"line\">  safari_pinned_tab: /images/logo-Shi.svg</span><br><span class=\"line\">  #android_manifest: /images/manifest.json</span><br><span class=\"line\">  #ms_browserconfig: /images/browserconfig.xml</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-主题风格设定\"><a href=\"#2-主题风格设定\" class=\"headerlink\" title=\"2. 主题风格设定\"></a>2. 主题风格设定</h2><p>一般来说，同一个主题会有不同的风格。比如next主题就包含了Muse，Mist，Pisces，和Gemini四种不同的风格。默认风格为Muse，但并不是我最喜欢的样式，所以我在尝试了所有风格之后，选择了Gemini的格式。我们只需要将所选风格前面的#去掉就可以使用这个风格了。下面是我修改之后的相关代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># ---------------------------------------------------------------</span><br><span class=\"line\"># Scheme Settings</span><br><span class=\"line\"># ---------------------------------------------------------------</span><br><span class=\"line\"></span><br><span class=\"line\"># Schemes</span><br><span class=\"line\"># scheme: Muse</span><br><span class=\"line\"># scheme: Mist</span><br><span class=\"line\"># scheme: Pisces</span><br><span class=\"line\">scheme: Gemini</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-侧边栏设置\"><a href=\"#3-侧边栏设置\" class=\"headerlink\" title=\"3. 侧边栏设置\"></a>3. 侧边栏设置</h2><p>我们也可以对网站的侧边栏进行设置，比如调整侧边栏位置，展示我们的头像，显示分类和标签，还有显示其他网页以及社交媒体的链接。<br>首先，我将侧边栏替换为了自己的专属头像（图片存储区域为themes&#x2F;next&#x2F;images&#x2F;avatar-1.gif)， 修改区域如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># Sidebar Avatar</span><br><span class=\"line\">avatar:</span><br><span class=\"line\">  # Replace the default image and set the url here.</span><br><span class=\"line\">  url: /images/avatar-1.gif</span><br><span class=\"line\">  # If true, the avatar will be dispalyed in circle.</span><br><span class=\"line\">  rounded: false</span><br><span class=\"line\">  # If true, the avatar will be rotated with the cursor.</span><br><span class=\"line\">  rotated: false</span><br></pre></td></tr></table></figure>\n<p>其次，我链接上了我一直使用的个人博客网址，修改如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">links_settings:</span><br><span class=\"line\">  icon: fa fa-link</span><br><span class=\"line\">  title: links</span><br><span class=\"line\">  # Available values: block | inline</span><br><span class=\"line\">  layout: block</span><br><span class=\"line\"></span><br><span class=\"line\">links:</span><br><span class=\"line\">  石磊磊的个人站点: https://shileilei.com</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-博客文章设置\"><a href=\"#4-博客文章设置\" class=\"headerlink\" title=\"4. 博客文章设置\"></a>4. 博客文章设置</h2><p>对博客的格式，我也做了一些相应的改动。由于默认的是显示item text，比如会显示“发布日期”，“分类”等等这几个字符。我将item_text设置为了false从而取消了这些字符的显示，具体参数如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># Post meta display settings</span><br><span class=\"line\">post_meta:</span><br><span class=\"line\">  item_text: false</span><br><span class=\"line\">  created_at: true</span><br><span class=\"line\">  updated_at:</span><br><span class=\"line\">    enable: false</span><br><span class=\"line\">    another_day: true</span><br><span class=\"line\">  categories: true</span><br></pre></td></tr></table></figure>\n<h2 id=\"5-打赏设置\"><a href=\"#5-打赏设置\" class=\"headerlink\" title=\"5. 打赏设置\"></a>5. 打赏设置</h2><p>我也对文章进行了打赏设置，从而在每篇文章的底部都会显示微信和支付宝的打赏二维码。首先，我们要从微信和支付宝上面获取打赏二维码，然后将图片保持在前面一直反复提到的themes&#x2F;next&#x2F;images&#x2F;文件夹中，并且修改文件名为wechatpay.png和alipay.png。然后相关参数的设置如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># Reward (Donate)</span><br><span class=\"line\"># Front-matter variable (unsupport animation).</span><br><span class=\"line\">reward_settings:</span><br><span class=\"line\">  # If true, reward will be displayed in every article by default.</span><br><span class=\"line\">  enable: true</span><br><span class=\"line\">  animation: false</span><br><span class=\"line\">  comment: 您的支持将鼓励我继续创作</span><br><span class=\"line\"></span><br><span class=\"line\">reward:</span><br><span class=\"line\">  wechatpay: /images/wechatpay.png</span><br><span class=\"line\">  alipay: /images/alipay.png</span><br><span class=\"line\">  #paypal: /images/paypal.png</span><br><span class=\"line\">  #bitcoin: /images/bitcoin.png</span><br></pre></td></tr></table></figure>\n<h2 id=\"6-SEO设置\"><a href=\"#6-SEO设置\" class=\"headerlink\" title=\"6. SEO设置\"></a>6. SEO设置</h2><p>为了可以让搜索引擎抓取到我们的页面，让更多的人看到我们的文章，我们就需要对SEO进行一些设置。具体可以参照下面几个网站的说明来进行设置，这里就不再赘述：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://www.google.com/webmasters</span><br><span class=\"line\">https://www.bing.com/webmaster</span><br><span class=\"line\">https://webmaster.yandex.ru</span><br><span class=\"line\">https://ziyuan.baidu.com/site</span><br></pre></td></tr></table></figure>\n<h2 id=\"7-评论区设置\"><a href=\"#7-评论区设置\" class=\"headerlink\" title=\"7.评论区设置\"></a>7.评论区设置</h2><p>因为Hexo所生成的是纯静态网页，所以我们需要借助第三方的插件才可以实现评论功能。Next主题提供了changyan，disqus，disqusjs，gitalk，livere和valine多种插件的选择。在做了一些research之后，最终选择了disqus这个第三方插件。</p>\n<p>在设置这个插件的时候，我们只需要去Disqus首页注册–&gt;点击”Get Started”–&gt;选择”I want to install Disqus on my site”–&gt;输入WebsitName–&gt;选择网站类别–&gt;Create a new site–&gt;选择“I don’t see my platform listed, install manually with Universal Code”–&gt;点击“Complete Setup”。完成上面这些操作之后，确保找到Disqus分配的shortname。然后我们将这个shortname复制粘贴到next主题的配置文件中，就完成了评论区的配置。具体参数如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># Multiple Comment System Support</span><br><span class=\"line\">comments:</span><br><span class=\"line\">  # Available values: tabs | buttons</span><br><span class=\"line\">  style: tabs</span><br><span class=\"line\">  # Choose a comment system to be displayed by default.</span><br><span class=\"line\">  # Available values: changyan | disqus | disqusjs | gitalk | livere | valine</span><br><span class=\"line\">  active: disqus</span><br><span class=\"line\">  # Setting `true` means remembering the comment system selected by the visitor.</span><br><span class=\"line\">  storage: true</span><br><span class=\"line\">  # Lazyload all comment systems.</span><br><span class=\"line\">  lazyload: false</span><br><span class=\"line\">  # Modify texts or order for any navs, here are some examples.</span><br><span class=\"line\">  nav:</span><br><span class=\"line\">    #disqus:</span><br><span class=\"line\">    #  text: Load Disqus</span><br><span class=\"line\">    #  order: -1</span><br><span class=\"line\">    #gitalk:</span><br><span class=\"line\">    #  order: -2</span><br><span class=\"line\"></span><br><span class=\"line\"># Disqus</span><br><span class=\"line\">disqus:</span><br><span class=\"line\">  enable: true</span><br><span class=\"line\">  shortname: https-shilei165-github-io</span><br><span class=\"line\">  count: true</span><br><span class=\"line\">  #post_meta_order: 0</span><br></pre></td></tr></table></figure>\n<p>在首次设置的时候，遇到了很多难题。下面这两篇文章给了我很多启发，大家也可以参考一下。<br><a href=\"https://theme-next.js.org/docs/third-party-services/comments\">https://theme-next.js.org/docs/third-party-services/comments</a><br><a href=\"https://titangene.github.io/article/hexo-disqus.html\">https://titangene.github.io/article/hexo-disqus.html</a></p>\n<p>如果重新部署，就会发现所有的博客和页面下面都会出现评论区。如果我们对某个页面不想展示留言，我们还需要做一些调整。比如我们不想在“关于”页面下展示留言板，我们就需要找到这个页面对应的md文件，储存在Hexo\\source\\文件夹中。打开这个md文件，然后添加一行comments: false，就可以关闭此页面的留言板功能了。具体如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">---</span><br><span class=\"line\">title: 关于博主</span><br><span class=\"line\">date: 2022-07-13 19:57:12</span><br><span class=\"line\">comments: false</span><br><span class=\"line\">---</span><br><span class=\"line\">**&lt;center&gt;石磊磊&lt;/center&gt;**</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"8-修改站点名和作者\"><a href=\"#8-修改站点名和作者\" class=\"headerlink\" title=\"8. 修改站点名和作者\"></a>8. 修改站点名和作者</h2><p>然后，我们还需要对网站的Title和Author进行修改。这样我们的网站名和作者才能展示到网站上。打开Hexo主目录下的_config.yml文件，然后定位到# Site对上面的参数进行设置。比我，我想把博客站点名设置为“石磊磊的个人站点”，并且把作者设置为“石磊磊”，参数如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># Site</span><br><span class=\"line\">title: 石磊磊的个人站点</span><br><span class=\"line\">subtitle: &#x27;&#x27;</span><br><span class=\"line\">description: &#x27;&#x27;</span><br><span class=\"line\">keywords:</span><br><span class=\"line\">author: 石磊磊</span><br><span class=\"line\">language: zh-CN</span><br><span class=\"line\">timezone: &#x27;&#x27;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"9-设置Hexo-next主题分类多层级描述\"><a href=\"#9-设置Hexo-next主题分类多层级描述\" class=\"headerlink\" title=\"9. 设置Hexo-next主题分类多层级描述\"></a>9. 设置Hexo-next主题分类多层级描述</h2><p>在转移文章的时候，我发现了一个文章分类的问题。同一篇文章可能分属不同的类别，但系统会默认所属的所有的类别是同级别的文章，从而在分类(categories)一栏显得十分混乱。比如我写的《Linux学习笔记-1》属于Linux分类，但同时还有一个父类技术杂谈。在直接从wordpress把文章转移过来的时候，系统就会同时显示这两个类别，在分类的页面中就会显得十分没有层次感。这时候我们就需要对文章的类别进行分层。<br>首先，我们需要将文章中的</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">categories:</span><br><span class=\"line\">  - - Linux</span><br><span class=\"line\">  - - 技术杂谈</span><br></pre></td></tr></table></figure>\n<p>改为</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">categories:</span><br><span class=\"line\">  - 技术杂谈</span><br><span class=\"line\">  - Linux</span><br></pre></td></tr></table></figure>\n<p>这样Linux就会默认为是技术杂谈的子类，而不是并列分类。如果需要将文章同时添加到多个同级别的类，我们可以参考下面这篇文章：</p>\n<p><a href=\"https://cs-cshi.github.io/hexo-blog/Hexo-NexT%20%E5%88%86%E7%B1%BB%E5%A4%9A%E5%B1%82%E7%BA%A7%E6%8F%8F%E8%BF%B0/\">Hexo-NexT 分类多层级描述</a></p>\n<p>同时为了增加分类的层次感，我们也可以修改&#x2F;themes&#x2F;next&#x2F;source&#x2F;css&#x2F;_common&#x2F;components&#x2F;pages&#x2F;categories.styl代码.category-list-child 的 padding-left 属性改为 60px。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">.category-list-child &#123;</span><br><span class=\"line\">  padding-left: 60px;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>另外如果需要对标签和文档进行进一步的美化，我们可以参考下面这篇文章：</p>\n<p><a href=\"https://jrbcode.gitee.io/posts/be9758cd.html\">Hexo+NexT博客归档&#x2F;标签&#x2F;分类页美化</a></p>\n<p>到此，我们的“装修”工作就到一个段落了。当然，你也可以继续对其他任何地方进行个性化的修改。在修改完成之后，记得同样使用下面的三联git命令来对网站进行更新和部署：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">hexo c</span><br><span class=\"line\">hexo g</span><br><span class=\"line\">hexo d</span><br></pre></td></tr></table></figure>\n<p>这时候如果查看我们的网站 <a href=\"https://shilei165.github.io/\">https://shilei165.github.io/</a> 就会发现所有修改已经成功启用。</p>\n<hr>\n","categories":["技术杂谈","Cloud & Web"],"tags":["Hexo","博客","网页","Next theme"]},{"title":"Machine Learning-学习笔记-07-Regularization","url":"/2022/08/18/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-7/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 07-正则化(Regularization)。</p>\n<span id=\"more\"></span>\n\n<h1 id=\"过度拟合的问题\"><a href=\"#过度拟合的问题\" class=\"headerlink\" title=\"过度拟合的问题\"></a>过度拟合的问题</h1><p>我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到过度拟合(over-fitting)的问题，可能会导致它们效果很差。</p>\n<p>下面是一个回归问题的例子：</p>\n<p><img src=\"/../images/overFitting.png\" alt=\"overFitting\"></p>\n<p>第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：预测新数据。我们可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎最合适。</p>\n<p>分类问题中也存在这样的问题：</p>\n<p><img src=\"/../images/overFitting_2.png\" alt=\"overFitting_2\"></p>\n<p>应该如何处理过度拟合问题？</p>\n<ul>\n<li><p>减少特征数量。</p>\n<ul>\n<li>可以是手工选择保留哪些特征</li>\n<li>使用一些模型选择的算法来帮忙（例如PCA）</li>\n</ul>\n</li>\n<li><p>正则化。 </p>\n<ul>\n<li>保留所有的特征，但是减少参数的大小（magnitude）。</li>\n<li>适用于有多个特征，但每个特征对预测函数的贡献都比较小。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h1><p>上面的回归问题中如果我们的模型是：  \\(h_\\theta(x)&#x3D;\\theta_0+\\theta_1x_1+\\theta_2x_2^2+\\theta_3x_3^3+\\theta_4x_4^4\\) 我们可以从之前的事例中看出，正是那些高次项导致了过拟合的产生，所以如果我们能让这些高次项的系数接近于0的话，我们就能很好的拟合了。 所以我们要做的就是在一定程度上减小这些参数 的值，这就是<strong>正则化的基本方法</strong>。</p>\n<p>我们决定要减少和的大小，我们要做的便是修改代价函数，在其中和 设置一点惩罚。这样做的话，我们在尝试最小化代价时也需要将这个惩罚纳入考虑中，并最终导致选择较小一些的和。 修改后的代价函数如下：</p>\n<p>$$<br>J(\\theta)&#x3D; \\frac{1}{2m}[\\sum_{i&#x3D;1}^m(h_\\theta(x^{(i)})-y^{(i)})^2+1000\\theta_3^2+1000\\theta_4^2]<br>$$</p>\n<p>类似的，假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对除\\(\\theta_0\\)以外的所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：</p>\n<p>$$<br>J(\\theta)&#x3D;\\frac{1}{2m}[\\sum_{i&#x3D;1}^{m}h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda \\sum_{j&#x3D;1}^{n}\\theta_j^2]<br>$$</p>\n<p>如果我们令\\(\\lambda\\)的值很大的话，为了使Cost Function 尽可能的小，所有的 \\(\\theta\\)的值（不包括\\(\\theta_0\\)）都会在一定程度上减小。 但若\\(\\lambda\\)的值太大了，那么\\(\\theta\\)（不包括\\(\\theta_0\\)）都会趋近于0，这样我们所得到的只能是一条平行于轴的直线。 所以对于正则化，我们要取一个合理的\\(\\lambda\\)的值，这样才能更好的应用正则化。 </p>\n<h1 id=\"正则化线性回归\"><a href=\"#正则化线性回归\" class=\"headerlink\" title=\"正则化线性回归\"></a>正则化线性回归</h1><p>正则化线性回归的代价函数为：</p>\n<p>$$<br>J(\\theta)&#x3D;\\frac{1}{2m}[\\sum_{i&#x3D;1}^{m}h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda \\sum_{j&#x3D;1}^{n}\\theta_j^2]<br>$$</p>\n<p>如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对进行正则化，所以梯度下降算法将分两种情形：</p>\n<p>$$<br>\\theta_0 :&#x3D; \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x_0^{(i)}<br>$$<br>$$<br>\\theta_j :&#x3D; \\theta_j - \\alpha[\\frac{1}{m}\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}+\\frac{\\lambda}{m}\\theta_j]\\ \\ \\ \\ \\ \\ for\\  j &#x3D; 1,2,3…<br>$$</p>\n<p>将上面的公式稍加整理，即可得到：<br>$$<br>\\theta_j :&#x3D; \\theta_j(1-\\alpha\\frac{\\lambda}{m}) - \\alpha\\frac{1}{m}[\\sum_{i&#x3D;1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}]<br>$$</p>\n<p>可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令值减少了一个额外的值。</p>\n<p>我们同样也可以利用正规方程来求解正则化线性回归模型，方法如下所示：</p>\n<p>$$<br>\\theta &#x3D; \\begin{pmatrix}<br>X^TX+\\lambda\\begin{bmatrix}<br>0&amp;\\ &amp;\\ &amp;\\ &amp;\\ \\\\<br>\\ &amp;1 &amp;\\ &amp;\\ &amp;\\ \\\\<br>\\ &amp;\\ &amp;1 &amp;\\ &amp;\\ \\\\<br>\\ &amp;\\ &amp;\\ &amp;\\ddots &amp;\\ \\\\<br>\\ &amp;\\ &amp;\\ &amp;\\ &amp;1 \\end{bmatrix}<br>\\end{pmatrix}^{-1} X^Ty<br>$$</p>\n<h1 id=\"正则化的逻辑回归模型\"><a href=\"#正则化的逻辑回归模型\" class=\"headerlink\" title=\"正则化的逻辑回归模型\"></a>正则化的逻辑回归模型</h1><p>我们也给代价函数增加一个正则化的表达式，得到代价函数：<br>$$<br>J(\\theta)&#x3D; -\\frac{1}{m}[\\sum_{i&#x3D;1}^{m}y^{(i)}log h_\\theta(x^{(i)}) + (1-y^{(i)})log(1-h_\\theta(x^{(i)}))]+\\frac{\\lambda}{2m}\\sum_{j&#x3D;1}^{n}\\theta_j^2<br>$$</p>\n<p>要最小化该代价函数，通过求导，得出梯度下降算法为：</p>\n<p>$$<br>\\theta_0 :&#x3D; \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i&#x3D;1}^m(h_\\theta(x^{i})-y^{(i)})x_0^{(i)}<br>$$<br>$$<br>\\theta_j :&#x3D; \\theta_j - \\alpha[\\frac{1}{m}\\sum_{i&#x3D;1}^m(h_\\theta(x^{i})-y^{(i)})x_j^{(i)}+\\frac{\\lambda}{m}\\theta_j]<br>$$<br>注：看上去同线性回归一样，但是知道\\(h_\\theta(x)&#x3D;g(\\theta^TX)\\) ，所以与线性回归不同。 Octave 中，我们依旧可以用 fminuc 函数来求解代价函数最小化的参数，值得注意的是参数\\(\\theta_0\\)的更新规则与其他情况不同。</p>\n<p>下面是 octave 中使用 fminunc 函数的代码示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [jVal, gradient] = costFunction(theta)</span><br><span class=\"line\"></span><br><span class=\"line\">    jVal = [...code to compute J(theta)...];</span><br><span class=\"line\"></span><br><span class=\"line\">    gradient(1) = [...code to compute derivative of the partial derivative of cost function at theta_0];</span><br><span class=\"line\"></span><br><span class=\"line\">    gradient(2) = [...code to compute derivative of the partial derivative of cost function at theta_1];</span><br><span class=\"line\">    .</span><br><span class=\"line\">    .</span><br><span class=\"line\">    .</span><br><span class=\"line\">    gradient(n+1) = [...code to compute derivative of the partial derivative of cost function at theta_n];</span><br><span class=\"line\">    </span><br><span class=\"line\">end</span><br><span class=\"line\">    </span><br><span class=\"line\">options = optimset(&#x27;GradObj&#x27;, &#x27;on&#x27;, &#x27;MaxIter&#x27;, &#x27;100&#x27;);</span><br><span class=\"line\">    </span><br><span class=\"line\">initialTheta = zeros(n+1,1);</span><br><span class=\"line\">    </span><br><span class=\"line\">[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</span><br></pre></td></tr></table></figure>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Information Systems 2- Introduction to Information Systems","url":"/2023/01/05/Information_Systems_Chapter_2/","content":"<h1 id=\"Learning-Objectives\"><a href=\"#Learning-Objectives\" class=\"headerlink\" title=\"Learning Objectives\"></a><strong>Learning Objectives</strong></h1><ul>\n<li>Describe the major functions of an information system</li>\n<li>Explain why it is important for business professionals to understand information systems</li>\n<li>Explain key concepts related to systems</li>\n<li>Describe the information processing cycle</li>\n<li>Describe the critical elements of an information system</li>\n<li>Explain how information systems help managers deal with information</li>\n<li>Give examples of business rules</li>\n<li>Descuss how information systems facilitate organizational change</li>\n<li>Compare and contrast common information systems</li>\n</ul>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"Why-All-Business-Professionals-Need-to-Be-Information-Systems-Managers\"><a href=\"#Why-All-Business-Professionals-Need-to-Be-Information-Systems-Managers\" class=\"headerlink\" title=\"Why All Business Professionals Need to Be Information Systems Managers\"></a>Why All Business Professionals Need to Be Information Systems Managers</h1><ul>\n<li>IS are increasingly ingrained in our business and professional lives.</li>\n<li>Everyone will use information system regardless of your major or your career.</li>\n<li>Learning how to effectively use IS can help you be more effective and successful in your career.</li>\n</ul>\n<h1 id=\"Overview-of-Systems\"><a href=\"#Overview-of-Systems\" class=\"headerlink\" title=\"Overview of Systems\"></a>Overview of Systems</h1><p>A <strong>System</strong> is a set of interacting components working together to form a complex, integrated whole to achieve some goal by taking inputs and processing them to produce outputs.</p>\n<ul>\n<li>A system is made up of different pieces, called components. It can take many different forms, ranging from human organs to computer softwares.</li>\n<li>These components work together; they are interrelated.</li>\n<li>A system has some purpose or goals.</li>\n<li>The goal is achieved by taking inputs and processing them to produce outputs.</li>\n</ul>\n<p>A few systems-related concepts that are not apparent from the definition.</p>\n<ul>\n<li>A system is separated from its environment by the system’s boundary.</li>\n<li>Most systems are <strong>open system</strong> – interact with their environments.</li>\n<li>Systems are often made up of <strong>subsystems</strong> – a part of larger system.</li>\n<li><strong>Equifinality</strong> – there are many different potential paths to the final outcome.</li>\n<li><strong>Feedback and control</strong> - a set of functions intended to ensure the proper operation of a system.</li>\n</ul>\n<h1 id=\"Foundations-of-Information-Systems\"><a href=\"#Foundations-of-Information-Systems\" class=\"headerlink\" title=\"Foundations of Information Systems\"></a>Foundations of Information Systems</h1><ul>\n<li>An information system does not require a computer. However, in this class, we are primarily concerned with computerized information system.</li>\n<li>Information systems include the following operations (also called information processing cycle)<ol>\n<li><em>Input</em> – Collection of data and their conversion into a form that allows processing.</li>\n<li><em>Processing</em> – Manipulation and transformation of data.</li>\n<li><em>Storage</em> – Holding place for data so that they can be retrieved at a larger time.</li>\n<li><em>Output</em> – Transformation of processed data into a form that can be understood.</li>\n<li><em>Control</em> – Enforcement of correct processing procedures.</li>\n</ol>\n</li>\n<li>Information systems have six critical elements.<ol>\n<li><em>Data</em> – Raw facts, text, numbers, images…</li>\n<li><em>Hardware</em> – Physical devices (computers&#x2F;hard disks, printers keyboards, etc.)</li>\n<li><em>Software</em> – Set of instructions that gorven the operation of IS (system software &amp; application software)</li>\n<li><em>Communication media</em> – Set of devices and protocols (rules) that enable computers to communicate with each other (network cabling, routers, etc.)</li>\n<li><em>People</em> – Individuals who use the IS (most important component – use&#x2F;interpret&#x2F;monitor&#x2F;build&#x2F;maintain)</li>\n</ol>\n</li>\n</ul>\n<h1 id=\"How-Information-Systems-Help-Us-Deal-with-Information\"><a href=\"#How-Information-Systems-Help-Us-Deal-with-Information\" class=\"headerlink\" title=\"How Information Systems Help Us Deal with Information\"></a>How Information Systems Help Us Deal with Information</h1><ul>\n<li>First, information systems let us gather large amounts of data quickly, easily, and reliably.<ul>\n<li>Examples include the check out system in a grocery store.</li>\n</ul>\n</li>\n<li>Second, information systems allow businesses to store and organize very large amounts of data.<ul>\n<li>IS allow businesses to store volumes of data is an organized manner that allows for rapid retrieval.</li>\n</ul>\n</li>\n<li>Third, information systems perform their data manipulations quicky, accurately, and consistently.<ul>\n<li>As long as the hardware is operating correctly and the software is designed and implemented correctly, an information system is very consistent in its manipulations.</li>\n</ul>\n</li>\n<li>Finally, information systems let us retrieve and output information in a variety of forms, depending on what is useful to the user.<ul>\n<li>The same information can be displayed on a screen, printed, or graphed.</li>\n</ul>\n</li>\n</ul>\n<p>One important function of many business information systems is to enforce <strong>business rules</strong>.</p>\n<ul>\n<li>A business rule is a statement that defines or constrains an aspect of a business with the intent of controlling behaviors within the business.</li>\n<li>All businesses have rules that govern their operations. (Hotel reservation&#x2F; course registration)</li>\n<li>Information systems enforce business rules by not allowing violations to occur.</li>\n</ul>\n<h1 id=\"How-Information-Systems-Facilitate-Organizational-Change\"><a href=\"#How-Information-Systems-Facilitate-Organizational-Change\" class=\"headerlink\" title=\"How Information Systems Facilitate Organizational Change\"></a>How Information Systems Facilitate Organizational Change</h1><ul>\n<li><p><strong>Process Improvements</strong></p>\n<ul>\n<li>IS can help organizations improve both the efficiency and effectiveness of processes.</li>\n<li>Example: customer self-service&#x2F; ATM.</li>\n</ul>\n</li>\n<li><p><strong>Automation</strong></p>\n<ul>\n<li>Some processes have been totally automated.</li>\n<li>Example: online ordering.</li>\n</ul>\n</li>\n<li><p><strong>Control</strong></p>\n<ul>\n<li>When properly designed and implemented, an information system can ensure that business rules are followed throughout a process.</li>\n<li>Example: check credit card before accepting payment.</li>\n</ul>\n</li>\n<li><p><strong>Information Flow</strong></p>\n<ul>\n<li>Workflow systems facilitate information flow throughout a work task.</li>\n<li>Example: grade change –&gt; auto email notification.</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"Common-Information-Systems\"><a href=\"#Common-Information-Systems\" class=\"headerlink\" title=\"Common Information Systems\"></a>Common Information Systems</h1><p><strong>Classify information systems according to the impact or “reach” of the system</strong>:</p>\n<ul>\n<li><p><strong>Personal applications</strong></p>\n<ul>\n<li>Help make individuals’ daily work more efficient and effective</li>\n<li>Example: Microsoft Office, Evernote or Onenote</li>\n</ul>\n</li>\n<li><p><strong>Transaction processing systems (TPSs)</strong></p>\n<ul>\n<li>Collect, monitor, process, report, and store large volumes of data that are created by business processes.</li>\n<li>Example: grocery store point-of-sale system</li>\n</ul>\n</li>\n<li><p><strong>Functional and management information systems</strong></p>\n<ul>\n<li>Monitor, control, and analyze the operation of functional areas</li>\n<li>Example: financial management systems, sales force automation systems</li>\n</ul>\n</li>\n<li><p><strong>Integrated enterprise systems</strong></p>\n<ul>\n<li>Multiple applications in cohesive, interrelated system</li>\n<li>Example: enterprise resource planning systems provide an integrated set of modules that carry out the information processing and reporting systems for the entire organization</li>\n</ul>\n</li>\n<li><p><strong>Interorganizational systems</strong></p>\n<ul>\n<li>Span organizational boundaries to connect companies to suppliers and customers.</li>\n<li>Electronic data interchange (EDI) is at the heart of many of these systems. It allows the systems interact with partner organization.</li>\n</ul>\n</li>\n<li><p><strong>Global systems</strong></p>\n<ul>\n<li>Interorganizational systems that cross national boundaries</li>\n<li>More complex than other systems</li>\n</ul>\n</li>\n</ul>\n","categories":["技术杂谈","Information Systems"],"tags":["Information Systems"]},{"title":"Machine Learning-学习笔记-08-exercise 2 summary","url":"/2022/08/19/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-8/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 08-exercise 2 summary。</p>\n<span id=\"more\"></span>\n\n<p><strong>Programming Exercise 2: Logistic Regression</strong></p>\n<p>In this exercise, you will implement logistic regression and apply it to two different datasets.</p>\n<h1 id=\"ex2-m\"><a href=\"#ex2-m\" class=\"headerlink\" title=\"ex2.m\"></a>ex2.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class - Exercise 2: Logistic Regression</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">% </span><br><span class=\"line\">%  This file contains code that helps you get started on the logistic</span><br><span class=\"line\">%  regression exercise. You will need to complete the following functions </span><br><span class=\"line\">%  in this exericse:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     sigmoid.m</span><br><span class=\"line\">%     costFunction.m</span><br><span class=\"line\">%     predict.m</span><br><span class=\"line\">%     costFunctionReg.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% Load Data</span><br><span class=\"line\">%  The first two columns contains the exam scores and the third column</span><br><span class=\"line\">%  contains the label.</span><br><span class=\"line\"></span><br><span class=\"line\">data = load(&#x27;ex2data1.txt&#x27;);</span><br><span class=\"line\">X = data(:, [1, 2]); y = data(:, 3);</span><br><span class=\"line\"></span><br><span class=\"line\">%% ==================== Part 1: Plotting ====================</span><br><span class=\"line\">%  We start the exercise by first plotting the data to understand the </span><br><span class=\"line\">%  the problem we are working with.</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf([&#x27;Plotting data with + indicating (y = 1) examples and o &#x27; ...</span><br><span class=\"line\">         &#x27;indicating (y = 0) examples.\\n&#x27;]);</span><br><span class=\"line\"></span><br><span class=\"line\">plotData(X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">% Put some labels </span><br><span class=\"line\">hold on;</span><br><span class=\"line\">% Labels and Legend</span><br><span class=\"line\">xlabel(&#x27;Exam 1 score&#x27;)</span><br><span class=\"line\">ylabel(&#x27;Exam 2 score&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Specified in plot order</span><br><span class=\"line\">legend(&#x27;Admitted&#x27;, &#x27;Not admitted&#x27;)</span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ============ Part 2: Compute Cost and Gradient ============</span><br><span class=\"line\">%  In this part of the exercise, you will implement the cost and gradient</span><br><span class=\"line\">%  for logistic regression. You neeed to complete the code in </span><br><span class=\"line\">%  costFunction.m</span><br><span class=\"line\"></span><br><span class=\"line\">%  Setup the data matrix appropriately, and add ones for the intercept term</span><br><span class=\"line\">[m, n] = size(X);</span><br><span class=\"line\"></span><br><span class=\"line\">% Add intercept term to x and X_test</span><br><span class=\"line\">X = [ones(m, 1) X];</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize fitting parameters</span><br><span class=\"line\">initial_theta = zeros(n + 1, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute and display initial cost and gradient</span><br><span class=\"line\">[cost, grad] = costFunction(initial_theta, X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Cost at initial theta (zeros): %f\\n&#x27;, cost);</span><br><span class=\"line\">fprintf(&#x27;Expected cost (approx): 0.693\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;Gradient at initial theta (zeros): \\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; %f \\n&#x27;, grad);</span><br><span class=\"line\">fprintf(&#x27;Expected gradients (approx):\\n -0.1000\\n -12.0092\\n -11.2628\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute and display cost and gradient with non-zero theta</span><br><span class=\"line\">test_theta = [-24; 0.2; 0.2];</span><br><span class=\"line\">[cost, grad] = costFunction(test_theta, X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nCost at test theta: %f\\n&#x27;, cost);</span><br><span class=\"line\">fprintf(&#x27;Expected cost (approx): 0.218\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;Gradient at test theta: \\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; %f \\n&#x27;, grad);</span><br><span class=\"line\">fprintf(&#x27;Expected gradients (approx):\\n 0.043\\n 2.566\\n 2.647\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% ============= Part 3: Optimizing using fminunc  =============</span><br><span class=\"line\">%  In this exercise, you will use a built-in function (fminunc) to find the</span><br><span class=\"line\">%  optimal parameters theta.</span><br><span class=\"line\"></span><br><span class=\"line\">%  Set options for fminunc</span><br><span class=\"line\">options = optimset(&#x27;GradObj&#x27;, &#x27;on&#x27;, &#x27;MaxIter&#x27;, 400);</span><br><span class=\"line\"></span><br><span class=\"line\">%  Run fminunc to obtain the optimal theta</span><br><span class=\"line\">%  This function will return theta and the cost </span><br><span class=\"line\">[theta, cost] = ...</span><br><span class=\"line\">  fminunc(@(t)(costFunction(t, X, y)), initial_theta, options);</span><br><span class=\"line\"></span><br><span class=\"line\">% Print theta to screen</span><br><span class=\"line\">fprintf(&#x27;Cost at theta found by fminunc: %f\\n&#x27;, cost);</span><br><span class=\"line\">fprintf(&#x27;Expected cost (approx): 0.203\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;theta: \\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; %f \\n&#x27;, theta);</span><br><span class=\"line\">fprintf(&#x27;Expected theta (approx):\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; -25.161\\n 0.206\\n 0.201\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot Boundary</span><br><span class=\"line\">plotDecisionBoundary(theta, X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">% Put some labels </span><br><span class=\"line\">hold on;</span><br><span class=\"line\">% Labels and Legend</span><br><span class=\"line\">xlabel(&#x27;Exam 1 score&#x27;)</span><br><span class=\"line\">ylabel(&#x27;Exam 2 score&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Specified in plot order</span><br><span class=\"line\">legend(&#x27;Admitted&#x27;, &#x27;Not admitted&#x27;)</span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ============== Part 4: Predict and Accuracies ==============</span><br><span class=\"line\">%  After learning the parameters, you&#x27;ll like to use it to predict the outcomes</span><br><span class=\"line\">%  on unseen data. In this part, you will use the logistic regression model</span><br><span class=\"line\">%  to predict the probability that a student with score 45 on exam 1 and </span><br><span class=\"line\">%  score 85 on exam 2 will be admitted.</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Furthermore, you will compute the training and test set accuracies of </span><br><span class=\"line\">%  our model.</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Your task is to complete the code in predict.m</span><br><span class=\"line\"></span><br><span class=\"line\">%  Predict probability for a student with score 45 on exam 1 </span><br><span class=\"line\">%  and score 85 on exam 2 </span><br><span class=\"line\"></span><br><span class=\"line\">prob = sigmoid([1 45 85] * theta);</span><br><span class=\"line\">fprintf([&#x27;For a student with scores 45 and 85, we predict an admission &#x27; ...</span><br><span class=\"line\">         &#x27;probability of %f\\n&#x27;], prob);</span><br><span class=\"line\">fprintf(&#x27;Expected value: 0.775 +/- 0.002\\n\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute accuracy on our training set</span><br><span class=\"line\">p = predict(theta, X);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Train Accuracy: %f\\n&#x27;, mean(double(p == y)) * 100);</span><br><span class=\"line\">fprintf(&#x27;Expected accuracy (approx): 89.0\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;\\n&#x27;);</span><br></pre></td></tr></table></figure>\n<h1 id=\"plotData-m\"><a href=\"#plotData-m\" class=\"headerlink\" title=\"plotData.m\"></a>plotData.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function plotData(X, y)</span><br><span class=\"line\">%PLOTDATA Plots the data points X and y into a new figure </span><br><span class=\"line\">%   PLOTDATA(x,y) plots the data points with + for the positive examples</span><br><span class=\"line\">%   and o for the negative examples. X is assumed to be a Mx2 matrix.</span><br><span class=\"line\"></span><br><span class=\"line\">% Create New Figure</span><br><span class=\"line\">figure; hold on;</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Plot the positive and negative examples on a</span><br><span class=\"line\">%               2D plot, using the option &#x27;k+&#x27; for the positive</span><br><span class=\"line\">%               examples and &#x27;ko&#x27; for the negative examples.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">pos = find(y==1); neg = find(y==0);</span><br><span class=\"line\">plot(X(pos,1),X(pos,2), &#x27;k+&#x27;,&#x27;LineWidth&#x27;,2,&#x27;MarkerSize&#x27;,5);</span><br><span class=\"line\"></span><br><span class=\"line\">plot(X(neg,1),X(neg,2), &#x27;ko&#x27;,&#x27;LineWidth&#x27;,2,&#x27;MarkerFaceColor&#x27;,&#x27;y&#x27;,&#x27;MarkerSize&#x27;,5);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"costFunction-m\"><a href=\"#costFunction-m\" class=\"headerlink\" title=\"costFunction.m\"></a>costFunction.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [J, grad] = costFunction(theta, X, y)</span><br><span class=\"line\">%COSTFUNCTION Compute cost and gradient for logistic regression</span><br><span class=\"line\">%   J = COSTFUNCTION(theta, X, y) computes the cost of using theta as the</span><br><span class=\"line\">%   parameter for logistic regression and the gradient of the cost</span><br><span class=\"line\">%   w.r.t. to the parameters.</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize some useful values</span><br><span class=\"line\">m = length(y); % number of training examples</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">J = 0;</span><br><span class=\"line\">grad = zeros(size(theta));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the cost of a particular choice of theta.</span><br><span class=\"line\">%               You should set J to the cost.</span><br><span class=\"line\">%               Compute the partial derivatives and set grad to the partial</span><br><span class=\"line\">%               derivatives of the cost w.r.t. each parameter in theta</span><br><span class=\"line\">%</span><br><span class=\"line\">% Note: grad should have the same dimensions as theta</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">h = sigmoid(X*theta);</span><br><span class=\"line\">J = (-y&#x27;*log(h)-(1-y&#x27;)*log(1-h))/m;</span><br><span class=\"line\"></span><br><span class=\"line\">grad = ((h-y)&#x27;*X)&#x27;/m;</span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"plotDecisionBoundary-m\"><a href=\"#plotDecisionBoundary-m\" class=\"headerlink\" title=\"plotDecisionBoundary.m\"></a>plotDecisionBoundary.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function plotDecisionBoundary(theta, X, y)</span><br><span class=\"line\">%PLOTDECISIONBOUNDARY Plots the data points X and y into a new figure with</span><br><span class=\"line\">%the decision boundary defined by theta</span><br><span class=\"line\">%   PLOTDECISIONBOUNDARY(theta, X,y) plots the data points with + for the </span><br><span class=\"line\">%   positive examples and o for the negative examples. X is assumed to be </span><br><span class=\"line\">%   a either </span><br><span class=\"line\">%   1) Mx3 matrix, where the first column is an all-ones column for the </span><br><span class=\"line\">%      intercept.</span><br><span class=\"line\">%   2) MxN, N&gt;3 matrix, where the first column is all-ones</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot Data</span><br><span class=\"line\">plotData(X(:,2:3), y);</span><br><span class=\"line\">hold on</span><br><span class=\"line\"></span><br><span class=\"line\">if size(X, 2) &lt;= 3</span><br><span class=\"line\">    % Only need 2 points to define a line, so choose two endpoints</span><br><span class=\"line\">    plot_x = [min(X(:,2))-2,  max(X(:,2))+2];</span><br><span class=\"line\"></span><br><span class=\"line\">    % Calculate the decision boundary line</span><br><span class=\"line\">    plot_y = (-1./theta(3)).*(theta(2).*plot_x + theta(1));</span><br><span class=\"line\"></span><br><span class=\"line\">    % Plot, and adjust axes for better viewing</span><br><span class=\"line\">    plot(plot_x, plot_y)</span><br><span class=\"line\">    </span><br><span class=\"line\">    % Legend, specific for the exercise</span><br><span class=\"line\">    legend(&#x27;Admitted&#x27;, &#x27;Not admitted&#x27;, &#x27;Decision Boundary&#x27;)</span><br><span class=\"line\">    axis([30, 100, 30, 100])</span><br><span class=\"line\">else</span><br><span class=\"line\">    % Here is the grid range</span><br><span class=\"line\">    u = linspace(-1, 1.5, 50);</span><br><span class=\"line\">    v = linspace(-1, 1.5, 50);</span><br><span class=\"line\"></span><br><span class=\"line\">    z = zeros(length(u), length(v));</span><br><span class=\"line\">    % Evaluate z = theta*x over the grid</span><br><span class=\"line\">    for i = 1:length(u)</span><br><span class=\"line\">        for j = 1:length(v)</span><br><span class=\"line\">            z(i,j) = mapFeature(u(i), v(j))*theta;</span><br><span class=\"line\">        end</span><br><span class=\"line\">    end</span><br><span class=\"line\">    z = z&#x27;; % important to transpose z before calling contour</span><br><span class=\"line\"></span><br><span class=\"line\">    % Plot z = 0</span><br><span class=\"line\">    % Notice you need to specify the range [0, 0]</span><br><span class=\"line\">    contour(u, v, z, [0, 0], &#x27;LineWidth&#x27;, 2)</span><br><span class=\"line\">end</span><br><span class=\"line\">hold off</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"sigmoid-m\"><a href=\"#sigmoid-m\" class=\"headerlink\" title=\"sigmoid.m\"></a>sigmoid.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function g = sigmoid(z)</span><br><span class=\"line\">%SIGMOID Compute sigmoid function</span><br><span class=\"line\">%   g = SIGMOID(z) computes the sigmoid of z.</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">g = zeros(size(z));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the sigmoid of each value of z (z can be a matrix,</span><br><span class=\"line\">%               vector or scalar).</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">g = 1./(1+e.^(-z));</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"predict-m\"><a href=\"#predict-m\" class=\"headerlink\" title=\"predict.m\"></a>predict.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function p = predict(theta, X)</span><br><span class=\"line\">%PREDICT Predict whether the label is 0 or 1 using learned logistic </span><br><span class=\"line\">%regression parameters theta</span><br><span class=\"line\">%   p = PREDICT(theta, X) computes the predictions for X using a </span><br><span class=\"line\">%   threshold at 0.5 (i.e., if sigmoid(theta&#x27;*x) &gt;= 0.5, predict 1)</span><br><span class=\"line\"></span><br><span class=\"line\">m = size(X, 1); % Number of training examples</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly</span><br><span class=\"line\">p = zeros(m, 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Complete the following code to make predictions using</span><br><span class=\"line\">%               your learned logistic regression parameters. </span><br><span class=\"line\">%               You should set p to a vector of 0&#x27;s and 1&#x27;s</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">p = round(sigmoid(X*theta));</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =========================================================================</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"ex2-reg-m\"><a href=\"#ex2-reg-m\" class=\"headerlink\" title=\"ex2_reg.m\"></a>ex2_reg.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">%% Machine Learning Online Class - Exercise 2: Logistic Regression</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Instructions</span><br><span class=\"line\">%  ------------</span><br><span class=\"line\">%</span><br><span class=\"line\">%  This file contains code that helps you get started on the second part</span><br><span class=\"line\">%  of the exercise which covers regularization with logistic regression.</span><br><span class=\"line\">%</span><br><span class=\"line\">%  You will need to complete the following functions in this exericse:</span><br><span class=\"line\">%</span><br><span class=\"line\">%     sigmoid.m</span><br><span class=\"line\">%     costFunction.m</span><br><span class=\"line\">%     predict.m</span><br><span class=\"line\">%     costFunctionReg.m</span><br><span class=\"line\">%</span><br><span class=\"line\">%  For this exercise, you will not need to change any code in this file,</span><br><span class=\"line\">%  or any other files other than those mentioned above.</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">%% Initialization</span><br><span class=\"line\">clear ; close all; clc</span><br><span class=\"line\"></span><br><span class=\"line\">%% Load Data</span><br><span class=\"line\">%  The first two columns contains the X values and the third column</span><br><span class=\"line\">%  contains the label (y).</span><br><span class=\"line\"></span><br><span class=\"line\">data = load(&#x27;ex2data2.txt&#x27;);</span><br><span class=\"line\">X = data(:, [1, 2]); y = data(:, 3);</span><br><span class=\"line\"></span><br><span class=\"line\">plotData(X, y);</span><br><span class=\"line\"></span><br><span class=\"line\">% Put some labels</span><br><span class=\"line\">hold on;</span><br><span class=\"line\"></span><br><span class=\"line\">% Labels and Legend</span><br><span class=\"line\">xlabel(&#x27;Microchip Test 1&#x27;)</span><br><span class=\"line\">ylabel(&#x27;Microchip Test 2&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">% Specified in plot order</span><br><span class=\"line\">legend(&#x27;y = 1&#x27;, &#x27;y = 0&#x27;)</span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%% =========== Part 1: Regularized Logistic Regression ============</span><br><span class=\"line\">%  In this part, you are given a dataset with data points that are not</span><br><span class=\"line\">%  linearly separable. However, you would still like to use logistic</span><br><span class=\"line\">%  regression to classify the data points.</span><br><span class=\"line\">%</span><br><span class=\"line\">%  To do so, you introduce more features to use -- in particular, you add</span><br><span class=\"line\">%  polynomial features to our data matrix (similar to polynomial</span><br><span class=\"line\">%  regression).</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Add Polynomial Features</span><br><span class=\"line\"></span><br><span class=\"line\">% Note that mapFeature also adds a column of ones for us, so the intercept</span><br><span class=\"line\">% term is handled</span><br><span class=\"line\">X = mapFeature(X(:,1), X(:,2));</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize fitting parameters</span><br><span class=\"line\">initial_theta = zeros(size(X, 2), 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Set regularization parameter lambda to 1</span><br><span class=\"line\">lambda = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute and display initial cost and gradient for regularized logistic</span><br><span class=\"line\">% regression</span><br><span class=\"line\">[cost, grad] = costFunctionReg(initial_theta, X, y, lambda);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Cost at initial theta (zeros): %f\\n&#x27;, cost);</span><br><span class=\"line\">fprintf(&#x27;Expected cost (approx): 0.693\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;Gradient at initial theta (zeros) - first five values only:\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; %f \\n&#x27;, grad(1:5));</span><br><span class=\"line\">fprintf(&#x27;Expected gradients (approx) - first five values only:\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; 0.0085\\n 0.0188\\n 0.0001\\n 0.0503\\n 0.0115\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute and display cost and gradient</span><br><span class=\"line\">% with all-ones theta and lambda = 10</span><br><span class=\"line\">test_theta = ones(size(X,2),1);</span><br><span class=\"line\">[cost, grad] = costFunctionReg(test_theta, X, y, 10);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nCost at test theta (with lambda = 10): %f\\n&#x27;, cost);</span><br><span class=\"line\">fprintf(&#x27;Expected cost (approx): 3.16\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27;Gradient at test theta - first five values only:\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; %f \\n&#x27;, grad(1:5));</span><br><span class=\"line\">fprintf(&#x27;Expected gradients (approx) - first five values only:\\n&#x27;);</span><br><span class=\"line\">fprintf(&#x27; 0.3460\\n 0.1614\\n 0.1948\\n 0.2269\\n 0.0922\\n&#x27;);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;\\nProgram paused. Press enter to continue.\\n&#x27;);</span><br><span class=\"line\">pause;</span><br><span class=\"line\"></span><br><span class=\"line\">%% ============= Part 2: Regularization and Accuracies =============</span><br><span class=\"line\">%  Optional Exercise:</span><br><span class=\"line\">%  In this part, you will get to try different values of lambda and</span><br><span class=\"line\">%  see how regularization affects the decision coundart</span><br><span class=\"line\">%</span><br><span class=\"line\">%  Try the following values of lambda (0, 1, 10, 100).</span><br><span class=\"line\">%</span><br><span class=\"line\">%  How does the decision boundary change when you vary lambda? How does</span><br><span class=\"line\">%  the training set accuracy vary?</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize fitting parameters</span><br><span class=\"line\">initial_theta = zeros(size(X, 2), 1);</span><br><span class=\"line\"></span><br><span class=\"line\">% Set regularization parameter lambda to 1 (you should vary this)</span><br><span class=\"line\">lambda = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">% Set Options</span><br><span class=\"line\">options = optimset(&#x27;GradObj&#x27;, &#x27;on&#x27;, &#x27;MaxIter&#x27;, 400);</span><br><span class=\"line\"></span><br><span class=\"line\">% Optimize</span><br><span class=\"line\">[theta, J, exit_flag] = ...</span><br><span class=\"line\">  fminunc(@(t)(costFunctionReg(t, X, y, lambda)), initial_theta, options);</span><br><span class=\"line\"></span><br><span class=\"line\">% Plot Boundary</span><br><span class=\"line\">plotDecisionBoundary(theta, X, y);</span><br><span class=\"line\">hold on;</span><br><span class=\"line\">title(sprintf(&#x27;lambda = %g&#x27;, lambda))</span><br><span class=\"line\"></span><br><span class=\"line\">% Labels and Legend</span><br><span class=\"line\">xlabel(&#x27;Microchip Test 1&#x27;)</span><br><span class=\"line\">ylabel(&#x27;Microchip Test 2&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">legend(&#x27;y = 1&#x27;, &#x27;y = 0&#x27;, &#x27;Decision boundary&#x27;)</span><br><span class=\"line\">hold off;</span><br><span class=\"line\"></span><br><span class=\"line\">% Compute accuracy on our training set</span><br><span class=\"line\">p = predict(theta, X);</span><br><span class=\"line\"></span><br><span class=\"line\">fprintf(&#x27;Train Accuracy: %f\\n&#x27;, mean(double(p == y)) * 100);</span><br><span class=\"line\">fprintf(&#x27;Expected accuracy (with lambda = 1): 83.1 (approx)\\n&#x27;);</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h1 id=\"mapFeature-m\"><a href=\"#mapFeature-m\" class=\"headerlink\" title=\"mapFeature.m\"></a>mapFeature.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function out = mapFeature(X1, X2)</span><br><span class=\"line\">% MAPFEATURE Feature mapping function to polynomial features</span><br><span class=\"line\">%</span><br><span class=\"line\">%   MAPFEATURE(X1, X2) maps the two input features</span><br><span class=\"line\">%   to quadratic features used in the regularization exercise.</span><br><span class=\"line\">%</span><br><span class=\"line\">%   Returns a new feature array with more features, comprising of </span><br><span class=\"line\">%   X1, X2, X1.^2, X2.^2, X1*X2, X1*X2.^2, etc..</span><br><span class=\"line\">%</span><br><span class=\"line\">%   Inputs X1, X2 must be the same size</span><br><span class=\"line\">%</span><br><span class=\"line\"></span><br><span class=\"line\">degree = 6;</span><br><span class=\"line\">out = ones(size(X1(:,1)));</span><br><span class=\"line\">for i = 1:degree</span><br><span class=\"line\">    for j = 0:i</span><br><span class=\"line\">        out(:, end+1) = (X1.^(i-j)).*(X2.^j);</span><br><span class=\"line\">    end</span><br><span class=\"line\">end</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n<h1 id=\"costFunctionReg-m\"><a href=\"#costFunctionReg-m\" class=\"headerlink\" title=\"costFunctionReg.m\"></a>costFunctionReg.m</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">function [J, grad] = costFunctionReg(theta, X, y, lambda)</span><br><span class=\"line\">%COSTFUNCTIONREG Compute cost and gradient for logistic regression with regularization</span><br><span class=\"line\">%   J = COSTFUNCTIONREG(theta, X, y, lambda) computes the cost of using</span><br><span class=\"line\">%   theta as the parameter for regularized logistic regression and the</span><br><span class=\"line\">%   gradient of the cost w.r.t. to the parameters. </span><br><span class=\"line\"></span><br><span class=\"line\">% Initialize some useful values</span><br><span class=\"line\">m = length(y); % number of training examples</span><br><span class=\"line\"></span><br><span class=\"line\">% You need to return the following variables correctly </span><br><span class=\"line\">J = 0;</span><br><span class=\"line\">grad = zeros(size(theta));</span><br><span class=\"line\"></span><br><span class=\"line\">% ====================== YOUR CODE HERE ======================</span><br><span class=\"line\">% Instructions: Compute the cost of a particular choice of theta.</span><br><span class=\"line\">%               You should set J to the cost.</span><br><span class=\"line\">%               Compute the partial derivatives and set grad to the partial</span><br><span class=\"line\">%               derivatives of the cost w.r.t. each parameter in theta</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">h = sigmoid(X*theta);</span><br><span class=\"line\">reg = lambda/(2*m)*(theta&#x27;*theta-theta(1)^2);</span><br><span class=\"line\">J = 1/m*(-y&#x27;*log(h)-(1-y&#x27;)*log(1-h))+reg;</span><br><span class=\"line\"></span><br><span class=\"line\">mask = ones(size(theta));</span><br><span class=\"line\">mask(1)=0;</span><br><span class=\"line\"></span><br><span class=\"line\">grad = 1/m*X&#x27;*(h-y) + lambda/m*(theta.*mask);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">% =============================================================</span><br><span class=\"line\"></span><br><span class=\"line\">end</span><br></pre></td></tr></table></figure>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Python网络爬虫--urllib请求库的用法","url":"/2022/07/22/Python%E7%88%AC%E8%99%AB--urllib%E8%AF%B7%E6%B1%82%E5%BA%93%E7%9A%84%E7%94%A8%E6%B3%95/","content":"<p>这篇文章将跟大家分享Python网络爬虫中经常会用到的网页请求库–urllib的一些用法。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"urllib库包含的模块\"><a href=\"#urllib库包含的模块\" class=\"headerlink\" title=\"urllib库包含的模块\"></a><strong>urllib库包含的模块</strong></h1><ul>\n<li><strong>request</strong>: HTTP请求模块</li>\n<li><strong>error</strong>：异常处理模块</li>\n<li><strong>parse</strong>：工具模块，提供拆分、解析、合并URL等操作</li>\n<li>robotparser：识别网站的robots.txt文件，来判断是否可以爬取（很少用到）。</li>\n</ul>\n<h1 id=\"request模块\"><a href=\"#request模块\" class=\"headerlink\" title=\"request模块\"></a><strong>request模块</strong></h1><p><strong>该模块包含如下的主要的functions：</strong></p>\n<ol>\n<li>urlopen(<em>url, data &#x3D; None, [timeout,]*,cafile &#x3D; None, capath &#x3D; None, cadefault &#x3D; False, context &#x3D; None</em>)<ul>\n<li>用于构建最基本的网页请求</li>\n</ul>\n</li>\n<li>install_opener(<em>opener</em>)<ul>\n<li>加载一个OpenerDirector实例作为默认的全局opener。</li>\n</ul>\n</li>\n<li>build_opener(<em>[handler,…]</em>) <ul>\n<li>构建一个由不同handler连接而成的opener。</li>\n</ul>\n</li>\n<li>pathname2url(<em>path</em>) <ul>\n<li>将pathname转换为URL。</li>\n</ul>\n</li>\n<li>url2pathname(<em>path</em>)<ul>\n<li>将URL转换为pathname。</li>\n</ul>\n</li>\n</ol>\n<p><strong>以及如下的classes:</strong></p>\n<ol>\n<li><p>BaseHandler – 所有其他Handler的父类，可以用于一些更高级的操作（比如处理Cookies，设置代理等）</p>\n<ul>\n<li>HTTPDefaultErrorHandler – 用于处理HTTP相应错误</li>\n<li>HTTPRedirectHandler – 用于重定向</li>\n<li>HTTPCookieProcessor(<em>cookiejar&#x3D;None</em>) – 用于处理Cookies</li>\n<li>ProxyHanlder(<em>proxies&#x3D;None</em>) – 用于设置代理</li>\n<li>HTTPPasswordMgr – 用于管理密码</li>\n<li>HTTPBasicAuthHandler – 用于管理认证</li>\n</ul>\n</li>\n<li><p>OpenerDirector – 利用Hanlder来构建Opener。</p>\n</li>\n<li><p>Request(<em>url, data&#x3D;None, headers&#x3D;{}, origin_req_host&#x3D;None, unverifiable&#x3D;False, method&#x3D;None</em>) – 如果需要在请求中加入Header等信息，可以通过Request类来构建一个请求。</p>\n</li>\n</ol>\n<h1 id=\"error：异常处理模块\"><a href=\"#error：异常处理模块\" class=\"headerlink\" title=\"error：异常处理模块\"></a><strong>error：异常处理模块</strong></h1><ol>\n<li>URLError<ul>\n<li>有reason属性，可以返回错误原因 <figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">from urllib import request, error</span><br><span class=\"line\">try:</span><br><span class=\"line\">\tresponse = request.urlopen(&#x27;https://shileilei.com&#x27;)</span><br><span class=\"line\">except error.URLError as e:</span><br><span class=\"line\">\tprint(e.reason)</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li>HTTPError – URLError的子类，专门用来处理HTTP请求错误，比如认证失败等。有三个属性：<ul>\n<li>code：返回HTTP状态码</li>\n<li>reason： 同其父类URLError一样，返回错误原因</li>\n<li>headers: 返回请求头</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"parse：工具模块，提供拆分、解析、合并URL等操作\"><a href=\"#parse：工具模块，提供拆分、解析、合并URL等操作\" class=\"headerlink\" title=\"parse：工具模块，提供拆分、解析、合并URL等操作\"></a><strong>parse：工具模块，提供拆分、解析、合并URL等操作</strong></h1><ol>\n<li>urlparse() – 可以实现URL的识别和分段。其API用法为：urllib.parse.urlparse(urlstring, scheme&#x3D;’’,allow_fragments&#x3D;True)<ul>\n<li>urlstring – 待解析的URL</li>\n<li>scheme – 默认协议，比如http或者https</li>\n<li>allow_fragments – 是否忽略fragment</li>\n</ul>\n</li>\n<li>urlunparse() – 将不同参数组合在一起构造URL。</li>\n<li>urlsplit() – 跟urlparse()类似，不过不单独解析params这一部分。</li>\n<li>urlunsplit() – 跟urlunparse()类似，传入参数可以是列表、元组等可迭代对象。</li>\n<li>urljoint() – 可以实现链接的解析、拼合与生成。</li>\n<li>urlencode() – 可以将字典类型转化为GET请求的URL参数。</li>\n<li>parse_qs() – 与urlencode()相反，可以将GET请求参数转化为字典。</li>\n<li>parse_qsl() – 可以将GET请求参数转化为元组组成的列表。</li>\n<li>quote() – 可以将内容转化为URL编码的格式。尤其是带有中文参数时，可以避免乱码问题。</li>\n<li>unquote() – –与quote()相反，可以对URL进行解码。</li>\n</ol>\n<h1 id=\"实战演练–使用urllib请求豆瓣电影排行榜\"><a href=\"#实战演练–使用urllib请求豆瓣电影排行榜\" class=\"headerlink\" title=\"实战演练–使用urllib请求豆瓣电影排行榜\"></a><strong>实战演练–使用urllib请求豆瓣电影排行榜</strong></h1><p>说了这么多，我们来请求豆瓣电影排行榜来实战演练一下。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import urllib</span><br><span class=\"line\">from urllib import request</span><br><span class=\"line\">from urllib.error import URLError, HTTPError</span><br><span class=\"line\">import ssl  #如果出现了认证错误，需要引入ssl模块</span><br><span class=\"line\"></span><br><span class=\"line\">ssl._create_default_https_context = ssl._create_unverified_context</span><br><span class=\"line\"></span><br><span class=\"line\">url = &#x27;https://movie.douban.com/chart&#x27;</span><br><span class=\"line\">opener = request.build_opener(request.HTTPCookieProcessor())</span><br><span class=\"line\">headers = &#123;</span><br><span class=\"line\">\t&#x27;User-Agent&#x27;:&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&#x27;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">req = request.Request(url=url, data=None, headers = headers, unverifiable=True, method = &#x27;GET&#x27;)</span><br><span class=\"line\">try:</span><br><span class=\"line\">\tresponse = opener.open(req)</span><br><span class=\"line\">\tprint(response.read().decode(&#x27;utf-8&#x27;))</span><br><span class=\"line\">except URLError as e:</span><br><span class=\"line\">\tprint(e.reason)</span><br></pre></td></tr></table></figure>\n<p>运行之后，不出意外的话，输出结果应该如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html lang=&quot;zh-CN&quot; class=&quot;ua-windows ua-webkit&quot;&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">    &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&gt;</span><br><span class=\"line\">    &lt;meta name=&quot;renderer&quot; content=&quot;webkit&quot;&gt;</span><br><span class=\"line\">    &lt;meta name=&quot;referrer&quot; content=&quot;always&quot;&gt;</span><br><span class=\"line\">    &lt;meta name=&quot;google-site-verification&quot; content=&quot;ok0wCgT20tBBgo9_zat2iAcimtN4Ftf5ccsh092Xeyw&quot; /&gt;</span><br><span class=\"line\">    &lt;title&gt;</span><br><span class=\"line\">豆瓣电影排行榜</span><br><span class=\"line\">&lt;/title&gt;</span><br><span class=\"line\">    </span><br><span class=\"line\">    &lt;meta name=&quot;baidu-site-verification&quot; content=&quot;cZdR4xxR7RxmM4zE&quot; /&gt;</span><br><span class=\"line\">    &lt;meta http-equiv=&quot;Pragma&quot; content=&quot;no-cache&quot;&gt;</span><br><span class=\"line\">    &lt;meta http-equiv=&quot;Expires&quot; content=&quot;Sun, 6 Mar 2005 01:00:00 GMT&quot;&gt;</span><br><span class=\"line\">    </span><br><span class=\"line\">    &lt;meta name=&quot;keywords&quot; content=&quot;电影排行榜、新片排行榜、豆瓣电影250&quot;/&gt;</span><br><span class=\"line\">    &lt;meta name=&quot;description&quot; content=&quot;豆瓣电影排行榜,提供最新电影排行榜、本周电影口碑榜和豆瓣电影TOP250&quot; /&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">...</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n","categories":["技术杂谈","Python"],"tags":["Python","编程","网络","爬虫"]},{"title":"Python常用函数--isinstance()和type()","url":"/2022/07/20/Python%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0--isinstance()%E5%92%8Ctype()/","content":"<p>在这篇文章中，我将给大家分享如何使用isinstance()和type()两个Python常用函数，并且分析它们之间的区别。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"isinstance-函数\"><a href=\"#isinstance-函数\" class=\"headerlink\" title=\"isinstance()函数\"></a><strong>isinstance()函数</strong></h1><p>isinstance()函数用来判断一个对象是否是一个已知类型。其语法如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">isinstance(object, classinfo)</span><br></pre></td></tr></table></figure>\n<p>其中object为实例对象，也就是我们需要判断的对象。classinfo为类的名称，可以是直接类或间接类、基本类型或者由他们组成的元组。<br>如果对象的类型与classinfo的类型相同，则返回True，否则返回False。<br>具体举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; a = &#x27;good&#x27;</span><br><span class=\"line\">&gt;&gt;&gt; isinstance (a, int)</span><br><span class=\"line\">False</span><br><span class=\"line\">&gt;&gt;&gt; isinstance (a, str)</span><br><span class=\"line\">True</span><br><span class=\"line\">&gt;&gt;&gt; isinstance (a,(str, int, list))</span><br><span class=\"line\">True</span><br></pre></td></tr></table></figure>\n<h1 id=\"type-函数\"><a href=\"#type-函数\" class=\"headerlink\" title=\"type()函数\"></a><strong>type()函数</strong></h1><p>type()函数可以返回对象的类型，具体语法如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">type(object)</span><br><span class=\"line\">type(name, bases, dict)</span><br></pre></td></tr></table></figure>\n<p>一个参数返回对象类型, 三个参数则返回新的类型对象。我们这里重点讨论一个参数的情况。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; type(123)</span><br><span class=\"line\">&lt;type &#x27;int&#x27;&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; type(&#x27;good&#x27;)</span><br><span class=\"line\">&lt;type &#x27;str&#x27;&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; type([2])</span><br><span class=\"line\">&lt;type &#x27;list&#x27;&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; type(&#123;name:&#x27;Leo&#x27;&#125;)</span><br><span class=\"line\">&lt;type &#x27;dict&#x27;&gt;</span><br></pre></td></tr></table></figure>\n<p>我们会发现，type()函数与isinstance()函数类似，都可以返回对象的类型。但他们在是否考虑类的继承关系有很大区别，具体区别如下：</p>\n<ul>\n<li>type()不考虑继承关系，也就是说不会认为子类是一种父类类型。</li>\n<li>isinstance()考虑继承关系，也就是说会认为子类是一种父类类型。</li>\n</ul>\n<p>比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">class A:</span><br><span class=\"line\">    pass</span><br><span class=\"line\"> </span><br><span class=\"line\">class B(A):</span><br><span class=\"line\">    pass</span><br><span class=\"line\"> </span><br><span class=\"line\">isinstance(A(), A)    # returns True</span><br><span class=\"line\">type(A()) == A        # returns True</span><br><span class=\"line\">isinstance(B(), A)    # returns True</span><br><span class=\"line\">type(B()) == A        # returns False</span><br></pre></td></tr></table></figure>\n","categories":["技术杂谈","Python"],"tags":["Python","编程","常用函数"]},{"title":"Python教程--文件的存储与读取","url":"/2022/07/31/Python%E6%95%99%E7%A8%8B--%E6%96%87%E4%BB%B6%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E8%AF%BB%E5%8F%96/","content":"<p>这篇文章将跟大家分享如何使用python来读取和存储文件和数据。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"读取和存储TXT文本\"><a href=\"#读取和存储TXT文本\" class=\"headerlink\" title=\"读取和存储TXT文本\"></a><strong>读取和存储TXT文本</strong></h1><p>存储数据最简单方便并且常用的格式为TXT文本格式，这种格式几乎兼容所有平台。</p>\n<h2 id=\"写入文件\"><a href=\"#写入文件\" class=\"headerlink\" title=\"写入文件\"></a>写入文件</h2><h3 id=\"基本写入\"><a href=\"#基本写入\" class=\"headerlink\" title=\"基本写入\"></a>基本写入</h3><p>这里会用到python内置的三个函数，open(), write()和close()。其中，open()函数可以将文件打开，write()函数用于将数据写入文件，close()函数用于关闭并保存文件。示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">file = open(&quot;example.txt&quot;, &#x27;w&#x27;)</span><br><span class=\"line\">file.write(&quot;This is an example.&quot;)</span><br><span class=\"line\">file.close()</span><br></pre></td></tr></table></figure>\n<p>执行上面的代码之后，我们就会发现在当前目录下，一个文件名为example.txt的文档被成功创建了。</p>\n<h3 id=\"简化写法\"><a href=\"#简化写法\" class=\"headerlink\" title=\"简化写法\"></a>简化写法</h3><p>另外，文件写入还有一种简化写法，那就是使用with as语法。with控制块结束时，文件会自动关闭，这样就可以将close()方法省略掉了。示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with open (&quot;example_2.txt&quot;, &#x27;w&#x27;) as file:</span><br><span class=\"line\">\tfile.write(&quot;This is another example.&quot;)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"改变存储路径\"><a href=\"#改变存储路径\" class=\"headerlink\" title=\"改变存储路径\"></a>改变存储路径</h3><p>如果想保存到其他目录下，我们也可以在文件名中加入路径，比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with open (&quot;C:\\\\users\\\\shil\\\\example_2.txt&quot;, &quot;w&quot;) as file:</span><br><span class=\"line\">\tfile.write(&quot;This is another example.&quot;)</span><br></pre></td></tr></table></figure>\n<p>路径中要使用双\\，其中第一个\\用作转义字符，也就是让系统识别\\是路径的一部分。我们也可以在前面加上r来表示路径：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with open (r&quot;C:\\users\\shil\\example_2.txt&quot;, &quot;w&quot;) as file:</span><br><span class=\"line\">\tfile.write(&quot;This is another example.&quot;)</span><br></pre></td></tr></table></figure>\n<p>另外，注意在Linux和OS系统中，文件路径要使用斜杠(&#x2F;)而不是反斜杠()。</p>\n<h3 id=\"读写状态\"><a href=\"#读写状态\" class=\"headerlink\" title=\"读写状态\"></a>读写状态</h3><p>python的open和C以及其它很多语言类似，有r,r+, w, w+等各种状态。</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>状态</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>r</td>\n<td>读取(read)</td>\n</tr>\n<tr>\n<td>w</td>\n<td>写入(write)</td>\n</tr>\n<tr>\n<td>a</td>\n<td>追加(append)</td>\n</tr>\n<tr>\n<td>r+</td>\n<td>可读取和写入(r+w)，就若不存在报错</td>\n</tr>\n<tr>\n<td>w+</td>\n<td>可读取和写入(w+r)，若不存在就创建</td>\n</tr>\n<tr>\n<td>a+</td>\n<td>可追加和写入(a+r)，若不存在就创建</td>\n</tr>\n</tbody></table>\n<p>在使用w和w+时要注意，该读写方式会覆盖原先的文件(如果存在一个同名文件的话)，使得原先的文件内容消失。</p>\n<p>对应的，如果是二进制文件，就都加一个b就好了:<br>‘rb’,’wb’, ‘ab’, ‘rb+’, ‘wb+’, ‘ab+’</p>\n<h2 id=\"读取文件\"><a href=\"#读取文件\" class=\"headerlink\" title=\"读取文件\"></a>读取文件</h2><p>我们也可以使用python来读取TXT文件。但需要注意，使用with语句时，open()返回的文件对象只能在with代码块内使用。</p>\n<h3 id=\"with语句内读取\"><a href=\"#with语句内读取\" class=\"headerlink\" title=\"with语句内读取\"></a>with语句内读取</h3><p>首先，我们先用上面提到的方法来创建一个多行的TXT文件。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with open (&quot;example.txt&quot;, &quot;w&quot;) as file:</span><br><span class=\"line\">\tfile.write(&quot;This is the first line.\\n&quot;)</span><br><span class=\"line\">\tfile.write(&quot;This is the second line.\\n&quot;)</span><br><span class=\"line\">\tfile.write(&quot;This is the third line.\\n&quot;)</span><br></pre></td></tr></table></figure>\n<p>然后，我们就可以逐行进行读取数据了，具体代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with open (&quot;example.txt&quot;, &quot;r&quot;) as file:</span><br><span class=\"line\">\tfor line in file:</span><br><span class=\"line\">\t\tprint(line)</span><br></pre></td></tr></table></figure>\n<p>执行之后，结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">This is the first line.</span><br><span class=\"line\"></span><br><span class=\"line\">This is the second line.</span><br><span class=\"line\"></span><br><span class=\"line\">This is the third line.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>我们发现结果已经成功输出，但同时发现跟原文件相比多了几行空白行。这是因为每一个print语句会自动加上一个换行符。要消除这些空白行，我们只需要在print语句中使用rstrip()，具体代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with open (&quot;example.txt&quot;, &quot;r&quot;) as file:</span><br><span class=\"line\">\tfor line in file:</span><br><span class=\"line\">\t\tprint(line.rstrip())</span><br></pre></td></tr></table></figure>\n<p>这时候再次执行，输出结果就跟原文件一致了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">This is the first line.</span><br><span class=\"line\">This is the second line.</span><br><span class=\"line\">This is the third line.</span><br></pre></td></tr></table></figure>\n<h3 id=\"with语句外读取\"><a href=\"#with语句外读取\" class=\"headerlink\" title=\"with语句外读取\"></a>with语句外读取</h3><p>如果要在代码块外访问文件的内容，可以将文件先储存在一个列表中，然后就可以在with代码块之后访问文件的内容了。示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with open (&quot;example.txt&quot;, &quot;r&quot;) as file:</span><br><span class=\"line\">\tlines = file.readlines()</span><br><span class=\"line\"></span><br><span class=\"line\">for line in lines:</span><br><span class=\"line\">\tprint(line.rstrip())</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"读取和存储JSON文件\"><a href=\"#读取和存储JSON文件\" class=\"headerlink\" title=\"读取和存储JSON文件\"></a><strong>读取和存储JSON文件</strong></h1><p>虽然TXT纯文本格式使用起来比较简单，但它有个缺点，那就是层次结构不清晰，并且不利于检索。相比较来说，JSON就可以通过对象和数组的组合来表示数据，从而提供结构化程度比较高的数据格式。同时这种格式更加有利于人的阅读和编写，易于机器解析和生成，并且有效地提升网络传输效率。</p>\n<h2 id=\"JSON基本结构\"><a href=\"#JSON基本结构\" class=\"headerlink\" title=\"JSON基本结构\"></a>JSON基本结构</h2><p>我们先来看一个JSON数据格式的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#123;</span><br><span class=\"line\">  &quot;province&quot;: &quot;Hebei&quot;,</span><br><span class=\"line\">  &quot;cities&quot;: &#123;</span><br><span class=\"line\">  &quot;city&quot;: [&quot;Shijiazhuang&quot;, &quot;Baoding&quot;]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;, &#123;</span><br><span class=\"line\">  &quot;province&quot;: &quot;Guangdong&quot;,</span><br><span class=\"line\">  &quot;cities&quot;: &#123;</span><br><span class=\"line\">  &quot;city&quot;: [&quot;Guangzhou&quot;, &quot;Shenzhen&quot;, &quot;Zhuhai&quot;]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;]</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>其中大括号{}包围的为字典，是由{key:value}的键值对结构来组成。方括号包围的为列表，是由0个或多个以英文逗号“,”分隔的值列表组成。JSON可以由这两种形式自由组合，可以无限次嵌套。</p>\n<h2 id=\"存储数据为JSON格式\"><a href=\"#存储数据为JSON格式\" class=\"headerlink\" title=\"存储数据为JSON格式\"></a>存储数据为JSON格式</h2><h3 id=\"基本数据存储\"><a href=\"#基本数据存储\" class=\"headerlink\" title=\"基本数据存储\"></a>基本数据存储</h3><p>我们可以使用json.jump()的方法来把数据写入JSON文件，或者使用json.jumps()的方法来将JSON格式的对象转化成字符串，然后再使用上面提到的类似的方法写入文件。示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import json</span><br><span class=\"line\"></span><br><span class=\"line\">cities = [&#123;</span><br><span class=\"line\">  &quot;province&quot;: &quot;Hebei&quot;,</span><br><span class=\"line\">  &quot;cities&quot;: &#123;</span><br><span class=\"line\">  &quot;city&quot;: [&quot;Shijiazhuang&quot;, &quot;Baoding&quot;]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;, &#123;</span><br><span class=\"line\">  &quot;province&quot;: &quot;Guangdong&quot;,</span><br><span class=\"line\">  &quot;cities&quot;: &#123;</span><br><span class=\"line\">  &quot;city&quot;: [&quot;Guangzhou&quot;, &quot;Shenzhen&quot;, &quot;Zhuhai&quot;]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;example.json&#x27;, &#x27;w&#x27;) as file:</span><br><span class=\"line\"></span><br><span class=\"line\">\tjson.dump(cities, file)</span><br></pre></td></tr></table></figure>\n\n<p>类似的，我们也可以使用dumps()来将JSON对象转换为字符串，示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with open(&#x27;example.json&#x27;, &#x27;w&#x27;) as file:</span><br><span class=\"line\"></span><br><span class=\"line\">\tfile.write(json.dumps(cities))</span><br></pre></td></tr></table></figure>\n\n<p>两种方式的输出结果相同，其内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#123;&quot;province&quot;: &quot;Hebei&quot;, &quot;cities&quot;: &#123;&quot;city&quot;: [&quot;Shijiazhuang&quot;, &quot;Baoding&quot;]&#125;&#125;, &#123;&quot;province&quot;: &quot;Guangdong&quot;, &quot;cities&quot;: &#123;&quot;city&quot;: [&quot;Guangzhou&quot;, &quot;Shenzhen&quot;, &quot;Zhuhai&quot;]&#125;&#125;]</span><br></pre></td></tr></table></figure>\n<p>如果想要保存的json文件层次更加清晰，我们可以加一个indent参数，使数据带有缩进。示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">with open(&#x27;example.json&#x27;, &#x27;w&#x27;) as file:</span><br><span class=\"line\"></span><br><span class=\"line\">\tjson.dump(cities, file, indent = 2)</span><br></pre></td></tr></table></figure>\n<p>此时写入结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;province&quot;: &quot;Hebei&quot;,</span><br><span class=\"line\">    &quot;cities&quot;: &#123;</span><br><span class=\"line\">      &quot;city&quot;: [</span><br><span class=\"line\">        &quot;Shijiazhuang&quot;,</span><br><span class=\"line\">        &quot;Baoding&quot;</span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;province&quot;: &quot;Guangdong&quot;,</span><br><span class=\"line\">    &quot;cities&quot;: &#123;</span><br><span class=\"line\">      &quot;city&quot;: [</span><br><span class=\"line\">        &quot;Guangzhou&quot;,</span><br><span class=\"line\">        &quot;Shenzhen&quot;,</span><br><span class=\"line\">        &quot;Zhuhai&quot;</span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<h3 id=\"保存用户生成的数据为JSON\"><a href=\"#保存用户生成的数据为JSON\" class=\"headerlink\" title=\"保存用户生成的数据为JSON\"></a>保存用户生成的数据为JSON</h3><p>对于用户生成的数据，我们也可以使用JSON格式保存下来。示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import json</span><br><span class=\"line\"></span><br><span class=\"line\">username = input(&quot;What is your name?&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;username.json&#x27;,&#x27;w&#x27;) as file:</span><br><span class=\"line\">\tjson.dump(username, file)</span><br><span class=\"line\">\tprint(&quot;Hello, &quot; + username + &quot;!&quot;)</span><br></pre></td></tr></table></figure>\n<p>运行此程序，就会得到如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">What is your name?Leo</span><br><span class=\"line\">Hello, Leo!</span><br></pre></td></tr></table></figure>\n<h2 id=\"读取JSON格式文件\"><a href=\"#读取JSON格式文件\" class=\"headerlink\" title=\"读取JSON格式文件\"></a>读取JSON格式文件</h2><p>跟存储JSON格式的数据类似，我们可以用json.load()方法来读取JSON，或者使用json.loads()的方法将JSON对象转化为字符串，然后进行读取。示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import json</span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;example.json&#x27;,&#x27;r&#x27;)as file:</span><br><span class=\"line\">\tcities = json.load(file)</span><br><span class=\"line\"></span><br><span class=\"line\">print(cities)</span><br></pre></td></tr></table></figure>\n<p>或者使用json.loads()的方法：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import json</span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;example.json&#x27;,&#x27;r&#x27;)as file:</span><br><span class=\"line\">\tstr = file.read()</span><br><span class=\"line\">\tcities = json.loads(str)</span><br><span class=\"line\"></span><br><span class=\"line\">print(cities)</span><br></pre></td></tr></table></figure>\n\n<p>输出结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#123;&#x27;province&#x27;: &#x27;Hebei&#x27;, &#x27;cities&#x27;: &#123;&#x27;city&#x27;: [&#x27;Shijiazhuang&#x27;, &#x27;Baoding&#x27;]&#125;&#125;, &#123;&#x27;province&#x27;: &#x27;Guangdong&#x27;, &#x27;cities&#x27;: &#123;&#x27;city&#x27;: [&#x27;Guangzhou&#x27;, &#x27;Shenzhen&#x27;, &#x27;Zhuhai&#x27;]&#125;&#125;]</span><br></pre></td></tr></table></figure>\n<h1 id=\"读取和存储CSV格式文件\"><a href=\"#读取和存储CSV格式文件\" class=\"headerlink\" title=\"读取和存储CSV格式文件\"></a><strong>读取和存储CSV格式文件</strong></h1><p>CSV，全称为Comma-Separated Values，顾名思义是一系列以逗号或者制表符来分隔的值，是一种非常方便的在文本中储存数据的方式。CSV文件对人来说阅读起来比较麻烦，但程序可轻松地提取并处理其中的数据。</p>\n<h2 id=\"写入CSV格式数据\"><a href=\"#写入CSV格式数据\" class=\"headerlink\" title=\"写入CSV格式数据\"></a>写入CSV格式数据</h2><h3 id=\"直接写入\"><a href=\"#直接写入\" class=\"headerlink\" title=\"直接写入\"></a>直接写入</h3><p>我们先来看一个最简单的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import csv</span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;data.csv&#x27;, &#x27;w&#x27;, newline=&#x27;&#x27;) as file:</span><br><span class=\"line\">\twriter = csv.writer(file)</span><br><span class=\"line\">\twriter.writerow([&#x27;name&#x27;,&#x27;age&#x27;,&#x27;gender&#x27;,&#x27;hobit&#x27;])</span><br><span class=\"line\">\twriter.writerow([&#x27;James&#x27;,&#x27;25&#x27;,&#x27;male&#x27;,&#x27;basketball&#x27;])</span><br><span class=\"line\">\twriter.writerow([&#x27;Louis&#x27;,&#x27;13&#x27;,&#x27;male&#x27;,&#x27;football&#x27;])</span><br><span class=\"line\">\twriter.writerow([&#x27;Jenny&#x27;,&#x27;16&#x27;,&#x27;female&#x27;,&#x27;badminton&#x27;])</span><br><span class=\"line\">\t</span><br></pre></td></tr></table></figure>\n\n<p>运行上面的程序，会生成一个data.csv文件，里面包含的内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">name,age,gender,hobit</span><br><span class=\"line\">James,25,male,basketball</span><br><span class=\"line\">Louis,13,male,football</span><br><span class=\"line\">Jenny,16,female,badminton</span><br></pre></td></tr></table></figure>\n<h3 id=\"多行写入\"><a href=\"#多行写入\" class=\"headerlink\" title=\"多行写入\"></a>多行写入</h3><p>上面的例子我们采用的是writerow()来逐行写入。除此之外，我们还可以调用writerows()的方法同时写入多行，示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import csv</span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;data.csv&#x27;, &#x27;w&#x27;, newline=&#x27;&#x27;) as file:</span><br><span class=\"line\">\twriter = csv.writer(file)</span><br><span class=\"line\">\twriter.writerow([&#x27;name&#x27;,&#x27;age&#x27;,&#x27;gender&#x27;,&#x27;hobit&#x27;])</span><br><span class=\"line\">\twriter.writerows([[&#x27;James&#x27;,&#x27;25&#x27;,&#x27;male&#x27;,&#x27;basketball&#x27;], [&#x27;Louis&#x27;,&#x27;13&#x27;,&#x27;male&#x27;,&#x27;football&#x27;], [&#x27;Jenny&#x27;,&#x27;16&#x27;,&#x27;female&#x27;,&#x27;badminton&#x27;]])</span><br><span class=\"line\">\t</span><br></pre></td></tr></table></figure>\n<p>注意这里writerows传入的是一个二维列表，包含了两层方括号。</p>\n<h3 id=\"DictWriter-以字典形式写入\"><a href=\"#DictWriter-以字典形式写入\" class=\"headerlink\" title=\"DictWriter 以字典形式写入\"></a>DictWriter 以字典形式写入</h3><p>python的csv库也提供了直接将字典写入CSV的函数：DictWriter()。还是上面的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import csv</span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;data.csv&#x27;, &#x27;w&#x27;, newline=&#x27;&#x27;) as file:</span><br><span class=\"line\">\tfileheader = [&#x27;name&#x27;,&#x27;age&#x27;,&#x27;gender&#x27;,&#x27;hobit&#x27;]</span><br><span class=\"line\">\twriter = csv.DictWriter(file, fileheader)</span><br><span class=\"line\">\twriter.writeheader()</span><br><span class=\"line\">\twriter.writerow(&#123;&#x27;name&#x27;:&#x27;James&#x27;,&#x27;age&#x27;:&#x27;25&#x27;,&#x27;gender&#x27;:&#x27;male&#x27;,&#x27;hobit&#x27;:&#x27;basketball&#x27;&#125;)</span><br><span class=\"line\">\twriter.writerow(&#123;&#x27;name&#x27;:&#x27;Louis&#x27;,&#x27;age&#x27;:&#x27;13&#x27;,&#x27;gender&#x27;:&#x27;male&#x27;,&#x27;hobit&#x27;:&#x27;football&#x27;&#125;)</span><br><span class=\"line\">\twriter.writerow(&#123;&#x27;name&#x27;:&#x27;Jenny&#x27;,&#x27;age&#x27;:&#x27;16&#x27;,&#x27;gender&#x27;:&#x27;female&#x27;,&#x27;hobit&#x27;:&#x27;badminton&#x27;&#125;)</span><br></pre></td></tr></table></figure>\n<p>最终写入的结果是完全相同的，内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">name,age,gender,hobit</span><br><span class=\"line\">James,25,male,basketball</span><br><span class=\"line\">Louis,13,male,football</span><br><span class=\"line\">Jenny,16,female,badminton</span><br></pre></td></tr></table></figure>\n<h2 id=\"读取CSV格式数据\"><a href=\"#读取CSV格式数据\" class=\"headerlink\" title=\"读取CSV格式数据\"></a>读取CSV格式数据</h2><h3 id=\"一般读取\"><a href=\"#一般读取\" class=\"headerlink\" title=\"一般读取\"></a>一般读取</h3><p>我们同样可以使用csv库来读取CSV文件。比如，我们可以使用如下代码把刚才写入的文件内容读出来：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import csv</span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;data.csv&#x27;, &#x27;r&#x27;) as file:</span><br><span class=\"line\">\treader = csv.reader(file)</span><br><span class=\"line\">\tfor row in reader:</span><br><span class=\"line\">\t\tprint(row)</span><br></pre></td></tr></table></figure>\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;name&#x27;, &#x27;age&#x27;, &#x27;gender&#x27;, &#x27;hobit&#x27;]</span><br><span class=\"line\">[&#x27;James&#x27;, &#x27;25&#x27;, &#x27;male&#x27;, &#x27;basketball&#x27;]</span><br><span class=\"line\">[&#x27;Louis&#x27;, &#x27;13&#x27;, &#x27;male&#x27;, &#x27;football&#x27;]</span><br><span class=\"line\">[&#x27;Jenny&#x27;, &#x27;16&#x27;, &#x27;female&#x27;, &#x27;badminton&#x27;]</span><br></pre></td></tr></table></figure>\n<h3 id=\"DictReader-以字典形式读取\"><a href=\"#DictReader-以字典形式读取\" class=\"headerlink\" title=\"DictReader 以字典形式读取\"></a>DictReader 以字典形式读取</h3><p>跟上面的DictWriter()函数类似，我们也可以使用DictReader()函数将CSV文件中的数据以字典形式读取出来。具体代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import csv</span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;data.csv&#x27;,&#x27;r&#x27;) as file:</span><br><span class=\"line\">\treader = csv.DictReader(file)</span><br><span class=\"line\">\tfor row in reader:</span><br><span class=\"line\">\t\tprint(row)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>输出结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;&#x27;name&#x27;: &#x27;James&#x27;, &#x27;age&#x27;: &#x27;25&#x27;, &#x27;gender&#x27;: &#x27;male&#x27;, &#x27;hobit&#x27;: &#x27;basketball&#x27;&#125;</span><br><span class=\"line\">&#123;&#x27;name&#x27;: &#x27;Louis&#x27;, &#x27;age&#x27;: &#x27;13&#x27;, &#x27;gender&#x27;: &#x27;male&#x27;, &#x27;hobit&#x27;: &#x27;football&#x27;&#125;</span><br><span class=\"line\">&#123;&#x27;name&#x27;: &#x27;Jenny&#x27;, &#x27;age&#x27;: &#x27;16&#x27;, &#x27;gender&#x27;: &#x27;female&#x27;, &#x27;hobit&#x27;: &#x27;badminton&#x27;&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"使用pandas库读取\"><a href=\"#使用pandas库读取\" class=\"headerlink\" title=\"使用pandas库读取\"></a>使用pandas库读取</h3><p>另外，我们还可以使用pandas库中的read_csv()方法来更加简单的读取CSV文件中的内容。还是上面的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import pandas as pd</span><br><span class=\"line\"></span><br><span class=\"line\">df = pd.read_csv(&#x27;data.csv&#x27;)</span><br><span class=\"line\">print(df)</span><br></pre></td></tr></table></figure>\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">    name  age  gender       hobit</span><br><span class=\"line\">0  James   25    male  basketball</span><br><span class=\"line\">1  Louis   13    male    football</span><br><span class=\"line\">2  Jenny   16  female   badminton</span><br></pre></td></tr></table></figure>\n","categories":["技术杂谈","Python"],"tags":["计算机","Python","编程","数据读写","教程"]},{"title":"Machine Learning-学习笔记-09-Neural Networks:Representation","url":"/2022/08/20/Machine%20Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-9/","content":"<p>这篇文章跟大家分享一下Machine Learning的学习笔记: 09-神经网络：表述(Neural Networks: Representation)。</p>\n<span id=\"more\"></span>\n\n<h1 id=\"非线性假设\"><a href=\"#非线性假设\" class=\"headerlink\" title=\"非线性假设\"></a>非线性假设</h1><p>我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。</p>\n<p>在特征值相对较少时，使用非线性的多项式项，能够帮助我们建立很好的分类模型。假设我们有非常多的特征（比如大于100个变量），我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合，我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。</p>\n<p>同样，在识别图像的训练模型中，由于每一个像素都是一个特征值，即使50x50的像素的小图片都会有 2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约产生至少300万个特征(\\(2500^2&#x2F;2\\))。很显然，普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们需要神经网络。</p>\n<h1 id=\"模型表示\"><a href=\"#模型表示\" class=\"headerlink\" title=\"模型表示\"></a>模型表示</h1><p>神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，activation unit）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数又可被成为权重（weight）。</p>\n<p><img src=\"/../images/neuralNetwork_1.png\" alt=\"neuralNetworks_1\"></p>\n<p>我们设计出了类似于神经元的神经网络，效果如下：</p>\n<p><img src=\"/../images/neuralNetwork_2.png\" alt=\"neuralNetworks_2\"></p>\n<p>其中\\(x_1,x_2,x_3\\) 是输入单元（input units），我们将原始数据输入给它们。\\(a_1,a_2,a_3\\) 是中间单元，它们负责将数据进行处理，然后呈递到下一层。 最后是输出单元，它负责计算\\(h_\\theta(x)\\)。</p>\n<p>下面引入一些标记法来帮助描述模型：</p>\n<p><strong>\\(a_i^{(j)}\\) : 代表第j层的第i个激活单元</strong></p>\n<p><strong>\\(\\theta^{(j)}\\) : 代表从第j层映射到第j+1层时的权重的矩阵</strong></p>\n<ul>\n<li>例如\\(\\theta^{(1)}\\)代表从第一层映射到第二层的权重的矩阵</li>\n<li>矩阵维度为：以第j+1层的激活单元数量为行数，以第j层的激活单元数加一为列数</li>\n</ul>\n<p>对于上图所示的模型，激活单元和输出分别表达为：</p>\n<p>$$<br>a_1^{(2)} &#x3D; g(\\theta_{10}^{(1)}x_0+\\theta_{11}^{(1)}x_1+\\theta_{12}^{(1)}x_2+\\theta_{13}^{(1)}x_3)<br>$$<br>$$<br>a_2^{(2)} &#x3D; g(\\theta_{20}^{(1)}x_0+\\theta_{21}^{(1)}x_1+\\theta_{22}^{(1)}x_2+\\theta_{23}^{(1)}x_3)<br>$$<br>$$<br>a_3^{(2)} &#x3D; g(\\theta_{30}^{(1)}x_0+\\theta_{31}^{(1)}x_1+\\theta_{32}^{(1)}x_2+\\theta_{33}^{(1)}x_3)<br>$$<br>$$<br>h_\\theta(x)&#x3D;a_1^{(3)}&#x3D;g(\\theta_{10}^{(2)}a_0^{(2)}+\\theta_{11}^{(2)}a_1^{(2)}+\\theta_{12}^{(2)}a_2^{(2)}+\\theta_{13}^{(2)}a_3^{(2)})<br>$$</p>\n<p>我们可以知道：每一个\\(a\\)都是由上一层所有的\\(x\\)和每一个\\(x\\)所对应的\\(\\theta\\)决定的。我们把这样从左到右的算法称为前向传播算法(FORWARD PROPAGATION)。</p>\n<p>上面的公式可以简化为：<br>$$<br>a^{(2)}&#x3D;g(z^{(2)})<br>$$<br>其中，\\(z^{(2)}&#x3D;\\theta*X\\)。</p>\n<p>我们可以继续使用同样的方法计算下一层的值：<br>$$<br>h_\\theta(x)&#x3D;a^{(3)}&#x3D;g(z^{(3)})<br>$$<br>其中，\\(z^{(3)}&#x3D;\\theta^{(2)}*a^{(2)}\\)。</p>\n<h1 id=\"实例和直观理解\"><a href=\"#实例和直观理解\" class=\"headerlink\" title=\"实例和直观理解\"></a>实例和直观理解</h1><p>神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与(AND)、逻辑或(OR)。</p>\n<p>我们可以使用下面的神经网络来表示逻辑与（AND）。</p>\n<p><img src=\"/../images/neuralNetwork_3.png\" alt=\"neuralNetworks_3\"></p>\n<p>我们设置权重为（-30,20,20），输出函数\\(h_\\theta(x)&#x3D;g(-30+20x_1+20x_2)\\)。我们知道g(x)的图像为：</p>\n<p><img src=\"/..%5Cimages%5CSigmoidFunction.svg\" alt=\"Sigmoid\"></p>\n<p>所以当我们将\\(x_1\\)和\\(x_2\\)分别设置为0和1时，会得到如下结果：</p>\n<p><img src=\"/../images/neuralNetwork_4.png\" alt=\"neuralNetworks_4\"></p>\n<p>我们发现只有当\\(x_1\\)和\\(x_2\\)同时为1时，我们的输出结果才为1，也就是AND的逻辑运算。</p>\n<p>逻辑或（OR）跟上面的AND类似，只是权重设置不同（三个权重分别设置为-10,20,20）。</p>\n<p><img src=\"/../images/neuralNetwork_5.png\" alt=\"neuralNetworks_5\"></p>\n<p>下面的神经元（权重分别设置为10,-20）可以被视为等同于逻辑非（NOT):</p>\n<p><img src=\"/../images/neuralNetwork_6.png\" alt=\"neuralNetworks_6\"></p>\n<p>我们可以利用神经元来组合成更为复杂的神经网络以实现更复杂的运算。例如我们要实现XNOR功能（输入的两个值必须一样，均为1或均为0），即\\(XNOR&#x3D;(x_1\\ AND\\ x_2)OR((NOT\\ x_1)AND(NOT\\ x_2))\\)。</p>\n<p>首先构造一个能表达\\((NOT\\ x_1)AND(NOT\\ x_2)\\)部分的神经元：</p>\n<p><img src=\"/../images/neuralNetwork_7.png\" alt=\"neuralNetworks_7\"></p>\n<p>然后将表示\\(x_1\\ AND\\ x_2\\)的神经元和表示\\((NOT\\ x_1)AND(NOT\\ x_2)\\)的神经元，以及表示\\(OR\\)的神经元相组合：</p>\n<p><img src=\"/../images/neuralNetwork_8.png\" alt=\"neuralNetworks_8\"></p>\n<p>我们就得到了一个能实现XNOR运算符功能的神经网络。</p>\n<h1 id=\"多类分类\"><a href=\"#多类分类\" class=\"headerlink\" title=\"多类分类\"></a>多类分类</h1><p>当我们有不止两种分类时（也就是y&#x3D;1,2,3…），比如以下这种情况，该怎么办？</p>\n<p>如果我们要训练一个神经网络算法来识别路人、汽车、摩托车和卡车，在输出层我们应该有4个值。例如，第一个值为1或0用于预测是否是行人，第二个值用于判断是否为汽车。</p>\n<p>下面是该神经网络的可能结构示例：</p>\n<p><img src=\"/../images/neuralNetwork_9.png\" alt=\"neuralNetworks_9\"></p>\n<p>神经网络算法的输出结果为四种可能情形之一：</p>\n<p><img src=\"/../images/neuralNetwork_10.png\" alt=\"neuralNetworks_10\"></p>\n","categories":["技术杂谈","Machine Learning"],"tags":["计算机","机器学习","Machine Learning","人工智能"]},{"title":"Python网络爬虫--requests库基本用法","url":"/2022/07/28/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB--requests%E5%BA%93%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/","content":"<p>这篇文章将跟大家分享Python网络爬虫中另一个强大的第三方网页请求库–requests库的一些基本用法。</p>\n<span id=\"more\"></span>\n<hr>\n<p>requests库是对urllib请求库的再次封装，从而使得网络请求变得更加容易。</p>\n<h1 id=\"requests库包含的主要方法\"><a href=\"#requests库包含的主要方法\" class=\"headerlink\" title=\"requests库包含的主要方法\"></a><strong>requests库包含的主要方法</strong></h1><p>requests包含有get(), post(), delete(), head(), requests()等七个方法。但我们平时一般只会用到get()和post()两个主要方法。</p>\n<ul>\n<li><strong>get(<em>url, params&#x3D;{key: value}, args</em>) – 用于发送GET请求到特定的url。</strong></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>url</td>\n<td>Required. The url of the request.</td>\n</tr>\n<tr>\n<td>params</td>\n<td>Optional. A dictionary, list of tuples or bytes to send as a query string.<br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>allow_redirects</td>\n<td>Optional. A Boolean to enable&#x2F;disable redirection. <br>Default <em>True</em> (allowing redirects)</td>\n</tr>\n<tr>\n<td>auth</td>\n<td>Optional. A tuple to enable a certain HTTP authentication. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>cert</td>\n<td>Optional. A String or Tuple specifying a cert file or key. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>cookies</td>\n<td>Optional. A dictionary of cookies to send to the specified url. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>headers</td>\n<td>Optional. A dictionary of HTTP headers to send to the specified url. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>proxies</td>\n<td>Optional. A dictionary of the protocol to the proxy url. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>stream</td>\n<td>Optional. A Boolean indication if the response should be immediately downloaded (False) or streamed (True). <br>Default <em>False</em></td>\n</tr>\n<tr>\n<td>timeout</td>\n<td>Optional. A number, or a tuple, indicating how many seconds to wait for the client to make a connection and&#x2F;or send a response. <br>Default <em>None</em> which means the request will continue until the connection is closed</td>\n</tr>\n<tr>\n<td>verify</td>\n<td>Optional. A Boolean or a String indication to verify the servers TLS certificate or not. <br>Default <em>True</em></td>\n</tr>\n</tbody></table>\n<ul>\n<li><strong>post(<em>url,data&#x3D;{key: value},json&#x3D;{key: value},args</em>) – 用于发送POST请求到特定的url。</strong></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>url</td>\n<td>Required. The url of the request</td>\n</tr>\n<tr>\n<td>data</td>\n<td>Optional. A dictionary, list of tuples, bytes or a file object to send to the specified url</td>\n</tr>\n<tr>\n<td>json</td>\n<td>Optional. A JSON object to send to the specified url</td>\n</tr>\n<tr>\n<td>files</td>\n<td>Optional. A dictionary of files to send to the specified url</td>\n</tr>\n<tr>\n<td>allow_redirects</td>\n<td>Optional. A Boolean to enable&#x2F;disable redirection. <br>Default <em>True</em> (allowing redirects)</td>\n</tr>\n<tr>\n<td>auth</td>\n<td>Optional. A tuple to enable a certain HTTP authentication. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>cert</td>\n<td>Optional. A String or Tuple specifying a cert file or key. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>cookies</td>\n<td>Optional. A dictionary of cookies to send to the specified url. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>headers</td>\n<td>Optional. A dictionary of HTTP headers to send to the specified url. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>proxies</td>\n<td>Optional. A dictionary of the protocol to the proxy url. <br>Default <em>None</em></td>\n</tr>\n<tr>\n<td>stream</td>\n<td>Optional. A Boolean indication if the response should be immediately downloaded (False) or streamed (True). <br>Default <em>False</em></td>\n</tr>\n<tr>\n<td>timeout</td>\n<td>Optional. A number, or a tuple, indicating how many seconds to wait for the client to make a connection and&#x2F;or send a response. <br>Default <em>None</em> which means the request will continue until the connection is closed</td>\n</tr>\n<tr>\n<td>verify</td>\n<td>Optional. A Boolean or a String indication to verify the servers TLS certificate or not. <br>Default <em>True</em></td>\n</tr>\n</tbody></table>\n<h1 id=\"基本GET请求\"><a href=\"#基本GET请求\" class=\"headerlink\" title=\"基本GET请求\"></a><strong>基本GET请求</strong></h1><p>网页请求中最常见的就是GET请求，下面我们来了解下怎么使用requests来发起网络请求吧。下面的例子，我们通过requests的get()方法来完成对请求<a href=\"http://www.google.com/\">www.google.com</a> 网页的请求。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">req = requests.get(&#x27;https://www.google.com&#x27;)</span><br><span class=\"line\">print(req.text)</span><br></pre></td></tr></table></figure>\n<p>如果我们想要传入参数，应该怎么办呢？比如我们现在想要添加参数q它的值为python，应该如下表示：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">data = &#123;</span><br><span class=\"line\">\t&#x27;p&#x27;:&#x27;python&#x27;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">req = requests.get(&#x27;https://www.google.com/search&#x27;,params=data)</span><br><span class=\"line\">print(req.text)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"添加headers\"><a href=\"#添加headers\" class=\"headerlink\" title=\"添加headers\"></a><strong>添加headers</strong></h1><p>因为很多网站都添加了反爬机制，如果我们传递header来模仿浏览器来登录，请求就会遭到拒绝。比如上面的例子中，如果我们把<a href=\"http://www.google.com/\">www.google.com</a> 换为 <a href=\"http://www.zhihu.com/\">www.zhihu.com</a> 或者 <a href=\"http://www.movie.douban.com/\">www.movie.douban.com</a> 都会遭到拒绝。下面我们一起通过来看下面的例子来了解一下如何添加header，从而解决此类问题吧。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">headers = &#123;&#x27;Accept&#x27;: &#x27;text/html, application/xhtml+xml, image/jxr, */*&#x27;,</span><br><span class=\"line\">               &#x27;Accept - Encoding&#x27;:&#x27;gzip, deflate&#x27;,</span><br><span class=\"line\">               &#x27;Accept-Language&#x27;:&#x27;zh-Hans-CN, zh-Hans; q=0.5&#x27;,</span><br><span class=\"line\">               &#x27;Connection&#x27;:&#x27;Keep-Alive&#x27;,</span><br><span class=\"line\">               &#x27;User-Agent&#x27;:&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 Edge/15.15063&#x27;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">url = &#x27;https://www.zhihu.com&#x27;</span><br><span class=\"line\">req = requests.get(url = url, headers = headers)</span><br><span class=\"line\">print(req.text)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"抓取网页\"><a href=\"#抓取网页\" class=\"headerlink\" title=\"抓取网页\"></a>抓取网页</h1><p>下面我们来以抓取某瓣的电影排行榜来演示下怎么抓取网页内容。首先,我们将网页的html格式输出出来,然后方便我们进一步来查看我们所需要找的电影名的规律。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">headers = &#123;&#x27;Accept&#x27;: &#x27;text/html, application/xhtml+xml, image/jxr, */*&#x27;,</span><br><span class=\"line\">               &#x27;Accept - Encoding&#x27;:&#x27;gzip, deflate&#x27;,</span><br><span class=\"line\">               &#x27;Accept-Language&#x27;:&#x27;zh-Hans-CN, zh-Hans; q=0.5&#x27;,</span><br><span class=\"line\">               &#x27;Connection&#x27;:&#x27;Keep-Alive&#x27;,</span><br><span class=\"line\">               &#x27;User-Agent&#x27;:&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 Edge/15.15063&#x27;,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">url = &#x27;https://movie.douban.com/top250&#x27;</span><br><span class=\"line\">req = requests.get(url = url, headers = headers)</span><br><span class=\"line\">print(req.text)</span><br></pre></td></tr></table></figure>\n<p>html格式输出之后，我们截取一部分内容如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;li&gt;</span><br><span class=\"line\">    &lt;div class=&quot;item&quot;&gt;</span><br><span class=\"line\">        &lt;div class=&quot;pic&quot;&gt;</span><br><span class=\"line\">            &lt;em class=&quot;&quot;&gt;1&lt;/em&gt;</span><br><span class=\"line\">            &lt;a href=&quot;https://movie.douban.com/subject/1292052/&quot;&gt;</span><br><span class=\"line\">                &lt;img width=&quot;100&quot; alt=&quot;肖申克的救赎&quot; src=&quot;https://img9.doubanio.com/view/photo/s_ratio_poster/public/p480747492.jpg&quot; class=&quot;&quot;&gt;</span><br><span class=\"line\">            &lt;/a&gt;</span><br><span class=\"line\">        &lt;/div&gt;</span><br><span class=\"line\">        &lt;div class=&quot;info&quot;&gt;</span><br><span class=\"line\">            &lt;div class=&quot;hd&quot;&gt;</span><br><span class=\"line\">                &lt;a href=&quot;https://movie.douban.com/subject/1292052/&quot; class=&quot;&quot;&gt;</span><br><span class=\"line\">                    &lt;span class=&quot;title&quot;&gt;肖申克的救赎&lt;/span&gt;</span><br><span class=\"line\">                            &lt;span class=&quot;title&quot;&gt;&amp;nbsp;/&amp;nbsp;The Shawshank Redemption&lt;/span&gt;</span><br><span class=\"line\">                        &lt;span class=&quot;other&quot;&gt;&amp;nbsp;/&amp;nbsp;月黑高飞(港)  /  刺激1995(台)&lt;/span&gt;</span><br><span class=\"line\">                &lt;/a&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">                    &lt;span class=&quot;playable&quot;&gt;[可播放]&lt;/span&gt;</span><br><span class=\"line\">            &lt;/div&gt;</span><br><span class=\"line\">            &lt;div class=&quot;bd&quot;&gt;</span><br><span class=\"line\">                &lt;p class=&quot;&quot;&gt;</span><br><span class=\"line\">                    导演: 弗兰克·德拉邦特 Frank Darabont&amp;nbsp;&amp;nbsp;&amp;nbsp;主演: 蒂姆·罗宾斯 Tim Robbins /...&lt;br&gt;</span><br><span class=\"line\">                    1994&amp;nbsp;/&amp;nbsp;美国&amp;nbsp;/&amp;nbsp;犯罪 剧情</span><br><span class=\"line\">                &lt;/p&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">                </span><br><span class=\"line\">                &lt;div class=&quot;star&quot;&gt;</span><br><span class=\"line\">                        &lt;span class=&quot;rating5-t&quot;&gt;&lt;/span&gt;</span><br><span class=\"line\">                        &lt;span class=&quot;rating_num&quot; property=&quot;v:average&quot;&gt;9.7&lt;/span&gt;</span><br><span class=\"line\">                        &lt;span property=&quot;v:best&quot; content=&quot;10.0&quot;&gt;&lt;/span&gt;</span><br><span class=\"line\">                        &lt;span&gt;2661267人评价&lt;/span&gt;</span><br><span class=\"line\">                &lt;/div&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">                    &lt;p class=&quot;quote&quot;&gt;</span><br><span class=\"line\">                        &lt;span class=&quot;inq&quot;&gt;希望让人自由。&lt;/span&gt;</span><br><span class=\"line\">                    &lt;/p&gt;</span><br><span class=\"line\">            &lt;/div&gt;</span><br><span class=\"line\">        &lt;/div&gt;</span><br><span class=\"line\">    &lt;/div&gt;</span><br><span class=\"line\">&lt;/li&gt;</span><br><span class=\"line\">&lt;li&gt;</span><br></pre></td></tr></table></figure>\n<p>我们会发现电影名位于&lt;li&gt; –&gt; &lt;div class&#x3D;”info”&gt; –&gt; &lt;span class&#x3D;”title”&gt;肖申克的救赎&lt;&#x2F;span&gt;这里面。然后，我们就可以利用正则表达式来筛选出所有的电影名。正则表达式的具体用法可以参照如下资料：</p>\n<p><a href=\"https://cuiqingcai.com/977.html\">Python 爬虫入门七之正则表达式</a></p>\n<p><a href=\"https://www.runoob.com/regexp/regexp-syntax.html\">正则表达式 - 语法</a></p>\n<p>另外，因为每个网页只能存放10个电影，我们就需要做一个循环来提取所有的相关网页，具体代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\">import re</span><br><span class=\"line\"></span><br><span class=\"line\">headers = &#123;&#x27;Accept&#x27;: &#x27;text/html, application/xhtml+xml, image/jxr, */*&#x27;,</span><br><span class=\"line\">               &#x27;Accept - Encoding&#x27;:&#x27;gzip, deflate&#x27;,</span><br><span class=\"line\">               &#x27;Accept-Language&#x27;:&#x27;zh-Hans-CN, zh-Hans; q=0.5&#x27;,</span><br><span class=\"line\">               &#x27;Connection&#x27;:&#x27;Keep-Alive&#x27;,</span><br><span class=\"line\">               &#x27;User-Agent&#x27;:&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 Edge/15.15063&#x27;,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">base_url = &#x27;https://movie.douban.com/top250?&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\">results = []</span><br><span class=\"line\">for i in range(0,9):</span><br><span class=\"line\">    param = &#123;</span><br><span class=\"line\">        &#x27;start&#x27;:str(i*25)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    req = requests.get(url = base_url, params = param, headers = headers)</span><br><span class=\"line\">    result = re.findall(&#x27;&lt;li&gt;.*?info.*?title&quot;&gt;(.*?)&lt;/span&gt;&#x27;,req.text,re.S)</span><br><span class=\"line\">    results = results + result</span><br><span class=\"line\">print(results)</span><br></pre></td></tr></table></figure>\n\n<p>运行之后，我们应该就会发现某瓣评分前250的电影名称被成功抓取了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;肖申克的救赎&#x27;, &#x27;霸王别姬&#x27;, &#x27;阿甘正传&#x27;, &#x27;泰坦尼克号&#x27;, &#x27;这个杀手不太冷&#x27;, &#x27;美丽人生&#x27;, &#x27;千与千寻&#x27;, &#x27;辛德勒的名单&#x27;, &#x27;盗梦空间&#x27;, &#x27;星际穿越&#x27;, &#x27;忠犬八公的故事&#x27;, &#x27;楚门的世界&#x27;, &#x27;海上钢琴师&#x27;, &#x27;三傻大闹宝莱坞&#x27;, &#x27;机器人总动员&#x27;, &#x27;放牛班的春天&#x27;, &#x27;无间道&#x27;, &#x27;疯狂动物城&#x27;, &#x27;大话西游之大圣娶亲&#x27;, &#x27;熔炉&#x27;, &#x27;控方证人&#x27;, &#x27;教父&#x27;, &#x27;当幸福来敲门&#x27;, &#x27;触不可及&#x27;, &#x27;怦然心动&#x27;, &#x27;龙猫&#x27;, &#x27;末代皇帝&#x27;, &#x27;寻梦环游记&#x27;, &#x27;蝙蝠侠：黑暗骑士&#x27;, &#x27;活着&#x27;, &#x27;哈利·波特与魔法石&#x27;, &#x27;指环王3：王者无敌&#x27;, &#x27;乱世佳人&#x27;, &#x27;素媛&#x27;, &#x27;飞屋环游记&#x27;, &#x27;我不是药神&#x27;, &#x27;摔跤吧！爸爸&#x27;, </span><br><span class=\"line\">&#x27;何以为家&#x27;, &#x27;十二怒汉&#x27;, &#x27;哈尔的移动城堡&#x27;, &#x27;少年派的奇幻漂流&#x27;, &#x27;鬼子来了&#x27;, &#x27;猫鼠游戏&#x27;, &#x27;大话西游之月光宝盒&#x27;, &#x27;天空之城&#x27;, &#x27;让子弹飞&#x27;, &#x27;钢琴家&#x27;, &#x27;闻香识女人&#x27;, &#x27;指环王2：双塔奇兵&#x27;, &#x27;天堂电影院&#x27;, &#x27;海蒂和爷爷&#x27;, &#x27;罗马假日&#x27;, &#x27;黑客帝国&#x27;, &#x27;指环王1：护戒使者&#x27;, &#x27;大闹天宫&#x27;, &#x27;死亡诗社&#x27;, &#x27;教父2&#x27;, &#x27;绿皮书&#x27;, &#x27;辩护人&#x27;, &#x27;狮子王&#x27;, &#x27;搏击俱乐部&#x27;, &#x27;饮食男女&#x27;, &#x27;美丽心灵&#x27;, &#x27;本杰明·巴顿奇事&#x27;, &#x27;窃听风暴&#x27;, &#x27;穿条纹睡衣的男孩&#x27;, &#x27;情书&#x27;, &#x27;两杆大烟枪&#x27;, &#x27;西西里的美丽传说&#x27;, &#x27;看不见的客人&#x27;, &#x27;音乐之声&#x27;, &#x27;拯救大兵瑞恩&#x27;, &#x27;飞越疯人院&#x27;, &#x27;小鞋子&#x27;, </span><br><span class=\"line\">&#x27;阿凡达&#x27;, &#x27;哈利·波特与死亡圣器(下)&#x27;, &#x27;沉默的羔羊&#x27;, &#x27;致命魔术&#x27;, &#x27;海豚湾&#x27;, &#x27;禁闭岛&#x27;, &#x27;布达佩斯大饭店&#x27;, &#x27;蝴蝶效应&#x27;, &#x27;美国往事&#x27;, &#x27;心灵捕手&#x27;, &#x27;低俗小说&#x27;, &#x27;春光乍泄&#x27;, &#x27;摩登时代&#x27;, &#x27;喜剧之王&#x27;, &#x27;七宗罪&#x27;, &#x27;功夫&#x27;, &#x27;致命ID&#x27;, &#x27;超脱&#x27;, &#x27;哈利·波特与阿兹卡班的囚徒&#x27;, &#x27;杀人回忆&#x27;, &#x27;加勒比海盗&#x27;, &#x27;红辣椒&#x27;, &#x27;被嫌弃的松子的一生&#x27;, &#x27;狩猎&#x27;, &#x27;请以你的名字呼唤我&#x27;, &#x27;7号房的礼物&#x27;, &#x27;剪刀手爱德华&#x27;, &#x27;断背山&#x27;, &#x27;勇敢的心&#x27;, &#x27;唐伯虎点秋香&#x27;, &#x27;入殓师&#x27;, &#x27;一一&#x27;, &#x27;哈利·波特与密室&#x27;, &#x27;第六感&#x27;, &#x27;爱在黎明破晓前&#x27;, &#x27;重庆森林&#x27;, &#x27;天使爱美丽&#x27;, &#x27;蝙蝠侠：黑暗骑士崛起&#x27;, </span><br><span class=\"line\">&#x27;幽灵公主&#x27;, &#x27;小森林 夏秋篇&#x27;, &#x27;菊次郎的夏天&#x27;, &#x27;阳光灿烂的日子&#x27;, &#x27;超能陆战队&#x27;, &#x27;完美的世界&#x27;, &#x27;无人知晓&#x27;, &#x27;爱在日落黄昏时&#x27;, &#x27;消失的爱人&#x27;, &#x27;借东西的小人阿莉埃蒂&#x27;, &#x27;甜蜜蜜&#x27;, &#x27;小森林 冬春篇&#x27;, &#x27;倩女幽魂&#x27;, &#x27;侧耳倾听&#x27;, &#x27;时空恋旅人&#x27;, &#x27;幸福终点站&#x27;, &#x27;驯龙高手&#x27;, &#x27;萤火之森&#x27;, &#x27;怪兽电力公司&#x27;, &#x27;玛丽和马克思&#x27;, &#x27;教父3&#x27;, &#x27;一个叫欧维的男人决定去死&#x27;, &#x27;寄生虫&#x27;, &#x27;玩具总动员3&#x27;, &#x27;大鱼&#x27;, &#x27;傲慢与偏见&#x27;, &#x27;告白&#x27;, &#x27;神偷奶爸&#x27;, &#x27;未麻的部屋&#x27;, &#x27;釜山行&#x27;, &#x27;被解救的姜戈&#x27;, &#x27;阳光姐妹淘&#x27;, &#x27;射雕英雄传之东成西就&#x27;, &#x27;哈利·波特与火焰杯&#x27;, &#x27;哪吒闹海&#x27;, &#x27;恐怖直播&#x27;, &#x27;我是山姆&#x27;, </span><br><span class=\"line\">&#x27;头号玩家&#x27;, &#x27;血战钢锯岭&#x27;, &#x27;新世界&#x27;, &#x27;模仿游戏&#x27;, &#x27;喜宴&#x27;, &#x27;七武士&#x27;, &#x27;花样年华&#x27;, &#x27;黑客帝国3：矩阵革命&#x27;, &#x27;头脑特工队&#x27;, &#x27;电锯惊魂&#x27;, &#x27;三块广告牌&#x27;, &#x27;达拉斯买家俱乐部&#x27;, &#x27;卢旺达饭店&#x27;, &#x27;你的名字。&#x27;, &#x27;九品芝麻官&#x27;, &#x27;疯狂原始人&#x27;, &#x27;上帝之城&#x27;, &#x27;谍影重重3&#x27;, &#x27;惊魂记&#x27;, &#x27;风之谷&#x27;, &#x27;心迷宫&#x27;, &#x27;英雄本色&#x27;, &#x27;纵横四海&#x27;, &#x27;海街日记&#x27;, &#x27;岁月神偷&#x27;, &#x27;记忆碎片&#x27;, &#x27;忠犬八公物语&#x27;, &#x27;爱在午夜降临前&#x27;, &#x27;荒蛮故事&#x27;, &#x27;绿里奇迹&#x27;, &#x27;色，戒&#x27;, &#x27;爆裂鼓手&#x27;, &#x27;小偷家族&#x27;, &#x27;贫民窟的百万富翁&#x27;, &#x27;无敌破坏王&#x27;, &#x27;东邪西毒&#x27;, &#x27;真爱至上&#x27;, &#x27;疯狂的石头&#x27;, &#x27;茶馆&#x27;, &#x27;冰川时代&#x27;, &#x27;雨中曲&#x27;, </span><br><span class=\"line\">&#x27;你看起来好像很好吃&#x27;, &#x27;恐怖游轮&#x27;, &#x27;黑天鹅&#x27;, &#x27;2001太空漫游&#x27;, &#x27;魔女宅急便&#x27;, &#x27;雨人&#x27;, &#x27;恋恋笔记本&#x27;, &#x27;遗愿清单&#x27;, &#x27;无间道2&#x27;, &#x27;牯岭街少年杀人事件&#x27;, &#x27;大佛普拉斯&#x27;, &#x27;可可西里&#x27;, &#x27;城市之光&#x27;, &#x27;背靠背，脸对脸&#x27;, &#x27;萤火虫之墓&#x27;, &#x27;小丑&#x27;, &#x27;源代码&#x27;, &#x27;东京教父&#x27;, &#x27;虎口脱险&#x27;, &#x27;初恋这件小事&#x27;, &#x27;人工智能&#x27;, &#x27;海边的曼彻斯特&#x27;, &#x27;罗生门&#x27;, &#x27;终结者2：审判日&#x27;, &#x27;青蛇&#x27;, &#x27;波西米亚狂想曲&#x27;, &#x27;二十二&#x27;, &#x27;奇迹男孩&#x27;, &#x27;疯狂的麦克斯4：狂暴之路&#x27;, &#x27;新龙门客栈&#x27;, &#x27;房间&#x27;, &#x27;心灵奇旅&#x27;, &#x27;无耻混蛋&#x27;, &#x27;血钻&#x27;, &#x27;千钧一发&#x27;]</span><br></pre></td></tr></table></figure>\n<h1 id=\"抓取图片\"><a href=\"#抓取图片\" class=\"headerlink\" title=\"抓取图片\"></a><strong>抓取图片</strong></h1><p>上面的例子中，我们抓取的是相关文字。当遇到图片、音频、以及影视资料的时候，我们又应该如何抓取呢？还是以某瓣为例，如果我们想要抓取电影的相关图片，首先要提取图片对应的二进制码。我们首先找到其中一个图片对应的url地址，然后利用Response的content属性就可以将图片的二进制码输出出来。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">img_url = &#x27;https://img9.doubanio.com/view/photo/s_ratio_poster/public/p480747492.jpg&#x27;</span><br><span class=\"line\">res = requests.get(img_url)</span><br><span class=\"line\">print(res.content)</span><br></pre></td></tr></table></figure>\n<p>接下来我们将图片保存下来：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">img_url = &#x27;https://img9.doubanio.com/view/photo/s_ratio_poster/public/p480747492.jpg&#x27;</span><br><span class=\"line\">res = requests.get(img_url)</span><br><span class=\"line\">with open(&#x27;Shawshank_Redemption.jpg&#x27;, &#x27;wb&#x27;) as f:</span><br><span class=\"line\">    f.write(res.content)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"POST请求\"><a href=\"#POST请求\" class=\"headerlink\" title=\"POST请求\"></a><strong>POST请求</strong></h1><p>requests库最常用两个方法是GET()和POST()，前面我们已经了解了GET()的请求方式，接下来我们再来看一下如何使用POST()。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">key_dict = &#123;&#x27;query&#x27;:&#x27;hello&#x27;&#125;</span><br><span class=\"line\">response = requests.post(url = &#x27;http://httpbin.org/post&#x27;, data = key_dict)</span><br><span class=\"line\">print(response.status_code)</span><br><span class=\"line\">print(response.text)</span><br></pre></td></tr></table></figure>\n<p>运行之后，其返回结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">200</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;args&quot;: &#123;&#125;, </span><br><span class=\"line\">  &quot;data&quot;: &quot;&quot;, </span><br><span class=\"line\">  &quot;files&quot;: &#123;&#125;, </span><br><span class=\"line\">  &quot;form&quot;: &#123;</span><br><span class=\"line\">    &quot;query&quot;: &quot;hello&quot;</span><br><span class=\"line\">  &#125;, </span><br><span class=\"line\">  &quot;headers&quot;: &#123;</span><br><span class=\"line\">    &quot;Accept&quot;: &quot;*/*&quot;, </span><br><span class=\"line\">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, </span><br><span class=\"line\">    &quot;Content-Length&quot;: &quot;11&quot;, </span><br><span class=\"line\">    &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, </span><br><span class=\"line\">    &quot;Host&quot;: &quot;httpbin.org&quot;, </span><br><span class=\"line\">    &quot;User-Agent&quot;: &quot;python-requests/2.28.1&quot;, </span><br><span class=\"line\">    &quot;X-Amzn-Trace-Id&quot;: &quot;Root=1-62e47885-6826fed24cbad6c70ff2fcf7&quot;</span><br><span class=\"line\">  &#125;, </span><br><span class=\"line\">  &quot;json&quot;: null, </span><br><span class=\"line\">  &quot;origin&quot;: &quot;24.163.13.126&quot;, </span><br><span class=\"line\">  &quot;url&quot;: &quot;http://httpbin.org/post&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>响应值为200，说明已经成功请求。另外，我们也可以在结果的form一项中也发现已经成功提交{“query”: “hello”}的表单数据。</p>\n","categories":["技术杂谈","Python"],"tags":["Python","编程","网络","爬虫"]},{"title":"Python网络爬虫--requests库进阶","url":"/2022/07/30/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB--requests%E5%BA%93%E8%BF%9B%E9%98%B6/","content":"<p>这篇文章将跟大家分享Python网络爬虫中另一个强大的第三方网页请求库–requests库的一些其他用法。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"Cookies–识别登录\"><a href=\"#Cookies–识别登录\" class=\"headerlink\" title=\"Cookies–识别登录\"></a><strong>Cookies–识别登录</strong></h1><p>Cookie,是网站为了识别用户身份、进行session追踪二存储在用户本地计算机上面的数据。比如，某些网站需要登录才能访问，那么就需要在请求中添加Cookie相关信息才能爬取网站。<br>前面我们使用urllib这个库处理Cookies的时候，需要先生命CookieJar对象。然后利用HTTPCookieProcessor()来构建Handler，最后再利用build_opener()来构建Opener，最后我们才可以用opener的open()函数来完成请求。这样的写法比较复杂，而有了requests这个请求库，我们就可以非常方便的设置Cookies。接下来，我们来看一个例子来说明如何处理Cookies吧。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">r = requests.get(&quot;https://www.google.com&quot;)</span><br><span class=\"line\">print(r.cookies)</span><br><span class=\"line\"></span><br><span class=\"line\">for k,v in r.cookies.items():</span><br><span class=\"line\">    print(k + &#x27;=&#x27; + v)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;RequestsCookieJar[&lt;Cookie 1P_JAR=2022-07-29-00 for .google.com/&gt;, &lt;Cookie AEC=AakniGOkbXuoHM4--93l8g4QiXNnw2nf7S4VxTMHVZzP2DJQNyiV0T6vp4g for .google.com/&gt;, &lt;Cookie NID=511=g1ObAMG2H7aUlRE2wvPCMVXxH8aCwHqjOMJzy7cXdYIZCyvRk3NdNUhic37IydzmXyv0i9S8A02PoI3SflxpoC6Pq3N4CkscuiWAOXgmyUHKNG6Ip-M9t2i-jC0_awX2nvuJ9vtn5-Z4K_GzGYuBGDtvFdx9wgC_kH6sPzE9suc for .google.com/&gt;]&gt;</span><br><span class=\"line\">1P_JAR=2022-07-29-00</span><br><span class=\"line\">AEC=AakniGOkbXuoHM4--93l8g4QiXNnw2nf7S4VxTMHVZzP2DJQNyiV0T6vp4g</span><br><span class=\"line\">NID=511=g1ObAMG2H7aUlRE2wvPCMVXxH8aCwHqjOMJzy7cXdYIZCyvRk3NdNUhic37IydzmXyv0i9S8A02PoI3SflxpoC6Pq3N4CkscuiWAOXgmyUHKNG6Ip-M9t2i-jC0_awX2nvuJ9vtn5-Z4K_GzGYuBGDtvFdx9wgC_kH6sPzE9suc</span><br></pre></td></tr></table></figure>\n<p>当然，我们也可以使用cookie来维持登录状态。比较简单的做法是从浏览器登录账户，然后找到并将Cookie内容复制下来。将其设置到请求的headers里面。这样做的唯一问题是会有一些繁琐。如果有机会的话，我们会专门写一篇文章来分享如何使用程序来自动获取并且使用cookie来模拟登录网站。</p>\n<h1 id=\"Session–会话维持\"><a href=\"#Session–会话维持\" class=\"headerlink\" title=\"Session–会话维持\"></a><strong>Session–会话维持</strong></h1><p>我们一般是通过http协议来访问网页的，而http协议是无法维持会话之间的状态。比如说我们成功登录一个网站之后，去访问这个网站的其他页面的时候，登录状态会消失。所以导致页面刷新后就需要反复重新登录来维持会话，这就会非常繁琐。所以我们需要想办法来维持会话。除了我们上面提到的cookie，我们也可以使用一种更为简洁的方法– session对象来维持登录状态。当使用它来成功登录某个网站之后，该网站的其它网页都会默认使用该session之前使用的cookie等参数。这样，我们就可以方便的维护一个会话，而不用担心cookies的问题。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\">import re</span><br><span class=\"line\"></span><br><span class=\"line\">session = requests.session()</span><br><span class=\"line\">data =&#123;</span><br><span class=\"line\">    &#x27;username&#x27;: &#x27;xxxxxxxx&#x27;,</span><br><span class=\"line\">    &#x27;password&#x27;: &#x27;xxxxxxxx&#x27;, </span><br><span class=\"line\">    &#x27;usecookie&#x27;: &#x27;0&#x27;,</span><br><span class=\"line\">    &#x27;action&#x27;:&#x27;login&#x27;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">url =&quot;https://www.ptwxz.com/login.php&quot;</span><br><span class=\"line\">result = session.post(url,data=data)</span><br><span class=\"line\"># print(result.text)</span><br><span class=\"line\">print(result.cookies)</span><br><span class=\"line\"># 再次请求 拿取书架上的数据</span><br><span class=\"line\">url2 = &quot;https://www.ptwxz.com/modules/article/bookcase.php&quot;</span><br><span class=\"line\">result2 = session.get(url2)</span><br><span class=\"line\">result2.encoding = &#x27;gb2312&#x27;</span><br><span class=\"line\"># print(result2.text)</span><br><span class=\"line\">book = re.findall(&#x27;&lt;table.*?&quot;checkbox&quot;.*?_blank&quot;&gt;(.*?)&lt;/a&gt;&lt;/td&gt;&#x27;,result2.text,re.S)</span><br><span class=\"line\">print(book)</span><br></pre></td></tr></table></figure>\n<p>输出结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;RequestsCookieJar[&lt;Cookie PHPSESSID=1a0627fa5d220f94aa39c668d6a7bb55 for www.ptwxz.com/&gt;, &lt;Cookie jieqiUserInfo=jieqiUserId%3D436281%2CjieqiUserName%3Dshilei165%2CjieqiUserGroup%3D3%2CjieqiUserVip%3D0%2CjieqiUserName_un%3Dshilei165%2CjieqiUserHonor_un%3D%26%23x6597%3B%26%23x8005%3B%2CjieqiUserGroupName_un%3D%26%23x666E%3B%26%23x901A%3B%26%23x4F1A%3B%26%23x5458%3B%2CjieqiUserLogin%3D1659144657 for www.ptwxz.com/&gt;, &lt;Cookie jieqiVisitInfo=jieqiUserLogin%3D1659144657%2CjieqiUserId%3D436281 for www.ptwxz.com/&gt;]&gt;</span><br><span class=\"line\">[&#x27;万相之王&#x27;]</span><br></pre></td></tr></table></figure>\n<p>我们发现书架上的书被成功获取。相信可以理解如何使用session以及session的作用了吧。</p>\n<h1 id=\"Proxies–代理设置\"><a href=\"#Proxies–代理设置\" class=\"headerlink\" title=\"Proxies–代理设置\"></a><strong>Proxies–代理设置</strong></h1><p>对于采取了比较强的反爬措施的网站来说，为了顺利爬取网站数据，我们一般需要使用代理IP来防止我们自己的IP被封禁。这时候就需要使用proxies参数来设置代理。</p>\n<p>代理主要分为HTTP和SOCKS代理两种。其中，HTTP代理能够代理HTTP访问，主要是代理浏览器访问网页，他的端口一般为80, 8080, 3128等。SOCKS代理，只是简单的传递数据包，而并不关心是何种协议。速度上来说，一般SOCKS代理要比HTTP代理快很多。</p>\n<p>我们先看一下不使用代理，来测试下自己的IP：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">url = &#x27;http://icanhazip.com&#x27;</span><br><span class=\"line\">try:</span><br><span class=\"line\">    response = requests.get(url)</span><br><span class=\"line\">    print(response.status_code)</span><br><span class=\"line\">    if response.status_code == 200:</span><br><span class=\"line\">        print(response.text)</span><br><span class=\"line\">except requests.ConnectionError as e:</span><br><span class=\"line\">    print(e.args)</span><br></pre></td></tr></table></figure>\n<p>运行上面的代码，我们就会返回类似如下的结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">200</span><br><span class=\"line\">24.163.xx.xxx</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>然后我们再来测试一下使用代理之后的情况。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">proxies = &#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">  &quot;http&quot;:&quot;http://103.148.178.xxx&quot;,</span><br><span class=\"line\">  &quot;https&quot;: &quot;https://122.9.101.6&quot;,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">url = &#x27;http://icanhazip.com&#x27;</span><br><span class=\"line\">try:</span><br><span class=\"line\">    response = requests.get(url, proxies = proxies)</span><br><span class=\"line\">    print(response.status_code)</span><br><span class=\"line\">    if response.status_code == 200:</span><br><span class=\"line\">        print(response.text)</span><br><span class=\"line\">except requests.ConnectionError as e:</span><br><span class=\"line\">    print(e.args)</span><br></pre></td></tr></table></figure>\n<p>结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">200</span><br><span class=\"line\">103.148.178.xxx</span><br></pre></td></tr></table></figure>\n<p>这时我们就可以发现返回的是我们代理所使用的IP，说明代理起作用了。<br>使用SOCKS代理的方法类似，但我们需要首先安装pysock这个库。安装完成之后我们就可以使用SOCKS代理了，示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">proxies = &#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">  &quot;http&quot;:&quot;socks5://103.148.178.xxx&quot;,</span><br><span class=\"line\">  &quot;https&quot;: &quot;socks5://103.148.178.xxx&quot;,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">url = &#x27;http://icanhazip.com&#x27;</span><br><span class=\"line\">try:</span><br><span class=\"line\">    response = requests.get(url, proxies = proxies)</span><br><span class=\"line\">    print(response.status_code)</span><br><span class=\"line\">    if response.status_code == 200:</span><br><span class=\"line\">        print(response.text)</span><br><span class=\"line\">except requests.ConnectionError as e:</span><br><span class=\"line\">    print(e.args)</span><br></pre></td></tr></table></figure>\n\n<p>在爬取大量数据的时候，往往需要使用多个代理。那我们应该如何构造呢？主要两种方法，一种是使用免费的多个IP，但往往效果不太好，另一种比较靠谱的方法是使用付费的IP代理服务。付费代理在很多网站上都有售卖，比较稳定，大家可以自行选购。</p>\n<p>但是无论是免费的IP还是收费的IP，都不能保证可以稳定使用，因为我们用到的IP很有可能已经被目标站点禁掉，或者代理服务器网络繁忙。所以我们就需要搭建一个代理池来提前将不可用的代理筛选掉。以后如果有机会，我们再给大家分享一下如何搭建代理池。</p>\n","categories":["技术杂谈","Python"],"tags":["Python","编程","网络","爬虫"]},{"title":"Linux学习笔记-3","url":"/2021/01/03/linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3/","content":"<p><strong>这篇文章将会分享关于Linux系统IP，用户管理，以及权限方面的知识。</strong></p>\n<span id=\"more\"></span>\n<h1 id=\"查看IP地址\"><a href=\"#查看IP地址\" class=\"headerlink\" title=\"查看IP地址\"></a><strong>查看IP地址</strong></h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ifconfig</span><br></pre></td></tr></table></figure>\n\n<p>ifconfig命令的英文全称是“network interfaces configuring”，即用于配置和显示Linux内核中网络接口的网络参数。</p>\n<h1 id=\"添加用户\"><a href=\"#添加用户\" class=\"headerlink\" title=\"添加用户\"></a><strong>添加用户</strong></h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo useradd </span><br><span class=\"line\">sudo adduser</span><br></pre></td></tr></table></figure>\n\n<p>useradd是一个linux命令，但是它提供了很多参数在用户使用的时候根据自己的需要进行设置；<br>adduser是一个perl 脚本，在使用的时候会出现类似人机交互的界面，提供选项让用户填写和选择，这个命令比起useradd来说比较简单，也比较傻瓜。</p>\n<p>例如使用useradd添加austin用户应使用如下指令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo useradd austin -m -s /bin/bash -g users</span><br></pre></td></tr></table></figure>\n\n<p>具体代表的意义如下</p>\n<p><strong>-m:</strong> make all the directories; <strong>-s &#x2F;bin&#x2F;bash:</strong> shell; <strong>-g users:</strong> users group</p>\n<p>使用adduser则相对简单，直接使用：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo adduser</span><br></pre></td></tr></table></figure>\n\n<p>然后会出现交互界面，填写相关信息。</p>\n<h1 id=\"登录和退出用户账号\"><a href=\"#登录和退出用户账号\" class=\"headerlink\" title=\"登录和退出用户账号\"></a><strong>登录和退出用户账号</strong></h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">login</span><br><span class=\"line\">logout</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"删除用户\"><a href=\"#删除用户\" class=\"headerlink\" title=\"删除用户\"></a><strong>删除用户</strong></h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo userdel</span><br></pre></td></tr></table></figure>\n\n<p>如果要同时删除用户所创建的所有文件则要用到</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo userdel -r</span><br></pre></td></tr></table></figure>\n\n<p>-r 的意思是recursively。</p>\n<h1 id=\"创建高级用户\"><a href=\"#创建高级用户\" class=\"headerlink\" title=\"创建高级用户\"></a><strong>创建高级用户</strong></h1><p>我用的树莓派，所以系统会自带一个pi的用户，权限非常高。如果想要创建一个同样权限的用户则需要首先创建一个账户，以leilei为例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo adduser leilei</span><br></pre></td></tr></table></figure>\n\n<p>然后输入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo usermod -a -G adm,dialout,cdrom,sudo,audio,video,plugdev,games,users,netdev,input,indiecity leilei</span><br></pre></td></tr></table></figure>\n\n<p>如果出现提示：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">usermod: group &#x27;indiecity&#x27; does not exist</span><br></pre></td></tr></table></figure>\n\n<p>那么将最后的indiecity以及前面的“，”删除即可。</p>\n<p>这时候可以操作其他用户的文件，但每次sudo之后都需要输入密码。如果不希望每次都输入账号密码来通过sudo操作，则可以通过visudo命令修改&#x2F;etc&#x2F;sudoers文件，代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo visudo</span><br></pre></td></tr></table></figure>\n\n<p>在nano编辑框中的最后一行下面加上：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">leilei ALL=(ALL) NOPASSWD: ALL</span><br></pre></td></tr></table></figure>\n\n<p>这时候再次进行sudo操作就不需要再次输入密码了。</p>\n<h1 id=\"查看文件权限\"><a href=\"#查看文件权限\" class=\"headerlink\" title=\"查看文件权限\"></a><strong>查看文件权限</strong></h1><p>输入如下指令就可以查看完整的文件权限信息</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ls -l</span><br></pre></td></tr></table></figure>\n\n<p>然后就会在terminal中出现如下信息</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">total 12</span><br><span class=\"line\">drwxr-xr-x 2 pi pi 4096 Dec  2 07:48 Bookshelf</span><br><span class=\"line\">-rw-r--r-- 1 pi pi    0 Jan  3 16:47 cats.txt</span><br><span class=\"line\">drwxr-xr-x 2 pi pi 4096 Dec  2 08:21 Desktop</span><br><span class=\"line\">-rw-r--r-- 1 pi pi    0 Jan  3 16:47 dogs.txt</span><br><span class=\"line\">drwx------ 2 pi pi 4096 Jan  3 13:08 my_files</span><br></pre></td></tr></table></figure>\n\n<p>以第一个文件夹中文件为例：drwxr-xr-x中一共有十个字符。这十个字符分成四组：第一个字符一组，然后剩下的九个字符每三个为一组。</p>\n<p>第一个字符代表是目录还是文件。“d”代表是directory，也就是目录或者是是文件夹。“-”则代表是文件。</p>\n<p>后面的三组依次代表所有者权限、所在组的权限、以及其他人的权限。其中每一组有三个字符分别是rwx，分别代表可读(read)、可写(write)、可执行(excute)。如果只读的话就会标记为r–，表示只有read权限。</p>\n<h1 id=\"修改文件权限\"><a href=\"#修改文件权限\" class=\"headerlink\" title=\"修改文件权限\"></a><strong>修改文件权限</strong></h1><p>输入如下指令即可修改文件权限 (###代表三个数字，file代表要修改的文件)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">chmod ### file</span><br></pre></td></tr></table></figure>\n\n<p>那么怎么确定这三个要输入的数字呢？r, w, x分别对应的数字如下</p>\n<p><strong>r</strong>: 4; <strong>w</strong>: 2; <strong>x</strong>:1</p>\n<p>然后，每一组的三个数字相加之和即可得到相应组应填的数字。比如，要改变cat.txt文件为所有者可读可写可执行，所在组只可读，其他人没有任何权限，这三个数字应当确定为：7， 4， 0。然后在终端输入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">chmod 740 cat.txt</span><br></pre></td></tr></table></figure>\n\n<p>再次输入ls -l查看权限，就会发现权限的变化。</p>\n<p>如果希望一次性改变所有所属文件夹以及文件的权限则需加上 -r (recursively)来进行操作，比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">chmod 740 -r my_files</span><br></pre></td></tr></table></figure>\n\n<p>则会改变my_files以及所属的所有文件夹及文件的权限。</p>\n<hr>\n","categories":["技术杂谈","Linux"],"tags":["command","Linux","学习笔记","树莓派"]},{"title":"Python网络爬虫--第三方库","url":"/2022/07/20/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB--%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93%E6%80%BB%E7%BB%93/","content":"<p>这篇文章将会分享总结Python网络爬虫所用到的一些常见的第三方库。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"请求库\"><a href=\"#请求库\" class=\"headerlink\" title=\"请求库\"></a><strong>请求库</strong></h1><p>请求库顾名思义是用来对网络资源发出请求，从而获得服务器的相应。</p>\n<ul>\n<li>urllib: urllib是Python自带的原生网络请求库，功能强大，但用起来不如requests方便、友好。</li>\n<li>requests: requrests是对Python内置的urllib的再次封装的请求库。由于它是阻塞式HTTP请求库，当我们发出请求之后，就会一直等待服务器响应，然后才会进行下一步处理。</li>\n<li>aiohttp: 异步Web服务的库，可以在服务器响应过程中处理一些其他的事情，从而提高抓取效率。</li>\n</ul>\n<h1 id=\"解析库\"><a href=\"#解析库\" class=\"headerlink\" title=\"解析库\"></a><strong>解析库</strong></h1><p>解析库顾名思义就是用来解析我们所爬取的网页所用到的工具包。我们常用到的解析库如下：</p>\n<ul>\n<li>lxml：支持HTML和XML的解析，支持XPath解析方式。</li>\n<li>Beautiful Soup：支持HTML和XML的解析，拥有强大的API和多样的解析方式。Beautiful Soup的HTML和XML解析器依赖于lxml库。</li>\n<li>pyquery：同样是一个强大的网页解析工具，提供了jQuery类似的语法来解析HTML，支持CSS选择器。</li>\n<li>tesserocr：tesserocr是Python的一个OCR识别库，可以处理爬取网页过程中遇到的图形验证码。这个库需要预先安装tesseract。</li>\n<li>chaojiying：除了tesserocr之外，我们还可以选择识别度更高但需要付费库chaojiying来进行图片和验证码的识别。</li>\n</ul>\n<h1 id=\"自动化测试工具\"><a href=\"#自动化测试工具\" class=\"headerlink\" title=\"自动化测试工具\"></a><strong>自动化测试工具</strong></h1><ul>\n<li>Selenium： Selenium是一个自动化测试工具，它可以模拟执行特定的浏览器动作，比如点击、下拉等操作。需要配合浏览引擎以及相应的驱动来操作。支持一般市面上见到的大部分浏览器，比如：<ul>\n<li>Chrome，Firefox，IE，Opera，和Safari浏览器，需要下载安装浏览器（例如Chrome）以及相应的驱动（例如ChromeDriver）来进行操作。</li>\n<li>Selenium还支持可脚本编程的PhantomJS浏览引擎来操作。PhantomJS运行效率很高，并且支持配置各种参数。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"数据库\"><a href=\"#数据库\" class=\"headerlink\" title=\"数据库\"></a><strong>数据库</strong></h1><ul>\n<li>MySQL：MySQL是一个轻量级的关系型数据库。</li>\n<li>MongoDB：MongoDB是由C++语言编写的非关系型数据库，基于分布式文件存储的开源数据系统。字段值可以包含文档、数组以及文档数组。</li>\n<li>Redis：Redis是一个基于内存的搞笑的非关系型数据库。</li>\n</ul>\n<h1 id=\"存储库\"><a href=\"#存储库\" class=\"headerlink\" title=\"存储库\"></a><strong>存储库</strong></h1><p>数据库仅仅提供存储数据服务，想要和Python交互，还需要安装Python存储库。</p>\n<ul>\n<li>MySQL需要安装PyMySQL存储库。</li>\n<li>MongoDB需要安装PyMongo存储库。</li>\n<li>Redis需要安装redis-py存储库。</li>\n</ul>\n<h1 id=\"Web库\"><a href=\"#Web库\" class=\"headerlink\" title=\"Web库\"></a><strong>Web库</strong></h1><p>Web服务程序可以用来搭建一些API接口，方便我们爬虫使用。例如，我们可以通过Web服务提供一个API接口来获取代理的IP。</p>\n<ul>\n<li>Flask: 轻量级的Web服务程序，简单、灵活、易用。</li>\n<li>Tornado：支持异步的Web框架，效率非常高。</li>\n</ul>\n<h1 id=\"APP爬取的相关库\"><a href=\"#APP爬取的相关库\" class=\"headerlink\" title=\"APP爬取的相关库\"></a><strong>APP爬取的相关库</strong></h1><p>除了爬取网页，Python爬虫也可以抓取APP的数据。这里需要用到抓包技术来抓取数据。</p>\n<ul>\n<li>Charles：一个强大的网络抓包工具，跨平台支持的很好。</li>\n<li>mitmproxy：支持HTTP和HTTPS的抓包程序，跟Charles类似，但是是通过控制台的形式操作。mitmproxy有两个关联组件mitmdump和mitmweb。<ul>\n<li>mitmdump是mitmproxy的命令行接口，利用它可以对接Python脚本，实现监听后的处理。</li>\n<li>mitmweb是一个Web程序，通过它可以清楚地观察到mitmproxy捕获的请求。</li>\n</ul>\n</li>\n<li>Appium：移动端的自动化测试工具，类似于Selenium。利用它可以驱动Android，iOS等设备完成自动化测试，比如点击、滑动、输入等操作。</li>\n</ul>\n<h1 id=\"爬虫框架\"><a href=\"#爬虫框架\" class=\"headerlink\" title=\"爬虫框架\"></a><strong>爬虫框架</strong></h1><p>如果爬取量不大，速度要求不高，直接用requests和Selenium等库写爬虫就可以完全满足我们的需求。但我们可以把这些组件抽取出来模块化形成爬虫框架，从而大大提高代码效率。这样做不仅可以简化代码，结构也会变得更加清晰。所以对于基础好的同学，使用框架会使一个很好的选择。</p>\n<ul>\n<li>Scrapy：一个十分强大的爬虫框架，主要依赖Twisted 14.0、lxml 3.4和pyOpenSSL 0.14。在不同平台下，所依赖的库也各部不相同。<ul>\n<li>Scrapy-Splash：Scrapy中支持JavaScript渲染的工具。</li>\n<li>Scrapy-Redis：Scrapy的分布式扩展模块，可以帮助实现Scrapy分布式爬虫的搭建。</li>\n<li>Scrapyd: 用于部署和运行Scrapy项目的工具，可以把写好的Scrapy项目上传到云主机并通过API来控制它。</li>\n</ul>\n</li>\n<li>pyspider：带有强大的WebUI、脚本编辑器、任务监控器、项目管理器以及结果处理器，同时支持多种数据库后端、多种消息队列，另外还支持JavaScript渲染页面的爬取。</li>\n</ul>\n<p>\t</p>\n","categories":["技术杂谈","Python"],"tags":["Python","编程","网络","爬虫"]},{"title":"Linux学习笔记 - 1","url":"/2021/01/01/linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/","content":"<p><strong>这篇文章将对目录操作，文件编辑，通配符(wildcard)等相关知识进行总结。</strong></p>\n<span id=\"more\"></span>\n<h1 id=\"常用Linux指令：\"><a href=\"#常用Linux指令：\" class=\"headerlink\" title=\"常用Linux指令：\"></a><strong>常用Linux指令：</strong></h1><ul>\n<li>pwd (print working directory) 显示当前工作路径</li>\n<li>ls (list files) 显示当前文件夹中所有文件</li>\n<li>cd (change directory) 改变工作路径</li>\n<li>cd &#x2F; 回到root根目录</li>\n<li>cd .. 回到上一层目录</li>\n<li>mkdir (make directory) 新建文件夹</li>\n<li>rmdir (remove directory) 删除文件夹</li>\n<li>nano 打开nano文本编辑器编辑文件 e.g. nano my_dogs.txt; nano prog.py</li>\n<li>cat (catalog) 查看文件</li>\n<li>mv (move) 移动文件 e.g. mv my_cars&#x2F;cars.txt my_stuff&#x2F;cars.txt</li>\n<li>cp (copy) 复制文件 e.g. cp my_cars&#x2F;cars.txt my_stuff&#x2F;cars.txt</li>\n<li>rm (remove) 删除文件</li>\n<li>rm-r (remove recursively) 将目录及以下之档案亦逐一删除</li>\n<li>touch 新建空文件</li>\n<li>sudo (superusers do) 获得超级管理权限</li>\n</ul>\n<h1 id=\"通配符（wildcard）\"><a href=\"#通配符（wildcard）\" class=\"headerlink\" title=\"通配符（wildcard）\"></a><strong>通配符（wildcard）</strong></h1><p>利用通配符可以大大提高我们的工作效率。比如我们想要移动五个前缀类似的文件(e.g. dog1.txt, dog2.txt, dog3.txt, dog4.txt, dog5.txt)，如果一个一个移动将会十分烦碎。这样的命令将会是：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">mv my_dogs/dog1.txt my_stuff</span><br><span class=\"line\">mv my_dogs/dog2.txt my_stuff</span><br><span class=\"line\">mv my_dogs/dog3.txt my_stuff</span><br><span class=\"line\">mv my_dogs/dog4.txt my_stuff</span><br><span class=\"line\">mv my_dogs/dog5.txt my_stuff</span><br></pre></td></tr></table></figure>\n\n<p>如果使用通配符就可以简化为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">mv my_dogs/dog*.txt my_stuff</span><br></pre></td></tr></table></figure>\n\n<p>常见的通配符如下表所示：</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-5-1024x407.png\"></p>\n<h1 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a><strong>其他</strong></h1><p>上方向键 (up key) 显示上一条指令。（同样或相似的指令就可以不必重复输入）</p>\n<p>大于号：将一条命令执行结果（标准输出，或者错误输出，本来都要打印到屏幕上面的）重定向其它输出设备（文件，打开文件操作符，或打印机等等）。大于号分为两种，分别是：</p>\n<p>&gt; 覆盖原有内容</p>\n<p>&gt;&gt; 在原有文件基础上追加内容</p>\n<hr>\n","categories":["技术杂谈","Linux"],"tags":["command","Linux","学习笔记"]},{"title":"Linux学习笔记 – 2","url":"/2021/01/03/linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2/","content":"<p><strong>这篇文章将对sort排序命令，关机和重启，一些特殊符号的意义，根目录(root directory)与家目录(home directory)的区别，tee 命令，pipe命令，和find、gerp查找命令进行总结。</strong></p>\n<span id=\"more\"></span>\n<h1 id=\"sort命令对文件进行排序\"><a href=\"#sort命令对文件进行排序\" class=\"headerlink\" title=\"sort命令对文件进行排序\"></a><strong>sort命令对文件进行排序</strong></h1><ul>\n<li><strong>sort</strong> 对内容按照字母顺序进行排序 (a –&gt; z)</li>\n<li><strong>sort -r</strong> (reverse) 对内容按照字母倒序进行排序(z –&gt; a)</li>\n<li><strong>sort -n</strong> (number) 对字母从小到大进行排序(1 –&gt; 10)</li>\n<li><strong>sort -n</strong> <strong>-r</strong> 对字母从大到小进行排序( 10 –&gt;1)</li>\n<li><strong>sort -M</strong> 对月份进行排序(Jan. –&gt;Dec.)</li>\n<li><strong>sort -M -r</strong> 对月份进行逆排序(Dec.–&gt;Jan.)</li>\n</ul>\n<h1 id=\"关机和重启\"><a href=\"#关机和重启\" class=\"headerlink\" title=\"关机和重启\"></a><strong>关机和重启</strong></h1><p>有些用户会使用直接断掉电源的方式来关闭linux，这是十分危险的。因为linux与windows不同，其后台运行着许多进程，所以强制关机可能会导致进程的数据丢失﹐使系统处于不稳定的状态﹐甚至在有的系统中会损坏硬件设备。所以每次对机器来安全关机是十分有必要的。下面是一些常用的关机和重启命令。</p>\n<ul>\n<li><strong>halt</strong> 最简单的关机命令</li>\n<li><strong>shutdown -h</strong> 跟halt命令相同，其实也是在调用shutdown下的halt命令</li>\n<li><strong>reboot</strong> 重新启动</li>\n</ul>\n<p>注意这些命令可能需要sudo来调用超级管理权限才能调用。</p>\n<h1 id=\"一些符号的意义\"><a href=\"#一些符号的意义\" class=\"headerlink\" title=\"一些符号的意义\"></a><strong>一些符号的意义</strong></h1><p><strong>~</strong> home目录，也就是家目录</p>\n<p><strong>&#x2F;</strong> root目录，也就是根目录</p>\n<p><strong>..</strong> 上一层目录</p>\n<p><strong>.</strong> 当前目录</p>\n<p>管线命令(pipe command)</p>\n<p>通常情况下，我们在终端只能执行一条命令，然后按下回车执行。pipe command就可以帮助我们实现同时执行多条命令。例如：</p>\n<p><code>cat my_files/my_dogs.txt sort -r</code></p>\n<p>就可以同时实现在终端查看my_dogs.txt并且将这个文件进行倒序排列。</p>\n<h1 id=\"根目录-root-directory-与家目录-home-directory-的区别\"><a href=\"#根目录-root-directory-与家目录-home-directory-的区别\" class=\"headerlink\" title=\"根目录(root directory)与家目录(home directory)的区别\"></a><strong>根目录(root directory)与家目录(home directory)的区别</strong></h1><ul>\n<li>用户登录后在 家目录 ，可用pwd命令查看，普通用户为 &#x2F;home&#x2F;用户名，root用户为&#x2F;root</li>\n<li>根目录是在最顶端的目录（因为已经不能cd ..到上一级目录了 ）</li>\n<li>根目录是所有用户的都可以操作的，家目录用户才有权限操作（管理员可以分配权限）</li>\n</ul>\n<h1 id=\"tee-命令\"><a href=\"#tee-命令\" class=\"headerlink\" title=\"tee 命令\"></a><strong>tee 命令</strong></h1><p>Linux tee命令用于读取标准输入的数据，并将其内容输出成文件。</p>\n<p>tee指令会从标准输入设备读取数据，将其内容输出到标准输出设备，同时保存成文件。</p>\n<p>例如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ls /tee my_root.txt</span><br></pre></td></tr></table></figure>\n\n<p>这条指令将会: (1) 列出root目录下的文件; (2) 将文件名保存在my_root.txt文件中。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ls ~ tee my_files.txt -a</span><br></pre></td></tr></table></figure>\n\n<p>这条指令将会: (1) 列出home目录下的文件; (2) 将文件名以后缀的形式(-a) 保存在my_files.txt的文件中。</p>\n<h1 id=\"find-查找命令和-grep-查找命令\"><a href=\"#find-查找命令和-grep-查找命令\" class=\"headerlink\" title=\"find 查找命令和 grep 查找命令\"></a><strong>find 查找命令和 grep 查找命令</strong></h1><p>Linux中有两个与查找相关的命令，一个是find，另一个是gerp。他们最大的区别是，find用于查找文件，而gerp用于查找文件中的内容。</p>\n<p>实例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">find . -name &quot;cats.txt&quot;</span><br></pre></td></tr></table></figure>\n\n<p>这条指令将会在当前目录中查找名为cats.txt的文件。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">grep chev my_files/cars.txt</span><br></pre></td></tr></table></figure>\n\n<p>这条指令将会在文件cars.txt中查找chev字符。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">grep -r -i chevy ~</span><br></pre></td></tr></table></figure>\n\n<p>-r 代表recursively; -i 代表ignore case。所以这条指令将会在home以及所属的文件夹中查找chevy并且不区分大小写。</p>\n<hr>\n","categories":["技术杂谈","Linux"],"tags":["command","Linux","学习笔记"]},{"title":"Linux学习笔记-4","url":"/2021/01/09/linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-4/","content":"<p><strong>本篇文章将会分享关于Linux的包的管理，systemctl系统服务管理器指令，以及使用scp指令来实现不同电脑间的文件传输等相关的一些知识。</strong></p>\n<span id=\"more\"></span>\n<h1 id=\"包-package-的管理\"><a href=\"#包-package-的管理\" class=\"headerlink\" title=\"包(package)的管理\"></a><strong>包(package)的管理</strong></h1><p>大多数现代类 Unix 操作系统都提供了一个集中的软件包管理机制，以帮助用户搜索、安装和管理软件。而软件通常以包的形式存储在仓库（repository）中，对软件包的使用和管理被称为包管理。而 Linux 包的基本组成部分通常有：共享库、应用程序、服务和文档。</p>\n<p>包管理器又称软件包管理系统，它是在电脑中自动安装、配制、卸载和升级软件包的工具组合，在各种系统软件和应用软件的安装管理中均有广泛应用。<strong>我们这里只介绍最为常见的apt包管理器。</strong></p>\n<p>APT(全称为Advanced Packaging Tools)，常见的以apt- 开头的包管理命令有：</p>\n<ul>\n<li><strong>sudo apt list –installed</strong> 查看已经安装的包</li>\n<li><strong>sudo apt install</strong> 对包进行安装</li>\n<li><strong>sudo</strong> <strong>apt remove</strong> 对包进行移除</li>\n<li><strong>sudo</strong> <strong>apt auto remove</strong> 对已经删除的包相关的配置文件进行自动移除</li>\n<li><strong>sudo apt update</strong> 更新已经安装的包的列表，查看是否有更新</li>\n<li><strong>sudo apt upgrade</strong> 对已经安装的包进行更新升级</li>\n</ul>\n<h1 id=\"systemctl系统服务管理指令\"><a href=\"#systemctl系统服务管理指令\" class=\"headerlink\" title=\"systemctl系统服务管理指令\"></a><strong>systemctl系统服务管理指令</strong></h1><p>systemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。systemctl是systemd的主要命令，用来管理系统。</p>\n<ul>\n<li><strong>sudo systemctl stop</strong> 停止某个进程</li>\n<li><strong>sudo systemctl start</strong> 开始某个进程</li>\n<li><strong>sudo systemctl restart</strong> 重启某个进程</li>\n<li><strong>sudo systemctl status</strong> 查看某个进程的状态</li>\n<li><strong>sudo systemctl reload</strong> 重新加载某个进程</li>\n<li><strong>sudo systemctl disable</strong> 取消开机自动启动某个进程</li>\n<li><strong>sudo systemctl enable</strong> 允许开机自动启动某个进程</li>\n</ul>\n<h1 id=\"scp跨机远程文件拷贝\"><a href=\"#scp跨机远程文件拷贝\" class=\"headerlink\" title=\"scp跨机远程文件拷贝\"></a><strong>scp跨机远程文件拷贝</strong></h1><p>scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。</p>\n<p>命令格式为： scp [参数] [原路径] [目标路径]</p>\n<p>比如将本机的local_file文件夹拷贝到 IP为192.168.4.20，用户名为user的home路径下则为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">scp -r local_file user@192.168.4.20:/home/</span><br></pre></td></tr></table></figure>\n\n<p>相反，如果想要远程将IP为192.168.4.20，用户名为user的home路径下的local_file复制到本地home路径下则为</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">scp -r user@192.168.4.20:/home/local_file /home/</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Linux"],"tags":["command","Linux","Raspberry Pi"]},{"title":"Python教程--使用python发送邮件","url":"/2021/01/16/python%E6%95%99%E7%A8%8B-%E4%BD%BF%E7%94%A8python%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/","content":"<p><strong>这篇文章中将会分享如何使用python来发送邮件的相关知识。</strong></p>\n<span id=\"more\"></span>\n<p>如果你希望在用户创建帐户时向用户发送确认邮件，或向组织成员发送邮件以提醒他们支付会费。 这时候如果手动发送邮件将是一项耗时且容易出错的任务，但是使用Python就可以轻松实现自动化。</p>\n<p>在使用oython来发送邮件之前，我们需要对邮箱进行一些设置，来允许使用第三方app来对它进行操作。如果使用的是gmail 的话打开这个网页进行设置： <a href=\"https://myaccount.google.com/lesssecureapps\">https://myaccount.google.com/lesssecureapps</a></p>\n<p>选择将允许不够安全的应用设置为启用（ allow less secure apps: on）。然后就可以使用python对邮箱进行操作了。</p>\n<h1 id=\"一、发送纯文本邮件\"><a href=\"#一、发送纯文本邮件\" class=\"headerlink\" title=\"一、发送纯文本邮件\"></a><strong>一、发送纯文本邮件</strong></h1><p>Python内置了 <a href=\"https://docs.python.org/3/library/smtplib.html\">smtplib</a> 模块，用于使用简单邮件传输协议（SMTP）发送电子邮件。</p>\n<p>当你通过Python发送电子邮件时，应确保你的SMTP连接已加密，以便其他人无法轻松访问你的邮件和登录凭据。有两种方法可以与你的电子邮件服务器建立安全连接：</p>\n<ul>\n<li>使用不安全的SMTP连接，然后使用 <code>.starttls()</code> 加密</li>\n<li>使用 <code>SMTP_SSL()</code> 建立安全的SMTP连接</li>\n</ul>\n<p>首先，我们先来看一下第一种情况的一个例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import smtplib</span><br><span class=\"line\"></span><br><span class=\"line\">with smtplib.SMTP(&#x27;smtp.gmail.com&#x27;, 587) as smtp:</span><br><span class=\"line\">smtp.ehlo()  # 身份确认</span><br><span class=\"line\">smtp.starttls() # 使用starttls进行加密</span><br><span class=\"line\">smtp.ehlo() # 再次确认身份</span><br><span class=\"line\">smtp.login(&#x27;username@gmail.com&#x27;,&#x27;password&#x27;) # 使用账号和密码登陆邮箱</span><br><span class=\"line\">subject = &#x27;Grab dinner this weekend?&#x27; # 创建邮件主题</span><br><span class=\"line\">body = &#x27;How about go for a dinner at 6pm this Sunday?&#x27; # 创建邮件内容</span><br><span class=\"line\">msg = f&#x27;Subject: &#123;subject&#125;\\n\\n&#123;body&#125;&#x27; </span><br><span class=\"line\">smtp.sendmail(&#x27;username@gmail.com&#x27;,&#x27;test@gmail.com&#x27;,msg) # 发送邮件到test@gamil.com账户</span><br></pre></td></tr></table></figure>\n\n<p>这里使用的端口为587。大多数电子邮件提供商使用与本教程中相同的连接端口，但你可以使用Google搜索来进行快速确认。</p>\n<p>再来看看使用SMTP_SSL( )来进行加密的方法：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import smtplib</span><br><span class=\"line\"></span><br><span class=\"line\">with smtplib.SMTP_SSL(&#x27;smtp.gmail.com&#x27;, 465) as smtp:</span><br><span class=\"line\">smtp.login(&#x27;username@gmail.com&#x27;,&#x27;password&#x27;) # 使用账号和密码登陆邮箱</span><br><span class=\"line\">subject = &#x27;Grab dinner this weekend?&#x27; # 创建邮件主题</span><br><span class=\"line\">body = &#x27;How about go for a dinner at 6pm this Sunday?&#x27; # 创建邮件内容</span><br><span class=\"line\">msg = f&#x27;Subject: &#123;subject&#125;\\n\\n&#123;body&#125;&#x27; </span><br><span class=\"line\">smtp.sendmail(&#x27;username@gmail.com&#x27;,&#x27;test@gmail.com&#x27;,msg) # 发送邮件到test@gamil.com账户</span><br></pre></td></tr></table></figure>\n\n<p>是不是比第一种方法简单了一些。我们还可以使用email.message的库来对代码进行进一步的简化，使得更容易理解：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import smtplib</span><br><span class=\"line\">from email.message import EmailMessage</span><br><span class=\"line\"></span><br><span class=\"line\">msg = EmailMessage()</span><br><span class=\"line\">msg[&#x27;Subject&#x27;] = &#x27;Grab dinner this weekend?&#x27; #  创建邮件主题</span><br><span class=\"line\">msg[&#x27;From&#x27;] = &#x27;username@gmail.com&#x27; #  设定发送邮箱</span><br><span class=\"line\">msg[&#x27;To&#x27;] = &#x27;test@gmail.com&#x27;  # 设定接收邮箱</span><br><span class=\"line\">msg.set_content(&#x27;How about go for a dinner at 6pm this Sunday?&#x27;) # 创建邮件内容</span><br><span class=\"line\"></span><br><span class=\"line\">with smtplib.SMTP_SSL(&#x27;smtp.gmail.com&#x27;, 465) as smtp:</span><br><span class=\"line\">smtp.login(&#x27;username@gmail.com&#x27;,&#x27;password&#x27;)  # 使用账号和密码登陆邮箱</span><br><span class=\"line\">smtp.send_message(msg)  # 发送消息</span><br></pre></td></tr></table></figure>\n\n<p>是不是这些书写会变得更加有条理一些。这里注意最后一行代码改为了smtp.send_message(msg) 这是因为我们在前已经设定好了发送邮箱和接收邮箱，只是发送的message所以用的send_message的方法。</p>\n<h1 id=\"二、添加照片附件\"><a href=\"#二、添加照片附件\" class=\"headerlink\" title=\"二、添加照片附件\"></a><strong>二、添加照片附件</strong></h1><p>Python不仅可以发送纯文本邮件，还可以在邮件中添加附件。在这里我们以常见的照片和PDF格式的附件为例，来讲述怎么添加附件。首先我们来看看怎么发送单张图片：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import smtplib</span><br><span class=\"line\">from email.message import EmailMessage</span><br><span class=\"line\"></span><br><span class=\"line\">msg = EmailMessage()</span><br><span class=\"line\">msg[&#x27;Subject&#x27;] = &#x27;Grab dinner this weekend?&#x27;</span><br><span class=\"line\">msg[&#x27;From&#x27;] = &#x27;username@gmail.com&#x27;</span><br><span class=\"line\">msg[&#x27;To&#x27;] = &#x27;test@gmail.com&#x27;</span><br><span class=\"line\">msg.set_content(&#x27;Image attached...&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">with open(&#x27;1.jpg&#x27;,&#x27;rb&#x27;) as f: # rb的意思是 read byte</span><br><span class=\"line\">file_data = f.read()</span><br><span class=\"line\">file_name = f.name()</span><br><span class=\"line\"></span><br><span class=\"line\">msg.add_attachment(file_data, maintype = &#x27;image&#x27;, subtype = &#x27;jepg&#x27;, filename = file_name)</span><br><span class=\"line\"></span><br><span class=\"line\">with smtplib.SMTP_SSL(&#x27;smtp.gmail.com&#x27;, 465) as smtp:</span><br><span class=\"line\">smtp.login(&#x27;username@gmail.com&#x27;,&#x27;password&#x27;)</span><br><span class=\"line\">smtp.send_message(msg)</span><br></pre></td></tr></table></figure>\n\n<p>如果是多张图片，并且格式不相同，我们可以将要发送的图片放入一个列表，然后使用imghdr的库来获取图片格式。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import smtplib</span><br><span class=\"line\">import imghdr</span><br><span class=\"line\">from email.message import EmailMessage</span><br><span class=\"line\"></span><br><span class=\"line\">msg = EmailMessage()</span><br><span class=\"line\">msg[&#x27;Subject&#x27;] = &#x27;The picture&#x27;</span><br><span class=\"line\">msg[&#x27;From&#x27;] = &#x27;username@gmail.com&#x27;</span><br><span class=\"line\">msg[&#x27;To&#x27;] = &#x27;test@gmail.com&#x27;</span><br><span class=\"line\">msg.set_content(&#x27;Image attached...&#x27;)</span><br><span class=\"line\">files = [&#x27;1.jpg&#x27;,&#x27;2.png&#x27;]</span><br><span class=\"line\"></span><br><span class=\"line\">for file in files:</span><br><span class=\"line\">with open(file,&#x27;rb&#x27;) as f:</span><br><span class=\"line\">file_data = f.read()</span><br><span class=\"line\">file_type = imghdr.what(f.name)</span><br><span class=\"line\">file_name = f.name</span><br><span class=\"line\"></span><br><span class=\"line\">msg.add_attachment(file_data, maintype = &#x27;image&#x27;, subtype = file_type, filename = file_name)</span><br><span class=\"line\"></span><br><span class=\"line\">with smtplib.SMTP_SSL(&#x27;smtp.gmail.com&#x27;, 465) as smtp:</span><br><span class=\"line\"></span><br><span class=\"line\">smtp.login(&#x27;username@gmail.com&#x27;,&#x27;password&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">smtp.send_message(msg)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、添加PDF附件\"><a href=\"#三、添加PDF附件\" class=\"headerlink\" title=\"三、添加PDF附件\"></a><strong>三、添加PDF附件</strong></h1><p>添加PDF附件跟添加照片非常类似，唯一的不同的是文件格式的不同。PDF的maintype是’applicaton’，subtype是’octet-stream’。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import smtplib</span><br><span class=\"line\">from email.message import EmailMessage</span><br><span class=\"line\"></span><br><span class=\"line\">msg = EmailMessage()</span><br><span class=\"line\">msg[&#x27;Subject&#x27;] = &#x27;The PDF&#x27;</span><br><span class=\"line\">msg[&#x27;From&#x27;] = &#x27;username@gmail.com&#x27;</span><br><span class=\"line\">msg[&#x27;To&#x27;] = &#x27;test@gmail.com&#x27;</span><br><span class=\"line\">msg.set_content(&#x27;Image attached...&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">files = [&#x27;BIOS.pdf&#x27;]</span><br><span class=\"line\">for file in files:</span><br><span class=\"line\">with open(file,&#x27;rb&#x27;) as f:</span><br><span class=\"line\">file_data = f.read()</span><br><span class=\"line\">file_name = f.name</span><br><span class=\"line\">msg.add_attachment(file_data, maintype = &#x27;application&#x27;, subtype = &#x27;octet-stream&#x27;, filename = file_name)</span><br><span class=\"line\"></span><br><span class=\"line\">with smtplib.SMTP_SSL(&#x27;smtp.gmail.com&#x27;, 465) as smtp:</span><br><span class=\"line\">smtp.login(&#x27;username@gmail.com&#x27;,&#x27;password&#x27;)</span><br><span class=\"line\">smtp.send_message(msg)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"四、群发邮件\"><a href=\"#四、群发邮件\" class=\"headerlink\" title=\"四、群发邮件\"></a><strong>四、群发邮件</strong></h1><p>如果需要把同一封邮件发送给多人，我们可以创建一个发送邮件的列表，然后将邮件的收件人改为列表即可。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import smtplib</span><br><span class=\"line\">from email.message import EmailMessage</span><br><span class=\"line\"></span><br><span class=\"line\">contacts = [&#x27;test1@gmail.com&#x27;,&#x27;test2@gmail.com&#x27;,test3@gmail.com]</span><br><span class=\"line\">msg = EmailMessage()</span><br><span class=\"line\">msg[&#x27;Subject&#x27;] = &#x27;The PDF&#x27;</span><br><span class=\"line\">msg[&#x27;From&#x27;] = &#x27;username@gmail.com&#x27;</span><br><span class=\"line\">msg[&#x27;To&#x27;] = &#x27;, &#x27;.join(contacts)</span><br><span class=\"line\">msg.set_content(&#x27;Image attached...&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">files = [&#x27;BIOS.pdf&#x27;]</span><br><span class=\"line\">for file in files:</span><br><span class=\"line\">with open(file,&#x27;rb&#x27;) as f:</span><br><span class=\"line\">file_data = f.read()</span><br><span class=\"line\">file_name = f.name</span><br><span class=\"line\">msg.add_attachment(file_data, maintype = &#x27;application&#x27;, subtype = &#x27;octet-stream&#x27;, filename = file_name)</span><br><span class=\"line\"></span><br><span class=\"line\">with smtplib.SMTP_SSL(&#x27;smtp.gmail.com&#x27;, 465) as smtp:</span><br><span class=\"line\">smtp.login(&#x27;username@gmail.com&#x27;,&#x27;password&#x27;)</span><br><span class=\"line\">smtp.send_message(msg)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"五、发送带格式的html邮件\"><a href=\"#五、发送带格式的html邮件\" class=\"headerlink\" title=\"五、发送带格式的html邮件\"></a><strong>五、发送带格式的html邮件</strong></h1><p>如果你要格式化电子邮件中的文本（粗体，斜体等），或者超链接或响应式的内容，则使用HTML非常方便。 由于并非所有电子邮件客户端都默认显示HTML内容，并且出于安全原因，有些人仅选择接收纯文本电子邮件，因此为HTML消息添加纯文本的替代非常重要。 由于电子邮件客户端将首先渲染最后一部分的附件，因此请确保在纯文本版本之后添加HTML消息。例如下面这个例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import smtplib</span><br><span class=\"line\">from email.message import EmailMessage</span><br><span class=\"line\"></span><br><span class=\"line\">contacts = [&#x27;test1@gmail.com&#x27;,&#x27;test2@gmail.com&#x27;,test3@gmail.com]</span><br><span class=\"line\">msg = EmailMessage()</span><br><span class=\"line\">msg[&#x27;Subject&#x27;] = &#x27;alternative&#x27;</span><br><span class=\"line\">msg[&#x27;From&#x27;] = &#x27;username@gmail.com&#x27;</span><br><span class=\"line\">msg[&#x27;To&#x27;] = &#x27;, &#x27;.join(contacts)</span><br><span class=\"line\">msg.set_content(&#x27;This is a plain text email&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">msg.add_alternative(&quot;&quot;&quot;\\</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">&lt;h1 style = &quot;color:SlateGray;&quot;&gt;This is an HTML Email!&lt;/h1&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;&quot;&quot;, subtype = &#x27;html&#x27;)   ## alternative will send first</span><br><span class=\"line\"></span><br><span class=\"line\">with smtplib.SMTP_SSL(&#x27;smtp.gmail.com&#x27;, 465) as smtp:</span><br><span class=\"line\"></span><br><span class=\"line\">smtp.login(&#x27;username@gmail.com&#x27;,&#x27;password&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">smtp.send_message(msg)</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","email","python","smtplib"]},{"title":"Python教程--os 模块","url":"/2021/01/15/python%E6%95%99%E7%A8%8B-os-%E6%A8%A1%E5%9D%97/","content":"<p><strong>这篇文章中将会分享python中关于os 模块相关的一些知识。</strong></p>\n<span id=\"more\"></span>\n<p>os就是“operating system”的缩写，顾名思义，os模块提供的就是各种 Python 程序与操作系统进行交互的接口。通过使用os模块，一方面可以方便地与操作系统进行交互，另一方面页可以极大增强代码的可移植性。</p>\n<h1 id=\"一、os模块常用方法\"><a href=\"#一、os模块常用方法\" class=\"headerlink\" title=\"一、os模块常用方法\"></a><strong>一、os模块常用方法</strong></h1><p>获取当前工作目录：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">print(os.getcwd())</span><br></pre></td></tr></table></figure>\n\n<p>改变当前路径到桌面：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">os.chdir(&#x27;/Users/leileishi/Desktop/&#x27;)</span><br></pre></td></tr></table></figure>\n\n<p>列出路径中的文件和文件夹：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">print(os.listdir())</span><br></pre></td></tr></table></figure>\n\n<p>新建文件夹</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">os.mkdir(&#x27;OS-Demon-2&#x27;)</span><br><span class=\"line\"># 或者</span><br><span class=\"line\">os.makedirs(&#x27;OS-Demon-2/Sub-Dir-1&#x27;)</span><br></pre></td></tr></table></figure>\n\n<p>注意：mkdir只能建立一个文件夹，而makedirs可以创建一个不存在的文件夹以及在它下面创建子文件夹。</p>\n<p>删除文件夹:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">os.rmdir(&#x27;OS-Demon-2&#x27;)</span><br><span class=\"line\">#或者</span><br><span class=\"line\">os.removedirs(&#x27;OS-Demon-2/Sub-Dir-1&#x27;)</span><br></pre></td></tr></table></figure>\n\n<p>同样的，rmdir只能移除一个文件夹，而removedirs可以移除文件夹（如果为空的话）以及下面的子文件夹。也就是说：若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推</p>\n<p>重命名</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">os.rename(&#x27;Arduino-2.jpg&#x27;, &#x27;Arduino.jpg&#x27;)</span><br></pre></td></tr></table></figure>\n\n<p>获取目录信息：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">print(os.stat(&#x27;Arduino.jpg&#x27;))</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、更多os模块方法总结\"><a href=\"#二、更多os模块方法总结\" class=\"headerlink\" title=\"二、更多os模块方法总结\"></a><strong>二、更多os模块方法总结</strong></h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">os.curdir   返回当前目录: (‘.’)</span><br><span class=\"line\">os.pardir   获取当前目录的父目录字符串名：(‘..’)</span><br><span class=\"line\">os.sep  输出操作系统特定的路径分隔符，win下为\\\\,Linux下为/</span><br><span class=\"line\">os.linesep  输出当前平台使用的行终止符，win下为\\t\\n,Linux下为\\n</span><br><span class=\"line\">os.pathsep  输出用于分割文件路径的字符串</span><br><span class=\"line\">os.name 输出字符串指示当前使用平台。win-&gt;nt; Linux-&gt;posix</span><br><span class=\"line\">os.system(“bash command”)   运行shell命令，直接显示</span><br><span class=\"line\">os.environ  获取系统环境变量</span><br><span class=\"line\">os.path.abspath(path)   返回path规范化的绝对路径</span><br><span class=\"line\">os.path.split(path) 将path分割成目录和文件名二元组返回</span><br><span class=\"line\">os.path.dirname(path)   返回path的目录。其实就是os.path.split(path)的第一个元素</span><br><span class=\"line\">os.path.basename(path)  返回path最后的文件名。如果path以／或\\结尾，那么就会返回空值。</span><br><span class=\"line\">os.path.exists(path)    如果path存在，返回True；如果path不存在，返回False</span><br><span class=\"line\">os.path.isabs(path) 如果path是绝对路径，返回True</span><br><span class=\"line\">os.path.isfile(path)    如果path是一个存在的文件，返回True。否则返回False</span><br><span class=\"line\">os.path.isdir(path) 如果path是一个存在的目录，则返回True。否则返回False</span><br><span class=\"line\">os.path.join(path1[, path2[,…]])将多个路径组合后返回，第一个绝对路径之前的参数将被忽略</span><br><span class=\"line\">os.path.getatime(path)  返回path所指向的文件或者目录的最后存取时间</span><br><span class=\"line\">os.path.getmtime(path)  返回path所指向的文件或者目录的最后修改时间</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","python","os"]},{"title":"Python教程--函数(Function)","url":"/2021/01/12/python%E6%95%99%E7%A8%8B-%E5%87%BD%E6%95%B0function/","content":"<p><strong>这篇文章中将会分享python中关于函数(Function)相关的一些知识。</strong></p>\n<span id=\"more\"></span>\n<p>通过前面几篇文章的学习，我们大概已经可以初步写出一些程序了。但我们会发现一个问题，那就是每次写完的程序不能重复利用。如果要用到相同或类似的功能，我们只能再把之前写过的东西重新写一遍。这样就大大降低了我们的程序使用效率。Python中的函数功能，就是为解决这个问题应运而生的。</p>\n<h1 id=\"一、什么是函数-Function\"><a href=\"#一、什么是函数-Function\" class=\"headerlink\" title=\"一、什么是函数(Function)?\"></a><strong>一、什么是函数(Function)?</strong></h1><p>函数是组织好的，可重复使用的，用来实现单一，或相关联功能的代码段。</p>\n<p>函数能提高应用的模块性，和代码的重复利用率。你已经知道Python提供了许多内建函数，比如print()。但你也可以自己创建函数，这被叫做用户自定义函数。</p>\n<p>你可以定义一个由自己想要功能的函数，以下是简单的规则：</p>\n<ul>\n<li>函数代码块以 <strong>def</strong> 关键词开头，后接函数标识符名称和圆括号**( )**。</li>\n<li>任何传入参数和自变量必须放在圆括号中间。圆括号之间可以用于定义参数。</li>\n<li>函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明。</li>\n<li>函数内容以冒号起始，并且缩进。</li>\n<li>return [表达式] 结束函数，选择性地返回一个值给调用方。不带表达式的return相当于返回 None。</li>\n</ul>\n<p>是不是看的有些头晕，别担心，我们可以看一个简单的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">def hello_func():</span><br><span class=\"line\">print (&#x27;Hello Functions!&#x27;)</span><br><span class=\"line\">hello_func()</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Hello Functions!</span><br></pre></td></tr></table></figure>\n\n<p>这样我们就创建了我们第一个自己的函数。每次调用的时候，只需要写出hello_func( )就可以了。如果只是输出一次”Hello Funcitons!”我们可能还感觉不到函数本身有什么强大的功能。但是，如果同样的函数我们在不同地方调用了很多次，最后发现有地方需要修改，我们就发现函数的妙用了。比如上面的函数，我们想要输出”Hello Funcitons!”一百次。在写完代码之后，老板突然说，你需要把“！”改成“.”。如果我们没有函数，只能熬夜加班挨个把他们改回来。但是，我们有了函数这个强大的工具，只需要修改函数本身，然后所有用到函数的地方都会被修改掉了。</p>\n<h1 id=\"二、参数传递\"><a href=\"#二、参数传递\" class=\"headerlink\" title=\"二、参数传递\"></a><strong>二、参数传递</strong></h1><p>在函数中，我们还可以在括号中传递参数。从而使得程序输出结果会根据我们输入的参数不同而随之发生变化。比如这个例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">def hello_func(greeting):</span><br><span class=\"line\">return (f&#x27;&#123;greeting&#125; Functions!&#x27;)</span><br><span class=\"line\">print(hello_func(&#x27;Hi&#x27;))</span><br></pre></td></tr></table></figure>\n\n<p>输出结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Hi Functions!</span><br></pre></td></tr></table></figure>\n\n<p>这里我们可以改变“Hi”为任意我们想要的打招呼的语句，而不用去改变函数本身。再举一个稍微复杂一点的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">def hello_func(greeting, name = &quot;You&quot;):</span><br><span class=\"line\">return (f&#x27;&#123;greeting&#125;, &#123;name&#125;!&#x27;)</span><br><span class=\"line\">print(hello_func(&#x27;Hi&#x27;))</span><br></pre></td></tr></table></figure>\n\n<p>这次我们传递了两个参数，一个是打招呼的语句，另一个是打招呼的对象。但我们赋予了name一个默认值”You”。所以我们可以只输入第一个参数，第二个参数就会自动赋予默认值。运行程序结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Hi, You!</span><br></pre></td></tr></table></figure>\n\n<p>同样，我们也可以改变第二个参数，这样我们就会输出我们想要的结果。比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">def hello_func(greeting, name = &quot;You&quot;):</span><br><span class=\"line\">return (f&#x27;&#123;greeting&#125;, &#123;name&#125;!&#x27;)</span><br><span class=\"line\">print(hello_func(&#x27;Hi&#x27;, name = &#x27;Corey&#x27;))</span><br></pre></td></tr></table></figure>\n\n<p>运行结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Hi, Corey!</span><br></pre></td></tr></table></figure>\n\n<p>前面所说的这些都是需要知道我们有多少个参数输入。但在某些条件下，你可能需要一个函数能处理比当初声明时更多的参数。那么我们就会用到不定长参数，在参数前面加*和**来表示。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">def student_info(*args, **kwargs):</span><br><span class=\"line\">print(args) </span><br><span class=\"line\">print(kwargs)</span><br><span class=\"line\">student_info(&#x27;Math&#x27;,&#x27;Art&#x27;,name = &#x27;Jone&#x27;, age = 22 )</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">(&#x27;Math&#x27;, &#x27;Art&#x27;)</span><br><span class=\"line\">&#123;&#x27;name&#x27;: &#x27;Jone&#x27;, &#x27;age&#x27;: 22&#125;</span><br></pre></td></tr></table></figure>\n\n<p>单个不定长度参数是用 *args 来标识，其中 * 是规定的，args可用其他名称替换，但一般习惯用 args 来表示。可变参数在传入函数后，被封装成一个 tuple 来进行使用。所以我们在函数内部，可以通过操作 tuple 的方法来操作参数。同样的，** kwargs 被用来在函数内部当作一个字典来用，用于不定长度的字典类型的参数。其中，**是规定的，不可变更，而kwargs可替换。</p>\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","python","函数"]},{"title":"Python教程--使用环境变量来隐藏密码","url":"/2021/01/17/python%E6%95%99%E7%A8%8B-%E4%BD%BF%E7%94%A8%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E6%9D%A5%E9%9A%90%E8%97%8F%E5%AF%86%E7%A0%81/","content":"<p><strong>这篇文章中将会分享如何在Mac和Linux系统下设置环境变量，从而在代码中隐藏密码等相关个人信息的相关知识。</strong></p>\n<span id=\"more\"></span>\n<p>在编写程序代码的时候，往往会涉及到一些登录的相关操作。这时候就需要在程序中输入账号和密码等相关个人信息。如果我们在分享代码的时候，没有注意就会把个人信息给泄露了。所以通过设置环境变量来隐藏个人信息就显得非常有必要。</p>\n<h1 id=\"一、设置环境变量\"><a href=\"#一、设置环境变量\" class=\"headerlink\" title=\"一、设置环境变量\"></a><strong>一、设置环境变量</strong></h1><p>比如，我们需要在程序中登陆一个数据库。账号和密码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">db_user = my_db_user</span><br><span class=\"line\">db_password = my_db_pass123!</span><br></pre></td></tr></table></figure>\n\n<p>我们怎么在mac和linux系统中设置环境变量来隐藏这些信息呢？</p>\n<p>首先，打开终端。输入nano .bash_profile，也就是使用nano编辑器来编辑.bash_profile这个储存环境变量的文件。进入nano编辑器之后，输入以下代码来设置环境变量：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">export DB_USER=&#x27;my_db_user&#x27;</span><br><span class=\"line\">export DB_PASS=&#x27;my_db_pass123!&#x27;</span><br></pre></td></tr></table></figure>\n\n<p><strong>这里一定要注意：</strong>等号前后不要有空格。</p>\n<p>然后我们编辑好之后按Ctr+O来保存文件，Enter之后，再按Ctr+X来退出编辑。再终端输入以下代码使得我们刚刚设置的环境变量生效：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">source ~/.bash_profile</span><br></pre></td></tr></table></figure>\n\n<p>然后在终端输入以下代码来确定环境变量是否生效：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">echo $DB_USER</span><br><span class=\"line\">echo $DB_PASS</span><br></pre></td></tr></table></figure>\n\n<p>如果输出我们刚刚设定的账号和密码说明已经生效。如果没有生效，这时候我们可能需要重启shell和python（也可以直接重启电脑）来使其生效。</p>\n<p>对于某些linux版本，可能储存环境变量的位置有所变化。如果.bash_profile无效，可以试一下设置.zshrc和 .bashrc文件。</p>\n<h1 id=\"二、调用环境变量\"><a href=\"#二、调用环境变量\" class=\"headerlink\" title=\"二、调用环境变量\"></a><strong>二、调用环境变量</strong></h1><p>设置好之后，我们接下来就要调用我们刚刚设置的环境变量了。在python中我们首先需要引入os模块，来寻找路径。然后，我们就可以通过os模块来调用环境变量了，具体代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\"></span><br><span class=\"line\">db_user =os.environ.get(&#x27;DB_USER&#x27;)          </span><br><span class=\"line\">db_password =os.environ.get(&#x27;DB_PASS&#x27;) </span><br></pre></td></tr></table></figure>\n\n<p>这时候，我们就可以成功调用环境变量来隐藏密码了。</p>\n<p>注意：在使用之前，我们也可以通过将 db_user，和db_password的值打印出来来确定是否成功调用环境变量。</p>\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","python","环境变量"]},{"title":"Python教程--切割列表和字符串","url":"/2021/01/14/python%E6%95%99%E7%A8%8B-%E5%88%87%E5%89%B2%E5%88%97%E8%A1%A8%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","content":"<p><strong>这篇文章中将会分享python中关于切割列表和字符串(slicing lists and string) 相关的一些知识。</strong></p>\n<span id=\"more\"></span>\n<p>我们有时候不希望输出整个列表和字符串而只是希望输出其中某一部分，这时候应该怎么办呢？今天这篇文章，我们就来学习一下在python中应当怎样分割列表和字符串。</p>\n<h1 id=\"一、切割列表\"><a href=\"#一、切割列表\" class=\"headerlink\" title=\"一、切割列表\"></a><strong>一、切割列表</strong></h1><p>切割列表的格式为：list[start:end:step]。start是输出开始的指针位置，end是输出结束的指针位置，step是输出的间隔数。如果只需要输出某个元素，则只需要在列表后面加上相应的指针位置。先看下面这个例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">my_list = [0,1,2,3,4,5,6,7,8,9]</span><br><span class=\"line\">print (my_list[3])</span><br><span class=\"line\">print (my_list[-1])</span><br><span class=\"line\">print (my_list[0:4])</span><br><span class=\"line\">print (my_list[0:5:2])</span><br><span class=\"line\">print (my_list[2:-1:2])</span><br><span class=\"line\">print (my_list[::-1])</span><br></pre></td></tr></table></figure>\n\n<p>输出结果分别为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">3</span><br><span class=\"line\">9</span><br><span class=\"line\">[0, 1, 2, 3]</span><br><span class=\"line\">[0, 2, 4]</span><br><span class=\"line\">[2, 4, 6, 8]</span><br><span class=\"line\">[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]</span><br></pre></td></tr></table></figure>\n\n<p>如果我们在start, end, step的位置不添加任何数值，则表示默认。他们的默认值分别为第一个指针位置(0)，最后一个指针位置(-1)，还有步数1。</p>\n<h1 id=\"二、切割字符串\"><a href=\"#二、切割字符串\" class=\"headerlink\" title=\"二、切割字符串\"></a><strong>二、切割字符串</strong></h1><p>用同样的方法我们也可以来切割字符串，比如下面的字符串：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sample_url = &#x27;http://shileilei.com&#x27;</span><br><span class=\"line\">print (sample_url)</span><br></pre></td></tr></table></figure>\n\n<p>我们如果直接运行，就会把我们的<a href=\"http://shileilei.com/\">http://shileilei.com</a>的网站给输出出来。但我们怎么才能将它们倒着输出呢？我们可以用前面学到的知识，来这样做：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sample_url = &#x27;http://shileilei.com&#x27;</span><br><span class=\"line\">print(sample_url[::-1])</span><br></pre></td></tr></table></figure>\n\n<p>输出结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">moc.ielielihs//:ptth</span><br></pre></td></tr></table></figure>\n\n<p>同样的，如果我们想知道一级域名是什么，应该这样做：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sample_url = &#x27;http://shileilei.com&#x27;</span><br><span class=\"line\">print(sample_url[-4::])</span><br></pre></td></tr></table></figure>\n\n<p>如果只想输出不带http:&#x2F;&#x2F;的网址，应当这样做：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sample_url = &#x27;http://shileilei.com&#x27;</span><br><span class=\"line\">print(sample_url[7:])</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Python"],"tags":["计算机","编程","python","切割列表和字符串"]},{"title":"Python教程--元组(Tuple)和集合(set)","url":"/2021/01/10/python%E6%95%99%E7%A8%8B-%E5%85%83%E7%BB%84tuple%E5%92%8C%E9%9B%86%E5%90%88set/","content":"<p><strong>这篇文章将会分享关于python中关于元组(Tuple)和集合(set)的一些相关知识</strong>。</p>\n<span id=\"more\"></span>\n<p>在上一篇文章中我们分享了关于列表的一些相关知识。如果掌握了上一篇讲的关于列表的知识，那么这一章节的内容就会非常容易理解。</p>\n<h1 id=\"一、元组（Tuple）\"><a href=\"#一、元组（Tuple）\" class=\"headerlink\" title=\"一、元组（Tuple）\"></a><strong>一、元组（Tuple）</strong></h1><p>先举一个例子，来说明什么是元组，它和列表有什么联系和区别？先看一个列表的例子</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">list_1 = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;]</span><br><span class=\"line\">list_2 = list_1</span><br><span class=\"line\"></span><br><span class=\"line\">print(list_1)</span><br><span class=\"line\">print(list_2)</span><br><span class=\"line\"></span><br><span class=\"line\">list_1[0] = &#x27;Art&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\">print(list_1)</span><br><span class=\"line\">print(list_2)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;]</span><br><span class=\"line\">[&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;]</span><br><span class=\"line\">[&#x27;Art&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;]</span><br><span class=\"line\">[&#x27;Art&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;]</span><br></pre></td></tr></table></figure>\n\n<p>我们发现，列表中的元素是可以进行变更的。元组跟列表看起啦非常相似，但是是用圆括号来括起来的。除了这点不同，还有别的区别吗？我们还同样的例子，再来用元组运行一下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">tuple_1 = (&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;)</span><br><span class=\"line\">tuple_2 = tuple_1</span><br><span class=\"line\"></span><br><span class=\"line\">print(tuple_1)</span><br><span class=\"line\">print(tuple_2)</span><br><span class=\"line\"></span><br><span class=\"line\">tuple_1[0] = &#x27;Art&#x27;</span><br><span class=\"line\">print(tuple_1)</span><br><span class=\"line\">print(tuple_2)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">(&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;)Traceback (most recent call last):</span><br><span class=\"line\">  File &quot;\\\\DESKTOP-RGP481O\\Users\\Leilei\\Python\\Lists_Tuples_Sets_T4-2.py&quot;, line 20, in &lt;module&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">(&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;)</span><br><span class=\"line\">    tuple_1[0] = &#x27;Art&#x27;</span><br><span class=\"line\">TypeError: &#x27;tuple&#x27; object does not support item assignment</span><br><span class=\"line\">[Finished in 0.3s]</span><br></pre></td></tr></table></figure>\n\n<p>我们发现运行结果出现了错误提示。提示“TypeError: ‘tuple’ object does not support item assignment”。这就揭示了<strong>元组与列表最大的一个不同点：元组不可变更，而列表可以</strong>。</p>\n<h1 id=\"二、集合-Set\"><a href=\"#二、集合-Set\" class=\"headerlink\" title=\"二、集合(Set)\"></a><strong>二、集合(Set)</strong></h1><p>除了列表和元组，python中还有另一个非常相似的概念-集合(set)。从外观来看，集合是用大括号来将里面的不同元素括起来。除了外观的不同之外，集合跟但列表和元组还有一个很大不同：<strong>集合(set)中的元素没有顺序，而列表和元组中的元素有顺序</strong>。我们来看下面这个例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">cs_courses = &#123;&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;&#125;</span><br><span class=\"line\">print(cs_courses)</span><br><span class=\"line\">print(&#x27;Math&#x27; in cs_courses)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;&#x27;Physics&#x27;, &#x27;History&#x27;, &#x27;CompSci&#x27;, &#x27;Math&#x27;&#125;</span><br><span class=\"line\">True</span><br></pre></td></tr></table></figure>\n\n<p>我们会发现，输出结果中的元素顺序跟我们输入的并不相同。如果多次运行，我们都会得到不一样的结果。所以集合更在意里面有什么元素，而不在乎他们的顺序是什么。<strong>对于验证某个某个元素是否在某个集合中，我们采用集合也会更为高效</strong>（虽然列表和元组也可以同样做到这一点）。</p>\n<p>另外，要说的一点是，<strong>集合中的元素不可以重复。如果有重复元素，集合将会将多余重复元素删除</strong>。比如我们下面这个例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">cs_courses = &#123;&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;&#125;</span><br><span class=\"line\">art_courses = &#123;&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Art&#x27;, &#x27;Design&#x27;&#125;</span><br><span class=\"line\">print(cs_courses.intersection(art_courses)) # show intersection between two sets</span><br><span class=\"line\">print(cs_courses.difference(art_courses)) # show difference between two sets</span><br><span class=\"line\">print(cs_courses.union(art_courses)) # combine two sets</span><br></pre></td></tr></table></figure>\n\n<p>输出结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;&#x27;History&#x27;, &#x27;Math&#x27;&#125;</span><br><span class=\"line\">&#123;&#x27;CompSci&#x27;, &#x27;Physics&#x27;&#125;</span><br><span class=\"line\">&#123;&#x27;History&#x27;, &#x27;Design&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;Art&#x27;, &#x27;CompSci&#x27;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们会发现，虽然两个集合中都含有History和Math元素，但在最后的合并结果中，这些元素都只出现了一次。另外，我们通过这个例子，也学会了怎么使用interesection( )、difference( )和union( )来对不同集合中的元素寻找交集、补集和并集。</p>\n<h1 id=\"三、空列表-Empty-List-、空元组-Empty-Tuple-和空集合-Empty-Set\"><a href=\"#三、空列表-Empty-List-、空元组-Empty-Tuple-和空集合-Empty-Set\" class=\"headerlink\" title=\"三、空列表(Empty List)、空元组(Empty Tuple)和空集合(Empty Set)\"></a><strong>三、空列表(Empty List)、空元组(Empty Tuple)和空集合(Empty Set)</strong></h1><p>对于怎么表示空的列表、元组和集合，这里有一点需要十分注意：空的集合不可用{ }来表示，因为空的大括号表示一个空的字典。字典我们将在下一章中学到，这里先提前提醒一下。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># Empty list</span><br><span class=\"line\">empty_list = []</span><br><span class=\"line\">empty_list = list()</span><br><span class=\"line\"></span><br><span class=\"line\"># Empty tuples</span><br><span class=\"line\">empty_tuple = ()</span><br><span class=\"line\">empty_tuple = tuple()</span><br><span class=\"line\"></span><br><span class=\"line\"># Empty sets</span><br><span class=\"line\">empty_set = &#123;&#125; # 注意：这不是空集合的正确表示方式，这里的大括号代表一个空的字典。</span><br><span class=\"line\">empty_set = set()</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Python"],"tags":["计算机","编程","python","元组和集合"]},{"title":"Python教程--在windows和mac上安装和设置python","url":"/2021/01/09/python%E6%95%99%E7%A8%8B-%E5%9C%A8windows%E5%92%8Cmac%E4%B8%8A%E5%AE%89%E8%A3%85%E5%92%8C%E8%AE%BE%E7%BD%AEpython/","content":"<p><strong>这篇文章将会分享如何在windows和mac上安装、设置和使用python。</strong></p>\n<span id=\"more\"></span>\n<h1 id=\"一、Mac上python3的安装和设置\"><a href=\"#一、Mac上python3的安装和设置\" class=\"headerlink\" title=\"一、Mac上python3的安装和设置\"></a><strong>一、Mac上python3的安装和设置</strong></h1><p>在mac上一般都已经预装了python，可以通过在terminal 输入以下指令来查看python是否安装以及版本信息：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">python --version</span><br></pre></td></tr></table></figure>\n\n<p>一般mac预装的python版本为python 2.7，如果你想安装最新的python 3可以跟着下面的教程来进行安装。</p>\n<p>进入<a href=\"http://www.python.org/downloads/\">www.python.org/downloads/</a>然后网站会直接检测到所使用的电脑为mac然后点击下载最新版本的python。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/python_install-2-1024x661.png\" alt=\"www.shileilei.com 安装python 3\"></p>\n<p>下载好之后，点击安装。安装好之后，再次打开terminal检查python 3的版本：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">python3 --version</span><br></pre></td></tr></table></figure>\n\n<p>注意：这里python和python3是不同的。调用python会调出python 2，而使用python3才会调用python3。</p>\n<h1 id=\"二、windows上python3的安装和设置\"><a href=\"#二、windows上python3的安装和设置\" class=\"headerlink\" title=\"二、windows上python3的安装和设置\"></a><strong>二、windows上python3的安装和设置</strong></h1><p>我们先打开终端(win+R键打开运行，然后输入cmd回车)来检查是否在windows上已经安装了python。输入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">python --version</span><br></pre></td></tr></table></figure>\n\n<p>如果需要安装python，同样进入<a href=\"http://www.python.org/downloads/\">www.python.org/downloads/</a>然后网站会直接检测到所使用的电脑系统，然后点击下载最新版本的python。</p>\n<p>下载好之后，点击安装。安装好之后，再次打开命令窗口，检查python的版本：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">python --version</span><br></pre></td></tr></table></figure>\n\n<p>如果安装成功，则会出现python的版本信息。</p>\n<h1 id=\"三、使用python\"><a href=\"#三、使用python\" class=\"headerlink\" title=\"三、使用python\"></a><strong>三、使用python</strong></h1><p>我们可以使用terminal来打开python，在命令行中输入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">python3</span><br></pre></td></tr></table></figure>\n\n<p>我们会看到“&gt;&gt;&gt;”这样的符号，表示我们进入了python3的运行界面。</p>\n<p>虽然这样也是可以运行python，但是我们希望可以有一个可编辑的python文件，并且具有更方便的可操作性。我们就需要使用python文本编辑器，python自带的文本编辑器叫做IDLE。找到IELD的应用程序，然后打开就可以写出我们的第一个python程序了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">print(&quot;Hello World!&quot;)</span><br></pre></td></tr></table></figure>\n\n<p>将这个文件保存之后，打开terminal 使用就可以运行我们刚刚写好的第一个python程序了。以这个文件的保存路径为桌面，文件名为intro.py为例，在terminal中输入以下代码，然后回车，我们刚刚写好的python程序就会运行，然后terminal就会给我们返回 Hello World! 这段文字。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">python3 ~/Desktop/intro.py</span><br></pre></td></tr></table></figure>\n\n<p>我们还可以用一些界面更加友好的第三方编辑软件，比如PyCharm，Sublime Text等等。</p>\n<p>个人比较推荐Sublime Text，可以在这里下载<a href=\"https://www.sublimetext.com/3\">https://www.sublimetext.com/3</a>。</p>\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","python","安装和设置"]},{"title":"Python教程--包管理器-pip","url":"/2021/01/13/python%E6%95%99%E7%A8%8B-%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8-pip/","content":"<p><strong>这篇文章中将会分享python中包管理器-pip相关的一些知识。</strong></p>\n<span id=\"more\"></span>\n<p>pip 是 Python 包管理工具，该工具提供了对Python 包的查找、下载、安装、卸载的功能。如果你是从官方下载的python软件，那么已经自带了pip包管理器。另外，Python 2.7.9 + 或 Python 3.4+ 以上版本也都自带 pip 工具。</p>\n<p>你可以通过以下命令来判断是否已安装：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip --version</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"一、pip-常用命令\"><a href=\"#一、pip-常用命令\" class=\"headerlink\" title=\"一、pip 常用命令\"></a><strong>一、pip 常用命令</strong></h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install PackageName   #安装包 PackageName代指需要下载的包的名称</span><br><span class=\"line\">pip uninstall PackageName    #卸载包</span><br><span class=\"line\">pip list    #列出所有安装的包</span><br><span class=\"line\">pip install --upgrade PackageName    #升级包</span><br><span class=\"line\">pip show PackageName    #显示包的详细信息</span><br><span class=\"line\">pip list -o 或者 pip list --outdated    #显示可升级的包</span><br><span class=\"line\">pip freeze    #把已安装的包以requirements参数的格式输出</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、打包发送所依赖的安装包\"><a href=\"#二、打包发送所依赖的安装包\" class=\"headerlink\" title=\"二、打包发送所依赖的安装包\"></a><strong>二、打包发送所依赖的安装包</strong></h1><p>如果我们创建了一个python程序，想要在别人的电脑上运行。那么我们就需要把这个程序所依赖的所有包也要一同发送给对方，这样对方才能在同一个环境下运行我们所创建的程序。我们就可以把所需要的包用以下代码输出到一个txt文件中：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip freeze &gt; requirements.txt</span><br></pre></td></tr></table></figure>\n\n<p>只要把这个requirements.txt文件发送给对方，然后在对方电脑输入以下指令，就可以安装所有所需的包：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、自动更新所有可升级的包\"><a href=\"#三、自动更新所有可升级的包\" class=\"headerlink\" title=\"三、自动更新所有可升级的包\"></a><strong>三、自动更新所有可升级的包</strong></h1><p>如果我们运行pip list -o 或者 pip list –outdated之后，我们发现需要更新的包太多，不想一个一个手动升级更新，我们可以运行以下代码完成一次性更新所有包：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">pip list --outdated --format=freeze  grep -v &#x27;^\\-e&#x27;  cut -d = -f 1   xargs -n1 pip install -U</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","python","pip"]},{"title":"Python教程--列表(List）","url":"/2021/01/09/python%E6%95%99%E7%A8%8B-%E5%88%97%E8%A1%A8list/","content":"<p><strong>这篇文章将会分享关于python中关于列表(list)的一些相关知识</strong>。</p>\n<span id=\"more\"></span>\n<p>前面我们已经学习了字符串(string)和数字(number)，那么接下来我们将会把这些字符串或者数字组合到一起，从而进行一些运算。这些字符串或者数字的组合有四种，包括列表(list)、元组(Tuple)、集合(set)和字典(dictionary)。首先，我们学习最为重要的列表(list)相关知识。</p>\n<h1 id=\"一、列表的特征\"><a href=\"#一、列表的特征\" class=\"headerlink\" title=\"一、列表的特征\"></a><strong>一、列表的特征</strong></h1><p>列表是Python中最具灵活性的有序集合对象类型，与字符串不同的是：列表可以包含任何种类的对象，包括数字、字符串、甚至是其他列表。</p>\n<p>列表都是可变对象，<strong>它支持在原处修改的操作</strong>。也可以通过指定的索引和分片获取元素，用中括号[ ]来定义。</p>\n<p>比如有一个名为courses的列表，包含了几门课程(History, Math, Physics, CompSci)，则应当写成如下格式：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;]  </span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、列表的基本操作\"><a href=\"#二、列表的基本操作\" class=\"headerlink\" title=\"二、列表的基本操作\"></a><strong>二、列表的基本操作</strong></h1><p>获取列表长度：len( )。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;]</span><br><span class=\"line\">print(len(courses))</span><br></pre></td></tr></table></figure>\n\n<p>则输出结果为其长度：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">4</span><br></pre></td></tr></table></figure>\n\n<p>返回其中某一个元素。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;]</span><br><span class=\"line\">print(courses[0]) #输出序列号为0的元素</span><br><span class=\"line\">print(courses[-1]) #输出最后一个元素</span><br><span class=\"line\">print(courses[0:2]) #输出序列号从0到2的元素</span><br></pre></td></tr></table></figure>\n\n<p>这里需要提一下，在python中序列号是从0开始算起。[0:2]代表列表中第一和第二个元素，[1:3]则代表第二和第三个元素。</p>\n<p>以上代码的输出结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">4</span><br><span class=\"line\">History</span><br><span class=\"line\">CompSci</span><br><span class=\"line\">[&#x27;History&#x27;, &#x27;Math&#x27;]</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、在列表中添加、插入和删除元素\"><a href=\"#三、在列表中添加、插入和删除元素\" class=\"headerlink\" title=\"三、在列表中添加、插入和删除元素\"></a><strong>三、在列表中添加、插入和删除元素</strong></h1><p>如果我们想要在一个列表后面加入一个元素，可以用append。还拿上面的courses列表来举例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">courses.append(&#x27;Art&#x27;)</span><br><span class=\"line\">print(courses)</span><br></pre></td></tr></table></figure>\n\n<p>将会返回如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;, &#x27;Art&#x27;]</span><br></pre></td></tr></table></figure>\n\n<p>如果我们想要把元素插入到特定位置，则可以用insert。例子如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">courses.insert(0,&#x27;PE&#x27;)</span><br><span class=\"line\">print(courses)</span><br></pre></td></tr></table></figure>\n\n<p>则会在index为0的位置插入PE，结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;PE&#x27;, &#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;]</span><br></pre></td></tr></table></figure>\n\n<p>那么，我们如果插入的是一个列表(list)那应该怎么办呢？是不是还可用前面提到的append或者insert?我们试一下看看得到什么结果。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">courses_2 = [&#x27;Art&#x27;,&#x27;Education&#x27;]</span><br><span class=\"line\">courses.insert(4,courses_2)</span><br><span class=\"line\">print (courses)</span><br></pre></td></tr></table></figure>\n\n<p>其返回结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;, [&#x27;Art&#x27;, &#x27;Education&#x27;]]</span><br></pre></td></tr></table></figure>\n\n<p>我们发现，用insert或者append会把列表本身作为一个元素插入进去。一般来说，这并不是我们想要的。那么我们应该怎么在一个列表中插入另一个列表呢？这就用到了extend。用法如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">courses_2 = [&#x27;Art&#x27;,&#x27;Education&#x27;]</span><br><span class=\"line\">courses.extend(courses_2)</span><br><span class=\"line\">print (courses)</span><br></pre></td></tr></table></figure>\n\n<p>其运行的结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;, &#x27;Art&#x27;, &#x27;Education&#x27;]</span><br></pre></td></tr></table></figure>\n\n<p>我们发现，这次我们得到了想要的结果：第二个列表中的元素分别合并到了第一个列表中。</p>\n<p>接下来我们讲怎么从列表中删除某个元素。常用的删除方法有两个：remove( )和pop( )。先说说remove( )，remove( ) 是删除首个符合条件的元素。用法如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;, &#x27;Art&#x27;, &#x27;Education&#x27;]</span><br><span class=\"line\">courses.remove(&#x27;Math&#x27;)</span><br><span class=\"line\">print (courses)</span><br></pre></td></tr></table></figure>\n\n<p>运行程序，Math元素将会被移除，然后得到如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;History&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;, &#x27;Art&#x27;, &#x27;Education&#x27;]</span><br></pre></td></tr></table></figure>\n\n<p>我们再来看看pop( )：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;, &#x27;Art&#x27;, &#x27;Education&#x27;]</span><br><span class=\"line\">popped = courses.pop(-1)</span><br><span class=\"line\">print (popped)</span><br><span class=\"line\">print (courses)</span><br></pre></td></tr></table></figure>\n\n<p>将会得到如下运行结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Education</span><br><span class=\"line\">[&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;, &#x27;Art&#x27;]</span><br></pre></td></tr></table></figure>\n\n<p>我们会发现，pop是根据索引（元素所在位置）来删除的。并且，pop会返回弹出的那个数值。</p>\n<h1 id=\"四、列表中元素的排序和筛选\"><a href=\"#四、列表中元素的排序和筛选\" class=\"headerlink\" title=\"四、列表中元素的排序和筛选\"></a><strong>四、列表中元素的排序和筛选</strong></h1><p>如果我们想要把一个列表中的元素顺序倒过来，应该怎么做呢？这时候我们可以用到reverse( )。用法如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">courses.reverse()</span><br><span class=\"line\">print (courses)</span><br></pre></td></tr></table></figure>\n\n<p>那么列表中元素将会反过来排列，得到如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;CompSci&#x27;, &#x27;Physics&#x27;, &#x27;Math&#x27;, &#x27;History&#x27;]</span><br></pre></td></tr></table></figure>\n\n<p>如果我们想要把列表中元素按照字母表的顺序排列，则会用到sort( )。用法如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">courses.sort()</span><br><span class=\"line\">print (courses)</span><br></pre></td></tr></table></figure>\n\n<p>那么列表中元素将会以首字母按照字母表顺序排列，得到如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;CompSci&#x27;, &#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;]</span><br></pre></td></tr></table></figure>\n\n<p>如果列表中元素是数字，则会按照从小到大排列。还可以用max( )、min( )和 sum( )对数字进行最大值、最小值和求和的计算。用法如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1, 5, 3, 8]</span><br><span class=\"line\">nums.sort()</span><br><span class=\"line\">print(nums)</span><br><span class=\"line\">print (min(nums)) </span><br><span class=\"line\">print (max(nums)) </span><br><span class=\"line\">print (sum(nums)) </span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[1, 3, 5, 8]</span><br><span class=\"line\">1</span><br><span class=\"line\">8</span><br><span class=\"line\">17</span><br></pre></td></tr></table></figure>\n\n<p>如果我们不想按照正序排列，则可以给sort加一个条件sort(reverse &#x3D; True)来实现。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ums = [1, 5, 3, 8]</span><br><span class=\"line\">nums.sort(reverse = True)</span><br><span class=\"line\">print(nums)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[8, 5, 3, 1]</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"五、在列表中查找元素\"><a href=\"#五、在列表中查找元素\" class=\"headerlink\" title=\"五、在列表中查找元素\"></a><strong>五、在列表中查找元素</strong></h1><p>如果我们想要查找某一个元素是否在列表中，或者想要知道某个特定元素的位置，可以用如下方法来实现：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">print (&#x27;Art&#x27; in courses)</span><br><span class=\"line\">print(courses.index(&#x27;Math&#x27;)) </span><br></pre></td></tr></table></figure>\n\n<p>其运行输出结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">False</span><br><span class=\"line\">1</span><br></pre></td></tr></table></figure>\n\n<p>Flase表示列表中没有art元素，第二个输出的1给出了我们Math在列表中处在第二个元素的位置（第一个元素为0）。</p>\n<h1 id=\"六、列表中的元素按照指定格式输出和还原\"><a href=\"#六、列表中的元素按照指定格式输出和还原\" class=\"headerlink\" title=\"六、列表中的元素按照指定格式输出和还原\"></a><strong>六、列表中的元素按照指定格式输出和还原</strong></h1><p>还是上面那个courses的列表，如果我们不想要按照原来的列表格式输出，而是想要每个元素之间都隔一个逗号或者短横线输出，那该怎么办呢？这时候我们可以用join( )来把列表中元素按照特定格式来组成一个字符串。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">course_str = &#x27;, &#x27;.join(courses)</span><br><span class=\"line\">print(course_str)</span><br><span class=\"line\">course_str = &#x27; - &#x27;.join(courses)</span><br><span class=\"line\">print(course_str)</span><br></pre></td></tr></table></figure>\n\n<p>将会得到如下输出结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">History, Math, Physics, CompSci</span><br><span class=\"line\">History - Math - Physics - CompSci</span><br></pre></td></tr></table></figure>\n\n<p>我们这时候又想把原先变成字符串的列表还原，又该用什么方法呢？这时候可以用split( )将字符串还原为列表。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">course_str = History - Math - Physics - CompSci</span><br><span class=\"line\">new_list = course_str.split(&#x27; - &#x27;) </span><br><span class=\"line\">print (new_list)</span><br></pre></td></tr></table></figure>\n\n<p>其运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;, &#x27;CompSci&#x27;]</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","python","列表"]},{"title":"Python教程–字典(Dictionary）","url":"/2021/01/10/python%E6%95%99%E7%A8%8B-%E5%AD%97%E5%85%B8dictionary%EF%BC%89/","content":"<p><strong>这篇文章将会分享关于python中关于字典(Dictionary）的一些相关知识</strong></p>\n<span id=\"more\"></span>\n<p>前面我们学习了python中三个非常重要的概念：列表(List)、元组(Tuple)和集合(Set)。接下来我们再学习最后一个非常重要的承载数据的集合：字典(Dictionary）。</p>\n<h1 id=\"一、什么是字典-Dictionary\"><a href=\"#一、什么是字典-Dictionary\" class=\"headerlink\" title=\"一、什么是字典(Dictionary)?\"></a><strong>一、什么是字典(Dictionary)?</strong></h1><p>字典定义了键(key)和值(value)之间一对一的关系，并且是以无序的方式储存的。跟集合(Set)非常像的一点是：定义 Dictionary 也同样是使用一对大括号 { }。 先看一个例子，来初步了解一下集合：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;courses&#x27;:[&#x27;Math&#x27;,&#x27;CompSci&#x27;]&#125;</span><br><span class=\"line\">print (student)</span><br><span class=\"line\">print (student[&#x27;name&#x27;])</span><br><span class=\"line\">print (student[&#x27;courses&#x27;])</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;&#x27;name&#x27;: &#x27;John&#x27;, &#x27;age&#x27;: 25, &#x27;courses&#x27;: [&#x27;Math&#x27;, &#x27;CompSci&#x27;]&#125;</span><br><span class=\"line\">John</span><br><span class=\"line\">[&#x27;Math&#x27;, &#x27;CompSci&#x27;]</span><br></pre></td></tr></table></figure>\n\n<p>我们发现字典中的元素都是成对出现的，一个是代表元素名称的“键(key)”，另一个是代表元素内容的“值(value)”。</p>\n<h1 id=\"二、get方法来获取字典中的元素\"><a href=\"#二、get方法来获取字典中的元素\" class=\"headerlink\" title=\"二、get方法来获取字典中的元素\"></a><strong>二、get方法来获取字典中的元素</strong></h1><p>上面获取字典元素的方法虽然简单，但却有一个问题：如果我们想要的获取的元素不存在，将会出现错误提示，然后整个程序都会无法运行。这个问题，我们可以用get方法来解决。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;courses&#x27;:[&#x27;Math&#x27;,&#x27;CompSci&#x27;]&#125;</span><br><span class=\"line\">print (student.get(&#x27;name&#x27;))</span><br><span class=\"line\">print (student.get(&#x27;phone&#x27;))</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">John</span><br><span class=\"line\">None</span><br></pre></td></tr></table></figure>\n\n<p>我们会发现，对于字典中没有phone，程序给我们返回了一个默认的None值，并且没有出现错误提示。那么如果我们想要返回一个自己设定的字符串，应该怎么做呢？请看下面的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;courses&#x27;:[&#x27;Math&#x27;,&#x27;CompSci&#x27;]&#125;</span><br><span class=\"line\">print (student.get(&#x27;phone&#x27;,&#x27;Not Found&#x27;))</span><br></pre></td></tr></table></figure>\n\n<p>我们再次运行会发现，结果变为了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Not Found</span><br></pre></td></tr></table></figure>\n\n<p>但如果这个phone在字典中存在的时候呢？这种方法就不再给我们返回Not Found，而是会给我们返回它所对应的值。比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student[&#x27;phone&#x27;] = &#x27;555-5555&#x27;</span><br><span class=\"line\">print (student.get(&#x27;phone&#x27;,&#x27;Not Found&#x27;))</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">555-5555</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、update方法更新字典中的元素\"><a href=\"#三、update方法更新字典中的元素\" class=\"headerlink\" title=\"三、update方法更新字典中的元素\"></a><strong>三、update方法更新字典中的元素</strong></h1><p>如果我们需要更新字典中的某对元素，我们可以使用update的方法来进行更新。具体使用方法可以参考下面的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;phone&#x27;:&#x27;555-5555&#x27;&#125;</span><br><span class=\"line\">print (student)</span><br><span class=\"line\">student.update(&#123;&#x27;name&#x27;:&#x27;Ann&#x27;,&#x27;age&#x27;:&#x27;26&#x27;,&#x27;phone&#x27;:&#x27;222-2222&#x27;&#125;)</span><br><span class=\"line\">print (student)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;&#x27;name&#x27;: &#x27;John&#x27;, &#x27;age&#x27;: 25, &#x27;phone&#x27;: &#x27;555-5555&#x27;&#125;</span><br><span class=\"line\">&#123;&#x27;name&#x27;: &#x27;Ann&#x27;, &#x27;age&#x27;: &#x27;26&#x27;, &#x27;phone&#x27;: &#x27;222-2222&#x27;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们会发现使用update的方法，字典内容得到了更新。</p>\n<h1 id=\"四、del或者pop方法删除字典中的元素\"><a href=\"#四、del或者pop方法删除字典中的元素\" class=\"headerlink\" title=\"四、del或者pop方法删除字典中的元素\"></a><strong>四、del或者pop方法删除字典中的元素</strong></h1><p>如果想要删除字典中的某对元素，我们可以使用del或者pop来进行删除。先来讲一下del如何使用。我们可以参考下面的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;phone&#x27;:&#x27;555-5555&#x27;&#125;</span><br><span class=\"line\">del student[&#x27;age&#x27;]</span><br><span class=\"line\">print (student)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;&#x27;name&#x27;: &#x27;John&#x27;, &#x27;phone&#x27;: &#x27;555-5555&#x27;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们发现age所对应的key和value都被删除掉了。</p>\n<p>我们也可以使用pop( )来对字典中某对元素进行删除，并且我们还可以将所删除的元素进行输出。比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;phone&#x27;:&#x27;555-5555&#x27;&#125;</span><br><span class=\"line\">age = student.pop(&#x27;age&#x27;)</span><br><span class=\"line\">print (student)</span><br><span class=\"line\">print (age)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;&#x27;name&#x27;: &#x27;John&#x27;, &#x27;phone&#x27;: &#x27;555-5555&#x27;&#125;</span><br><span class=\"line\">25</span><br></pre></td></tr></table></figure>\n\n<p>我们发现跟del方法一样，age这一对元素在字典中被删除掉了。并且我们还可以得到被删除的age所对应的内容。</p>\n<h1 id=\"五、输出字典中的key和value\"><a href=\"#五、输出字典中的key和value\" class=\"headerlink\" title=\"五、输出字典中的key和value\"></a><strong>五、输出字典中的key和value</strong></h1><p>如果我们只想输出key值，可以使用keys( )的方法。如果只想输出value值，可以使用values( )的方法。而如果想一起输出，我们可以使用item( )的方法。具体使用方法如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;phone&#x27;:&#x27;555-5555&#x27;&#125;</span><br><span class=\"line\">print (len(student))</span><br><span class=\"line\">print (student.keys())</span><br><span class=\"line\">print (student.values())</span><br><span class=\"line\">print (student.items())</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">dict_keys([&#x27;name&#x27;, &#x27;age&#x27;, &#x27;phone&#x27;])</span><br><span class=\"line\">dict_values([&#x27;John&#x27;, 25, &#x27;555-5555&#x27;])</span><br><span class=\"line\">dict_items([(&#x27;name&#x27;, &#x27;John&#x27;), (&#x27;age&#x27;, 25), (&#x27;phone&#x27;, &#x27;555-5555&#x27;)])</span><br></pre></td></tr></table></figure>\n<h1 id=\"六、遍历字典中的key和value\"><a href=\"#六、遍历字典中的key和value\" class=\"headerlink\" title=\"六、遍历字典中的key和value\"></a><strong>六、遍历字典中的key和value</strong></h1><p>接下来我们来看一下如何遍历字典中的key和value。</p>\n<h2 id=\"1-遍历key值：\"><a href=\"#1-遍历key值：\" class=\"headerlink\" title=\"1. 遍历key值：\"></a>1. 遍历key值：</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;phone&#x27;:&#x27;555-5555&#x27;&#125;</span><br><span class=\"line\">for key in student:</span><br><span class=\"line\">  print (key)</span><br></pre></td></tr></table></figure>\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">name</span><br><span class=\"line\">age</span><br><span class=\"line\">phone</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-遍历value值：\"><a href=\"#2-遍历value值：\" class=\"headerlink\" title=\"2. 遍历value值：\"></a>2. 遍历value值：</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;phone&#x27;:&#x27;555-5555&#x27;&#125;</span><br><span class=\"line\">for value in student.values():</span><br><span class=\"line\">  print (value)</span><br></pre></td></tr></table></figure>\n<p>结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">John</span><br><span class=\"line\">25</span><br><span class=\"line\">555-5555</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-遍历字典项：\"><a href=\"#3-遍历字典项：\" class=\"headerlink\" title=\"3. 遍历字典项：\"></a>3. 遍历字典项：</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;phone&#x27;:&#x27;555-5555&#x27;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">for item in student.items():</span><br><span class=\"line\">  print(item)</span><br></pre></td></tr></table></figure>\n<p>结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">(&#x27;name&#x27;, &#x27;John&#x27;)</span><br><span class=\"line\">(&#x27;age&#x27;, 25)</span><br><span class=\"line\">(&#x27;phone&#x27;, &#x27;555-5555&#x27;)</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-遍历字典的key和value：\"><a href=\"#4-遍历字典的key和value：\" class=\"headerlink\" title=\"4. 遍历字典的key和value：\"></a>4. 遍历字典的key和value：</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">student = &#123;&#x27;name&#x27;:&#x27;John&#x27;,&#x27;age&#x27;:25,&#x27;phone&#x27;:&#x27;555-5555&#x27;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">for key, value in student.items():</span><br><span class=\"line\">  print(key + &quot;:&quot; + str(value)</span><br></pre></td></tr></table></figure>\n<p>结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">name:John</span><br><span class=\"line\">age:25</span><br><span class=\"line\">phone:555-5555</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","python","字典"]},{"title":"Python教程--字符串(String)","url":"/2021/01/09/python%E6%95%99%E7%A8%8B-%E5%AD%97%E7%AC%A6%E4%B8%B2string/","content":"<p><strong>这篇文章将会分享关于python中关于string的一些相关知识</strong>。</p>\n<span id=\"more\"></span>\n<p>在上一篇文章中我们写出了我们的第一个python程序。接下来我们更加深入的学习一些关于字符串的命令和操作。</p>\n<h1 id=\"一、结果中输出单引号\"><a href=\"#一、结果中输出单引号\" class=\"headerlink\" title=\"一、结果中输出单引号\"></a><strong>一、结果中输出单引号</strong></h1><p>要输出一段字符串我们知道可以这样来输出：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">message = &#x27;Hello World!&#x27;</span><br><span class=\"line\">print = (message)</span><br></pre></td></tr></table></figure>\n\n<p>那么我们要输出的字符串中本身就有单引号或者双引号应该怎么办呢？比如我们想要输出Bobby’s World，如果还像上面一样这样写代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">message = &#x27;Bobby&#x27;s World&#x27;</span><br><span class=\"line\">print = (message)</span><br></pre></td></tr></table></figure>\n\n<p>就会出现问题，因为有三个单引号，计算机无法识别到底哪里是需要输出的内容。要解决这个问题，我们有三个方案。</p>\n<h3 id=\"方案一：使用双引号\"><a href=\"#方案一：使用双引号\" class=\"headerlink\" title=\"方案一：使用双引号\"></a>方案一：使用双引号</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">message = “Bobby&#x27;s World”</span><br><span class=\"line\">print = (message)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"方案二：使用-来标记\"><a href=\"#方案二：使用-来标记\" class=\"headerlink\" title=\"方案二：使用\\来标记\"></a>方案二：使用\\来标记</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">message = &#x27;Bobby\\&#x27;s World&#x27;</span><br><span class=\"line\">print = (message)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"方案三：使用三个单引号’’’-‘’’\"><a href=\"#方案三：使用三个单引号’’’-‘’’\" class=\"headerlink\" title=\"方案三：使用三个单引号’’’ ‘’’\"></a>方案三：使用三个单引号’’’ ‘’’</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">message = &#x27;‘’Bobby&#x27;s World&#x27;‘’</span><br><span class=\"line\">print = (message)</span><br></pre></td></tr></table></figure>\n\n<p>当采用方案三的时候，我们还可以进行多行输出，比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">message = &#x27;&#x27;&#x27;I like Bobby\\&#x27; </span><br><span class=\"line\">world&#x27;&#x27;&#x27;</span><br><span class=\"line\">print (message)</span><br></pre></td></tr></table></figure>\n\n<p>就会得到这样的输出结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">I like Bobby&#x27;</span><br><span class=\"line\">world</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、选择输出结果\"><a href=\"#二、选择输出结果\" class=\"headerlink\" title=\"二、选择输出结果\"></a><strong>二、选择输出结果</strong></h1><p>如果我们不想要把所有的结果都输出出来，我们可以选择部分输出，比如输入这样的代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">message = &#x27;Bobby\\&#x27; world&#x27;</span><br><span class=\"line\">print (message)</span><br><span class=\"line\">print (message[10])</span><br><span class=\"line\">print (message[0:5])</span><br><span class=\"line\">print (message[:5])</span><br></pre></td></tr></table></figure>\n\n<p>就会相应得到这样的输出结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Bobby&#x27; world</span><br><span class=\"line\">l</span><br><span class=\"line\">Bobby</span><br><span class=\"line\">Bobby</span><br></pre></td></tr></table></figure>\n\n<p>方括号中可以选择字符的输出范围，注意是从0开始数。[0:5]代表的是从第1个字符到第5个字符。</p>\n<h1 id=\"三、大小写\"><a href=\"#三、大小写\" class=\"headerlink\" title=\"三、大小写\"></a><strong>三、大小写</strong></h1><p>如果我们要指定输出字符的大小写，可以用lower 和upper的方法，代码如下（#后面的部分为注释，不算入执行代码中）：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">message = &#x27;Bobby\\&#x27; world&#x27;</span><br><span class=\"line\">print (message.lower()) # output lower case</span><br><span class=\"line\">print (message.upper()) # output upper case</span><br></pre></td></tr></table></figure>\n\n<p>会得到这样的输出结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">bobby&#x27; world</span><br><span class=\"line\">BOBBY&#x27; WORLD</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"四、计数和查找\"><a href=\"#四、计数和查找\" class=\"headerlink\" title=\"四、计数和查找\"></a><strong>四、计数和查找</strong></h1><p>如果想要对字符串进行计数和查找，可以使用count和find的方法，举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">message = &#x27;Bobby\\&#x27; world&#x27;</span><br><span class=\"line\">print (message.count(&#x27;b&#x27;)) # 对字符串中b字母的个数进行计数</span><br><span class=\"line\">print (message.find(&#x27;world&#x27;)) # 对world所在的位置进行输出</span><br><span class=\"line\">print (message.find(&#x27;hello&#x27;)) # 如果所查找的字符出不存在则会返回-1</span><br></pre></td></tr></table></figure>\n\n<p>会得到这样的输出结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">2</span><br><span class=\"line\">7</span><br><span class=\"line\">-1</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"五、字符串组合输出\"><a href=\"#五、字符串组合输出\" class=\"headerlink\" title=\"五、字符串组合输出\"></a><strong>五、字符串组合输出</strong></h1><p>如果我们要对两段或两段以上不同的字符串进行输出，我们可以采用最简单的方法：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">greeting = &#x27;Hello&#x27;</span><br><span class=\"line\">name = &#x27;Michael&#x27;</span><br><span class=\"line\">message = greeting + &#x27;, &#x27; + name +&#x27;. Welcome!&#x27;</span><br><span class=\"line\">print (message)</span><br></pre></td></tr></table></figure>\n\n<p>这时候，我们就可以得到这样的输出结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Hello, Michael. Welcome!</span><br></pre></td></tr></table></figure>\n\n<p>数据量小的时候，还算比较方便。但如果数据量比较大的时候，这种方法就比较麻烦了，那么我们可以采用下面这种format的方法，用{ }来留下空位，然后后面用format来告诉程序，留下的空位需要填上什么：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">new_message = &#x27;&#123;&#125;, &#123;&#125;. Welcome!&#x27;.format(greeting, name)</span><br><span class=\"line\">print (new_message)</span><br></pre></td></tr></table></figure>\n\n<p>还可以采用更为简单的如下方法，在要输出的字符串前面加上 f 然后同样同{ }留空位，并且在{ }中填写这个位置中需要填上什么。代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">new_message = f&#x27;&#123;greeting&#125;, &#123;name&#125;. Welcome!&#x27; </span><br><span class=\"line\">print (new_message)</span><br></pre></td></tr></table></figure>\n\n<p>以上三种方法，都会输出同样的结果。但针对数据量比较大的时候，第二种和第三种方法就会显现出它的优势。</p>\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","python","string","字符串"]},{"title":"Python教程--循环(Loops and Iterations)","url":"/2021/01/11/python%E6%95%99%E7%A8%8B-%E5%BE%AA%E7%8E%AFloops-and-iterations/","content":"<p><strong>这篇文章将会分享关于python中关于循环(Loops and Iterations)的一些相关知识。</strong></p>\n<span id=\"more\"></span>\n<p>在前面的文章中，我们学习了列表、元组、集合、以及字典的相关知识。接下来我们要把我们学到的这些东西运动起来，从而让python发挥更加强大的作用。首先，我们进入循环语句的学习。</p>\n<h1 id=\"一、for-循环\"><a href=\"#一、for-循环\" class=\"headerlink\" title=\"一、for 循环\"></a><strong>一、for 循环</strong></h1><p>for 为遍历循环，可以遍历任何序列，如 list，tuple，迭代器等。先举一个最简单的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1, 2, 3, 4, 5]</span><br><span class=\"line\">for num in nums:</span><br><span class=\"line\">print (num)</span><br></pre></td></tr></table></figure>\n\n<p>运行程序，我们会得到如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Break-和-Continue\"><a href=\"#Break-和-Continue\" class=\"headerlink\" title=\"Break 和 Continue\"></a>Break 和 Continue</h2><p>上面是一个最简单的for循环的例子，它会把序列中的所有的元素都遍历一遍。但如果我们只想针对特定元素查找呢？如果还用前面的方法，在我们找到所需要的元素之后，后面的所有元素也会被接着循环。针对这个问题，我们可以在得到我们想要的结果之后，用break语句来结束循环。比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1, 2, 3, 4, 5]</span><br><span class=\"line\">for num in nums:</span><br><span class=\"line\">if num ==3:</span><br><span class=\"line\">print(&#x27;Found!&#x27;)</span><br><span class=\"line\">break</span><br><span class=\"line\">print (num)</span><br></pre></td></tr></table></figure>\n\n<p>执行程序，返回结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">Found!</span><br></pre></td></tr></table></figure>\n\n<p>与之相反的，如果我们想要跳过某种特定条件，然后还想让程序继续执行，我们可以用continue语句。比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1, 2, 3, 4, 5]</span><br><span class=\"line\">for num in nums:</span><br><span class=\"line\">if num ==3:</span><br><span class=\"line\">print(&#x27;Found!&#x27;)</span><br><span class=\"line\">continue</span><br><span class=\"line\">print (num)</span><br></pre></td></tr></table></figure>\n\n<p>执行程序，运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">Found!</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、循环的嵌套\"><a href=\"#二、循环的嵌套\" class=\"headerlink\" title=\"二、循环的嵌套\"></a><strong>二、循环的嵌套</strong></h1><p>如果数据结构比较复杂，直接用单循环会比较吃力。这时候就会用到嵌套循环，也就是说在一个循环体里面嵌入另一个循环。外循环每执行一次，内循环全部执行完。然后重复这个过程，直到外循环执行完毕，整个循环才会结束。我们举个简单的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1, 2, 3, 4, 5]</span><br><span class=\"line\">for num in nums:</span><br><span class=\"line\">for letter in&#x27;abc&#x27;:</span><br><span class=\"line\">print(num, letter)</span><br></pre></td></tr></table></figure>\n\n<p>执行程序，我们会得到如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1 a</span><br><span class=\"line\">1 b</span><br><span class=\"line\">1 c</span><br><span class=\"line\">2 a</span><br><span class=\"line\">2 b</span><br><span class=\"line\">2 c</span><br><span class=\"line\">3 a</span><br><span class=\"line\">3 b</span><br><span class=\"line\">3 c</span><br><span class=\"line\">4 a</span><br><span class=\"line\">4 b</span><br><span class=\"line\">4 c</span><br><span class=\"line\">5 a</span><br><span class=\"line\">5 b</span><br><span class=\"line\">5 c</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、while-循环\"><a href=\"#三、while-循环\" class=\"headerlink\" title=\"三、while 循环\"></a><strong>三、while 循环</strong></h1><p>除了使用for循环，python还给我们提供了另外一种循环：while循环。在大多数时候，for循环和while循环是可以互换的。但while循环在特定条件下可以发挥它高效而又神奇的功效。我们先举个例子来认识以下while循环：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">x = 0</span><br><span class=\"line\">while x &lt; 10:</span><br><span class=\"line\">print (x)</span><br><span class=\"line\">x +=1</span><br></pre></td></tr></table></figure>\n\n<p>运行程序，我们会得到如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">0</span><br><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td></tr></table></figure>\n\n<p>我们也可以使用for循环达到同样的效果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">for i in range(10):</span><br><span class=\"line\">print(i)</span><br></pre></td></tr></table></figure>\n\n<p>这种情况下，我们可以使用任意一种循环来执行我们所需的任务。但如果我们想要创建一个无限循环，也就是说我们想要创造一个一直运行下去直到得到我们想要的结果才停止的程序，那么while循环就比较好用了。比如下面这个例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">x = 0</span><br><span class=\"line\">while True:</span><br><span class=\"line\">if x == 5:</span><br><span class=\"line\">break</span><br><span class=\"line\">print (x)</span><br><span class=\"line\">x +=1</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">0</span><br><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td></tr></table></figure>\n\n<p>但这个程序有一个问题，就是如果一直找不到我们所要的结果，程序会一直运行下去。它不会自动终止，所以会一直耗用我们电脑的内存。如果我们想要终止这个无限循环的程序，我们可以按Ctr + c来跳出程序。</p>\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","python","循环"]},{"title":"Python教程--导入模块和标准库(Import Modules and Standard Library)","url":"/2021/01/13/python%E6%95%99%E7%A8%8B-%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97%E5%92%8C%E6%A0%87%E5%87%86%E5%BA%93import-modules-and-standard-library/","content":"<p><strong>这篇文章中将会分享python中关于导入模块和标准库(Import Modules and Exploring Standard Library</strong>)<strong>相关的一些知识。</strong></p>\n<span id=\"more\"></span>\n<p>前面介绍了Python中函数的用法，通过使用函数我们可以大大提高我们写代码的效率。今天我们介绍一下怎么来导入模块和使用标准库，从而我们可以使用别人写好并且封装好的一些函数。从而，使我们实现各种各样的功能，而不用自己花费大量的时间来写出别人已经写过的代码。</p>\n<h1 id=\"一、导入模块-Import-Modules\"><a href=\"#一、导入模块-Import-Modules\" class=\"headerlink\" title=\"一、导入模块(Import Modules)\"></a><strong>一、导入模块(Import Modules)</strong></h1><p>首先，我们在同一个文件夹下面建立两个python文件，一个名为my_module.py的导入模块文件，另一个为my_courses.py的python主程序文件。通过这两个文件之间的相互调用，我们将了解怎么样在一个文件中导入其他文件中的函数。在my_module.py中写入如下代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">print(&#x27;Imported my_module...&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">test = &#x27;Test String&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\">def find_index(to_search, target):</span><br><span class=\"line\">&#x27;&#x27;&#x27;Find the index of a value in a sequence&#x27;&#x27;&#x27;</span><br><span class=\"line\">for i, value in enumerate(to_search):</span><br><span class=\"line\">if value == target:</span><br><span class=\"line\">return i</span><br><span class=\"line\">return -1</span><br></pre></td></tr></table></figure>\n\n<p>第一行的print代码是为了验证我们是否可以导入这个模块。在另一个my_courses.py的文件中，输入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import my_module</span><br></pre></td></tr></table></figure>\n\n<p>如果结果中返回以下代码，说明模块导入成功。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Imported my_module...</span><br></pre></td></tr></table></figure>\n\n<p>接下来我们看看我们可以通过导入的模块做些什么？在my_courses.py中写入以下代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import my_module</span><br><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">index = my_module.find_index(courses, &#x27;Math&#x27;)</span><br><span class=\"line\">print(index)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Imported my_module...</span><br><span class=\"line\">1</span><br></pre></td></tr></table></figure>\n\n<p>这说明，我们成功导入了my_module.py模块，并且成功调用了其中的函数。在调用模块的时候，我们不能直接使用被调用模块中的函数，需要在前面加上模块名称，比如在这里我们想要调用my module.py中的find_index( )函数，我们是这么使用的：my_module.find_index(courses, ‘Math’)。</p>\n<p>我们还可以对调入的模块重新命名，比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import my_module as mm</span><br><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">index = mm.find_index(courses, &#x27;Math&#x27;)</span><br><span class=\"line\">print(index)</span><br></pre></td></tr></table></figure>\n\n<p>在这里我们将my_module重新命名为mm，从而让我们可以比较简洁快速的调用模块。</p>\n<p>另外，我们还可以只调用某个模块中的某个特定函数，比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">from my_module import find_index</span><br><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">index = find_index(courses, &#x27;Math&#x27;)</span><br><span class=\"line\">print(index)</span><br></pre></td></tr></table></figure>\n\n<p>这样的话，我们就可以直接使用被调用模块中的函数，而不用在前面加上被调用模块的名称。但要注意使用这种方法的时候，我们是无法调用模块中除了这个函数以外的任何其他函数的。</p>\n<h1 id=\"二、添加模块导入路径\"><a href=\"#二、添加模块导入路径\" class=\"headerlink\" title=\"二、添加模块导入路径\"></a><strong>二、添加模块导入路径</strong></h1><p>在python中我们可以导入刚才的模块是因为我们现在文件夹的位置在sys.path的文件列表中。如果我们将刚才的my_module.py文件放到其它位置，则我们将无法导入刚才的模块。这是应为my_module.py代码因为它所在的目录不在sys.path里。我们可以通过以下方法查看sys.path包含的路径：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import sys </span><br><span class=\"line\">print(sys.path)</span><br></pre></td></tr></table></figure>\n\n<p>我们会看到相应的路径。如果我们想要自定义一个常见的路径，可以使用以下方法：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import sys</span><br><span class=\"line\">sys.path.append(&#x27;~/Desktop/my_module&#x27;) </span><br></pre></td></tr></table></figure>\n\n<p>如果使用的是windows系统，则需要在路径前面加一个r来表示string \\是用于表示路径。例如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import sys</span><br><span class=\"line\">sys.path.append(r&quot;C:\\Users\\Leilei\\OneDrive\\桌面&quot;)</span><br><span class=\"line\">print(sys.path)</span><br></pre></td></tr></table></figure>\n\n<p>我们会发现，刚刚添加的桌面路径已经被添加到了sys.path的列表中。我们就可以直接调用存放在桌面上的python模块了。</p>\n<h1 id=\"三、标准库的导入和使用\"><a href=\"#三、标准库的导入和使用\" class=\"headerlink\" title=\"三、标准库的导入和使用\"></a><strong>三、标准库的导入和使用</strong></h1><p>Python 标准库非常庞大，所提供的组件涉及范围十分广泛。这个库包含了多个内置模块 (以 C 编写)，Python 程序员必须依靠它们来实现系统级功能，例如文件 I&#x2F;O，此外还有大量以 Python 编写的模块，提供了日常编程中许多问题的标准解决方案。其中有些模块经过专门设计，通过将特定平台功能抽象化为平台中立的 API 来鼓励和加强 Python 程序的可移植性。</p>\n<p>比如我们想要在课程中随机选一门课，这时候我们不需要自己再写一个random程序，而只需要导入标准库然后使用就可以了。举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import random</span><br><span class=\"line\">courses = [&#x27;History&#x27;, &#x27;Math&#x27;, &#x27;Physics&#x27;,&#x27;CompSci&#x27;] </span><br><span class=\"line\">random_course = random.choice(courses)</span><br><span class=\"line\">print(random_course)</span><br></pre></td></tr></table></figure>\n\n<p>每次运行程序，我们都会随机得到一门课程的输出。</p>\n<p>再比如，我们想要将度数转换为弧度角，并且计算它的sin值。这个也有写好的数学标准库可以直接实现这个功能，举例代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import math</span><br><span class=\"line\">rads = math.radians(90)</span><br><span class=\"line\">print(math.sin(rads))</span><br></pre></td></tr></table></figure>\n\n<p>运行程序我们就会输出90度弧度角的sin值：1.0。</p>\n<p>另外，还有很多非常有用或者有趣的标准库。比如：os标准库可以对文件和目录访问进行操作；datetime和calendar可以提供日历和日期相关函数等等。</p>\n<p>更多标准库的详细信息，可以查看这里：</p>\n<p><a href=\"https://docs.python.org/zh-cn/3/library/index.html\">https://docs.python.org/zh-cn/3/library/index.html</a></p>\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","python","模块和标准库"]},{"title":"Python教程--数字(Number)","url":"/2021/01/09/python%E6%95%99%E7%A8%8B-%E6%95%B0%E5%AD%97number/","content":"<p><strong>这篇文章中将会分享python中关于数字及运算相关的一些知识。</strong></p>\n<span id=\"more\"></span>\n<p>通过前面对于python中string的学习，大家应该对python有了一定的了解。接下来我们继续学习怎么对数字进行运算和输出。</p>\n<h1 id=\"一、Python中的整数运算和浮点运算\"><a href=\"#一、Python中的整数运算和浮点运算\" class=\"headerlink\" title=\"一、Python中的整数运算和浮点运算\"></a><strong>一、Python中的整数运算和浮点运算</strong></h1><p>数字分为两种一种是整数 int，另一种是带小数点的float。通过type( )就可以查看数字的类型。比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">num = 3</span><br><span class=\"line\">print (type(num))</span><br></pre></td></tr></table></figure>\n\n<p>就会返回如下值，告诉你num的类型为int。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;class &#x27;int&#x27;&gt;</span><br></pre></td></tr></table></figure>\n\n<p>如果把num换成一个小数，比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">num = 3.14</span><br><span class=\"line\">print (type(num))</span><br></pre></td></tr></table></figure>\n\n<p>则会返回如下值，来告诉你num的类型为float。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;class &#x27;float&#x27;&gt;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、Python中的数学运算符\"><a href=\"#二、Python中的数学运算符\" class=\"headerlink\" title=\"二、Python中的数学运算符\"></a><strong>二、Python中的数学运算符</strong></h1><p>相加： +；相减： -； 相乘：*；相除：&#x2F;；次幂运算： **；</p>\n<p>取整除，返回商的整数部分（向下取整）：&#x2F;&#x2F;；</p>\n<p>取模 ， 返回商的余数部分： %；</p>\n<p>加减乘除这里不再赘述，对于其他几个运算符，举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">a = 5</span><br><span class=\"line\">b = 2</span><br><span class=\"line\">print (a**b)</span><br><span class=\"line\">print (a//b)</span><br><span class=\"line\">print (a%b)</span><br></pre></td></tr></table></figure>\n\n<p>运算上面的python代码，我们将会返回如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">25</span><br><span class=\"line\">2</span><br><span class=\"line\">1</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、Python中的逻辑运算\"><a href=\"#三、Python中的逻辑运算\" class=\"headerlink\" title=\"三、Python中的逻辑运算\"></a><strong>三、Python中的逻辑运算</strong></h1><p>相等：&#x3D;&#x3D;；不等：!&#x3D;；大于：&gt;；小于： &lt;；大于等于： &gt;&#x3D;；小于等于 &lt;&#x3D;；</p>\n<p>比较只有两种结果True 和 Flase，如果逻辑判断成立则为True，反之则为Flase。比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">print (3 == 2)</span><br><span class=\"line\">print (3 &gt; 2)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">False</span><br><span class=\"line\">True</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"四、字符串和数字的转化\"><a href=\"#四、字符串和数字的转化\" class=\"headerlink\" title=\"四、字符串和数字的转化\"></a><strong>四、字符串和数字的转化</strong></h1><p>一个数字既可以是字符(string)，又可以是可进行数学运算的整数(int)或者是浮点数(float)。那么他们之间怎么转化呢？</p>\n<p>如果两个字符串类型的数字相加，则不能得到数学运算的结果。比如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">num_1 = &#x27;100&#x27;</span><br><span class=\"line\">num_2 = &#x27;200&#x27;</span><br><span class=\"line\">print(num_1+num_2)</span><br></pre></td></tr></table></figure>\n\n<p>其运行结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">100200</span><br></pre></td></tr></table></figure>\n\n<p>因为计算机把num_1和num_2作为了两个字符串，所以输出结果为直接他们罗列在一起。如果想对此进行数学运算则需要对其改变类型。相应的代码为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">num_1 = &#x27;100&#x27;</span><br><span class=\"line\">num_2 = &#x27;200&#x27;</span><br><span class=\"line\">num_1 = int(num_1)</span><br><span class=\"line\">num_2 = int(num_2)</span><br><span class=\"line\">print(num_1+num_2)</span><br></pre></td></tr></table></figure>\n\n<p>其运行结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">300</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","python","number","数字","运算符"]},{"title":"《荀子·修身》-01","url":"/2020/05/20/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-01/","content":"<p><strong>原文：</strong></p>\n<p><strong>见善，修然必以自存也；见不善，愀然必以自省也。善在身，介然必以自好也；不善在身，灾然必以自恶也。故非我而当者，吾师也；是我而当者，吾友也；谄谀我者，吾贼也。故君子隆师而亲友，以致恶其贼。好善无厌，受谏而能诫，虽欲无进，得乎哉！小人反是：致乱而恶人之非己也；致不肖而欲人之贤己也；心如虎狼，行如禽兽，而又恶人之贼己也。谄谀者亲，谏争者疏，修正为笑，至忠为贼，虽欲无灭亡，得乎哉！《诗》曰：“滃滃訿訿，亦孔之哀。谋之其臧，则具是违；谋之不臧，则具是依。”此之谓也。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>先说下作者，荀子，名況，被尊称为荀卿，战国时期儒家学者和思想家。对于诸子百家的见解，他都有所批判和继承，从而形成了一套自己的理论。《修身》是一篇讲述怎么修行自身的文章，文章非常优美，并且让人受益良多。修身是做成一切大事的基础，身不修则家不齐，家不齐则国家不治，国家不治则天下不平。</p>\n<p><strong>见到有善行，一定要要恭谨自查，自己是否也有此善行；见到不善的行为，一定要惊心警惕，反省自己是否也有此不善。自己身上的善，一定要固守；身上的不善，一定要畏恶它如同灾祸。批评我而且批评得恰当的人，是我的老师；赞扬我而且赞扬得恰当的人，是我的朋友；阿谀奉承我的人，是祸害我的贼人。</strong></p>\n<p>这里有一个概念，什么人是老师，什么人是朋友，什么人是敌人。你课堂上的老师不一定是你真正的老师，但对于你的缺点提出批评并给出中肯建议的人肯定是你的老师。对你的优点欣赏的人，是志同道合的朋友。无论黑白对错而谄媚奉承的人，是想从你这里得到好处的小人，是让你迷失正确判断的贼人。</p>\n<p><strong>所以君子尊崇老师而亲近朋友，对于谄媚之人则深恶痛绝。追求好的德行永远不满足，被人指出自己的错误而能够改正，即使自己不想进步，可能吗？小人则刚好相反：自己极其昏乱，还憎恨别人指出自己的过失；自己非常无能，却希望别人说自己贤能；心像虎狼一样狠辣，行为如同禽兽一般不堪，却又憎恨被人指出他的罪恶。亲近阿谀奉承自己的人，却疏远规劝自己的人，把善良正直的话当作对自己的讥笑，把极端忠诚的行为看成是对自己的戕害，这样的人即使想不灭亡，可能吗？</strong></p>\n<p>这里指出了什么是君子，什么是小人。就像《出师表》里写的：“亲贤臣，远小人，此先汉所以兴隆也，亲小人，远贤臣，此后汉所以倾颓也。”亲近君子，就可以即时修正自己的错误想法，对自身有一个比较正确的定位和反馈。亲近小人，就失去了外界对自身健康的反馈机制，就会向着灭亡的方向越走越远。做君子需要胸怀，没有谁会喜欢别人指出自己的过失，这是人性的弱点。修身修的就是这些人性的弱点，想做君子贤人就得和人的本性相斗争。</p>\n<p><strong>《诗经》说：“胡乱吸取，乱加诋毁，实在是非常可悲啊。本来计划做好事，结果却违反，本来计划不好，反而一一依从。”就是说的这样的小人。</strong></p>\n<p>当有各种意见汇聚到一起，还能进行甄别，知道应该如何抉择，是一件不容易的事情。想做出正确的抉择，就首先要修身、明智，并且对于谄媚的小人和坦荡君子进行甄别。做决定不要以自己的喜好来做判断，而是要根据事实进行分析。世界上最重要的一条定律就是熵增定律，世界上的一切在没有外力干涉的时候都在向着混乱度增加的方向在运行。如果不读书不修身没有任何外力作用，人们就会偏向于做一些让自己舒服的决定，但这些决定都会让自己加速走向灭亡。比如，多玩一会儿游戏，多看一会儿电视，多喝一罐可乐，多抽一包烟，少跑一次步，少学习一个小时等等等等，这些短时间看不出结果，但时间久了，积累的复利效应会让你感觉到这些小的地方让人有了巨大差距。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"Python教程--推导式(Comperhension)","url":"/2021/01/14/python%E6%95%99%E7%A8%8B-%E6%8E%A8%E5%AF%BC%E5%BC%8Fcomperhension/","content":"<p><strong>这篇文章中将会分享python中关于推导式(comperhension)相关的一些知识。</strong></p>\n<span id=\"more\"></span>\n<p>Comprehension是Python语言的一个特性，有些略微不太好翻译。Comprehension字面翻译过来，是“理解，包容”的含义，有人翻译为生成器，解析器，或者推导式。我们可以理解为 Comprehension是用来生产列表、元组、集合以及字典的工具。</p>\n<h1 id=\"一、列表推导式-List-Comperhension\"><a href=\"#一、列表推导式-List-Comperhension\" class=\"headerlink\" title=\"一、列表推导式 (List Comperhension)\"></a><strong>一、列表推导式 (List Comperhension)</strong></h1><p>我们先看一个例子，如果我们想要输出列表中的每一个元素，我们首先想到的可能是写出一个如下的for循环代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1,2,3,4,5,6,7,8,9,10]</span><br><span class=\"line\">my_list = []</span><br><span class=\"line\">for n in nums:</span><br><span class=\"line\">my_list.append(n)</span><br><span class=\"line\">print (my_list)</span><br></pre></td></tr></table></figure>\n\n<p>这么做没有问题，但可能有一点太复杂。我们再来看看List Comperhension是怎么做的：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1,2,3,4,5,6,7,8,9,10]</span><br><span class=\"line\">my_list = [n for n in nums]</span><br><span class=\"line\">print(my_list)</span><br></pre></td></tr></table></figure>\n\n<p>我们会发现，它们运行之后会得到同样的结果。但是，list comperhension就要明显简洁的多。再来举一个稍微复杂一点的例子，如果我们想要输出列表中的每一个元素的平方，我们如果用for循环会写出如下代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1,2,3,4,5,6,7,8,9,10]</span><br><span class=\"line\">my_list = []</span><br><span class=\"line\">for n in nums:</span><br><span class=\"line\">my_list.append(n*n)</span><br><span class=\"line\">print (my_list)</span><br></pre></td></tr></table></figure>\n\n<p>如果用List Comperhension的方法呢？代码如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1,2,3,4,5,6,7,8,9,10]</span><br><span class=\"line\">my_list = [n*n for n in nums]</span><br><span class=\"line\">print(my_list)</span><br></pre></td></tr></table></figure>\n\n<p>有没有很简洁？接着，我们想要只输出偶数，如果用for循环，将会是如下代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1,2,3,4,5,6,7,8,9,10]</span><br><span class=\"line\">my_list = []</span><br><span class=\"line\">for n in nums:</span><br><span class=\"line\">if n%2 == 0:</span><br><span class=\"line\">my_list.append(n)</span><br><span class=\"line\">print(my_list)</span><br></pre></td></tr></table></figure>\n\n<p>如果用List Comperhension的方法，则会非常简洁：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1,2,3,4,5,6,7,8,9,10]</span><br><span class=\"line\">my_list = [n for n in nums if n%2 == 0]</span><br><span class=\"line\">print(my_list)</span><br></pre></td></tr></table></figure>\n\n<p>接下来，我们想要输出一个嵌套的循环。输出字母’abcd’和数字’0123’的所有组合，用for循环，将会是如下代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">my_list = []</span><br><span class=\"line\">for letter in &#x27;abcd&#x27;:</span><br><span class=\"line\">for num in &#x27;0123&#x27;:</span><br><span class=\"line\">my_list.append((letter,num))</span><br><span class=\"line\">print(my_list)</span><br></pre></td></tr></table></figure>\n\n<p>用List Comperhension的方法也可以同样完成这个任务：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">my_list = [(letter,num) for letter in &#x27;abcd&#x27; for num in range(4)]</span><br><span class=\"line\">print(my_list)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、字典推导式-Dictionary-Comperhension\"><a href=\"#二、字典推导式-Dictionary-Comperhension\" class=\"headerlink\" title=\"二、字典推导式 (Dictionary Comperhension)\"></a><strong>二、字典推导式 (Dictionary Comperhension)</strong></h1><p>字典也同样可以有推导式。举一个例子，我们有如下两个列表，一个是名字(names)，一个是英雄名字(heros)，我们希望得到一个{‘name’:’hero’}样式的字典。用for 循环需要如下代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">names = [&#x27;Bruce&#x27;,&#x27;Clark&#x27;,&#x27;Peter&#x27;,&#x27;Logan&#x27;,&#x27;Wade&#x27;]</span><br><span class=\"line\">heros = [&#x27;Batman&#x27;,&#x27;Superman&#x27;,&#x27;Spiderman&#x27;,&#x27;Wolverine&#x27;,&#x27;Deadpool&#x27;]</span><br><span class=\"line\">my_dict = &#123;&#125;</span><br><span class=\"line\">for name, hero in zip(names, heros):</span><br><span class=\"line\">my_dict[name] = hero</span><br><span class=\"line\">print(my_dict)</span><br></pre></td></tr></table></figure>\n\n<p>这里的zip是用于将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。运行以上程序结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;&#x27;Bruce&#x27;: &#x27;Batman&#x27;, &#x27;Clark&#x27;: &#x27;Superman&#x27;, &#x27;Peter&#x27;: &#x27;Spiderman&#x27;, &#x27;Logan&#x27;: &#x27;Wolverine&#x27;, &#x27;Wade&#x27;: &#x27;Deadpool&#x27;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果用Dictionary Comperhension的方法，我们可以用如下代码得到同样的结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">my_dict = &#123;name: hero for name, hero in zip(names, heros)&#125;</span><br><span class=\"line\">print(my_dict)</span><br></pre></td></tr></table></figure>\n\n<p>如果我们想要添加某个筛选条件，也可以同样的在后面加上if判断语句。比如运行如下代码，将会把 ‘Peter’: ‘Spiderman’ 从结果中去除出去。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">my_dict = &#123;name: hero for name, hero in zip(names, heros) if name != &#x27;Peter&#x27;&#125;</span><br><span class=\"line\">print(my_dict)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、集合推导式-Set-Comperhension\"><a href=\"#三、集合推导式-Set-Comperhension\" class=\"headerlink\" title=\"三、集合推导式 (Set Comperhension)\"></a><strong>三、集合推导式 (Set Comperhension)</strong></h1><p>同样的，集合也可以用同样的推导式来使得代码更加简洁。因为集合中的元素不可以重复，我们可以利用这个特性来去除列表中的重复元素。用我们前面学过的for循环将会是如下代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1,1,2,1,3,4,3,4,5,5,6,7,8,7,9,9]</span><br><span class=\"line\">my_set = set()</span><br><span class=\"line\">for n in nums:</span><br><span class=\"line\">my_set.add(n)</span><br><span class=\"line\">print(my_set)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;1, 2, 3, 4, 5, 6, 7, 8, 9&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如果用Set Comperhension的方法，我们可以用如下代码得到同样的结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">nums = [1,1,2,1,3,4,3,4,5,5,6,7,8,7,9,9]</span><br><span class=\"line\">my_set = set(n for n in nums)</span><br><span class=\"line\">print(my_set)</span><br></pre></td></tr></table></figure>\n\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","python","comperhension","推导式"]},{"title":"Python教程--条件判断(if, elif, else)","url":"/2021/01/12/python%E6%95%99%E7%A8%8B-%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%ADif-elif-else/","content":"<p><strong>这篇文章将会分享关于python中关于条件判断 (if, elif, else)</strong> <strong>的一些相关知识。</strong></p>\n<span id=\"more\"></span>\n<p>条件判断是通过一条或多条判断语句的执行结果（True或者False）来决定执行的代码块。</p>\n<h1 id=\"一、if-elif-else-条件判断\"><a href=\"#一、if-elif-else-条件判断\" class=\"headerlink\" title=\"一、if, elif, else 条件判断\"></a><strong>一、if, elif, else 条件判断</strong></h1><p>在Python语法中，使用if、elif和else三个关键字来进行条件判断。我们先来看一个例子，来说明条件判断是怎么一回事：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">language = &#x27;Python&#x27;</span><br><span class=\"line\">if language == &#x27;Python&#x27;:</span><br><span class=\"line\">print(&#x27;Language is Python&#x27;)</span><br><span class=\"line\">else:</span><br><span class=\"line\">print(&#x27;No match&#x27;)</span><br></pre></td></tr></table></figure>\n\n<p>程序运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Language is Python</span><br></pre></td></tr></table></figure>\n\n<p>这就是一条最为简单的条件判断语句。首先，if语句会对language和Python进行比较。判断他们相同，就会输出’Language is Python’。如果不相同，则会输出’No match’。</p>\n<p>如果有两条以上的条件需要进行判读，我们就需要用到elif语句。我们再写一个例子，来看elif是如何使用的：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">language = &#x27;Java&#x27;</span><br><span class=\"line\">if language == &#x27;Python&#x27;:</span><br><span class=\"line\">print(&#x27;Language is Python&#x27;)</span><br><span class=\"line\">elif language ==&#x27;Java&#x27;: </span><br><span class=\"line\">print(&#x27;Language is Java&#x27;)</span><br><span class=\"line\">else:</span><br><span class=\"line\">print(&#x27;No match&#x27;)</span><br></pre></td></tr></table></figure>\n\n<p>运行程序，结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Language is Java</span><br></pre></td></tr></table></figure>\n\n<p>请注意，因为if, elif, 和else语句在python中已经足够使用，所以<strong>在Python中没有switch – case语句</strong>。</p>\n<h1 id=\"二、Python中的逻辑判断\"><a href=\"#二、Python中的逻辑判断\" class=\"headerlink\" title=\"二、Python中的逻辑判断\"></a><strong>二、Python中的逻辑判断</strong></h1><p>逻辑判断对于条件判断语句来说是非常重要的。在Python教程–数字(number)那一篇我们已经提到了四种逻辑判断：</p>\n<p>相等：&#x3D;&#x3D;；不等：!&#x3D;；大于：&gt;；小于： &lt;；大于等于： &gt;&#x3D;；小于等于 &lt;&#x3D;；</p>\n<p>还有一种逻辑判断我们之前没有提到过，那就是is判断。is判断可能跟&#x3D;&#x3D;有点类似，所以我们举个例子来简单说明一下他们之间的区别：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">a = [1,2,3]</span><br><span class=\"line\">b = [1,2,3]</span><br><span class=\"line\"></span><br><span class=\"line\">print(a==b)</span><br><span class=\"line\">print(a is b)</span><br></pre></td></tr></table></figure>\n\n<p>如果我们运行这个程序会得到如下结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">True</span><br><span class=\"line\">False</span><br></pre></td></tr></table></figure>\n\n<p>我们会发现，列表a等于列表b，但a并不是b。这是因为a和b虽然内容一样，但他们却是不同的列表，占用了不同的内存空间。就像两个双胞胎，虽然他们长得一样，但本质上确实两个不同的人。如果我们运行以下代码，输出他们的id就会发现他们之间的不同：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">a = [1,2,3]</span><br><span class=\"line\">b = [1,2,3]</span><br><span class=\"line\">print(id(a))</span><br><span class=\"line\">print(id(b))</span><br></pre></td></tr></table></figure>\n\n<p>结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">2379654490944</span><br><span class=\"line\">2379654511872</span><br></pre></td></tr></table></figure>\n\n<p>我们会发现两者含有不同的id，所以is逻辑判断本质上是来比较他们id是否相同。我们再来举一个例子，来看看他们在什么情况下是相同的：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">a = [1,2,3]</span><br><span class=\"line\">b = a</span><br><span class=\"line\">print(a is b)</span><br><span class=\"line\">print(id(a))</span><br><span class=\"line\">print(id(b))</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">True</span><br><span class=\"line\">2379654813376</span><br><span class=\"line\">2379654813376</span><br></pre></td></tr></table></figure>\n\n<p>我们这次就会发现a和b是相同的，因为他们的id相同，也就是说他们占用了相同的内存空间。</p>\n<h1 id=\"三、True和False的定义\"><a href=\"#三、True和False的定义\" class=\"headerlink\" title=\"三、True和False的定义\"></a><strong>三、True和False的定义</strong></h1><p>Python中的True和False的定义，在不同版本的Python中是这样定义的：</p>\n<ul>\n<li>Python 2：None, 0, 和空字符串都被算作 False，其他的均为 True</li>\n<li>Python 3：None，0，空字符串，空列表，空字典都算是False，所有其他值都是True</li>\n</ul>\n<p>因为我所用的是python 3的版本，所以就以我用的python 3为例，来举例说明一下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">a = 0</span><br><span class=\"line\">if a:</span><br><span class=\"line\">print(11)</span><br><span class=\"line\">else:</span><br><span class=\"line\">print(22)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">22</span><br></pre></td></tr></table></figure>\n\n<p>如果把0换成None, ( ), [ ], { }也会得到相同的结果。我们再来举一个条件判断为True的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">a = 2</span><br><span class=\"line\">if a:</span><br><span class=\"line\">print(11)</span><br><span class=\"line\">else:</span><br><span class=\"line\">print(22)</span><br></pre></td></tr></table></figure>\n\n<p>运行结果为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">11</span><br></pre></td></tr></table></figure>\n\n<p>这里可以把2可以换为任意不为0的数字，或者是非空的列表、字典、字符串（None除外）。</p>\n<hr>\n","categories":["技术杂谈","Python"],"tags":["计算机","编程","教程","python"]},{"title":"《荀子·修身》-05","url":"/2020/05/22/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-04-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>志意修则骄富贵，道义重则轻王公；内省而外物轻矣。传曰：“君子役物，小人役于物。”此之谓矣。身劳而心安，为之；利少而义多，为之；事乱君而通，不如事穷君而顺焉。故良农不为水旱不耕，良贾不为折阅不市，士君子不为贫穷怠乎道。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前文讲到了怎么调理性情，修养身心。这一小节继续论述君子在生活中具体应该怎么做。</p>\n<p><strong>志向美好就能傲视富贵，看重道义就能鄙薄王公贵族；内心省察自己，就觉得外来的财物轻微了。古书上说：“君子支配外界事物，小人则被外物所支配。”说得就是这个道理。</strong></p>\n<p>君子永远不追求外物，被外物所累，而是学会利用外物达到自己的目标。小人则相反，小人永远在追逐这些浮光掠影，在追逐中丧失了自我，沦为了外物的奴隶。世界上很多人这一生过的浑浑噩噩，被社会中的名利权情推着走，一生追逐名和利，追逐浮光掠影，光鲜浮华的外在这样的一种形象。而自己真正想做什么、想要什么从来不去仔细思考。这样的人就成为了名和利的奴隶，是非常可悲的。想要不成为名利的奴隶，过得自由洒脱，就要努力修身，因为只有修身到了一定程度，才有可能看破这些的虚妄，才会有可能傲视富贵，鄙薄权力。</p>\n<p><strong>身体劳累，但内心感到安适的事，就去做它；利益少但意义重大的事，就去做它；侍奉暴君违背礼仪而显达，不如侍奉穷困的君主而按照礼仪治理国家。所以好的农民不因为遭到水灾、旱灾就不再耕种，好的商人不因为亏本就不再做买卖，有志向和学问的人不因为贫穷而怠慢道义。</strong></p>\n<p>落实到具体行动来说，君子有所为，有所不为。君子要把目光放长远，不计较一时的得失。有意义的、重要的事情，就算暂时得不到回报也要坚持去做。简单来说，要多看看路，而少看看墙。要坚定自己的目标，不被暂时的困难和诱惑所击倒。做一件事情，总会遇到自己想不到的困难，如果就此放弃，那么也就不会等收获的那一天了。每一次战胜生活中的困难和诱惑都是一次磨练，都是对身心的一次修行，要学会拥抱挫折，从挫折中成长。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"Python教程--虚拟环境(Virtual Environment)","url":"/2021/01/13/python%E6%95%99%E7%A8%8B-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83virtual-environment/","content":"<p><strong>这篇文章中将会分享python中关于虚拟环境 (virtual environment) 相关的一些知识。</strong></p>\n<span id=\"more\"></span>\n<h1 id=\"一、什么是虚拟环境？\"><a href=\"#一、什么是虚拟环境？\" class=\"headerlink\" title=\"一、什么是虚拟环境？\"></a><strong>一、什么是虚拟环境？</strong></h1><p>虚拟环境就是借助虚拟机docker来把一部分内容独立出来，我们把这部分独立出来的东西称作“容器”，在这个容器中，我们可以只安装我们需要的依赖包，各个容器之间互相隔离，互不影响。</p>\n<p>在实际项目开发中，我们通常会根据自己的需求去下载各种相应的框架库，如Scrapy、Beautiful Soup等，但是可能每个项目使用的框架库并不一样，或使用框架的版本不一样，这样需要我们根据需求不断的更新或卸载相应的库。直接对我们的Python环境操作会让我们的开发环境和项目造成很多不必要的麻烦，管理也相当混乱。</p>\n<p>比如，项目A需要某个框架1.0版本，项目B需要这个库的2.0版本。如果没有安装虚拟环境，那么当你使用这两个项目时，你就需要来回的卸载安装，这样很容易就给你的项目带来很多麻烦。所以在用python进行多个项目操作时，安装虚拟环境还是十分有必要的。</p>\n<h1 id=\"二、如何安装虚拟环境\"><a href=\"#二、如何安装虚拟环境\" class=\"headerlink\" title=\"二、如何安装虚拟环境\"></a><strong>二、如何安装虚拟环境</strong></h1><p>在电脑终端输入以下指令即可安装虚拟环境：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install virtualenv</span><br></pre></td></tr></table></figure>\n\n<p>通过上面的步骤安装成功之后，我们就可以创建虚拟环境了。首先新建一个虚拟环境所用的文件夹，以Environments为例，然后在这个文件夹下面就可以存放不同项目的虚拟环境了。新建完文件夹之后，cd 指令在终端进入所在文件夹，使用以下指令建立名为project1_env的虚拟环境:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">virtualenv project1_evn</span><br></pre></td></tr></table></figure>\n\n<p>然后对应的虚拟环境就会在当前所在目录进行创建。</p>\n<h1 id=\"三、激活和退出虚拟环境\"><a href=\"#三、激活和退出虚拟环境\" class=\"headerlink\" title=\"三、激活和退出虚拟环境\"></a><strong>三、激活和退出虚拟环境</strong></h1><p>如果们要使用这个名为project1_env的虚拟环境，我们就需要对其进行激活。在mac和linux上使用以下指令，可将其激活：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">source ./bin/activate</span><br></pre></td></tr></table></figure>\n\n<p>在windows系统上略微有点不同，代码为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">.\\Scripts\\activate.bat</span><br></pre></td></tr></table></figure>\n\n<p>在使用完虚拟环境之后，mac和linux系统上可以使用以下指令推出虚拟环境：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">deactivate</span><br></pre></td></tr></table></figure>\n\n<p>在windows上则为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">.\\Scripts\\deactivate.bat</span><br></pre></td></tr></table></figure>\n\n<p>如果一个项目完结了，或者说测试完成了，我们不再需要这个虚拟环境之后。我们只需要将对应的文件夹删除即可删除我们所创建的虚拟环境。</p>\n<h1 id=\"四、使用特定版本的python创建虚拟环境\"><a href=\"#四、使用特定版本的python创建虚拟环境\" class=\"headerlink\" title=\"四、使用特定版本的python创建虚拟环境\"></a><strong>四、使用特定版本的python创建虚拟环境</strong></h1><p>使用以下指令即可创建一个依赖于特定python版本的虚拟环境：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">virtualenv -p usr/bin/python 2.7 py27_env</span><br></pre></td></tr></table></figure>\n\n<p>其中usr&#x2F;bin&#x2F;python 2.7为计算机中存放python的位置，可以通过which python指令来进行查看。py27_env为我们所创建的虚拟环境。</p>\n<hr>\n","categories":["技术杂谈","Python"],"tags":["编程","教程","python","virtual environment","虚拟环境"]},{"title":"《荀子·修身》-03","url":"/2020/05/20/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-03/","content":"<p><strong>原文：</strong></p>\n<p><strong>以善先人者谓之教，以善和人者谓之顺；以不善先人者谓之谄，以不善和人者谓之谀。是是非非谓之智，非是是非谓之愚。伤良曰谗，害良曰贼。是谓是，非谓非曰直。窃货曰盗，匿行曰诈，易言曰诞。趣舍无定谓之无常。保利弃义谓之至贼。多闻曰博，少闻曰浅。多见曰闲，少见曰陋。难进曰偍，易忘曰漏。少而理曰治，多而乱曰秏</strong>。</p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>用好的言行引导别人叫做教导，用好的言行去附和别人叫做顺应，用不善的言行引导别人叫做谄媚，用不善的言行去附和别人叫做阿谀。</strong></p>\n<p>发心不同结果也不同，人在社会中要善于鉴别善与不善。被好的言行引导，人们可以诸事顺利，生活幸福。被不好的言行引导，人们会误入歧途，带来灾祸。</p>\n<p><strong>以是当是，以非当非，就叫做明智，以是为非，以非为是，就叫做愚蠢。用言论中伤善良，就叫做谗言，用言论陷害良士，就叫做虐害。以是为是，以非为非，就是正直。</strong></p>\n<p>是是非非，要用头脑去思考。要博学之，审问之，慎思之，明辨之，笃行之。想要明辨是非，首先要学习，站在巨人的肩膀上，就可以博学。博学之后，还要反复审问，多问几个为什么。然后，学会辩证全面的思考。再然后，才能形成清晰的判断力。最后，用学习来的知识来指导实践。</p>\n<p><strong>窃取财物，就叫做偷窃，隐瞒自己的行为，就叫做欺骗，信口开河，就叫做虚妄，对取舍犹豫不决，就叫做无常，为了保住利益而背信弃义，就叫做大贼。听到的事情多叫做广博，听到的事情少叫做浅薄，见多识广叫做娴雅，见识少叫做孤陋寡闻。难于进取叫做废弛，学过的经常遗忘叫做遗漏。事情少但井井有条叫做治理、管理，事情多但繁多而杂乱无章叫做昏乱不明。</strong></p>\n<p>这里列举了生活中常见很多种行为。修身之人切记远离偷窃、欺骗、虚妄、无常、大贼、浅薄、孤陋寡闻等等的人性的缺点。做人信义两字尤为重要。信义之后才是多闻和进取。孔子也说，“益者三友：友直，友谅，友多闻”。也在劝我们要与正直、诚信、见多识广的人交朋友。另外，做事情的时候要少而理，少不是真的事情少，而是善于在繁杂的事务中，找到最重要的那个点，对于繁杂无益的活动不要浪费自己的精力。老子说：“吾有三宝：一曰慈，二曰俭，三曰不敢为天下先。” 这里面的俭就是少，不要浪费自己的精力在无意义的事情上，人生很短暂，要抓住重点，删繁就简，完成自己的人生意义。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"《荀子·修身》-06","url":"/2020/05/24/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-06/","content":"<p><strong>原文：</strong></p>\n<p><strong>体恭敬而心忠信，术礼义而情爱人；横行天下，虽困四夷，人莫不贵。劳苦之事则争先，饶乐之事则能让，端悫诚信，拘守而详；横行天下，虽困四夷，人莫不任。体倨固而心埶诈，术顺墨而精杂污；横行天下，虽达四方，人莫不贱。劳苦之事则偷儒转脱，饶乐之事则佞兑而不曲，辟违而不悫，程役而不录：横行天下，虽达四方，人莫不弃。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>这一节继续讲在生活中修身的具体做法，以及为什么要修身。</p>\n<p><strong>外貌恭敬，内心忠信，遵循礼义并且性情仁爱，这样的人走遍天下，即使困顿在边远地区，也没有人不敬重他的；劳累辛苦的事抢先去做，有利可图、享乐的事却能让给别人，诚实守信，谨守法度而又明察事理，这样的人走遍天下，即使困顿在边远地区，也没有人不信任他的。</strong></p>\n<p>忠本义为尽心竭力，依照“声中有义”、“因声求义”学说，“忠”字可以认为是“中心不二”、“心”意集“中”，心无旁骛。无论是对待上级、朋友、家人还是自己都要忠。儒家文化在于王权结合的过程中，过多的强调了对上级、对国家的忠，而忽视了对朋友、家人、和自己的忠。在现代社会下，我们更应该去仔细想想对朋友、家人、和自己的忠。比如，人们可以想想自己做的决定有没有忠于自己的内心，有没有被名利所驱使。仁是儒家很重要的另一个理念。我觉得跟道家和佛家说的慈意思很像。仁者爱人，仁的意思就是爱别人，对人心怀慈悲。自己不喜欢做的，不强迫别人去做。</p>\n<p>论语里有一段很有意思的对话，原文是这么说的：“子曰：‘参乎！吾道一以贯之’曾子曰：‘唯。’子出，门人问曰：‘何谓也？’曾子曰：‘夫子之道，忠恕而已矣。’” 大意是孔子向曾子传道，说大道可以用一个“一”字来概括，曾子明白了。其他人问他的时候，他害怕众人不明白，说道用两个字“忠恕”就可以来概括了。世间万事万物，本质上来讲都是一样的，这个本源的规律就是“一”。世人看不透，就需要用更复杂也更易懂的方式来解释，所以才有了各种各样的方法，有了各种各样的学说。就像《金刚经》里说的“一切圣贤皆以无为法而有差别”。所有圣贤说的道的本质一样，但表现形式会有差别。忠恕两字，就是对一的解释，忠就是我们前面说的，心无二心，意无二意的意思。恕就是我们前面说的仁，了己了人，明始明终的意思。</p>\n<p><strong>外表傲慢固执，内心阴险狡诈，滥用慎到和墨翟的学说，并且性情肮脏，这样的人走遍天下，即使显贵四方，没有人不轻视他的；遇到劳累辛苦的事就逃避，遇到有利可图、得以享乐的事就用花言巧语地谄媚，毫不谦让地迅速抢夺，邪僻恶劣又不诚信，轻贱而不善良，这样的人走遍天下，即使显贵四方，没有人是不摒弃他的。</strong></p>\n<p>这里又提到了不修身的后果，贪嗔痴慢疑五毒俱全的人，必将害人害己。业精于勤，荒于嬉，行成于思，毁于随。做人万不可任着自己内心的各种情绪和欲望来做事，如不能做到克己修身，必将一无所成，被人唾弃。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"《荀子·修身》-02","url":"/2020/05/20/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-02/","content":"<p><strong>原文：</strong></p>\n<p><strong>扁善之度，以治气养生，则后彭祖；以修身自名，则配尧禹。宜于时通，利以处穷，礼信是也。凡用血气、志意、知虑，由礼则治通，不由礼则勃乱提僈；食饮，衣服、居处、动静，由礼则和节，不由礼则触陷生疾；容貌、态度、进退、趋行，由礼则雅，不由礼则夷固、僻违、庸众而野。故人无礼则不生，事无礼则不成，国家无礼则不宁。《诗》曰：“礼仪卒度，笑语卒获。”此之谓也。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>使人无往而不善的法则是：用调理血气来保养身体，那么自己的寿命会仅次于彭祖；用善行来洁身自好，那么自己的名声可与尧、禹媲美。既适宜于用来处守显达的顺境，也有利于处守困窘的境遇，这全在于礼法和信义。</strong></p>\n<p>春秋战国时期儒家讲克己复礼，希望恢复周朝的礼仪制度。这是那个时代的情况所决定的。那个时代是一个弱肉强食，礼崩乐坏的时代。没有了礼法的限制，王公贵族醉生梦死，平民百姓易子相食，所以儒家希望可以恢复礼法。现代社会已经发生了很大变化，不可能再恢复周的礼。但现代社会有现代社会的礼，如今是一个全球化的时代，中国的商品被摆放在全世界的货架上销售，网络的出现让人与人之间的沟通不再有障碍。所以，当今社会需要一个更加开放的心态，来面对全世界不同的文化。开放、包容、平等、自由将是现在社会的礼法。信义也是更加重要，做人要有信用才能在社会中立足，对人对己都要有信用。答应别人的事情要说到做到，否则不可轻易许诺于人。给自己规定的学习内容和决定克服的陋习，也不可颓废，轻易放过自己。</p>\n<p><strong>凡是使用血气、意志，智慧和思虑的时候，遵循礼法就通达顺利，不遵循礼义就产生谬误错乱，行为就会迟缓怠惰；在吃饭、穿衣、居处及活动的时候，遵循礼义的行为就会和谐适当，不遵循礼义就会触犯禁忌而生病；人的容貌、态度、进退、行走，遵循礼义就温雅可亲，不遵循礼义就显得傲慢、固执、邪僻，粗野。</strong></p>\n<p>遵循现代社会礼法，做事坦荡大气，就会理直气壮，内心没有一丝忐忑不安，自然通达顺利，气场十足。内心没有各种不安情绪，必然吃得香，睡得足，所谓不做亏心事，不怕鬼敲门。没有不安情绪，坦坦荡荡，自然眉头舒展，气定神闲，让人愿意亲近。</p>\n<p><strong>所以，人没有礼义就不能生存，做事情不讲礼义，事情就办不成，国家没有礼义就不能安宁。《诗经》说：“礼仪完全符合法度，一言一笑完全得当。”说的就是这种情况。</strong></p>\n<p>得到者多助，失道者寡助。做事走正途，心中坦荡阳光的人，总能驱走阴暗，无往而不利。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"《荀子·修身》-08","url":"/2020/05/25/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-08/","content":"<p><strong>原文：</strong></p>\n<p><strong>夫骥一日而千里，驽马十驾，则亦及之矣。将以穷无穷，逐无极与？其折骨绝筋，终身不可以相及也。将有所止之，则千里虽远，亦或迟、或速、或先、或后，胡为乎其不可以相及也！不识步道者，将以穷无穷，逐无极与？意亦有所止之与？夫“坚白”、“同异”、“有厚无厚”之察，非不察也，然而君子不辩，止之也。倚魁之行，非不难也，然而君子不行，止之也。故学曰：”迟彼止而待我，我行而就之，则亦或迟、或速、或先、或后，胡为乎其不可以同至也！”故蹞步而不休，跛鳖千里；累土而不辍，丘山崇成。厌其源，开其渎，江河可竭。一进一退，一左一右，六骥不致。彼人之才性之相县也，岂若跛鳖之与六骥足哉！然而跛鳖致之，六骥不致，是无它故焉，或为之，或不为尔！道虽迩，不行不至；事虽小，不为不成。其为人也多暇日者，其出入不远矣。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>良马一天能奔跑千里，劣马跑十天也可以达到。但是，如果用有限的气力要去穷尽无尽的路途，追赶起来没完没了，那么即使劣马跑断了骨头，走断了脚筋，一辈子也不能赶上千里马啊！如果有个终点，那么千里的路程虽然很遥远，也不过是快点、慢点，早点、晚点而已，怎么不能到达目的地呢？</strong></p>\n<p>只要有一个明确的目标，即使资质较差的劣马总有一天可以追赶上日行千里的良驹。所以君子要明白自己想要成为什么样的人，要做成什么样的事情，如果立好了志向，就按照自己的节奏往目标走去，不要左顾右盼，对自己产生怀疑。只要不放弃，总有一天可以到达那个想要到达的地方。</p>\n<p><strong>不认识道路的人，是去走那无穷之路，追逐没有终点的所在呢？还是有所止境呢？对那些“坚白”、“同异”、“有厚无厚”等命题的考察、辨析，不是不明察，然而君子不去辩论它们，是因为君子有自己追求的目标，所以有所节制啊。那些怪异的行为，并不是不难做到，但是君子并不去做，也是因为君子有自己追求的目标，所以有所节制。</strong></p>\n<p>“坚白”、“同异”、“有厚无厚”指战国名家惠施、公孙龙的学说，有坚石非石、白马非马；同者异、异者同；空间无限等命题。如果一个人不确定自己要走的路，每个有用无用的问题都要研究，都去花费自己宝贵的精力，那么是非常不值得的。所以君子要学会有所节制，把有限的生命花费在值得关注的事情上。</p>\n<p><strong>所以古语相传：“学习就像行路，当别人停下来等待我的时候，我就努力赶上去，这样或慢或快，或早或晚，怎么不能一同到达目的地呢？”所以只要一步一步地走个不停，那么即使瘸了腿的甲鱼也能走千里；土一层一层不停堆积起来，山丘也能够堆成；堵塞水源，开通沟渠，即使是长江、黄河也会枯竭；一会儿前进，一会儿后退，一会儿向左，一会儿向右，就是六匹千里马拉车也不能到达目的地。</strong></p>\n<p>合抱之木，生于毫末；九层之台，起于累土。只要不停的去积累，确定好的那个目的地有一天总能到达。如果分散了自己的精力，东一榔头西一棒子，每样事情都不会深入，最后白白浪费了精力，什么也不会做成。</p>\n<p><strong>至于人的资质，即使相距悬殊，难道会像瘸了腿的甲鱼和六匹千里马那样悬殊吗？然而瘸了腿的甲鱼能够到达目的地，六匹千里马拉的车却不能到达，这并没有其他的原因，只不过是有的去做，有的不去做罢了！路程即使很近，但如果不走就不能到达；事情虽然很小，但不做就不能完成。那些无所事事的人，他们是不可能超过别人的。</strong></p>\n<p>人的生理必然会有一定差异，但一般不会大到足以绝对的影响结果。更多的差异来自于人性格中有没有韧性，做事坚持不懈，资质好与不好的人最终都会到达终点。我们周围不乏这样的人，目标和理想总是很不错，但从未见他真正行动起来。晚上想想千条路，早上醒来走原路。种一棵树最好的时间，除了十年前，就是现在。行动起来，才有可能把目标变为现实。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"《荀子·修身》-07","url":"/2020/05/25/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-07/","content":"<p><strong>原文：</strong></p>\n<p><strong>行而供冀，非渍淖也；行而俯项，非击戾也；偶视而先俯，非恐惧也。然夫士欲独修其身，不以得罪于比俗之人也。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>走路时小心谨慎，不是因为怕陷于泥沼；走路时低头俯视，不是因为怕碰撞着什么；与别人对视而先低下头，不是因为惧怕对方。读书人这样做，只是想独自修养自己的身心，而不愿去得罪世俗之人。</strong></p>\n<p>君子做事谨慎小心，不是因为害怕得罪世俗之人，而是不想沾惹一些凡俗之事，而破坏了自己的心境。孔子说君子不立于危墙之下，不是君子怕死，而是这样死了没有任何意义。花费精力与世俗之人争斗，简直就是浪费了自己的精力。君子应当节俭自己的精力和时间来修习自身，提高自身，不要浪费在一些毫无意义的事情上。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"《荀子·修身》-10","url":"/2020/05/27/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-10/","content":"<p><strong>原文：</strong></p>\n<p><strong>端悫顺弟，则可谓善少者矣；加好学逊敏焉，则有钧无上，可以为君子者矣。偷儒惮事，无廉耻而嗜乎饮食，则可谓恶少者矣；加愓悍而不顺，险贼而不弟焉，则可谓不详少者矣，虽陷刑戮可也。老老而壮者归焉，不穷穷而通者积焉，行乎冥冥而施乎无报，而贤不肖一焉。人有此三行，虽有大过，天其不遂乎！</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>端正朴实，尊重长者，就可以称为好少年了；如果还好学上进，谦虚敏捷，那就没有人能超过他了，这样的人可以称为君子了。苟且偷安，懒惰怕事，没有廉耻而又贪图吃喝，就可以称为坏少年了；如果还放荡凶暴，不尊敬长者，险恶害人，这就叫做凶险的少年了，这样的人即使遭受刑杀，也毫不可惜。尊敬长者，那么青壮年便会归附；不轻侮处境艰难的人，因而明通事理的人便都会来聚集；暗中做好事，施惠不图报答，这样贤人和不贤的人都会归向你，人有这三种好德行，即使有天大的过失，恐怕上天也不会让他大祸临头吧。</strong></p>\n<p>踏实做人，好好做事，对的事情即使困难没有利益也要坚持去做。做事磊落，待人诚恳，同情弱者，必然贤者归附。在帮助他人的时候，不彰显自己的功劳，且不求回报，大家都会看在眼里，然后会从心底敬重你。做到这些，就可以说是一个受人敬重的君子了。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"《荀子·修身》-04","url":"/2020/05/21/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-04/","content":"<p><strong>原文：</strong></p>\n<p><strong>治气养心之术：血气刚强，则柔之以调和；知虑渐深，则一之以易良；勇胆猛戾，则辅之以道顺；齐给便利，则节之以动止；狭隘褊小，则廓之以广大；卑湿重迟贪利，则抗之以高志；庸众驽散，则劫之以师友；怠慢僄弃，则照之以祸灾；愚款端悫，则合之以礼乐，通之以思索。凡治气养心之术，莫径由礼，莫要得师，莫神一好。夫是之谓治气养心之术也。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前面三节讲了怎么去辨别君子和小人，以及社会中形形色色的人和现象。在生活中我们要慎重交友，注重修身。这一小节讲了一些大概的修身养气的方法。</p>\n<p><strong>调理血气，修养身心的方法是：对血气刚强的，就用心平气和使其顺服；思想深沉而不明朗的，就用坦率、平易的方法去同化他；勇猛乖张的，就用疏导的方式辅助他；对性急嘴快的，就用动静相辅相成的方式去节制他；</strong></p>\n<p>修身的目的是让我们刚柔并济，内方外圆。在做事的时候有条不紊，思虑周全；在做人的时候，不卑不亢，进退得当。做一个有人格魅力的人，可以让大家信服的人。针对不同的人，养气治心的方法是不一样的。刚强的人要趋于平和，阴暗的人要更加阳光，乖张的人要更加顺从，性急的人就要知道节制，从而达到中正平和的一种状态。</p>\n<p><strong>对心胸狭窄的，就用宽宏大量来开导他；对于志向卑下、思想迟钝、贪图小利的，就用高尚的志向去提高他；对庸俗散漫的，就用良师益友去改造他；对怠慢、轻浮、自暴自弃的，就用招致灾祸后果使他明了；对于愚钝、朴实、端庄、拘谨的，就用礼仪音乐去协调他，用深思熟虑去开导他。</strong></p>\n<p>同样的，心胸狭小的人要注意宽心，思想境界低的要注意树立远大高尚志向，庸俗散漫的就要多像良师益友学习，怠慢轻浮的人就多想想灾祸的后果，过分朴实的就用艺术来熏陶。这些缺点，每个人身上可能或多或少会有一些，要注意反省，并采用相应的方法来提高自身。良师益友是人生很宝贵的财富，对于自己看不到的缺点，旁人的指正和意见就会显得尤为珍贵。</p>\n<p><strong>凡是调理血气、修养思想的方法，最直接的就是遵循礼义，得到好的老师的指导更重要的了，没有什么比专心一致更神妙的了。这就是所说的调理血气、修养思想的方法。</strong></p>\n<p>这里荀子概括的来说，治气养心最简单最直接的方式就是遵循礼仪，得到好的老师指导，做事专心致志。遵照社会的道德和法律标准来做，至少可以保证不出特别出格的事情。得到名师指导，可以让我们更加清晰的看清自己，也知道努力的方向在哪里。专心致志的作用更是神奇。这些年国外特别流行一个词叫做“心流”，是指人在全身心投入一件事情的时候，感受不到时间的流逝的一种状态。研究表明，在心流的状态下，人的效率更高，更不容易感到疲惫，心神更加安宁，因而也会更加长寿。因此，在做重要的事情的时候，最好找出一段安静的时间，让自己进入这种状态，我相信你会变的更加幸福。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"《道德经》-1-2","url":"/2020/05/30/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-1-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>故常无欲以观其妙；常有欲以观其徼。此两者，同出而异名，同谓之玄。玄之又玄，衆妙之门。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前文讲了可道之道不是恒道，可名之名不是恒名。无名无形是事物的根本，有名有形使事物得以有功用。接着原文继续分析第一章节的后半部分～</p>\n<p><strong>所以常常保持无的状态来观察事物的妙要，常常保持有的状态来观察事物的归趣。</strong></p>\n<p>本句自古有两种断句的争论。第一种是：常无，欲以观其妙。常有，欲以观其徼。解释为：常无，意欲观察其深渊高妙。常有，意欲观察其所归趋。</p>\n<p>第二种是：常无欲，以观其妙。常有欲，以观其徼。解释为：常没有欲（欲可理解为人的情欲和志欲），才能观察到其中的妙要。常有欲，才能观察到其规律及目回的。</p>\n<p>我个人来说更倾向于第一种断句，因为前文一直在说有和无，还没有提到欲望这个概念，所以根据句意来说，应该是第一种断句方式更为合理。当然理解为第二种也没有太大关系，本质上来说，要表达的思想是一致的。</p>\n<p>保持空灵的无欲无求的状态，就能撇开自身的欲望和情绪来真正看清事物的本来面目。如果一个人掺杂了自己的想法在里面，就特别容易迷失自己，就会倾向于相信事物会朝着自己希望的样子发展。保持有知有欲的状态，就可以寻找到事物的发展规律，从而知道事物的走向。只有深入钻研一件事，才能了解和找到这样东西的属性，从而知道这件事将会如何发展下去。</p>\n<p><strong>有和无是同出于一个本源，而发展出来的具有不同名相的两个概念，都可被称作玄。它不是一般的玄妙，而是玄之又玄，深远又深远，是宇宙天地万物之奥妙的总门。</strong></p>\n<p>虽然有和无是事物的两个不同方面，但又不可割裂开来。有无是相生相随的，后面的章节也说过：“有之以为利，无之以为用”。空气看起来是无的，但却充斥着各种气体分子，气体分子看起来是实体的，但原子核所占空间的比例仅仅像在一个大足球场放了一个足球，剩余的空间又都是空虚的。有和无的概念解释起来真的是玄妙非凡，几乎我们生活中所有的事物都可以用有和无来理解，所以才会说玄之又玄，众妙之门。</p>\n<p>比如一个房子，只有内部空着的时候，才可以住人。如果完全是个实体，就失去了它的功用（住人）；如果完全是虚无的，也同样失去了它的住人的功用。还有我们的时间安排，如果被琐事塞的满满的，就不能腾出时间来学习新的东西，从而反思提高进步；相反，如果完全空着大把的时间，又会觉得空虚，不知道自己方向在哪里，该做些什么。用孔子的话来说就是“学而不思则罔，思而不学则殆”。所以说，有无不可偏废，有无相结合，求中庸之道，做事做人才能符合道，也才能了解世界的本质和人生的意义。把握了有无的规律，就把握住了宇宙万物的奥妙的总门。</p>\n<hr>\n<p>第一章开宗明义讲出了《道德经》的最重要的几个概念。可道之道非恒道，可名之名非恒名。不可执迷于名相，重要的是名相之后的道理和规律。另外有两个概念非常重要，那就是有和无的概念，掌握好有和无，就算是掌握了所有法门的关键所在。</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《荀子·修身》-09","url":"/2020/05/26/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-09/","content":"<p><strong>原文：</strong></p>\n<p><strong>好法而行，士也；笃志而体，君子也；齐明而不竭，圣人也。人无法，则伥伥然；有法而无志其义，则渠渠然；依乎法，而又深其类，然后温温然。礼者、所以正身也，师者、所以正礼也。无礼何以正身？无师吾安知礼之为是也？礼然而然，则是情安礼也；师云而云，则是知若师也。情安礼，知若师，则是圣人也。故非礼，是无法也；非师，是无师也。不是师法，而好自用，譬之是犹以盲辨色，以聋辨声也，舍乱妄无为也。故学也者，礼法也。夫师、以身为正仪，而贵自安者也。《诗》云：“不识不知，顺帝之则。”此之谓也。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>爱好礼法而能依其行事的，是士；意志坚定，而又亲身实践的，是君子；思虑敏捷而智慧又永不枯竭的，是圣人。人没有礼法，就会无所适从；有礼法，却不知其意义，就会局促不安，遵循礼法而又深明事类，精确把握它的具体规则，然后才能优游不迫，得心应手。</strong></p>\n<p>首先要做一个士，才能做君子，而后做圣人。知礼懂法，且意志坚定的去践行，这是一个君子应该做的事情。但想要不迷惑，做任何事都得心应手的，就得去追求大道，掌握背后规律，多问几个为什么。</p>\n<p><strong>礼法，是用来端正自身的行为的；老师，是用来正确解释礼法的。没有礼法，怎么能够端正身心呢？没有老师，又怎能知道礼义是正确的呢？礼法怎样规定就怎样去做，这就是性情习惯于按照礼的要求去做；老师怎么说就怎么说，这就是理智顺从老师。性情习惯于遵礼而行，理智顺从老师，这就是圣人了。所以，违背了礼法，就是无视法度；违背了老师，就是无视老师。不遵照老师的教导，违背礼法，喜欢自以为是，这就好像用盲人去分辨颜色，用聋子去分辨声音，除了胡说妄为是不会干出什么好事来的。所以，学习就是学礼法，老师要以身作则，而且又要安心于这样做。《诗经》说：“不知不觉，顺应天帝的法则。”就是说的这种情况。</strong></p>\n<p>这里的观点我并不是十分同意。遵守礼法、顺从老师在古代等级森严的社会是美德。但现代社会更加复杂多样，凡事不可盲从，要多问几个为什么。现在社会正处在剧变时期，统一的新的价值观还没有形成，旧的价值观还没有完全坍塌，各种价值观并存。人在这个时代还是要多学习各家学说，选取对自己有帮助的适合自己的，从而对社会本质有一个更加深入的了解，形成自己的一个世界观价值观。个人觉得，评价一种学说观点适不适合自己，要从这个学说有没有让自己和周围的人的生活更幸福来评判。如果可以帮助自己和他人更幸福，那么这学说就是有价值的。实践是检验真理的唯一标准，而不是盲从。</p>\n<p>当然，孔子说三人行必有我师焉，如果这里的老师解释为在某些方面值得自己学习的人，那么这么说又是没有什么问题的。像比自己优秀的人学习，就会让自己更有智慧，视野更加开阔，从而成就更优秀的自己。</p>\n<hr>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"《道德经》-1-1","url":"/2020/05/29/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-1-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>道可道，非常道。名可名，非常名。无名天地之始；有名万物之母。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>说在前面的话：《道德经》是对我影响非常大的一本国学经典。在真正研读这本书之前，我曾多次听说过这本书。尤其是看《曾国藩》的时候，里面多次提到《道德经》。曾国藩在研读此书之后发生的蜕变，让我感受到了这本书的神奇的魅力。还有著名的央视主持人白岩松多次曾在公开场合提及《道德经》是他的生命之书。第一次认真逐句研读这本书是在三年前，当时就被这部神奇的经典震惊到了。读完之后仿佛有一股神奇的力量注入了我的灵魂，抽丝剥茧般把我思想中的杂质去除了出去，也用一个更高的视角让我看到了世界的另外一面。后面反复读了很多次，也曾看了多家的注解，至今我都不敢说自己完全理解了《道德经》里面说了什么。我相信每一个人读完之后，也都会有自己的理解，都会领悟到自己的道。</p>\n<p>在内容上来说，《道德经》跟佛教的很多般若部的经书内容很像，都是站在更高的视角来审视我们这个世界的真相。但我感觉《道德经》相对来说更容易被中国人所理解，因为对于经典来说每个文字都可以承载很多的含义，翻译过的文字无论多美妙都会失去很多他本来的意思。《道德经》是用我们自己的文字写成的，而汉字几千年来一直得到了很好的传承，所以理解起来就会相对更加容易。接下来，让我们一起进入《道德经》的世界吧～</p>\n<p><strong>可道之道，不是恒久不变的大道。可名之名，不是自然常在之名。</strong></p>\n<p>每一个可以被说出来、被规定、被写下来的规矩和道理，都只是在一定条件下适用的道。随着外部条件变化，这些规矩、道理都会发生变化。以前看起来对的，现在不一定对。国内看起来适用的，国外看来不一定能接受。比如秦汉以前讲究周礼和井田制度，但放到现在肯定是不适应的。所以说，要有辩证思维，适用于别人的，不一定适用于自己，要多加思考，才能辨明是非。</p>\n<p>可名之名，也不是自然常在之名。这个名可以理解为名称，也可以理解为名望。世间的任何事物的命名都是人来命名的，这个名只是用来区分不同的功用，方便人们交流。但随着人类文明的发展，人们已经忘了名本身的意义，给了名太多的附加属性。分别之心都是由此而来。但是，真的有那么多不同吗？所谓的好坏美丑高低大小，都是相对的，完全看从哪个角度来看。比如说，唐代以胖为美，而现代以瘦为美。现代的女孩子听说被人评价自己胖，感觉是在贬低自己，侮辱自己，但如果放到唐代，我相信听到说自己胖的女孩子应该会觉得是在夸自己。胖瘦本身并没有任何附加意义，只是一个属性，而人们的分别心给了它附加意义。</p>\n<p><strong>无名是天地的开始。有名是万物之母。</strong></p>\n<p>在盘古开天辟地之前，一切都处在混沌之中，所有的东西都是一样的，所以是无分别的，无名的。现代物理学也证实，万物的本质都是由微小的原子所组成的，其实并无差别。所以无差别，就没有所谓的名，这才是天地开始本来的样子。</p>\n<p>有了名之后，就有了万物的分别。一切物体或者生命随着微小粒子的排列组合不同，构成了我们这个五彩缤纷的世界，这个过程就像母亲一样孕育了世间万物。</p>\n<p>一个很好的例子就是人从孕育到生长的过程。在胚胎干细胞分裂之前，所有的细胞的属性都是一样的，这时候就是无名的。但随着细胞的分裂生长，干细胞演变成了身体各个组织，比如肝脏、骨头、皮肤等等，从这里开始就有了名相的区分。</p>\n<p>然后随着细胞分裂，一个小生命也就诞生了。在诞生之初，所有的小孩脑袋里都是空的，这时候也是无差别的，不会说这个小孩是科学家，另一个是医生，所以这时候又可以说是无名的。小孩子在不同的社会家庭环境中成长，被教育成了拥有不同性格不同技能的成年人，我们就会给这个人加上很多名，比如科学家、政治家、好人、坏人等等。这个时候，这个人就是有名的状态了。人本质是没有什么不同的，但一个个标签名相又都是被环境、自身、家庭等等孕育出来的。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道德经"]},{"title":"《道德经》-10-2","url":"/2020/06/13/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-10-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>涤除玄览，能无疵乎？爱民治国，能无知乎？天门开阖，能为雌乎？</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第十章前文主要在讲人要懂得守藏精神，回到至柔之和的状态。继续讲第十章，看看老子还有哪些感悟～</p>\n<p><strong>扫除杂念而深入观察心灵，能没有瑕疵吗？</strong></p>\n<p>玄览比较难理解，在有的版本中写为玄鉴。玄，是奥妙深邃的意思。览，当镜子解。所以玄览就是指人心灵深处明澈如镜。</p>\n<p>人来到这个世界之处，心灵一丝不染，眼神纯真天真，没有意思伪装。然而随着年龄增大，内心被世俗沾染上了各种习气。内心开始有了分别心，有了欲望，有了争斗。所以老子提倡人应该把内心打扫干净，不要被社会所污染。从花花世界的物欲外求中重新审视自己的内心，重新回到刚刚来到这个世界时的纯净。</p>\n<p><strong>爱民治国，能遵行自然无为的规律吗？</strong></p>\n<p>当领导的总喜欢显示自己的政绩，当老板的总喜欢让下属觉得自己厉害。然而真正的厉害是尧舜禹一般的人物，他们只负责制定规则，然后每个人都按照自己的职责去办事情，组织和公司运行得非常顺利，从而很少需要领导去救火，也就不会显示领导的高明。为无为而无不为，才是真正的领导之道。</p>\n<p>《击壤歌》是一首远古先民咏赞美好生活的歌谣，这首歌是这么描述的当时的平民生活”日出而作，日入而息，凿井而饮，耕田而食。帝力于我何有哉！”这首展现农耕时代先民幸福生活的歌谣，也在侧面反映了当时社会的和谐。而这种和谐，正是老子描述的无为而治的状态。民众自食其力，日出而作，日落而息，自己的幸福生活跟统治者有什么关系呢？</p>\n<p><strong>感官的开阖，能保持柔和清净吗？</strong></p>\n<p>天门，有多种解释。一说指耳目口鼻等人的感官；一说指兴衰治乱之根源；一说是指自然之理；一说是指人的心神出入即意念和感官的配合等。此处依”感官说”。</p>\n<p>一吸之间，人们能有十万八千念。睁开眼睛，就能看到物欲的诱惑；打开耳朵，就能听到喧嚣繁杂；鼻子一闻，就能闻到花香四溢；张开嘴巴，就能享受珍馐美味。感官一开一闭之间，人心就随着欲望走了。所以老子的发问直抵灵魂：在感官欲望面前，我们能够保持清净柔和之心吗？保持住了，你就能够守藏精神，摆脱世俗，摆脱欲望。</p>\n<hr>\n<p>第十章比较复杂，讲的也比较长，明天将继续分析第十章的最后一部分。</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-10-3","url":"/2020/06/15/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-10-3/","content":"<p><strong>原文：</strong></p>\n<p><strong>明白四达，能无知乎？生之、畜之，生而不有，为而不恃，长而不宰，是谓玄德。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>继续分析第十章剩下的部分：</p>\n<p><strong>对事物明白通达，能不用心机吗？</strong></p>\n<p>无论是老子还是释加牟尼都是非常反对“智”的。他们追求的是一种大智慧，用《金刚经》中的话来说是“般若”智慧。这种大智慧不同于人世间人们为争夺利益或者达到某种目的而采取的策略权谋手段。俗话说“静能生慧”，这种大智慧是需要静心内观而来，需要一个人的人格修养达到一种境界而来的。而另一个成语“急中生智”则反映了我们平时说的“智”的由来，这种“智”是人在危急时刻的一种临场应变而来，是为了达到某种目的而采取的一种手段。</p>\n<p>真正的大智慧是大智若愚的状态，诚信做人做事，看起来收效很慢，但获得的却是长久的收益。相反，心机狡诈看起来很聪明，但却失去的他人的信任，一个没有信誉的人，人生之路必将越走越窄。老子后面也说到“大道甚夷，而民好径”。明明大道是一片坦途，而人们却喜欢走小路，总以为走小路会更快。但事实却往往相反，学英语最快的捷径就是认真背单词把基础打牢，事业成功的最快捷径就是认真学习钻研自己的领域，身体健康最快的捷径是坚持锻炼保持良好的生活习惯。</p>\n<p><strong>让万事万物生长繁衍，产生万物、养育万物而不占为己有，作万物之长而不主宰他们，这就叫做“玄德”。</strong></p>\n<p>“玄德”是深远玄妙的大德。看过《三国演义》的人都知道刘备字玄德。这个名字就起的非常好，从他的字里可以看出他的家庭必然对黄老学说非常了解，而刘备一生所遵守的人生信条也跟这个玄德息息相关，从而在他身边凝聚了一大批仁人志士。</p>\n<p>那么具体来说什么样的品德算是玄德呢？生之、畜之，生而不有，为而不恃，长而不宰，这样的德行是玄德。<strong>首先，要让万物都生长繁衍，做事情要有利他的想法。</strong>伟大的企业家、政治家，都是在壮大自己的同时，会让所有人都受益，从而实现共赢。一个人的格局和心胸决定了一个人可以做出多大的事业。<strong>其次，虽然万物因为自己获利，但却能做到不占有不居功。</strong>比如华盛顿这个美利坚合众国的缔造者，本可以凭借着国父的身份当上永久的国家元首，但他却在任期结束之后，选择自选放弃权利，不再谋求连任。这点就非常了不起，几百年过去了，美国人乃至全世界的人们无不对他敬仰有加。<strong>最后，领导众人，但却不主宰众人。</strong>领导大家是为了让组织更有序，工作更有效率，从而让大家都过得更好，而不是为了显示自己的权威。在人格上，任何人都是平等的，一个人不应该因为自己手里的权力而膨胀，也不应该因为自己被领导而失去尊严。</p>\n<hr>\n<p>文</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-10-1","url":"/2020/06/12/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-10/","content":"<p><strong>原文：</strong></p>\n<p><strong>载营魄抱一，能无离乎？专气致柔，能婴儿乎？</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一章主要讲了持满戒盈的道理，凡事不可过分追求圆满和极限。月盈则亏，物壮则老，功成身退天之道。接下来看看第十章又讲了什么。</p>\n<p><strong>肉体负载着魂魄，人是精神和肉体的统一，能不能抱守大道，守住精神不离肉体？</strong></p>\n<p>人是精神和肉体的统一，虽然我们看不到魂魄的存在，但我们可以感受到每个人都有不同的性格，不同的思维和不同的精神状态。比较遗憾的是，人在大部分时间，精神和肉体都是分离的。而且很容易三分钟热度，被一点风吹草动所影响。比如吃饭的时候，有几个人是在认真品味饭菜的真实味道？大家都是一边吃饭，一遍看电视或者聊天。有时候吃完饭了，都没有认真体会饭菜的味道。</p>\n<p>在做事情的时候也是如此，很多人做事情的时候很容易分神，手里忙着一件事情，脑袋里又想着另外的事情，从而导致工作效率低下。我前面文章也提到过，进入“心流”的状态会让人有意想不到的收获。人在高度专注的时候，根本不会体会到时间的流逝，全身心投入到一件事情里去，会让你的创造力呈指数型提升。这也几乎是所有的大师都会有的一种状态，就仿佛是高僧入定一般，自动屏蔽了一切干扰。人们如果能够守住魂魄不分离，那么无论在事业、身体、还是精神面貌上都会得到一个很大的提升。</p>\n<p><strong>结聚精气以致至柔之和，能不能回复到像婴儿一样的状态？</strong></p>\n<p>“专气”就是心不散乱，结聚精气。“致”在王弼的注解中解为极致的意思。</p>\n<p>观察婴儿我们会发现，他们身体柔软，气血充盈。婴儿的内心没有一丝分别心，也没有一丝欲念，甚至没有自我意识，这就跟前面提到的天地的状态非常像，所以老子认为婴儿是人类最接近于道的一个人生阶段。他们没有刻意为之，却一举一动都在符合着道。那么我们怎么才能回到这么纯真的状态呢？老子就说能不能专注我们的精气，从而回到至柔之和的状态呢？这里用的是反问，他并没有直接给出我们答案，答案可能需要我们自己去追寻。</p>\n<p>另外，老子认为柔是生命的特征，而僵硬是死亡的特征。比如有生命的植物、动物，活着的时候都是柔软的，一旦死亡，就会变得僵硬。一些健身项目，比如瑜伽也非常注重身体的柔韧性，通过对身体的拉伸，从而达到强身健体的目的。身体健康要讲究柔，那么做事要不要讲究柔呢？我们如果细心观察，就不难发现善于以柔克刚，用柔的方式解决问题的人，会让人更舒服，事情也会更容易得到解决。相反，如果一味的刚，效果反而会非常差，甚至有可能会给自己带来祸患。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《荀子·修身》-11","url":"/2020/05/28/%E3%80%8A%E8%8D%80%E5%AD%90%C2%B7%E4%BF%AE%E8%BA%AB%E3%80%8B-11/","content":"<p><strong>原文：</strong></p>\n<p><strong>君子之求利也略，其远害也早，其避辱也惧，其行道理也勇。君子贫穷而志广，富贵而体恭，安燕而血气不惰，劳勌而容貌不枯，怒不过夺，喜不过予。君子贫穷而志广，隆仁也；富贵而体恭，杀埶也；安燕而血气不衰，柬理也；劳勌而容貌不枯，好交也；怒不过夺，喜不过予，是法胜私也。《书》曰：“无有作好，遵王之道。无有作恶，遵王之路。”此言君子之能以公义胜私欲也。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>君子对于谋求私利很不在意，对于祸害早早远离，对于耻辱警惕而回避，对于道义所在，又勇于担当。君子贫穷却志向广大，富贵却恭敬有礼，气定神闲却血气充盈，整日劳倦却容色不枯老，发怒的时候不过分处罚，高兴的时候不过分赏赐。</strong></p>\n<p>这里讲了君子的几个特征：不戚戚于贫贱，不汲汲于富贵；知荣辱，知退进；贫而无谄，富而无骄；做事不过分，不把自己的喜好强加与人，求中庸之道。如果能做到这些，可以说是一个君子了。</p>\n<p><strong>君子贫穷却志向广大，是因为尊崇仁爱；富贵而恭敬有礼，是不以势骄人；气定神闲却血气不衰，是按照礼仪所宜去做；劳累的时候却容色不枯老，是注重礼仪；发怒的时候不过分处罚，高兴的时候不过分赏赐，是能以礼法克制私意。</strong></p>\n<p>这里讲了君子为何能做到这些。因为崇尚仁爱，所以志向广大，也是老子说的“慈故能勇”。一个人只有心怀仁慈，才能有更大的格局，心怀天下受苦受难之人，从而才有可能作出一番事业。不以财势骄人，说明并不把功名富贵放在心上，金钱名望地位都是身外物，君子役物，小人役于物。君子做事张弛有度，有规划，有取舍，谦谦君子，不会慌里慌张。另外，君子喜怒不过于形于色，懂得克制自己的情绪。发怒的时候，也不会因为自己的情绪而过分处罚，高兴的时候，也不会因为自己的情绪而过分赏赐他人。这样有求与你或有怨与你的人，就不会钻空子，通过情绪来利用你。</p>\n<p><strong>《尚书》说：“不要凭着个人的喜好办事，要遵照先王的正道去做。不要凭着个人的憎恶办事，要遵照先王的礼仪去做。”者是说君子能用公义战胜私意了。</strong></p>\n<p>真正的高人是制定规则的人，在一个好的规则下，所有人做事做人都有所依据，尽心尽力做好自己的时期就会得到应有的酬劳。在中国古代，这个最好的规则，就是圣人制定的礼法，如果所有人按照这个礼法来做，当时的世界应该也是长幼有序，母慈子孝。时代变了，人口、资源、环境、文化、等等的外部条件都发生了变化，显然圣人的礼法已经不适应我们这个时代。</p>\n<p>我们正处于一个剧变时代，旧的制度还在发挥着影响，新的制度还没有完全形成。世界大国都在角力，经济和军事力量强大的国家会把自己的价值观输出给其他国家，未来的走向现在还没有完全明朗。生在这个时代是幸运的，因为我们可以多方思考，从而更加接近世界的真实面貌，不会被一种固有而统一的观念所束缚。生在这个时代同时又是不幸的，各种价值观的碰撞，让我们有时候会不知所措，不知道到底应该怎样做才是对的。</p>\n<p>所以我们要努力思考，从流传了千年的典籍中汲取智慧无疑是一种非常高效的思维训练方式。既然能够经历千年时间的考验，其中必有过人之处。但尽信书不如无书，看书也要采取思辨的方式，去仔细考量是不是适应于我们这个时代。从历史书中我们就可以知道，人性这几千年并没有发生什么大的变化，人性的丑恶和善良一直不断的在历史中重复上演。积善之家必有余庆，积不善之家必有余殃。所以修身（修心、修德、修智慧）还是很重要的，无论贫富贵贱，我们都要保持自己独立的人格，不被外物所役使，不被情绪所蒙蔽，不去计较一时的得失，从而成为一个可以在社会中顶天立地的伟岸君子。</p>\n<hr>\n<p>这是《荀子·修身》的最后一节了，不知不觉已经学习完了《金刚经》还有《荀子·修身》两部经典。接下来可能会继续写一些《道德经》、《论语》或是《心经》之类的经典。更新速度可能会略微变慢，因为随着经济的重启，在家的悠闲时光也要结束了。但学习不会停止，会一直保持终身学习的习惯，让自己更为更好的人。小伙伴们一起加油～</p>\n","categories":["哲学思考","荀子·修身"],"tags":["修身","儒家","荀子"]},{"title":"《道德经》-12","url":"/2020/06/17/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-12/","content":"<p><strong>原文：</strong></p>\n<p><strong>五色令人目盲；五音令人耳聋；五味令人口爽；驰骋田猎，令人心发狂；难得之货，令人行妨。是以圣人为腹不为目，故去彼取此。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第十一章讲了有无的道理。这一章其实还是在讲无，不过是从感官享受的角度来讲。</p>\n<p><strong>五彩缤纷的色彩，令人眼花缭乱；各种杂乱的声音，令人耳朵失灵；充满滋味的食物，令人的味觉出错；纵情骑马狩猎，令人心情放荡发狂；稀有的物品，使人行为不轨。</strong></p>\n<p>道家讲五色、五音、五味、驰骋田猎、难得之货会让人目盲、耳聋、口爽、心发狂和行妨。佛家讲五蕴皆空，色、声、香、味、触、法皆是空相。若能所见诸相非相，就能够见到如来本性。儒家讲克己复礼，也提倡控制自己的感官欲望。古代的先贤圣哲基本上都在告诉我们同样一个道理，要控制自己的欲望，不要执着于感官享受。一切感官享受不但是空而不实的，而且还会伤害我们的身体。</p>\n<p>五色不仅仅是指青、黄、赤、白、黑五种色彩，而是包含一切眼睛见到的东西。一切新鲜的事物、美好的事物都能够勾起人们的占有欲和比较心。私欲轻则会让人们陷入想得而不能得的烦恼之中，重则会让人铤而走险去谋求对事物的占有。这句话也可以从养生角度来理解，各种颜色的刺激会让人的眼睛疲劳，从而会导致视力退化。</p>\n<p>五音同样不仅仅指宫、商、角、徵、羽五种音调，而是指听到的各种各样的声音和言论。杂乱的声音和言论让人无所适从，尤其是在信息时代，每个人都可以在互联网上发表自己的言论。对于同一件新闻热点，持有不同的观点的人相互攻讦，都在讲述自己的观念，黑白莫辨、混淆视听，让人不知所从。同样，这句话也可以从养生角度来理解，各种嘈杂的声音，让人的耳朵不堪其累，从而导致听力下降。</p>\n<p>五味同样不仅仅指酸、苦、甘、辛、咸这五种味道，而是指多种多样的美味。人们吃习惯了美味的东西，就想吃更有滋味的东西。吃了新鲜的东西，就会想要去品尝更加稀罕的东西。五谷杂粮、鸡鸭鱼肉不能满足人们对于味道追求的时候，就开始吃山珍野味。果子狸、穿山甲、猴脑、熊掌等都成了人们的盘中餐。首先，这种追求会让人味觉失灵，一旦味蕾习惯了重口味的东西，再吃五谷杂粮就让人失去了兴趣。其次，这种追求会让人更加追逐感官享受，从而成为身体和欲望的奴隶。然后，这种追求会伤害人的身体，各种调味料都其实是由中药衍伸而来都有其偏性，吃多了会让人生病。最后，这种追求特别容易导致传染病的流行，口蹄疫、狂犬病、犬瘟热、登革热、艾博拉病毒、_SARA_等冠状病毒等都与人类吃野生动物有关。</p>\n<p>驰骋田猎代表一切可以让人感觉到刺激的事物，比如打游戏、黄赌毒、飙车、打猎、极限运动等。纵情放肆会让人瞬间产生大量多巴胺，从而让人感觉到愉悦。而这种愉悦的体验，会让人对这种刺激产生成瘾依赖。不禁感叹多少人因为想要追寻这种一瞬间的愉悦而丢掉了卿卿性命。</p>\n<p>难得之货代指一切稀缺资源（美貌、高贵的身份、奢侈品、金钱等），它们同样会让人心理失衡。稀缺资源的属性注定了它不可能被每个人可以轻易得到。人这个动物有个很奇怪的属性，就是周围人都没有一样东西的时候，哪怕缺衣少食，都可以活得心安理得。而一旦周围的人都拥有一样东西而自己没有的时候，哪怕锦衣玉食，都觉得少了点什么。得不到而想得的时候，人们就会铤而走险，想尽一切办法去得到这个东西。有些人冒着生命危险去整容，有些人冒着对身体伤害的风险来节食，有些人为了获得金钱而贩毒走私，有些人为了获得高位而阿谀奉承。这一切丑恶现象的根源都是因为难得之货把人心弄的失衡了。</p>\n<p><strong>所以，圣人但求吃饱肚子而不追逐声色之娱，所以摒弃物欲的诱惑而保持安定知足的生活方式。</strong></p>\n<p>腹指的是满足生活的基本需求，而目指的是多欲奢侈的一种生活方式。圣人只求吃饱穿暖，不求声色犬马、纵情享受。</p>\n<p>所有人都想要追求幸福快乐。而圣人看到了声色享受带来的快乐是不可持久的，所以转而追求一种更加永恒的快乐，一种内心富足而产生的终极快乐。这种快乐不由感觉享受而来，而是由对这个世界更加深刻的认识而来，由对欲望和自身的克制而来，由对天下的慈悲而来。所以圣人反对声色享受这种短视行为，而用修身明理来证得终极智慧，从而获得长久的快乐。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道德经"]},{"title":"《道德经》-13-2","url":"/2020/06/19/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-13-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>何谓贵大患若身？吾所以有大患者，为吾有身，及吾无身，吾有何患？故贵以身为天下，若可寄天下；爱以身为天下，若可托天下。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>十三章前半部分讲了什么是宠辱若惊。我们接着讲后半部分，看看什么是贵大患若身。</p>\n<p><strong>什么叫做贵大患若身？我们之所以有大患，是因为我有自身意识；如果我没有自身意识，我还会有什么祸患呢？</strong></p>\n<p>这里的“贵”，几乎所有的注家都把它当作动词来解。但我认为这里的“贵”与上文的“宠”字相对应，都应当作名词解释。因为如果做动词解释，这句话的意思就成了“珍惜大的忧患就像珍惜我们的身体一样”，就与前文完全不衔接。如果做名词解释，理解为“身处尊贵地位的人”，全篇就非常好理解了。</p>\n<p>“贵大患若身”的意思应当是“身处尊贵地位的人最大的忧患乃是有自身这个概念”。前文我也曾提及，《道德经》和《金刚经》其实内容非常的相像，两者是可以相互印证的。《金刚经》中反复提及的一个概念就是“无我相、人相、众生相、寿者相”，其实也是在说不要认为有一个我的存在，有自我的执念是一切颠倒梦想的根源。为什么有宠辱呢？是因为有一个我的概念存在。有了自我意识，就有了得失和荣辱。一切为自己的私利而争夺的行为都是有为，所以要破开我执，返璞归真，进入无欲无为的状态，这也正是《道德经》的核心所在。</p>\n<p>接下来进一步解释，之所以有大患是因为我们有自身意识。更具体来说，人有了自身意识就会为了自身利益争夺，人心就会在荣辱得失的大海中沉浮。而一旦矛盾激化，就会激发人们内心的好狠斗勇之心，在此之中人们可能会失去灵魂也可能会失去性命，所以就有大患。如果没有自我意识呢？那么就不会有任何私欲，一个无私无欲的人就跟小孩一样，他人也不会与你争斗，所以就能保全自身。尤其是对于领导管理者，要不与民争利，不与下属争利，只有这样才能赢得民心，从而保全自身。</p>\n<p><strong>故而，能够将自我修炼融入到治理天下过程中的人，可以把天下重任委托给他。在治理天下过程中能够全身心的投入其全部热情的人，可以托身于天下万民之上。</strong></p>\n<p>一个人能以家庭为自身，他就能拖得起家庭的重任。一个人以企业为自身，他就能托得起企业的重任。一个人以国家为自身，他就能托得起国家的重任。一家人如果能够不分彼此，那么家庭关系必然是和谐的。尤其是作为一家之长，如果把每个家庭成员都当成自身身体的一部分那样去珍爱和呵护，完全没有个人私欲，那么这个人就是值得大家信赖和依靠的家长。同样的一个人如果把更大的企业和国家当成自己身体，看成自己的生命，那么这个企业或者国家交给这个人就是值得信赖的。简而言之，一个人的心的范围画的有多大，就可以把多大的责任交给这个人。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-11","url":"/2020/06/16/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-11/","content":"<p><strong>原文：</strong></p>\n<p><strong>三十辐，共一毂，当其无，有车之用。埏埴以为器，当其无，有器之用。凿户牖以为室，当其无，有室之用。故有之以为利，无之以为用。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前文一直在讲无的重要性。无离、无疵、无为、无知等等都是在让人洗涤社会浸染的尘埃，从而返璞归真。第十一章继续用一些生活中的实际例子来讲有无的关系。</p>\n<p><strong>三十根辐条汇集到一根毂中，有了车轮中空的地方，才有车的作用。</strong></p>\n<p>车轮只有中空，才能跑的更快。如果做成实心的，那么车轮的重量将会非常大，抗震性也不如空心的好，那么这个车子的性能将会大大降低。所以，车轮只有中空的才能让车子发挥出最好的性能。人也一样，心中没有负担和压力，做事情才能更加自如，同时也会激发出更大的创造力。心中没有欲望和恐惧，做事才能不畏首畏尾、进退失措。所以，人如果能够做到无，将会和装有空心轮子的车子一样发挥出最大的性能。</p>\n<p><strong>揉和陶土做成器皿，有了器具中空的地方，才有器皿的作用。开凿门窗建造房屋，有了门窗四壁内的空虚部分，才有房屋的作用。</strong></p>\n<p>生活中几乎所有用到的器皿都是空心的，如果碗、杯子等器皿都做成实心的，那么什么就都不能被装进去了。房屋也是如此，只有内部空虚，才能住人。只有挖出窗和门，阳光、空气和人才有了进出房间的通道。所以，世间的道理都是相通的，人只有谦虚不自满，才能有进步的空间。只有扫除污秽和固有执念，才能给真知留出空间。</p>\n<p><strong>所以，“有”给人便利，“无”发挥了它的作用。</strong></p>\n<p>只有无也不行，因为无是由有而来的。没有辐条、轮毂、碗壁、墙壁、房顶这些实有的东西，又哪里来的无呢？所以说有无相结合才能发挥事物最大的功用。</p>\n<p>人们为什么要假期呢？人们为什么需要休息和睡觉呢？有些持有极端观点的人认为这些休息都是不必要的，休息只能浪费时间。还有些大厂甚至推荐996的工作制度，认为只有这样才能创造更多的价值。但我认为，适当假期和休息完全是非常有必要的，人在一段时间的休整之后，才能有更大的冲劲和创造力。“无”和“有”是相辅相成的，很多人连续不断的努力工作，但却一直无法攻克一个难题，然而往往在休假放松的时候灵感突然就来了。</p>\n<p>俗话说“百无一用是书生”，读书很多时候也被看作是“无用”的。但我们发现真正有大成就的人无一不是喜欢读书的人。因为读书的收益是需要很久的积累才能有效果的，而一旦积累到一定程度，举手投足，做任何决定无不在受书本的影响，所以无用之处藏着大用。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-13-1","url":"/2020/06/18/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-13/","content":"<p><strong>原文：</strong></p>\n<p><strong>宠辱若惊，贵大患若身。何谓宠辱若惊？宠为下，得之若惊，失之若惊，是谓宠辱若惊。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前一章老子告诉我们一切感官刺激都是虚妄的，多度贪婪都会伤害人的身心。接下来，我们看看老子在这一章又告诉了我们什么道理。</p>\n<p><strong>受到宠爱和受到侮辱都好像受到惊恐，</strong>身处高位最大的忧患乃是自身<strong>。</strong></p>\n<p>开篇点题，宠和辱是一样的，无论受到侮辱还是宠爱都要当作受到惊吓一样。另外，又说身处高位最大的忧患乃是自身。这里看的我们一头雾水，不过老子紧随其后就开始解释这两句话。</p>\n<p><strong>什么叫做得宠和受辱都感到惊慌失措？得宠是卑下的，得到宠爱感到格外惊喜，失去宠爱则令人惊慌不安。这就叫做得宠和受辱都感到惊恐。</strong></p>\n<p>为什么要把宠和辱都当作受到惊吓一样呢？一般人都喜欢宠而不喜欢辱，实际上有宠必然有辱。就像有无总是相伴而生一样，宠和辱是相生相对的两个概念。</p>\n<p>一旦心中有了宠的概念，必然也就有了高下贵贱的分别。宠是高位俯视低位而施舍出的好。我们总是会听到我们很宠爱我们的狗，但却没有人说我们被我们的狗宠爱。因为，狗需要人的施舍，而人不需要狗的施舍。人一旦觉得自己得宠，先不要沾沾自得，你实际上已经处在了卑微的低位，人格上已经不平等了。处在低位的人时刻想要高位的人的赞同，放佛高位之人的认同就是他做一切事情的出发点。然而永久的认同是不可能存在的，当这个认同不在的时候，就成了辱。</p>\n<p>宠辱的分别根源来自于我们内心的失衡，在于太在意某件事情，或者某个人的看法。尤其人是在职场特别犯一个毛病，职场新人太过于在意领导、上级的看法，从而努力去迎合他们，把自己搞得身心俱疲。事实上，这些人的看法有那么重要吗？他人说你不行，你就要自暴自弃吗？他人说你很厉害，你就膨胀了吗？那如果今天有人说你很棒，明天有人说你很差劲，那你岂不都要人格分裂了。所以无论外界评价如何，很多时候事情的本质并没有任何变化，变化的只是我们的内心。对事物要有自己清晰的认识，我们每个人都不是圣人，也都没有恶贯满盈。有缺点、有优点，才是一个真实的人。你是这样，上司是这样，国家元首也是这样。对于外界的评价不必太过在意，但我们内心要有一杆秤，知道自身的优缺点。对于优点要发挥，对于缺点要改进。君子博学日参醒乎己，我们学习进步不是为了给外界展示什么，而是为了让我们生活的更幸福，精神更饱满，心灵更纯净。</p>\n<hr>\n<p>明天继续分析什么叫贵大患若身。</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-14","url":"/2020/06/20/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-14/","content":"<p><strong>原文：</strong></p>\n<p><strong>视之不见，名曰夷；听之不闻，名曰希；搏之不得，名曰微。此三者不可致诘，故混而为一。其上不皦，其下不昧。绳绳不可名，复归于无物。是谓无状之状，无物之象，是谓惚恍。迎之不见其首，随之不见其后。执古之道，以御今之有。能知古始，是谓道纪。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一章讲了“宠辱若惊”和“贵大患若身”的智慧，接下来我们一起看一看第十四章老子又讲了什么人生哲理。</p>\n<p><strong>无状无色，不可以看到，把它叫做“夷”；无声无响，不可以听到，把它叫做“希”；无形无相，不可以摸到，把它叫做“微”。这三者的形状无从追究，它们原本就浑然而为一。</strong></p>\n<p>这里老子又开始对大自然进行探索，来观察到底“道”是什么样子的。“夷”、“希”、“微”是道的三个特征，道无名无相，口不能言，书不能传，只能受之以静，求之以神，不可问诘而得之。</p>\n<p>也正是因为道的无状无相，无声无响，所以才能无所不通，无所不往。世界上伟大的人都相信世界背后有一个终极规律在推动着世界的运转。释加牟尼把它称为“如来”，老子把它称为“道”，耶稣把它称为“上帝”，毛泽东把它称为“矛盾”，爱因斯坦把它称为“统一场论”。虽然名称和形式各有不同，但没有谁说自己见过听过或者摸过这个世界的本源力量，因为这个终极规律是无色、无状、无形、不可说、不可得、不可思议的。《金刚经》里说过“一切圣贤皆因无为法而有差别”，这个差别就是指外在体现形式。</p>\n<p>这种本源力量无从追究它的源头，它可能在我们这个宇宙产生之前就已经存在了。物理学家说我们这个宇宙起始于一场大爆炸，大爆炸开始的那个点叫做“奇点”。“奇点”包含了我们整个宇宙的物质、能量和时间，它是一个体积无限小、密度无限大、引力无限大、时空曲率无限大的点。我们中国也有盘古开天辟地的神话故事，在盘古开天劈地之前世界一片混沌。没有日月星辰、没有高山大海，一切都混而为一，也跟“奇点”的描述很像。这个“奇点”可能就包含宇宙的本源力量，虽然“奇点”之后的一切物理现象都可以用现代物理的规律来解释，但“奇点”从哪里来？“奇点”之前是什么样子的？自古至今人类对此都是好无头绪，可能已经完全超出我们所能理解的范围了。</p>\n<p><strong>它的上面既不显得光明亮堂；它的下面也不显得阴暗晦涩，无头无绪、延绵不绝却又不可称名，一切运动都又回复到无形无象的状态。这就是无状之状，无物之象，也就是“惚恍”。迎着它，看不见它的前头，跟着它，也看不见它的后头。把握着早已存在的“道”，来驾驭现实存在的具体事物。能认识、了解宇宙的初始，这就叫做认识“道”的规律。</strong></p>\n<p>道既有形有无形，它无处不在，却又毫无头绪。看不见、抓不到、摸不得，但道却又是真实存在的。老子给它进行了一个特别贴切的描述叫做“惚恍”，意思是若存若亡，仿佛能看到它，但仿佛又不能看到它。就跟“如来”这个词很像，如来者，无所从来，亦无所去。仿佛来了，又仿佛没来。让人无法真正的去描述，去捉摸。</p>\n<p>虽然不可名状，但如果运用前人总结出来的一些“道”的规律来指导实践，却总能够无往不利，感受到“道”的存在和它巨大的力量。这就是为什么人们能够感知到这个虚无缥缈的“道”的存在，从而让人们前赴后继，去探究这个世界的真相。这个“道”并不会因为时间和空间的改变而有不同。上古虽远，其道存焉，故虽在今，可知古始。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-16-1","url":"/2020/06/23/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-16-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>致虚极，守静笃。万物并作，吾以观复。夫物芸芸，各复归其根。归根曰静，是谓复命。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第十五章讲了得道之人的几个特征：谨慎、机警、庄重、润物无声、朴实无华、心胸开阔、包容且不另类。老子在讲述完这些特质之后，不禁感叹知道易，行道难。谁能够浊以静之徐清？谁又能够安以久动之徐生？第十六章就告诉我们应该怎么做才能达到这种状态，接下来我们一起来品读一下第十六章吧。</p>\n<p><strong>尽力使心灵的虚寂达到极点，使生活清静坚守不变。</strong></p>\n<p>“致虚极，守静笃”可谓是全文精华的总结。修行提高自身就是要去除一切妄念，使心灵复归于最初的纯净状态。佛家讲其实没有人相、我相、众生相、寿者相，一切相皆是人的妄想执着。所以人不可以着相，如果所见诸相非相，就可以见到如来本性。所见诸相非相就是道家说的至虚极。极致到没有任何欲望，没有任何分别心，没有任何妄为。没有你我的分别，没有肤色、种族、性别、物种、阶级等一切分别。圣人无常心，以百姓之心为心。百姓所想所念，即是圣人所想所念。圣人与天地与百姓融为一体，天地万物即是圣人之心。到达至虚极，就可以破掉一切执着妄想，看到自己清净的初心，得证至高智慧。</p>\n<p>纷繁的世界带动着我们的心时刻在变动，人们的大脑一刻不停的在受到干扰，一呼一吸之间就能有十万八千念。排除这些杂念就要“守静”，守静守到极致就是“守静笃”。水混了静放一段时间就能变得澄清。同样，人的心乱了，安静下来就能复归清明。</p>\n<p><strong>万物都一齐蓬勃生长，我从而考察其往复的道理。那万物纷纷芸芸，各自返回它的本根。返回到它的本根就叫做清静，清静就叫做复归于生命。</strong></p>\n<p>对待万物的繁衍生息、蓬勃生长，我们不能随着心动，而要细心观察事物背后的规律。世间一切都在循环往复的运转，一切发生过的事情还会再次发生。生命有生老病死，东西有成坏毁空，每一个轮转就是一个轮回。但死亡远远不是终点，而是另一个起点。落红不是无情物，化作春泥更护花。枯黄的树叶落到泥土中，成为了树木的肥料，孕育着来年的新生。任何毁坏的东西都会进入大的循环，重新成为一个新生的事物。事物本质上并没有毁坏也没有新生，只是在不断的变化，不断的重新排列组合。而人们只注意到了终结的一瞬间，以为死亡是瞬间发生的事情。其实从出生下来，人们就不断的在走向死亡。产品自从被生产出来，就会不断的走向损坏。而死亡和损坏本身也蕴含着新的生机，在死亡的一瞬间就是重新回到了大自然母亲的怀抱，重新回到了这个循环，为新的诞生而铺垫。所以这一切变化都在不断的发生，从未终止也从不会终止，这就是我们生存的这个世界的终极秘密。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-17-1","url":"/2020/06/25/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-17-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>太上，下知有之；其次，亲而誉之；其次，畏之；其次，侮之。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在第十六章中老子告诉了我们“致虚极，守静笃”的修身明心之法。通过观复就能知道世界恒常不变的道理，然后就能容、公、王、天，最终与道合同、没身不殆。接下来我们一起来看看老子在第十七章中又讲了哪些人生哲理吧。</p>\n<p><strong>最上等的管理，人民只知道有个领导存在；稍次一级的管理，人民亲近他并且称赞管理他们的领导；再次一等的管理，人民畏惧管理他们的领导；更次一等的管理，人民轻蔑侮辱管理他们的领导。</strong></p>\n<p>第十七章主要讲了管理和修身的几层境界。对于《道德经》永远不要只从一个方面来理解，这本书讲的是世界最本源的一些规律，所以世界上方方面面的事情几乎都是适用的。不过应用最广的两个方面还是修身和组织管理。其实修身也是管理，一个人管理好了嘴巴，管理好了眼睛，管理好了耳朵，管理好了欲望，管理好了身体，管理好了时间，管理好了情绪就是修身很成功的人了。管理好了自己，了解了人性和天道，就可以把范围扩大到手管理一个家庭、公司、甚至国家。这就是为什么中国人讲究修身、齐家、治国、平天下这么一个逐步提高和扩大的个人追求的次序。</p>\n<p>太上，就是至上、最好。这么一个管理的境界就是人民只知道有这么个人，但这个当领导的从来不随便发号施令，从来不彰显自己的功德，但一切都运转的很顺利，每个人各得其所，各尽其职，各展其能。这样的圣人领导者，只是制定好了规则，从不干涉细节。这样的领导者古今罕见，也就尧舜禹这样的远古圣明之君有几分这样的风采。这样的人领导人民，就像大道领导世间万物一样，只把基本规则制定好，然后就任万物自己发展，没有自己的个人喜好和意志。</p>\n<p>稍微低上一个层次的就稍微比较常见了。这样的人，大家都称赞他领导有方，也深受大家爱戴。他们的德行是可以被大家见到的，他们的恩惠是可以被称道的，所以大家才会亲而誉之。如果遇到这样的人领导国家，政治清明，人民幸福，国家安定。遇到这样的人领导公司，业绩优秀，人事和谐，分工明确。遇到这样的人领导家庭，家庭和谐，生活富足，邻里和睦。可是这样的人一旦不在其位，他所开辟的稳定繁荣昌盛的局面将很有可能会面临瘫痪和崩塌。因为这样的一个组织，完全靠的是领导者的个人魅力和能力来保证组织正常有效的运转的。</p>\n<p>再低上一个层次的管理就更常见了。在一个组织中，大家都畏惧他们的领导。这样的组织管理完全建立在恐惧的基础上。学生害怕挨训所以完成作业，小孩害怕挨骂所以听爸妈话，员工害怕失业所以不敢违逆老板，人民害怕刑罚所以遵守规定。这样的管理虽然愚笨，但却在环境相对稳定的时候也还能正常运转。但是因为内部压力太大，所以禁不起任何风吹草动，当面临挑战的时候非常容易土崩瓦解。</p>\n<p>再低上一个层次就不能称之为有效的管理了。这样的组织中，大家的愤怒情绪已经战胜了恐惧。人民已经不再掩饰内心的愤怒，对管理者直接加以侮辱和反抗。如果一个国家到了这个阶段，就已经是大厦将倾。一个企业到了这个阶段，就马上要关门大吉。如果一个家庭到了这个阶段，就马上要分崩离析。</p>\n<p>管理者们千万不要等到了最后一个阶段才警醒，一定要时刻反省自己、审视自己，防患于未然。当被领导的人开始有畏惧情绪的时候，不要沾沾自得，觉得自己了不起，而是要深刻反省，因为这时候离灾祸已经不远了。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-15-1","url":"/2020/06/21/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-15-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>古之善为士者，微妙玄通，深不可识。夫唯不可识，故强为之容；豫兮若冬涉川；犹兮若畏四邻；俨兮其若容；涣兮若冰之将释。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第十四章中老子描述了道无形无状、无色无相。虽不可见，却又无处不在，功用无穷。接下来我们一起看看老子在第十五章又讲述了什么人生哲理吧。</p>\n<p><strong>古时候的得道之人，微妙通达，深刻玄远，不是一般人可以理解的。正因为不能认识他，所以只能勉强地形容他说：他小心谨慎，好像大象冬天踩着薄冰过河；他警觉戒备，好像大狗防备着四邻。</strong></p>\n<p>上一章讲了道是什么样，这里进一步讲得道之人是什么样的。因为得道之人就跟道一样微妙玄通，难以描述，所以老子勉强用了一些句子来描述这种人。首先，这样的人特别谨慎。“豫”和“犹”都是古时候的野兽，性情都非常机警谨慎。“豫”在《说文》中的解释是“象之大者”。很多人认为是一种类似于大象的动物，至少这种动物体积应该比较大。可以想像一下像大象一样的体积庞大的动物冬天踏冰过河时候的状态，肯定是非常小心，一步都不敢踩空。“犹”有说是五尺大犬（释文），有说是猿类（史记、水经注）。但无论到底是哪种说法，描述中都说这种动物都非常机警。养过狗的都知道，狗是一种非常机警的动物。周围的邻居稍微有点动静，它就会竖起耳朵，躁动不安。老子通过对当时大家都知道的两种动物的描述，得道之人谨慎小心的形态就描绘的非常生动形象了。</p>\n<p>孔子也说过“毋以恶小而为之，毋以善小而不为”。谨言慎行是每一个君子应该有的作风。曾子一日三醒，每天都要多次问自己：“为人谋而不忠乎？与朋友交而不信乎？传不习乎？”如果发现做得不妥就立即改正。巴菲特对待每一分钱的投资也都是相当谨慎。他有一个降落伞理论：如果有一个投资机会，盈利的概率达不到从飞机跳下时降落伞打开的概率，他就不会投资。几乎每一个伟大的人都在劝诫我们不要对自身放松警惕，往往差之毫厘，就会失之千里。</p>\n<p><strong>他恭敬郑重，好像在赴宴做客一样；他润物无声，好像冰块缓缓消融。</strong></p>\n<p>这里的“容”应该是当时抄写的时候给抄错了，原字应当是“客”。“涣”是解散、消逝的意思。</p>\n<p>这里又描述了得道之人的两个状态：恭敬郑重、润物无声。大家去别人家做客都是打扮的很正式，表现的很恭敬和郑重。得道之人就时刻保持这种状态，对谁都不随便，恭敬郑重，对人对事都认真对待，不轻易越线。《庄子》里说过人们应该这么处理人际关系：“<strong>君子之交淡若水，小人之交甘若醴；君子淡以亲，小人甘以绝</strong>”，就跟这里的意思很接近了。君子之交不用表现的很随便不见外而显得很亲近，而是一种心灵的交流，就算十年、二十年不联系，见面了也是知己，可以交心。而小人之交呢？往往通过互相交换秘密、互相给对方好处或者表现的不见外来显示他们关系的亲密。君子之交是淡而亲，小人之交是甘以绝。不越线，是可以让友情常保青春的秘诀。</p>\n<p>冰块消融的时候是无声而缓慢的，一不留神可能就发现冰块融化成了水。这是在形容得道之人对于矛盾、冲突、负面情绪或者不好的习惯的调整修正的时候是润物细无声的。在不动声色中一个大矛盾大问题可能就化解了，有一种四两拨千斤的味道。如果别人犯了什么错误，也可以做到在不知不觉中让人意识到并且改正，而不是疾风暴雨似的批评而让人难堪。老子在后面也会提到“大智不割”的智慧，意思是真正的有大智慧的人，永远不轻易割伤他人，不让人觉得不舒服。君子圆润而不圆滑，做事方正但不鲁莽。润物无声是解决问题的最快也是最好方式。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-15-2","url":"/2020/06/22/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-15-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>敦兮其若朴；旷兮其若谷；混兮其若浊；孰能浊以静之徐清？孰能安以久动之徐生？保此道者，不欲盈。夫唯不盈，故能蔽不新成。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第十五章前半部分描述了得道之人的几个特征：“豫兮若冬涉川；犹兮若畏四邻；俨兮其若容；涣兮若冰之将释”。第十五章的后半部分将继续描述得道之人的其余的一些特征。</p>\n<p><strong>他纯朴厚道，好像没有经过加工的璞玉；他旷远豁达，好像深幽的山谷；他浑厚宽容，好像不清的浊水。</strong></p>\n<p>除了前文提到的谨慎、机警、庄重、润物无声，得道之人也是淳朴、豁达、和包容的。老子反复呼吁人们返璞归真，反对人们用心机和智谋来为自己争夺利益。老子提倡的是“大智若愚，大巧若拙，大辩若讷”，提倡以德服人而不以权谋治人。普通人经过后天的熏染，身上会染上各种社会习气，有了分别心、欲望和固有观念，从而变得不再纯粹。有些人贪图享乐，有些人害怕失去。一切妄想执着，都会让人心理失衡，种种怪象皆由此而生。而得道之人却仿佛是一块未加工的璞玉，身上毫无被雕琢的痕迹，看起来朴实无华，却又价值连城。</p>\n<p>得道之人的另一个特征是心胸开阔，他们的心就像幽深的山谷一般可以包容一切。壁立千仞，无欲则刚，海纳百川，有容乃大。一个人只有心胸开阔，包容一切，才能成就大的事业。</p>\n<p>另外，水至清则无鱼，人至察则无徒。得道之人虽然心中有丘壑，却并不表现的与众不同，而与众人和光同尘。虽然看到了世俗之人的各种小缺点，却表现的浑然不知。他们不自命不凡，也不曲高和寡。</p>\n<p><strong>谁能使浑浊的水安静下来，慢慢澄清？谁能使安静变动起来，慢慢显出生机？保持这个“道”的人不会自满。正因为他从不自满，所以能够去故更新。</strong></p>\n<p>人们在社会中沾染了各种社会习气，失去了率真朴实的本性，被欲望和执着妄想迷住了眼睛，那么应该怎么返璞归真呢？老子在这里告诉了人们修行法门，只要安静下来，浑浊的心就会变得澄清。而静又是动的内在力量，一切生机又从静中而来。在一动一静中，生命就会历久弥新，焕发出新生的力量。</p>\n<p>”孰能“这两个字体现出了能这样做的人真是少之又少，说明了行道之难。怎么修道其实讲起来很容易，简单到用六个字就可以概括：”至虚极，守静笃“。可是有几个人又能真正做到呢？可能现在一刻的你做到了，谁又能保证下一刻的你还能继续做到呢？可能在一件事情上做到了，谁又能保证所有的事情上都能做到呢？所以修行之路是一条漫漫长路，永远没有终点。得道之人，永远保持谦逊，永远不自满，永远在向大自然虚心地学习。正因为这种不自满，才能让得道之人不懈怠，时刻焕着生机。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-17-2","url":"/2020/06/26/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-17-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>信不足焉，有不信焉。悠兮，其贵言，功成事遂，百姓皆谓我自然。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第十七章前半部分我们一起学习了管理和修身的四层境界：下知有之，亲而誉之，畏之，侮之。那么为什么管理水平差异如此之大呢？我们应该怎样才能保持一个有效的管理呢？第十七章后半部分就给出了我们答案，接下来我们一起来学习一下吧。</p>\n<p><strong>管理者的诚信不足，人民才会不相信他。最好管理是多么悠闲，他很少发号施令，事情办成功了，老百姓说“我们本来就是这样的”。</strong></p>\n<p>一切果都有因，一切外部的不幸都可以在自身找到原因。对于修身和管理，最重要的就是诚信。管理的失效是因为缺少诚信，修身没有成效也是因为缺少诚信。俗话说”人无信则不立“，一个人如果没有信用，无论对自己还是对他人，都是无法在这个社会安身立命的。对自己没有诚信，今日事总是拖到明日再做，那么将是明日复明日，明日何其多的结果。自己决定的事情，就要努力去做到，不要给自己找借口。答应他人的事情，赴汤蹈火也一定要做到，否则就会失信于人。管理的基础在于信任，有信任的团队是一个有凝聚力、有战斗力的团队。管理者首先要做到言必信，行必果，这样才能在队伍中树立个人威望。要做到信，就要制定好规则，而且这个规则要对所有人都适应，管理者不可自己破坏规则。春秋战国时期礼崩乐坏，很大一部分原因是周天子自己都开始不遵守礼乐。</p>\n<p>制定好规则的管理将是非常轻松的管理，只需要大家按照这个规则去做事情，就可以做到各尽其能，各司其职，赏罚分明。管理者不需要到处救火，不需要展现自己过人的才能。每个人都有自己的工作流程，知道什么该做，什么不该做，目的非常明确，也不会进退失据。</p>\n<p>在一个好的框架和规则下，所有人都可以得到自己想要的东西，所有人都感到自由和轻松。世界上没有绝对的自由，只有在规则下合理适度的自由。规则的目的也不是限制自由，而是更好的保护每一个人的自由。所以，好的规则不会让人感受到过度的束缚，会让人感觉事情本应如此。</p>\n<p>按照好的规则办事，等到事情完成之后，人们就会感觉“我们本来就是这样的”。这一切都是本应该发生，与上级管理有什么关系。这就像我们呼吸空气一样，我们甚至很难察觉到它的存在。比如上古时候的农民不需要杂七杂八的上级指导他们怎么播种，不需要上级给他们传达各种精神。他们只需要凿井而饮，日出而作，日落而息，待到收获时节，他们觉得这一切本应该如此，并没有感受到这是谁的恩赐。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-16-2","url":"/2020/06/24/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-16-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>复命曰常，知常曰明。不知常，妄作凶。知常容，容乃公，公乃王，王乃天，天乃道，道乃久，没身不殆。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第十六章前半部分告诉了我们“致虚极，守静笃”的道理。对于万物的运转我们要学会观复，而不是心随流转。下面我们继续学习第十六章的后半部分，看看老子又分享了哪些智慧。</p>\n<p><strong>复归于生命就叫自然的常态，认识了自然规律就明白了事理，不认识自然规律的轻妄举止，往往会出乱子和灾凶。</strong></p>\n<p>世间万物都在一刻不停的循环往复。其实无死也无生，一切都只是在变化，不停的在重新排列组合，这种变化才是世界唯一的恒常之道。世界在被一只看不见的手支配着，让世间的一切都随着转动。通晓洞悉了这种变化，就可以说是从梦中醒来，看到了世界运转的枢纽。如果看不到这种变化，就会有种种执着妄想。有人祈求长生，有人追求功名，有人沦为金钱的奴隶，有人纸醉金迷、肆意放纵。可是我们只是在世间停留几十年，只是因缘和合而生的幻象。这些物质、名利转眼间就消失得无影无踪。几十年时间在宇宙的漫长岁月中也不过只是一刹那，人生已经非常短暂，为何不去做一些自己真正想做的事情呢？为什么不抓紧时间去真正思考一下人生呢？不知道这个恒常的变化，人们就会在欲海中沉浮，沉溺于五色、五音、五味等感官享受，这样不但不能给我们带来真正的幸福，还会让我们精神溃散、身体毁坏。</p>\n<p><strong>认识自然规律就会包容，包容就会坦然公正，公正无私就能王于天下，王于天下才能德与天通，德与天通则与道合同，与道合同乃能长久，终身不会遭到危险。</strong></p>\n<p>知道这个恒常的规律，人们就会包容、从容。因为人和世间的其他任何东西一样，不过是因缘和合刚好组成的个体。聚在一起的终会散去，散开来的终会以另一种形式聚合。就像《三国演义》里面说的：“话说天下大势，分久必合，合久必分”，一切都如此，聚散不过是常态。知道了死亡其实远不是终点，就会对死亡少了恐惧。死且不怕，还会害怕什么困难吗？知道了自我意识不过是聚合而生的幻象，就会无私无我，就会包容一切。包容世间一切，认识到自己不过是自然的一部分，就会以天下为己任，就会无私公正。无私公正的人必然受人爱戴，王于天下。这样的圣人已然无私心，天下的民心就是圣人之心，世界的意志就是圣人的意志，达到这样的高度才能德与天通，完全读懂这个世界。当德与天通的时候就摸到了大道的门槛，圣人将与道合同，从而长久不衰，他的思想将永远润泽着世人。</p>\n<p>读到这里，我们不妨用世俗一点的眼光来解读一下所谓的成败。当年称霸天下的秦始皇一朝风光过后，所建帝国土崩瓦解，后代子嗣惨遭屠戮。而孔子虽没有列土封侯，但他的思想却能几千年绵延不绝。站在几十年的角度看成败，秦始皇无限风光；站在几千年的角度看成败，孔子福泽万代。所站的高度不同，取得的功业也就不同。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-18","url":"/2020/06/27/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-18/","content":"<p><strong>原文：</strong></p>\n<p><strong>大道废，有仁义；智慧出，有大伪；六亲不和，有孝慈；国家昏乱，有忠臣。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在第十七章中我们学习了做人做事的四个层次，并且了解了之所以出现劳心劳力的去做一件事但却没能把事情处理好的原因在于诚信不足。人无信则不立，对人对己都要讲究诚信。所以我们做人做事要向“下知有之”的最高境界去学习，制定好规则，让一切自然运转，尤其注意制定规则者本人也不可轻易破坏规则。接下来我们继续一起学习第十八章，看看老子又带给我们什么样的人生启发了。</p>\n<p><strong>大道被废弃了，才有提倡仁义的需要；大的智慧的出现，是因为伪诈盛行；家庭出现了纠纷，才能显示出孝与慈；国家陷于混乱，才能见出忠臣。</strong></p>\n<p>就像第二章中提到的美丑善恶、高低长短都是相对出现的。美好的呈现是因为罪恶的衬托，贤能的出现是因为世事的混乱。仁义是一种非常美好的品质，但它的提倡正是因为大道的废弛，因为社会上有不仁不义的事情出现。老子不是反对仁义，他在这里只是在阐述一个世界的本质。如果社会上所有人都按照道的规则来做事，所有人都无私无欲、利益众生，那么大家肯定会觉得仁义行事做就像人饿了需要吃饭一样，是再正常不过的事情。怎么会有仁义这个概念在呢？仁义的出现，就证明了世界已经被分割为了二元的，事情既然有仁义的一面，也必然有不仁义的一面。同样的，大智慧、大圣贤的出现，是因为世间伪诈盛行；父慈子孝的出现，是因为社会中有六亲不和的现象；忠臣的出现，是因为国家混乱、邪僻争权。</p>\n<p>这是在告诉我们不要被事物美好的一面所迷惑，美好总是伴随着不美好而生的。最美好的事物是润物细无声，是我们很难察觉的。就像上一章提到的：“太上，下知有之；其次，亲而誉之”。亲而誉之，就是我们能够感受到的好，但却比下知有之低了一个层次。</p>\n<p>最好的仁义是大家都仁义做事，却都不感到自己的仁义；最高的智慧是大家都心灵纯净，却都不觉得自己有多高明；最大的孝慈是每个人都发自内心爱护和尊重家庭中的其他个体，却不感觉到自己的孝慈；最大的忠臣是让社会正常运转，每个人都恪尽职守，不需要有人站出来力挽狂澜。</p>\n<p>讲到这里，想到世界上最美好最珍贵的东西往往都很难感受到他们的存在，也不会觉得这些东西有多珍贵和美好。相反，世人通常认为的有价的、珍贵的东西，其实价值都有其局限性。比如水和空气是我们每个人生存必备的两样东西，而我们却很难注意到他们的珍贵性，也许只有空气污染，水源匮乏的时候才能意识到他们的珍贵。最好的保养身体的方法就是好好睡觉、好好吃饭、适当运动、心情舒畅，而我们却特别容易忽略这个根本，往往热衷于去寻找各种珍贵的营养品和先进的医疗保健器材。最好最快的获得知识的方式就是去看书去思考，而不是花上很多钱去报一些特别贵的课程被人收割智商税。最好的感情是平淡、信任、不需要向对方证明什么，而不是看起来轰轰烈烈，为了让对方感动而做出很多壮烈的举动的情感。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-19","url":"/2020/06/28/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-19/","content":"<p><strong>原文：</strong></p>\n<p><strong>绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧弃利，盗贼无有。此三者以为文不足。故令有所属：见素抱朴，少私寡欲。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第十八章中老子告诉人们不要沉迷于对美好的幻象的执着当中。一切美都是相对于丑来出现的，而真正的美好本应是顺应大道、一切自然，甚至是很难察觉的。第十九章老子会更进一步来阐述怎么去按照道的原则去做事，接下来我们一起来学习这一章节吧。</p>\n<p><strong>抛弃聪明智巧，人民可以得到百倍的好处；抛弃仁义，人民可以恢复孝慈的天性；抛弃巧诈和货利，盗贼也就没有了。</strong></p>\n<p>既然善恶美丑都是出自人心，都是由于人们心中的分别而产生的，那么人们只要能够消除这种分别心人们就能够重新回到自然的本性。</p>\n<p>既然“智慧出，有大伪”，那么就应该抛弃对智巧聪明的崇拜，从而消除社会中的狡诈，这样普通老百姓就能够安居乐业。既然“大道废，有仁义”，那么抛弃对仁和义的推崇，大道才能凸显，人民才能恢复孝慈的本性。既然“难得之货，令人行妨”，那么放弃对名利的崇拜，盗贼也就没有了。</p>\n<p>老子崇尚自然，认为人应该回归本性，而不应该被人为强行压制。一切的出现必然有其规律，哪怕是社会中的丑恶现象。比如森林火灾的出现，虽然会对生态多样性造成影响，但同样会清除腐烂或者有疾病的动植物，让肥料重新回到大地，让阳光照射到地面，让新一代幼苗得以生长。类似的，人类历史上每隔一段时间的战乱，也有它有利的一面。天下大势分久必合，合久必分，这个合和分的过程也是社会资源重新分配的过程。类似的还有经济危机、瘟疫流行等等，这些事情虽然都造成了一定程度的破坏，但却又让社会重新焕发出了生机。有些事情的发生是人类所不希望看到的，但自然不以人的喜好而有所改变。看到这里我就觉得老子是最早的自由市场经济的提倡者，虽然市场有它不好的一面，但我们不能过多调控。经济危机的发生反而能让市场淘汰一些不好的资产，从而能够获得自我造血能力，能让经济持续繁荣。</p>\n<p>况且，真相是人类永远无法压抑真正的趋势，暂时的压制只能让下一次的反扑来的更迅猛。从大的方面来举例，秦朝害怕老百姓反抗，没收了全国的武器，以为就可以太平了。最后，陈胜吴广削了竹竿起义还是推翻了秦的暴政。从小的方面来举例，减肥的时候，压抑自己的食欲，最后终归会跟自己和解，吃的反而更多，体重也超过之前。</p>\n<p><strong>圣智、仁义、巧利这三者全是巧饰，作为治理社会病态的法则是不够的，所以要使人们有所归属，使人们保持纯洁朴实的本性，减少私欲杂念。</strong></p>\n<p>圣智、仁义、巧利都只是术的层面上的御人之术，都只是令人眼花缭乱的巧饰，不足以从根本上去解决问题。提倡仁义，社会上就会出现假仁假义；崇尚名利，社会上就会出现唯利是图。这样治理国家，总是会按下葫芦浮起瓢。</p>\n<p>要让一个组织真正长久的和谐正常运转，就要让这个组织中的所有人心有所属。所有人都不为私名不为私利，团结协作，这个组织想不欣欣向荣都难。一个公司，如果员工不为私利，把公司当成家，那么公司会管理的非常好。一个家庭，如果家庭成员不为私利，把他人的困难都当成自己困难，那么这个家庭会非常和谐。一个人，如果眼睛、耳朵、口舌、大脑、四肢都不图自己一时爽快，那么身体就会健康长寿。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-2-1","url":"/2020/05/31/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-2-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>天下皆知美之为美，斯恶已。皆知善之为善，斯不善已。故有无相生，难易相成，长短相较，高下相倾，音声相和，前后相随。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一章开宗明义讲了可道之道非恒道，可名之名非恒名，故世人不可执着于名相。有无的道理是世界的根本，是非常玄妙深远的，从有无的规律中可以窥探到道的秘密。从第二章开始，《道德经》将展开来说道的原理和具体表现。</p>\n<p><strong>天下都知道美之为美，这就不美了。天下都知道善之为善，这就不善了。</strong></p>\n<p>前文的有和无代表事物的相对立的两个方面，这里有和无又可以扩展为美和恶，善和不善等等的事物的对立面。美和善的存在正是因为恶和不善的存在而产生的，有了美的标准必然就会有恶的标准，有了善的标准必然有了不善的标准。所以说任何标榜的正义美好都是从不美好中产生出来的。如果大家都尊老爱幼，知书达理，那么这些我们看起来的美德就会像吃饭睡觉一样被大家认为是理所当然的事情，怎么还需要社会花大力气去提倡呢？正是因为社会中这些我们认为不美好的存在，才需要去提倡一些我们认为美好的存在。</p>\n<p>从这里我们可以得出以下几个结论：1）对于任何人的褒奖，其实都是对于另一些人的批判。对于某个人一方面的褒奖，也同样是对这个人另一方面的批判。2）社会中越是提倡的东西，也越是社会中缺少的东西。比如社会舆论鼓励生育，就说明生育率低下；社会舆论鼓励年轻人去西部发展，说明年轻人不愿意去西部就业。3）从人的角度来说，一个人越是夸耀自己的头衔，越是对自己真实水平感到心虚；越是夸耀自己的外在，越是对自己的内在感到拿不出手；越是表现的自负，也同时在某些方面会越是自卑。</p>\n<p>另外这里还有一层意思，就是如果全天下人都知道一个事物的美好了，那么这个美好就要打一个问号了。比如连邻居大妈都知道股市可以抄底赚钱的时候，基本是也是股市最危险的时候了。身边每一个大学生都要考取研究生的时候，那么研究生的光环也就是要消失的时候了。</p>\n<p>美丑善恶没有一个固定的标准，他们都是可以相互依存互相转化的，比如龙涎香作为香水的定型剂，可以说是世界上最香的东西了，可是这种东西却是伴随着鲸鱼的呕吐物或者粪便一起产生的。以前要打倒资本主义，现在要开放市场经济；以前提倡计划生育好政府来养老，现在又提倡推迟退休好自己来养老。其实根本原因都是因为社会在变，标准也在变。这里跟《金刚经》里的意思很接近，同样是在说，不要太执迷于事物相状，要看清背后的规律。</p>\n<p><strong>所以说有和无是相互对立而产生的，难和易是相互对立而形成的，长和短是相互对立而表现的，高和下是相互对立而存在的，音和声是相互对立而和谐的，前和后是相互对立而出现的。</strong></p>\n<p>有无、难易、长短、高下、音声、前后都是事物的两个对立面，但都不会是独立而存在的。如果没有有，何谈无的存在？对立统一、相互依存、相互转化才是事物的真实面貌。就像前面提到的善恶美丑一样，世间的任何事物都存在两面性，如果找到那个平衡点、转化点，就找到了道。</p>\n<p>如果觉得自己拥有的财富少，那是因为没有见到比自己更加贫穷的人。如果觉得自己水平高，那是因为一叶障目，不见泰山。生活中有些人总是会觉得自己的命运特别差，比如读研究生的时候，发现研究生不免学费了；要到工作的时候，工作不包分配了；等到该买房的时候，楼市价格一飞冲天了。其实任何时代都是最好的时代，任何时代都有属于自己的机遇，也同时有自己的社会问题。如果能看到积极的一面，找到机遇并加以利用，总能过上幸福的生活。也许在你看到这个不好的一面的时候，很多人正在加以利用，并因此获得了自己的机会。比如工作虽然不包分配，但也刚好可以有寻找自己喜欢的工作的自由，不必受到限制。房价上涨让一批人买不起房的同时，也让一批人的财富迅速得到增值。</p>\n<p>在有中寻无，在难中寻易，在长中寻短，就可以突破现有的局限，改变一些自己的固有认知。凡天下难事，必作于易；天下大事，必作于细。小的和容易的做好了，大的和难的也就做成了。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-2-2","url":"/2020/06/01/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-2-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>是以圣人处无为之事，行不言之教；万物作焉而不辞，生而不有，为而不恃，功成而弗居。夫唯弗居，是以不去。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前文讲到善恶美丑难易高低都是相互依存、相互转化的。所有的标准都是比较的结果，强调了美就出现了恶，强调了善就出现了不善。那么现实生活中，我们应该怎么做呢？接下来老子就给出了答案。</p>\n<p><strong>所以圣人用无为的方式来做事，用不言的方式来教化人。</strong></p>\n<p>首先解释一下无为，无为不是不作为，不是什么都不做，恰恰相反，无为这件事还很难做到。对自身来说，无为是指没有“为”这个概念在做事，这里就跟《金刚经》中提到的“菩萨于法应无所住行于布施”的意思非常接近。圣人身体力行地在践行真理，从而让这个社会变得更加美好，但心中并没有一个好坏美丑的标准，没有分别心，也就不会觉得自己做出了有美德的事情。同样的，圣人也就不会用言语来告诉大家哪种方式是正确的，因为一旦有了正确的做法，必然就会出现不正确的做法。圣人用行为感召人，但却不会制定标准。</p>\n<p>另一层意思是指圣人对于周围发生的事情，不会妄为来做事。对于社会中的种种行为，圣人的心非常包容。他们不会去制定一个善恶美丑的特定标准，也不会对于不符合标准的去打压，对于符合标准的去赞扬。因为圣人知道任何标准都有两面性，不能完全绝对化。这就提醒管理者在制定规则的时候，一定要慎之又慎。比如少生优育可以提高人均的资源分配量，但同时也会较少社会中的劳动力总量。如果只考虑到事情好的一面，当副作用来的时候，还得再次手忙脚乱、拨乱反正。</p>\n<p><strong>世间的万物生长兴起了而不推辞，生养了万物而不据为己有，培养了万物而不自恃有功。正是因为如此，所以功绩才不会泯没。</strong></p>\n<p>这里的几句是在解释什么是无为。先解释一下“辞”，辞就是推辞、拒绝的意思。首先，对于万事万物的生长发展，老子的见解是要完全随应万物，不强加干涉，这是第一种不为。因为万事万物自然有其自己的规律，就像四季轮转、日夜变换，过了最热的盛夏，自然天气就开始转凉；度过了最黑暗的夜晚，太阳就会照耀大地。</p>\n<p>生养了万物不据为己有，这是第二种无为。家里有了小宝宝的朋友，不要有小孩子是从我肚子里生的，所以要听我的话的这种想法。还有一些公司老板，也不可有员工是我的私有财产，一切都要听老板安排这种想法。每一个个体都是独立的，都是值得被尊重的。</p>\n<p>另外还要为而不恃。为而不恃，就是做了一件事而不自恃自己做了这件事。比如说一个人做了好事，做完之后这件事就结束了，就要把事情忘掉。人总会放大自己的付出，而忽略他人的付出。一旦自己付出了，而对方没有给出自己期望的回报，本来有功德的事情，也就没有功德了，甚至还有可能生出怨恨之心。</p>\n<p>最后还要做到功成而弗居。中国古代有尧舜禹这样的圣人，现代有华盛顿、孙中山这样的伟人，之所以他们伟大，就是因为他在获得最高权位之后，不自恃自己在位时的功绩，不贪恋权位不为己谋私，在位之时行帝道，得人心。（帝道，是指好民之所好，恶民之所恶，天下共举，依然辞让，仆人之出，天下庆幸。）对于一个人来说，有了点功绩成就，也不要自居功劳，而夸夸其谈。有时候一个人的成功是一个团队集体努力合作的结果，要清醒地认识到，这不是一个人的功劳。当过于强调自己的功劳的时候，其他人的功劳就会被抹杀掉了，这时候他们的积极性就会被磋商，从而有可能导致一些团队内部问题，甚至高位者会因失去民心而垮台。其实本质来说，根本就没有功德、成功、行善等等这回事。一切都不过是分别心在起作用，一切不过都是人们的执念。</p>\n<p>所以最后就总结说，正因为不自恃自己的功绩，真正的“道”才不会远离这个人。说的就是这个道理啊。</p>\n<hr>\n<p>第二章节到这里就讲完了，总结一下，这一章讲了做人做事应该行无为之事，行不言之教。具体来说，要做到：万物作焉而不辞，生而不有，为而不恃，功成而弗居。只有做到这些，才算走在正“道”上。</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-20-3","url":"/2020/07/01/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-20-3/","content":"<p><strong>原文：</strong></p>\n<p><strong>澹兮其若海，飂兮若无止，衆人皆有以，而我独顽似鄙。我独异于人，而贵食母。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十章比较长，终于分析到了本章的最后一部分了。这一章节更多的是在讲得道之人的一种内心状态。前面说得道之人宁静淡泊，就像小孩一样。并且看起来不光鲜亮丽，也不明察秋毫。接下来看看得道之人还有什么样的状态吧。</p>\n<p><strong>像大海一样辽阔无际；像飓风一样无休无止。世人都精明灵巧有本领，唯独我愚昧而笨拙。我唯独与人不同的，关键在于得到了“道”。</strong></p>\n<p>得道之人内心广阔无边，不会被世俗的色声香味触法等吸引，不会因此而内心起波澜。得道之人永远不会止步，不会被名利和所谓的舒适而停下追寻真理的脚步。大道漫漫，学海无涯。我们这一生如果坚持追求真理，将会是收获颇丰的一生。而如果停止思考，将会是碌碌无为的一生。</p>\n<p>世人都有专长的技能，在社会中成为了一件具有特定功能的工具。而得道之人，似乎看起来非常愚笨，没有特定的专长。他们就像水一样，随物赋形，他们拥有的只是极好的学习能力和思考能力。这样的能力能让他们遇到无论什么样的困难都不会被吓到，他们对此会像小孩一样充满好奇，在研究问题和解决问题中自得其乐。</p>\n<p>得道之人唯一不同于常人的地方就是领悟了“道”的关键，而这个“道”的关键就是事物的根本规律。对于同一个事物，不同人看到的点是不一样的。对于生老病死，普通人沉浸在对生的欢乐或者对死的悲伤中不能自拔。而得道之人跳脱出了这个主观感受，他们感兴趣的是这个生老病死本身的规律。再举一个更通俗的例子，大部分普通人停留在对美食、游戏、艺术作品的享受之中。而有眼光的厨师会观察大众的饮食偏好，去改进自己的厨艺；有眼光的游戏爱好者，会在为玩家服务中找到自身价值；有眼光的艺术家，会通过观察其他艺术作品而提升自己；有眼光的投资人会观察大众喜好的趋势，从而找到商机。如果你想有所思考，有所不同，就要学会超脱事物本身，学会透过现象去观察本质。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-21","url":"/2020/07/02/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-21/","content":"<p><strong>原文：</strong></p>\n<p><strong>孔德之容，唯道是从。道之为物，唯恍唯惚。忽兮恍兮，其中有象；恍兮忽兮，其中有物。窈兮冥兮，其中有精；其精甚真，其中有信。自古及今，其名不去，以阅衆甫。吾何以知衆甫之状哉？以此。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十章讲了得道之人的内心的状态。世人都想表现的聪明能干，惟独得道之人像是无知无察的庸人。世人都喜欢热闹繁华，而唯独得道之人独自淡泊，喜欢观察繁华背后的规律。接下来我们继续学习第二十一章，看看老子又教给我们什么样的人生智慧了吧。</p>\n<p><strong>大德的形态，是由道所决定的。“道”这个东西，没有清楚的固定实体。它是那样的恍恍惚惚，其中却有形象。它是那样的恍恍惚惚，其中却有实物。</strong></p>\n<p>“孔”是大的意思。也有说“孔”通“空”。空德既是大德。无论怎么解释这个字，孔德的意思都是指道德经中所提倡的德。就像前文提到的水一样，无所不包，能受污垢，谦卑处下。这样的人不随世俗所行，唯独从于道。世俗喜欢繁华，他们喜欢安静。世人被名利所累，他们淡泊以明志。世人处处彰显自己的聪明睿智，他们大智若愚、和光同尘。</p>\n<p>“道”具体是什么？没有人说得清。老子勉强给它的描述是恍恍忽忽，释迦摩尼勉强给它的描述是如来。这么这个东西既然看不清、摸不到，为什么大家都认为道是真实存在的？因为恍忽之中有具体的象和物。万法之象都是道的投影，世间万物都是由道生成。</p>\n<p><strong>它是那样的深远暗昧，其中却有精质；这精质是最真实的，这精质是可以信验的。从当今上溯到古代，它的名字永远不能废除，依据它，才能观察万物的初始。我怎么才能知道万事万物开始的情况呢？是从“道”认识的。</strong></p>\n<p>“道”虽然深远暗昧，其中有精实。这种精实，是可以证实，可以验证的。就像人类是由受精卵孕育而来，这个受精卵就包含了长成一个人所需的一切信息。尤其是里面的DNA，虽然小到人们用肉眼看不到，但却传答的信息毫无差错。宇宙的孕育也是一样，也是由最初的本源携带着“道”构成了我们这个世界，所以世间一切无不包含着道。</p>\n<p>从古至今，道是恒常都存在的。正因为它的恒常的存在，就有机会让我们认识我们这个宇宙，认识道的本来面貌。就像我们从孩子身上就可以得到很多父母的信息一样，我们从身处的现实也可以摸索到道的几分真容。</p>\n<p>佛说：“一花一世界，一叶一菩提”。如果我们留心就会发现世界是一环套一环，再小的东西都包含了更大实体的映射。比如一粒沙子放大之后来看就跟我们所处的地球没有两样，一个蚂蚁的社会结构跟我们人类的社会结构也没有区别。地球上有无数的沙子，宇宙中也有无数的星球；蚂蚁的世界有阶级有分工，人类的世界也一样。因为道无所不在，所以观小可以知大，观大又可以知小。这就是为什么佛在几千年前就知道一杯水中有十万八千虫，宇宙中有无数大千世界的道理。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-20-2","url":"/2020/06/30/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-20-2/","content":"<p>原文：</p>\n<p>荒兮其未央哉！衆人熙熙，如享太牢，如春登台。我独怕兮其未兆；如婴儿之未孩；儽儽兮若无所归。衆人皆有馀，而我独若遗。我愚人之心也哉！沌沌兮，俗人昭昭，我独若昏。俗人察察，我独闷闷。</p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十章比较长，我会分为三个部分来讲。第一部分老子劝说世人放弃世俗之学，抛弃内心的各种固有观念，重新回到无知无欲的状态。接下来我们一起学习第二十章的第二部分，看看老子又带给我们什么样的人生启发吧。</p>\n<p><strong>辽远荒废啊，好像没有尽头的样子。众人都熙熙攘攘、兴高采烈，如同去参加盛大的宴席，如同春天里登台眺望美景。</strong></p>\n<p>“荒兮”，是形容像荒原大漠一样，有辽远荒废之意。“未央”是没有尽头的意思。</p>\n<p>人生就像一盘你争我夺，你来我往的一盘大棋。这种争斗永无止境，一代人的故事，在下一代人身上又会重演。仿佛一台大戏，永远都在重复上演。众人贪图外部世界的光鲜亮丽，探求虚华美景、灯红酒绿，在追求声色中打发日子。</p>\n<p><strong>而我却独自淡泊宁静，没有情欲的行兆；如同婴儿还不会发出嘻笑声。疲倦闲散啊，好像浪子还没有归宿。众人都有所剩余，而我却像什么也不足。我真是只有一颗愚人的心啊！</strong></p>\n<p>而圣人淡泊以明志，随处红尘，但却能泰然处之。圣人就如同小孩还不会表达自己的时候一样，内心纯净，无我无他，一尘不染。</p>\n<p>君子不器，圣人不自归于任何某一种特定环境。圣人的品德仿佛水一样，没有特定的表现形式。世俗之人都尽可能的为自己争夺财货名声，觉得自己很了不起，他们有余财用来奢侈，有余智用来狡诈。而圣人相反，好像总是显得有些不足，显得很“愚笨”，没有余财没有余智，他们看破一切，看淡一切。</p>\n<p><strong>众人光辉自炫，唯独我迷迷糊糊；众人都那么严厉苛刻，唯独我这样淳厚宽宏。</strong></p>\n<p>俗人但凡有一点成就就会满世界炫耀，生怕有人不知道。俗人待人很苛刻，明察秋毫，显得自己很聪明。而得道之人确是“昏昏”、“闷闷”，仿佛很普通很糊涂。他们不以世人认为的成就为成就，不以割伤他人的明察秋毫来显示自己聪明。得道之人不在意外界的声音，他们在意的只是自己的内心。“水至清则无鱼，人至察则无徒”，难得糊涂是一种宽容，一种胸襟，一种非常高的人生境界。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-20-1","url":"/2020/06/29/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-20-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>绝学无忧，唯之与阿，相去几何？善之与恶，相去若何？人之所畏，不可不畏。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第十九章老子提出了绝圣弃智、绝仁弃义、绝巧弃利的观点，认为只有这样人民才能回复到无知无欲的纯真状态。提出这种观点非常符合《道德经》的行文逻辑，因为一切都是相对出现的，只有没有分别才能讲事物的两面合二为一，从而符合道的精神。接下来我们一起来学习第二十章，看看老子又带给我们什么样的人生启发吧。</p>\n<p><strong>抛弃世俗之学，才能没有忧患。</strong></p>\n<p>“为学日益，为道日损”。我们从小到大的学习，都是在一天天增长学识，增加本领的同时，思维也在固化。成年人不再有儿时的各种幻想，不再有童年的简单的快乐。随着每天各种信息的灌输，我们被社会的大染缸染成了五颜六色，变成了一个毫无特色，追逐名利、为五斗米折腰的庸庸之辈。而求道却要去除那些华而不实的东西，去除固有陈旧观念，去除让我们眼花缭乱的东西。从而真正解放一个人的心灵，让一个人去真正放手去追逐自己想要的东西，真正去看清世界的本来面貌。</p>\n<p>绝学不是不让人追求真理，也不是不让人学习知识。而是要教人断除后天人心的浊识俗见，绝弃人心私欲及其小聪明之类的奸巧妄心。凡是一切不利于心身健康，有染于先天本性之学，都应当拒之门外，以免损精耗神，累及身心。绝学也是在教人不要执着于书本知识，凡事要经过自己的思考。一切理论都有它的缺陷和不足，一切道理都有它不适应的地方。所以在开篇第一句中老子就提到“道可道，非常道”，一切可说之道都不是恒常之道。</p>\n<p><strong>应诺和呵斥，相距有多远？美好和丑恶，又相差多少？</strong></p>\n<p>唯是指恭敬地答应，是晚辈回答长辈的声音；阿是指怠慢地答应，这是长辈回答晚辈的声音。唯的声音低，阿的声音高，这是区别尊贵与卑贱的用语。</p>\n<p>一切贵贱皆由分别心而来，一切美丑皆由对事物的区别对待而造成。尊贵与卑贱的人又有哪里不同吗？都是一个鼻子两个眼睛，都有人的喜怒哀乐。高位之人不可被阿谀奉承搞昏了头脑，低位之人不要被冷漠鄙视弄丢了自信。一切都在变动之中，贵贱美丑都有可能发生互换。比如，在赵国做人质的嬴政，机缘巧合竟然成了秦始皇；身处高位的丞相李斯，一朝不慎就沦为了阶下囚。唐朝以胖为美，现在的姑娘唯恐他人说自己胖。几十年前，有钱的地主和知识分子被人批斗，现在有钱的资本家和知识分子被人敬仰。人没有变高也没有变低，事物没有变丑也没有变美，只不过人心的标准变了。被这些标准牵着鼻子走，内心不扭曲不崩溃都是奇迹。如果一个人时时刻刻想着满足他人的期许，这个人又能高出他人几分呢？</p>\n<p><strong>人们所畏惧的，不能不有所敬畏。</strong></p>\n<p>既然没有善恶美丑，那么是不是就可胡作非为呢？也不是的。人心会变，但世间的规律并不会以人心为转移。人不是心里想着自己可以飞起来，就可以飞起来的。生了病也不会念两句咒语就会痊愈的。</p>\n<p>宇宙间最大之畏，莫过于自然规律。即使是圣人，也逃脱不了这个规律。得大智慧者，只是认识到了这个规律，然后依照规律行事，所以才没有忧患。整日纵欲饮酒，身体早晚会吃不消；整日算计他人，总有一日会被他人算计。一切果都有其因，君子不可以不慎独。所以人要有所敬畏，尤其是对于大自然，对于我们这个世界的根本规则的敬畏。</p>\n<hr>\n<p>文章同</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-23-2","url":"/2020/07/06/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-23-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>故从事于道者，道者同于道；德者同于德；失者同于失。同于道者，道亦乐得之；同于德者，德亦乐得之；同于失者，失亦乐得之。信不足，焉有不信焉。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十三章前半部分讲了希言自然的道理，并用“飘风不终朝，骤雨不终日”的例子，告诫我们做人做事是一个长期坚持的过程，一蹴而就不可能根本改变现状。接下来我们继续学习第二十三章的后半部分，看看老子又给我们讲了什么人生哲理吧。</p>\n<p><strong>所以，从事于道的就同于道，从事于德的就同于德，从事于失的人就同于失。同于道的人，道也乐于得到他；同于德的人，德也乐于得到他；同于失的人，失也乐于得到他。</strong></p>\n<p>如果一举一动都跟道相合，那么这个人就与道同，道也会加持他。同样，如果一个人的举动跟德相合，那么这个人就跟德同，德也会加持他。一个人如果以在社会上失败的状态或品质做事，自然失也会加持他。</p>\n<p>所谓求仁得仁，一个人怎么为人处事，就会得到相应的生活状态。一个人追求知识，探索大道，道的大门就会向他敞开。这样的人生活就会处处顺应自然，没有过多的烦恼和忧患。如果一个人追求人们的赞誉，处处注意个人名声和讲究外在形象，那么这样的人就会获得他人的称赞。如果一个人行为有失，做事毫无章法和原则，那么不幸的事情总会发生在这样的人身上，就会到达低级、失败、没落、庸俗的状态。</p>\n<p>所有的不幸都有其原因，所有的幸福也都有其原因。人的出身无法决定，他人的想法我们无法改变，但我们可以改变我们自己。我们可以让努力让自己变成自己想要成为的样子，比如拥有努力、正直、博闻、乐观、宽容的品质，改变懒惰、贪婪、顽痴的习气。你努力朝哪个方向走，你就变成了哪种人。</p>\n<p><strong>信不足，就会有不信。</strong></p>\n<p>对于道的信念不足，就不会笃信有道的存在。不信道的存在，就会有失的行为，失的行为就导致不幸的降临。相反，信道者，一言一行都与道同，道的力量也会加持这个人，从而让这个人走向正向循环，从而对道更加深信不疑。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-22-2","url":"/2020/07/04/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-22-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长。夫唯不争，故天下莫能与之争。古之所谓曲则全者，岂虚言哉！诚全而归之。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十二章前半节讲了“曲则全，枉则直，洼则盈，弊则新，少则得，多则惑”的道理。所以圣人对待万事万物都怀有一颗平常心，不追求一味的得到和盈满。下半章老子讲继续讲述这个道理，我们一起来看一看吧～</p>\n<p><strong>不自我表现，反能显明；不自以为是，反能是非彰明。</strong></p>\n<p>一个人的自我表现、自我吹嘘，只能得到他人表面的认可，而非从心底的佩服。相反，把事情做漂亮了，但表现的很低调，这样就能得到他人真正的认可和尊重。一个人不自以为是，不显得与众不同，才能融入大众，名声才能得到彰显。</p>\n<p>每个人都不是傻子，是非曲直自在公道人心。你做的好和不好，众人心中自有一杆秤，如果表面夸耀的能力大于实际能力，就会留给人一种不靠谱的印象，徒惹他人鄙视。相反，如果实际能力大于表面夸耀的能力，就会觉得这个人低调谦逊，与大众和光同尘。大家也就乐意以结识和抬高此人为荣耀，此人的名声反而能够得到彰显。</p>\n<p>《庄子》中有一个例子非常形象，里面这样写道：“亲父不为其子媒。亲父誉之，不若非其父者也。”所以，夸耀和表扬的话永远都是从他人口中说出更有分量。</p>\n<p><strong>不主动占据功劳，反能得有功劳；不自大，所以才能久而不危。</strong></p>\n<p>功劳也不是可以抢来的，而是要他人加给自己的。不是自己的功劳，或者不是众人心中认可的功劳，而要占为己有，只能招来大家的嫉恨和轻视。</p>\n<p>这些都是告诉我们不要贪图名声和利益，德不配位是一件非常危险的事情。自我加持不但不能赢来大家的尊重，反而容易招致祸患。想到前阵子一个姑娘开越野车进故宫，还在微博拍照自我显摆的故事。这个姑娘本想是自我夸耀他的地位与众不同，本想赢得大家的高看一眼，结果反而惹祸上身，招致了大家的唾骂。</p>\n<p><strong>正因为不与人争，所以遍天下没有人能与他争。古时所谓“曲则全”的话，怎么会是空话呢？它实实在在能够达到。</strong></p>\n<p>一个人不屑与他人争夺，远离世俗，反而风轻云淡，能赢得大家的拥护。因为不争，所以他的品德和境界已经高出众人很多，天下人也就无法与他争。</p>\n<p>“曲则全”是非常高明的退让的智慧，退让不是软弱，退让是谦逊和低调，是不争，是淡泊。圣人守“一”为天下式，得与不得在圣人心中没有什么不同。有了得失的心态，就算得到了物，也是最大的失败。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-23-1","url":"/2020/07/05/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-23-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>希言自然，故飘风不终朝，骤雨不终日。孰为此者？天地。天地尚不能久，而况于人乎？</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十二章讲了曲则全的道理，所以圣人 抱一为天下式。接下来我们看看第二十三章，老子又教给我们什么样的人生哲理吧～</p>\n<p><strong>一切要顺应自然。狂风刮不了一个早晨，暴雨下不了一整天。谁使它这样的呢？天地。天地的狂暴尚且不能长久，更何况是人呢？</strong></p>\n<p>前文提到过“听之不闻名曰希”，希言就是这种我们到处都可听到却又不能听懂的言语。然后老子给我们举了飘风和暴雨的例子，狂风暴雨尚是我们日常可以见到的自然现象，但我们却很少能从中解读出深刻的人生哲理。</p>\n<p>我们简单观察就能发现狂风暴雨虽然来势汹汹，但却都不能持久。这就是自然之言，是天地告诉我们每个人的道理。至于能不能读得懂，就看你有没有留心观察生活了。老子就对自然观察细致入微，他认为我们人应该效法天地，从这个自然现象中领悟到猛烈的事物无法长久的道理。一时的头脑发热，不休不眠的投入到一件事情，并不能让人们把事情做好。因为，这种状态是以透支人的身体和牺牲掉生活为前提的，是必然无法持久的。同样，急风骤雨似的改革很难收到成效，只要政策一松动，就会出现反弹，从而导致改革流产。所以我们要抱有细水长流的心思去做事做人，日复一日的提高和改进自己，一点点去积累，长期下来就能看到效果。</p>\n<p>另外，强烈的情绪也是不可持久的。无论我们目前感觉有多么难过，多么悲伤，多么快乐，这些都是不可持久的。在自己情绪极其低落的时候，不妨告诉自己“飘风不终朝，骤雨不终日”，我们就会有信心迎接明天的朝阳。在自己情绪极其高涨的时候，也不妨告诫自“飘风不终朝，骤雨不终日”，从而戒骄戒躁，踏实做事。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-22-1","url":"/2020/07/03/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-22-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>曲则全，枉则直，洼则盈，弊则新，少则得，多则惑。是以圣人抱一为天下式。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在第二十一章中老子再次描述了道的一些不可描述但又无所不在特点。第二十二章老子再次把视角拉回了现实生活中。我们一起看看领悟了道对我们的生活有什么现实指导吧～</p>\n<p><strong>委曲便会保全，屈枉便会直伸。</strong></p>\n<p>曲己从众，不自专，反而自身能够保全。委屈自己成全别人，自己最终反而能够得以伸直。这是老子典型的以柔克刚的哲理。人有时候要学会委曲和忍让，虽然看起来当时是吃亏了，但长久的效应可能是我们得以保全。相反，一时的争夺和狡诈，虽然看起来当时是占到了便宜，但长久看来可能是吃了大亏。</p>\n<p>我们有句谚语“小不忍则乱大谋”，讲的就是要学会吃亏和忍耐。处处得让人处且饶人，留给人们的是一种宽容和可靠的印象。处处都不想吃亏，留给人的则是一种斤斤计较，不能吃亏的印象。人们在选择长期合作伙伴的时候，或者在推选领导的时候，总会愿意寻找像前者这样的人。因为这种人会让人信任，让人舒服，不会机关算尽，凡事总会留有余地。</p>\n<p>比如俞敏洪当年创业的时候，找到了几乎当年所有的舍友来一起合伙创业，唯独剩下了一个人。据俞敏洪所说，之所以没有选择剩下的这个同学，是源于一个故事。事情是这样的，这个同学每周末回家带五个苹果回来，他们宿舍刚好五个人，同宿舍的同学刚开始以为他是要给每一个人分一个苹果。结果发现他们想错了，这个同学带的五个苹果都是给自己吃的，周一到周五刚好每天一个。</p>\n<p><strong>低洼便会充盈，陈旧便会更新。</strong></p>\n<p>瓶子空了才能装水，东西旧了才会换新的。人也一样，只有放低了姿态，才有可能获得他人的尊重；只有虚心，才能提高和进步。自满和骄傲的人，永远看到的只是自己的长处和他人的短处。幸运是强者的谦辞，命运是弱者的借口。真正的强者是永远不会觉得自己无所不能的，永远都是低调谦逊的。乔布斯的座右铭是：“保持愚蠢，保持饥饿”。保持愚蠢和饥饿，才会让自己时刻变得更聪明更进取。</p>\n<p><strong>少取便会获得，贪多便会迷惑。</strong></p>\n<p>我个人有个读书的经验：读书最怕贪多。囫囵吞枣读一百本书，不如认真反复研读一本好书。读书真正的价值在于思考，而不在于量的多少。只有自己思考过的、悟到的道理才是自己的。</p>\n<p>除了读书，生活中的其他方面也是如此。人的精力都是有限的，把一样做好做精就很不容易了，不要贪图多和大。做事业要集中于一点，找到自己的专长和兴趣点。社会交际也在精不在多，三五个知己，一个相爱的人也就足够了。</p>\n<p><strong>所以有道的人坚守“一”作为天下事理的范式。</strong></p>\n<p>圣人之所以伟大，是因为他们深刻懂得前面说的这些道理。月盈则亏，物极必反，这是自然界的基本规律。所以保持一个平稳的心态：不贪图便宜，不贪图圆满，不贪图快和大，这对于我们做事做人都有极大的指导意义。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-25-1","url":"/2020/07/08/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-25-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>有物混成，先天地生。寂兮寥兮，独立不改，周行而不殆，可以为天下母。吾不知其名，字之曰道，强为之名曰大。大曰逝，逝曰远，远曰反。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十四章老子讲了“企者不立；跨者不行”的人之道，告诫人们要戒除焦躁和虚荣的毛病。在讲完人之道之后，第二十五章老子又开始讲天之道。我们一起来看看老子眼中的天之道是什么样的吧。</p>\n<p><strong>有一个东西混然而成，在天地形成以前就已经存在。听不到它的声音也看不见它的形体，寂静而空虚，不依靠任何外力而独立长存永不停息，循环运行而永不衰竭，可以作为万物的根本。</strong></p>\n<p>对于道的起源，第四章中也曾描绘到：“吾不知谁之子，象帝之先”，这里再次提及这个概念。“道”是先于天地而生，是我们这个世界的根本规律和法则。甚至可以说我们这个世界都是由“道”而构成的。虽然这个支配我们世界的规则看不到也听不到，但是它确实是真实永恒存在的。大到宇宙星球，小到一粒沙土，无不遵循着同一种规律。正因为看到了这个规律，所以释伽牟尼在两千多年前就知道世界上存在着恒河沙数的大千世界，也知道一杯水中有无数生命。他靠的不是科学仪器，而是靠的对这种规律的理解。</p>\n<p>掌握这种规律其实也不难，要诀前文其实已经提到过：“至虚极，守静笃。万物并作，吾以观复。” 所以，想要获得终极智慧，我们要做的就是把心放空，真正的静下来，然后观察发生在我们身边的一件件不起眼的小事。云卷云舒、花开花落，无一不是这个规律的体现。所有由因缘聚合而生的事物都会消亡，而消亡又总是伴随着新生。因为我们这个世界本身就是一个不断变化的排列组合，唯一不变的就是在背后推动这个排列组合变化的规律，也就是”道“。</p>\n<p><strong>我不知道它的名字，所以勉强把它叫做“道”，再勉强给它起个名字叫做“大”。它广大无边而运行不息，运行不息而伸展遥远，伸展遥远而又返回本原。</strong></p>\n<p>“道”只是一个勉强而被命名的名字，不要一听到“道”和“佛”就觉得充满了迷信色彩，就联想到要修仙成佛。其实宗教的迷信色彩是后世人为加上去的。如果认真读原文并且思考，我们就会发现作者的观点充满了思辨，是非常科学的。老子是在告诉我们一种生活哲学，是让我们更好的在这个社会生存。所以，无论读书还是做事，我们一定要有第一手资料，要有自己的判断，不要道听途说。</p>\n<p>“道”和“大”都体现了这个本源规律的一些特点。首先，就像我们四通八达的道路交通系统一样，“道”可以连接一切，并且让一切都在其轨道有条不紊运行。其次，“道”又包含一切，无论是物质的还是非物质的，有生命的还是没生命的，有思想的还是没思想的，所有的万事万物都蕴含了道，并且被道所支配。</p>\n<p>我觉得生命就是一个“大曰逝，逝曰远，远曰反”的红尘炼心的过程，可能这就是生命本身的意义所在。有一个乞丐和富翁的故事可以非常形象的说明我的这个观点。这个故事是这样的：</p>\n<blockquote>\n<p>从前有个富翁，他看到一个乞丐在沙滩上晒太阳，就取笑他不思进取。乞丐反问他，你进取的目的是什么，答，赚更多的钱。乞丐又问，赚了钱以后呢？答，在自己的小岛上享受阳光。乞丐微笑着说，我不正是在沙滩上享受阳光吗？</p>\n</blockquote>\n<p>看完这个故事，我就想虽然享受的都是阳光，但乞丐和富翁享受阳光时的心态和境遇是不可能一样的。从白手起家做起，经历过商海沉浮，见识过世间百态而成功的富人，在努力得到了自己想要的生活的同时，也获得了丰富的人生阅历，获得了更加豁达的心境，也锤炼了更加坚韧的意志。</p>\n<p>就像不下水就不可能学会游泳一样，一切书本中所传授的知识和智慧，如不亲身实践都不可能真正掌握。尼采说过：“但凡不能杀死你的，最终都会使你更强大。” 经过迷茫、痛苦甚至绝望的人生，才会更加懂得珍惜身边的幸福，才会看破一些执着、虚荣和幻想。 </p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-24","url":"/2020/07/07/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-24/","content":"<p><strong>原文：</strong></p>\n<p><strong>企者不立；跨者不行；自见者不明；自是者不彰；自伐者无功；自矜者不长。其在道也，曰：馀食赘行。物或恶之，故有道者不处。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十三章中老子讲了自然之道是无为希言。只有从事于道才能同于道，道也会加持行道之人。如果行为有失，失也会加持这个人，让此人在毁灭和堕落中越陷越深。下面我们看看第二十四章老子又讲了什么哲理吧。</p>\n<p><strong>踮起脚跟想要站得高，反而站立不住；迈起大步想要前进得快，反而不能远行。</strong></p>\n<p>“企者不立；跨者不行”是在告诉我们暂时勉强而为之的事情都不能保持长久，我们没必要逞一时之勇。人生是一场长跑，暂时的领先和落后并不重要。重要的是保持良好的心态，把事情有条不紊的一件件做好。</p>\n<p>另外，还要找到自己真正所热爱的事业，找到自己真正所爱的人，让自己真正生活在自己舒服的环境中，而不是勉强工作，勉强找个人陪。真正舒服的状态会让人享受自己的生活，也会让人们的事业和家庭走的更远。</p>\n<p><strong>自逞已见的反而得不到彰明；自以为是的反而得不到显昭；自我夸耀的建立不起功勋；自高自大的不能做众人之长。</strong></p>\n<p>第<a href=\"https://shileilei.com/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-22-2/\">二十二章</a>中已经阐述过“不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长“的道理。这里就不在赘述。有兴趣的可以点击<a href=\"https://shileilei.com/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-22-2/\">这里</a>查看第二十二章的讲解。</p>\n<p><strong>从道的角度看，以上这些急躁炫耀的行为，只能说是剩饭赘瘤。因为它们是令人厌恶的东西，所以有道的人决不这样做。</strong></p>\n<p>得道之人根本瞧不上这些外在的名利，更不会费尽心机去争夺这些外在的东西。急躁、炫耀、居功等等这些行为，不仅会扭曲人们的心灵，还会伤害人们的身体。所以有志于学道之人应当远离这些行为。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-25-2","url":"/2020/07/09/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-25-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>故道大，天大，地大，王亦大。域中有四大，而王居其一焉。人法地，地法天，天法道，道法自然。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十五章前半部分老子描述了什么是天之道。道无名无形，却又无所不包、无处不在。知道了天之道，对我们的人生有什么指导作用呢？在后半部分老子就给出了答案，我们一起来学习吧～</p>\n<p><strong>所以说道大、天大、地大、王也大。宇宙间有四大，而王居其中之一。</strong></p>\n<p>道大是因为道包含天地万物，无所不容、无处不在。天大地大是因为天无所不盖、地无所不载。王大是因为王制定规则、指引众生、管理众生。《说文》中对王士这样解释的：</p>\n<blockquote>\n<p>王，天下所归往也。董仲舒曰:<strong>“古之造文者，三画而连其中谓之王。三者，天、地、人也;而参通之者，王也。”</strong></p>\n</blockquote>\n<p>所以说王是通天地人三者的圣人，是众望所归的领袖。这样的领袖顺应自然之道，让万民众生按照规律繁衍生息。这种功德可与天地滋养万物的功德平齐，所以在宇宙中的四大中，王占有一席之地。</p>\n<p>虽然人民群众的力量是伟大的，但这种力量需要有人来引导才能真正发挥它的作用。兵熊熊一个，将熊熊一窝。这句话就非常形象的指出了领导的巨大作用。翻开历史我们就会发现一个很有意思的现象，伟大的人物身边总是聚集着一堆不世英才。几乎秦末汉初的所有英雄豪杰都出自沛县这个小地方，曹操身边的大将都是他的发小兄弟，屠猪买酒的关张在跟刘备结义之后却能成为一方英豪，这都是为什么？难道是历史的巧合吗？我看绝对不是。千里马常有，而伯乐不常有。韩信、萧何、夏侯渊、张飞、刘备都是千里马，而刘邦、曹操、刘备是发现他们和引导他们的伯乐。真正的王者虽没有万夫不当之勇，却有识人用人之能，有汇聚天下英才的魅力。我敢说如果关羽、张飞没有遇到刘备，历史上甚至都不会留下他们的名字。</p>\n<p>所以说一个国家最重要的是元首，一个企业最重要的是CEO，一个家庭最重要的是家长，一个人最重要的是头脑。只有把方向把握对了，再稍微努努力就会成功。相反，如果方向错了，再努力都是徒劳。</p>\n<p><strong>人取法地，地取法天，天取法“道”，而道纯任自然。</strong></p>\n<p>人要向大地学习他的厚重、安静、包容、不求回报、任劳任怨的品德。地又是取法于天，天施而不求报，生长万物，无所收取。天又是取法于道，道清静不言，孕育万物，包容万物，从而世间一切在道的作用下有条不紊运行。而道呢？它纯仁自然，一切都出自本心，出自空无。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-27-1","url":"/2020/07/13/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-27-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>善行无辙迹，善言无瑕讁；善数不用筹策；善闭无关楗而不可开，善结无绳约而不可解。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十六章中老子告诫我们要“重”且“静”，只有这样我们才能不失本、不失君。接下来我们一起看一看第二十七章老子又告我们什么样的人生哲理吧～</p>\n<p><strong>善于行走的，不会留下辙迹；善于言谈的，不会发生病疵；善于计数的，用不着竹码子；善于关闭的，不用栓梢而使人不能打开；善于捆缚的，不用绳索而使人不能解开。</strong></p>\n<p>真正的善行、善言、善数、善闭、善结的人都不是我们可以用常规方法可以想象的。这几句话跟“大智若愚”、“大巧若拙”、“大方无隅”的道理一样。我们通常所认为的好，都受限于我们的认知水平，而超出我们认知以外的好，就不是普通人可以理解的了。</p>\n<p>真正的善行是什么？是不行而无所不行、不为而而无所不为。善行者顺应自然之道，让万物自行运转。他们求诸于己，而不外求。这跟后文提到的“不出户，知天下；不窥牖，见天道”表达了相似的见解。</p>\n<p>真正的善言是什么？不是巧言善辩，而是不言而言。任何可以说出来的话，总会有人挑毛病，总会得罪人。哪怕是夸奖他人的话，也会得罪人。有人会说夸奖的话怎么还会得罪人？因为夸奖一个人的一个优点，他有可能会想为什么没有夸奖他其他的方面，是自己在其他方面做的不足吗？还有没有被夸到的人也会想，为什么夸他人而不夸我，是我做的不好吗？一个人认真做事，少一些巧言，才能真正做到圆融无碍。一个人自身做好表率，自然就是最有力的辩论。</p>\n<p>真正的善数是什么？不是借助于工具算得一清二楚，而是心中无所计算。道生一，一生二，二生三，三生万物。世间的一切归根到底都是由道而生，都可以归结到“一”。把握住了”一“，还需要什么精确的计算吗？与人交往，失去的越多就得到的越多。相反，精明的算计得到，却往往导致的是更多的失去。塞翁失马，焉知非福。如果站在一个大的角度去看世界，我们就会有不一样的得失观。</p>\n<p>真正的善闭是什么？不是深沟高垒和铜门铁锁，而是不闭而闭。公孙瓒在于袁绍的战争中，他把自己的城池修的坚韧无比，但最后还是被袁绍挖通了地下通道。美国旧金山有一个恶魔岛，人们把监狱建在这个小岛上，离陆地有好几海里，水又深又冷，加上坚固的监狱围墙和守卫，犯人几乎无法逃出。建设者以为这是世界上最牢固的监狱，没有犯人可以逃出。但后来还是有几名水性极好的犯人越过围墙，游过水域逃走了。</p>\n<p>世人的善闭，再好的闭都有漏洞，因为道高一尺魔高一丈。戒烟戒酒的最好方式是不是不接触这些东西，而是完全对此毫不感兴趣。不使自己陷入贫穷最好的方式不是不花钱，而是努力挣钱。同样的，战争中最好的防守不是建筑深沟高垒，而是具有致对方于死地的威慑力。</p>\n<p>真正的善结是什么？不是用用绳子把东西捆起来，而是不解之结。让一个人留在身边最好的方法，不是束缚住他的人，而是俘获他的心。让一个人佩服的最好方式，不是自吹自擂，而是提高自己踏实做事。让一个人努力工作的最好方式，不是限制他的人身自由，而是激发他的兴趣和热情。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-26","url":"/2020/07/11/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-26/","content":"<p><strong>原文：</strong></p>\n<p><strong>重为轻根，静为躁君。是以圣人终日行不离辎重。虽有荣观，燕处超然。奈何万乘之主，而以身轻天下？轻则失本，躁则失君。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在上一章中老子讲了什么是天之道，并且提出“人法地，地法天，天法道，道法自然”的概念。天地所以长久是因为他们遵循了道，人要想长久也应该像道学习。第二十六章老子又开始讲人之道，讲了我们在生活中应该具体怎么向道学习。接下来我们一起来学习第二十六章吧。</p>\n<p><strong>厚重是轻率的根本，静定是躁动的主宰。</strong></p>\n<p>凡是东西轻了就不能承载重的，小了就不能镇住大的。做长辈做领导的，如果不自重就不能被人尊重。所以应该把厚重是为根本，不可轻率浮躁。一动不如一静，不变可以应万变。同样，做长辈做领导的，如果不静就会失去威严。毛毛躁躁的人不能让人感到心中安定、踏实可靠。</p>\n<p>主宰一方就要有泰山崩于前而色不变的稳重和安静。在困难和灾难来临之时，要能够不被外界所干扰，需运筹帷幄，居中调度，且不失方寸。</p>\n<p><strong>因此君子终日行走，不离开载装行李的车辆，虽然有美食胜景吸引着他，却能安然处之。</strong></p>\n<p>老子在这里打了个比方，说君子以前出远门的时候，虽然整天在外，但却不离开装着行李的车辆。虽然沿途有很多美食美景吸引他们，但他们却都能安然处之。古时没有现代社会这么多的饭店旅馆，在外出门都需要自备干粮，晚上还需要住在车上。所以说，辎重是君子在外的根本，离开了辎重，他们将无衣无食，在外无所依靠。</p>\n<p>美食胜景都是外在的浮光掠影。就像我们在社会中被附加的一些名望和地位，都是华而不实的。我们应该虚其心，实其腹。找到我们的根本，从而让我们真正幸福快乐。</p>\n<p>如果我们是学生，那么学习就是我们的根本。如果我们是会计师，财会技能就是我们的根本。如果我们是商人，公司和生意就是我们的根本。相比于谋生的职业，我们的身体健康又是根本中的根本。没有一个好的身体，挣再多钱也无福消受。所以我们要真正抓住重点，把心思用到对我们真正重要的事情上来。</p>\n<p><strong>为什么大国的君主，还要轻率躁动以治天下呢？轻率就会失去根本；急躁就会丧失主导。</strong></p>\n<p>奈何一词把对万乘之主轻浮躁动的行为的惋惜伤痛之情表达的淋漓尽致。真是恨铁不成钢，明明这么简单的道理就摆在面前，那些大国的君主却轻率躁动来治理天下，从而导致民不聊生。一个人轻浮就会失去“根”，急躁就会丧失“君”。这个“根”对于管理国家和公司来说，就是臣民和下属的人心。对于管理自身来说，就是精气神。这个“君”对于管理国家和公司来说，就是个人地位和领导力。对于管理自身来说，就是一个人的理智和判断力。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-27-2","url":"/2020/07/14/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-27-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>是以圣人常善救人，故无弃人；常善救物，故无弃物。是谓袭明。故善人者，不善人之师；不善人者，善人之资。不贵其师，不爱其资，虽智大迷，是谓要妙。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十七章的前半部分老子讲了“五善”。接下来我们一起学习后半章节的内容吧～</p>\n<p><strong>因此，圣人经常挽救人，所以没有被遗弃的人；经常善于物尽其用，所以没有被废弃的物品。这就叫做内藏着的聪明智慧。</strong></p>\n<p>圣人拥有前面所说的五种善，常处无为之事，行不言之教，在一言一行中教化了百姓。圣人不做怪行，不用权谋，不善巧辩，不用科刑，却能够教化百姓，让他们依道行事。虽然每个人的天赋秉性各异，但世人往往为了寻求他人认同，而去努力做一些不符合他们秉性的事情。圣人可以去除世人的贪嗔痴，去除他们的妄想执着，让每个人都能遵照着自己的本心和才能选择适合自己的位置。每个人只要能发挥出他们的长处，都不可能是一个废人。</p>\n<p>霍金被誉为继爱因斯坦后最杰出的理论物理学家，其著作《时间简史》于1988年出版，成为最畅销书籍，被译成40多种文字，发行量高达2500多万册。这些伟大成就的背后，是他一生都在与渐冻人症所做的抗争。我们每个人的身体都比霍金健康，但我们中的大多数为什么却没能够做出一些成就呢？这就是因为我们把自己放在了不适合的位置上或者做着没有价值的重复劳动。如果一个人从事自己所热爱并且擅长的工作，那么将很快就能成为这个领域的专家。</p>\n<p>作家格拉德威尔在《异类》一书中指出：人们眼中的天才之所以卓越非凡，并非天资超人一等，而是付出了持续不断的努力。1万小时的锤炼是任何人从平凡变成超凡的必要条件。他将此称为“一万小时定律”。如果你将这一万小时用来聊天，你将是一个聊天高手；如果你将这一万小时用来做流水线工作，你将是一个出色的流水线工人；如果你将这一万小时用来学习摄影，你将成为摄影大师。所以说，你把时间花在哪里，你就变成了什么样的人。如果你有自己的梦想，那么请立刻行动起来，并且付诸一万小时的实施吧。</p>\n<p><strong>所以善人可以做为恶人们的老师，不善人可以作为善人的资粮和借鉴。不尊重自己的老师，不爱惜他的借鉴作用，虽然自以为聪明，其实是大大的糊涂。这就是精深微妙的道理。</strong></p>\n<p>善人可以作为不善之人的老师，不善之人可以作为善人的借鉴。每一类人都有其用处，哪怕是不善之人。不善之人也是善人的资粮和后备军，每一个不善之人如果合理教导都可以变成善人。如果一个人不向比他更优秀的人学习，不以比他更差的人为借鉴，那么这样的人就算非常聪明，也是大大的糊涂。如果能够明白这一点，那么就算是明白道的最精妙之处了。</p>\n<p>孔子说：“三人行，必有我师焉。”每个人都有他的长处，都有值得我们学习的地方。所以，我们要善于向他人学习。那么我们应该怎么学习呢？孔子又说了：“择其善者而从之，其不善者而改之。”对于值得学习的，我们要吸收；对于不值得学习的，我们要自省。只有这样，我们才能变得越来越好，越来越接近道。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-28-2","url":"/2020/07/16/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-28-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归于朴。朴散则为器，圣人用之，则为官长，故大制不割。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十八章的前半部分讲了知雄守雌、知白守黑的道理。后半部分将对前文进行进一步的讨论，接下来我们一起来学习一下后半章节的内容吧～</p>\n<p><strong>深知什么是荣耀，却安守卑辱的地位，甘愿做天下的川谷。甘愿做天下的川谷，永恒的德性才得以充足，回复到自然本初的素朴纯真状态。</strong></p>\n<p>荣辱与前文的雄雌、黑白相类似。荣指荣耀，比喻被人夸奖、羡慕的状态，而辱是指侮辱，比喻被人贬低、鄙视的状态。其实荣和辱又有什么区别呢？前文也曾提到“宠为下，得之若惊，失之若惊，是谓宠辱若惊”。在乎他人眼光的人其实是处在低位，是一个没有强大内心的人的外在表现。君子要知道什么是荣，但却不能贪恋荣。即既要有积极前进的一面，也要有谦虚不争的一面。积极进取的一面是努力做事、心怀天下，谦虚不争的一面是不争名利权情。甘愿不争而做天下的川谷的人，才能不失去本心，永远保持清醒纯真的状态。</p>\n<p>“朴”原意是指没加工的木材，我们现代社会经常用做形容不加修饰。在这里老子用“朴”来代指人们最初的那个本心，人们回归道的那种状态。人们回归无知无欲，清静无为的状态的时候，将会不再有痴嗔贪等各种习气，会得到无上的智慧。</p>\n<p><strong>朴素本初的东西经制作而成器物，有道的人沿用真朴，则为百官之长，所以完善的政治是不可分割的。</strong></p>\n<p>“朴”就好比人体的干细胞。干细胞可以转化为人体所有的器官和组织，而“朴”可以有无穷的功用。但是有一点，干细胞可以转化为器官组织，但这个过程是不可逆的。“朴”也是一样，散掉之后就变成了各种器，每个人都有各种各样的功能和特长。孔子在《易传》里说：“形而上者谓之道，形而下者谓之器。”意思是，道是无形的，器是有形的。所以孔子就说“君子不器”。真正有志的君子都是追求大道，而不是追求形而下的器。既然道这么好，那么它有什么用呢？下文就说了：“圣人用之，则为官长”。官长就是百官之长，可以统帅一切的人物。</p>\n<p>圣人靠什么来统帅一切呢？靠的是顺应自然的天之道。靠的是制定一个顺应自然本性的规则，让万物都各归其位，各尽其职，每个人都愉悦努力的做好自己的工作。“大制”指的是完美无缺的政治思想和政治制度，这种制度跟道驾驭世界的规则相对应。“无割”指的是不可割裂，即人与人、人与世界的契合一致与和谐统一。也可以理解为不割伤，一切人在这个规则下都能感到幸福和满足。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-28-1","url":"/2020/07/15/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-28-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>知其雄，守其雌，为天下溪。为天下溪，常德不离，复归于婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归于无极。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十七章中老子讲了五种“善”：善行、善言、善数、善闭、善结。正因为圣人行五善，所以圣人可以让万物各安其所，从而人无弃人、物无弃物。接下来我们继续学习第二十八章，看看老子又教给我们什么样的人生哲理吧～</p>\n<p><strong>深知什么是雄强，却安守雌柔的地位，甘愿做天下的溪涧。甘愿作天下的溪涧，永恒的德性就不会离失，回复到婴儿般单纯的状态。</strong></p>\n<p>“雄”用来比喻尊贵和强大，“雌”用来比喻卑贱和弱小。人们都向往最贵和强大，但老子在这里却告诉我们要知雄守雌，这是为什么呢？</p>\n<p>人们在尊贵和强大的时候，最容易犯的一个毛病是自大。如果人们能够拥有强大的本领、内心和地位的同时，能够爱护尊重弱者，那么必将天下归之，成为一个伟大的领导。</p>\n<p>每个人都有强大和柔弱的地方和时候。比如，人在幼年时弱小，壮年时强壮，老年时又变得弱小。又比如，一个人或许身体很强壮，但精神却很柔弱。每个人都不是全才，每个人都不可能一直保持盈满的状态。所以在我们盈满强壮之时，要懂得守弱。在壮年之时，不可欺负弱小。在有权势之时，对低位者保持尊重。这不仅是对他人的慈悲，也是给自己留了后路。</p>\n<p>无论强大还是弱小，都要保持本心。只有保持住本心，才能让永恒的德行不远离自己，从而恢复到婴儿般纯真的状态。无论外界给自己回馈的是什么，我们都要对自己有一个清醒的认识。他人敬仰也好，鄙视也罢，我们只是我们自己。我们既没有他们想象的那么好，也没有他们想象的那么差。这句话反过来也适用，那些伟大的尊贵的人物，没有我们想象的那么好；那些被人唾弃的人物，也没有我们想象的那么差。大家都只是人这种生物，并没有太大不同，这些外在的东西大部分都是人们给强加上去的。</p>\n<p><strong>深知什么是明亮，却安于暗昧的地位，甘愿做天下的模式。甘愿做天下的模式，永恒的德行不相差失，恢复到不可穷极的真理。</strong></p>\n<p>“白”用来比喻光鲜亮丽的一种状态，“黑”用来比如一种默默无闻的状态。人们都向往光鲜亮丽、出人头地，而老子在这里却告诉我们知白守黑，这是为什么呢？</p>\n<p>很多真正有志于创作的企业家、作家、学者都特别害怕出名。因为一出名，他们就要应付来自社会各界的应酬，从而占据他们真正创作的时间。“白”就是这种昭昭的光环，这种放在聚光灯下为众人瞩目的状态。这种状态下，人们很容易就飘起来，就忘了自己的本。所以要切记知白守黑的道理。虽然有光环，我们自己要知道我们只是个普通人，是一个需要在自己岗位上默默奉献的人。只有这样，才能作为天下真正的楷模，给众人树立榜样。这也是老子一直所提倡的“处无为之事，行不言之教”。做到了知白守黑，永恒的德行才会一直存在，也不会出大的差错。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-29-1","url":"/2020/07/17/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-29-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>将欲取天下而为之，吾见其不得已。天下神器，不可为也，为者败之，执者失之。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十八章中老子讲了知雄守雌的道理。荣辱黑白不过是一种相对的状态，不必为此而心中忐忑。知荣守辱是一种豁达的心态，是站在更高的视角来看世界的一种淡然。接下来我们一起来学习一下第二十九章中的内容吧～</p>\n<p><strong>想要治理天下，却又要用强制的办法，我看他不能够达到目的。</strong></p>\n<p>用强力只能让人们害怕和产生愤怒情绪，不可能真正收服人心。老子在前文提到管理有四个层次：太上，下知有之；其次，亲而誉之；其次，畏之；其次，侮之。用强力来统治和管理只能落在第三或者第四个层次。要么畏之，要么侮之。无论哪种情况，结果都不容乐观。</p>\n<p>用蛮力的人是非常愚蠢的，采用蛮力来管理可能正是因为他们的无能为力，所以只能用此下策。最高明的管理是制定良好的制度，让一切顺应天道人心。如果智慧不够，第一层次达不到，那就要亲力亲为、树立榜样，从而让人心归附。如果既缺乏智慧还不肯吃苦，那么怎么可能做好管理呢？其实不单单是管理，天下做任何事情都是一样的。想要做好一件事情，要么有智慧，要么就努力。除此之外，再别无他途。</p>\n<p><strong>人是天下的神器，是不能够违背客观规律而加以强力统治。用强力统治天下，就一定会失败；强力把持天下，就一定会失去天下。</strong></p>\n<p>人是不可能被强力统治的。比如周朝的时候，周厉王贪财好利，千方百计地搜刮人民。为了不让人民抱怨，他采取高压政策，派人监视百姓。使得亲友熟人在路上遇到了都不敢互相招呼，只能以眼神示意。这样的暴政使得国人最终忍无可忍，引起了民变，他也被逼逃离都城。秦始皇一统六国，不可不谓盛极一时。但人民群众拿起竹竿就推翻了他辛苦建立的王朝。防民之口甚于防川，社会或者家庭中的矛盾堵不如疏。</p>\n<p>第二十七章说过：“善结无绳约而不可解”。怎么样才能让人们死心塌地的追随呢？答案是获取他们的忠心和爱戴。这种心中的绳结要比绑在人手脚绑上有形的绳结要结实牢靠的多。管理靠的是大家互相信任和协作，靠的是有效有序的一个组织架构。而不是靠违背自然规律的强权打压和无限制的使用制裁手段。采用强力来治理国家，国家必然混乱。采用强力来治理公司，公司必然没有生气。采用强力来治理家庭，家庭必然缺少友爱。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-29-2","url":"/2020/07/18/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-29-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>故物或行或随；或歔或吹；或强或羸；或挫或隳。是以圣人去甚，去奢，去泰。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十九章前半节讲了天下不可取不可为的道理，告诫我们不要以蛮力来管理一个组织。我们能够改变的只有我们自己，只有自己朝好的方向改变了，周围的人才能被感染和被影响。接下来我们继续学习第二十九章的后半节～</p>\n<p><strong>所以有所前行必有所后随；有所气缓必有所气急；有所刚强必有所赢弱；有所安居必有所危殆。</strong></p>\n<p>世人秉性不一，千人千面，任何脾气性格的都有。因为任何事物都是相对而生的，有这样的百态众生，正是世界的真实一面。不要奢望世界上的人都按照自己的规则做事情，因为这种想法本身就是违背自然规律的。</p>\n<p>我们不过是因缘和合而生，刚好孕育在我们这个世界上的产物。就像天上的云一般，刚好形成了各种各样的形状。但这种状态也不过是转瞬即逝，因为天道的规律永远在推动着这个世界在不断变化，所以以前适用的一些经验，现在就不一定适用了。走在前面的，不学习可能很快就落后了。强大的，不懂得保持之道，可能很快就变得弱小了。安逸舒适的，不居安思危时刻警醒，很快就会变得危机四伏了。</p>\n<p>既然芸芸众生各有秉性，人事状态不断更迭，那么又该如何正确有效地进行管理呢？下面老子就给出了答案。</p>\n<p><strong>因此，圣人要除去那种极端、奢侈的、过度的措施法度。</strong></p>\n<p>圣人的治理之法说出来也非常简单，就是：“去甚，去奢，去泰”六个字。甚、奢、泰都是极端、过分的一些举措。人贵在自律，无论是有资源还是没有资源，有权势还是没有权势。不懂自律的人，永远无法成为一个真正自由的人。想要聚拢人心，就要克制自己的私欲和情绪。想要做成一项事业，就要克制自己的懒惰和怯懦，不停的朝着自己的目标前进。想要拥有和谐的工作和生活环境，就要包容他人。想要不成为金钱的奴隶，就要懂得克制自己的消费。想要不成为欲望的奴隶，就要懂得克制自己的欲望。</p>\n<p>中国人讲的中庸之道，不是平庸而之道，而是中正平和之道。《中庸》里写道：“喜怒哀乐之未发，谓之中；发而皆中节，谓之和；中也者，天下之大本也；和也者，天下之达道也。”一切活动都要控制在一定合理的范围内。喜怒哀乐是人的本性，我们不要试图去消除情绪，而是要接纳情绪，试图让情绪对自己和他人的影响达到最小。适度的放松和娱乐，是我们享受生活的一部分，但过度的纵情享乐，就是浪费自己最宝贵的时间和毁掉自己。所以凡事要学会有度有节，才能管理好自身，管理好团队。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-3-2","url":"/2020/06/03/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-3-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>是以圣人之治，虚其心，实其腹，弱其志，强其骨。常使民无知无欲。使夫知者不敢为也。为无为，则无不治。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三章前半节从任何事物都是矛盾的相生相克的观点出发，讲了治国修身的三点具体措施：不尚贤，不贵难得之货，不见可欲。后半节对这一观点继续进行延伸。</p>\n<p><strong>所以圣人治国治家治身，都是空灵人的内心，填饱人的肚子，削弱人的志向，强壮人的筋骨体魄。</strong></p>\n<p>“圣人之治“中的这个“治”至少包含了三层意思。对于国家管理者来说是治国，对于家庭管理者来说是治家，对于个人来说是治身（修身）。</p>\n<p>管理一个组织，就要让大家（包括领导者自己）消磨掉争斗之心，攀比之心，使人内心变得空灵，从而减少纷争，减少内耗。打虎亲兄弟，上阵父子兵，就是因为在危险来临的时候大家能互相想着对方，从而达到了降低伤亡，提高战斗力的目的。如果在一个组织中，大家都只想着自己的利益，那么这个组织就会内斗不断，是不会有什么对外战斗力的。除了让大家不争斗，还要给大家实际的利益，让大家生活的体面，这就是实其腹。一切只喊口号的给员工打鸡血都是耍流氓。大家只有得到实际利益了，才会发自内心的拥护这个组织，才能把大家真正团结在一起。一个所有人都能和谐共处并且能得到实惠的国家、公司、组织、家庭，还会发展不好吗？</p>\n<p>我们自身也是一个小天地，也需要经营。对于内心来说，我们要学会做减法，把被社会浸染的固有观念去除掉，去掉执念和分别心，使内心变得空灵。内心空灵了之后，智慧自然就有了。有时候人没有智慧，就是因为被固有观念填的太满，然后真正的智慧就没有空间来存放了。对于身体来说，我们要吃的好，睡得好，并且积极锻炼。</p>\n<p>人们平时会觉得有志是一件好事啊，为什么老子要让人弱其志呢？对于“志”，后面的章节有解释到：“强行者有志”。所以说什么样的人有志呢？知其不可为而为之，不达目的不罢休的人。这是因为老子不主张人力过分干涉自然的规律，对于一个有志的人来说，很有可能会强力改造周围环境，使其偏离原来的发展规律。如果这个人的执念是有问题的，那么破坏力将非常大。比如希特勒，可以说是有志的代表，在二战期间对犹太人进行泯灭人性的大屠杀，造成了无数人的伤亡。那么难道老子在鼓吹让我们不要有理想吗？我觉得恰恰相反，老子要追求的理想是相比于一般的求名利的志向来说更难做到的。就是后面提到的，“为无为，则无不治”。是一个人消除了一切执着偏见分别心，然后身体力行去感召人，踏踏实实做一些真正能利益众生的事情。</p>\n<p><strong>使人没有小聪明也没有欲望。从而使得“聪明人”不敢胡作非为。这时候领导者不用去刻意做什么，却能把国家、家庭、自身治理得很好。</strong></p>\n<p>对于这几句话，历来都容易被误解为是老子愚民思想的典型体现。我觉得这是没有真正看懂《道德经》在说什么，也不懂老子。这里的“知”通“智”，更多的是在指一种世俗的智慧，一种俗世的生活哲学。跟老子或者释加牟尼讲的大智慧是有着本质区别的。所以在佛经中，但凡出现智慧的解释，一般都是直接用音译“般若”，来描述这种大智慧，就是因为担心大家误解。</p>\n<p>一个社会中，所有人都不再耍小聪明，也没有私欲的时候，大家会有一个从外求到内求的转变。不会再想着怎样做才能让大家觉得我高端大气上档次，怎样才能受人尊重等等的。而是会更多的关心自己要做什么，喜欢做什么。而当一个人在做着自己真正喜欢做的事情的时候，会是阻力最小、效率和幸福度最高的时候，这才是真正的大同社会。在这样的社会中，领导者还需要刻意的去彷徨呐喊，忙忙碌碌的指挥大家该做什么不该做什么吗？所以说，这才是最高级的领导“为无为，则无不治”。</p>\n<hr>\n<p>总结一下，这一章讲的是老子从事物都是矛盾的相生相克的观点出发，分析了治国修身的三点具体措施：不尚贤，不贵难得之货，不见可欲。从而使人虚心实腹，弱志强骨。最后达到“为无为，则无不治“的理想大同状态。</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-3-1","url":"/2020/06/02/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-3-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>不尚贤，使民不争；不贵难得之货，使民不为盗；不见可欲，使民心不乱。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一章中，老子从有无的道理衍生出了无为的道理。这一章延续前文，继续讲述道在生活中的体现。</p>\n<p><strong>不崇尚贤能之人，使人民不争斗；不看重难得稀有之物，使人民不为盗贼；不显露引起贪欲之物，使人民心不乱。</strong></p>\n<p>不尊贤者的虚名，人们就不会争相攀比。这里的意思不是说不要学习贤者，而是说不要崇尚贤者，不要有分别心。心中如果有了贤与不肖的区别，那么人们就会争相去做一些符合贤的表象的事情，从而引来比较争斗之心，而这样做的结果就是离真正的“贤”就相去甚远了。《金刚经》也提到：“若菩萨有我相、人人相、众生相、寿者相，即非菩萨”，基本跟这里是一个意思。所以说，大智慧都是相通的。</p>\n<p>社会不看重稀有难得之物，民众就不会绞尽脑汁去获取这些东西。俗话说物以稀为贵，但很多稀有的东西，对我们来说并没有什么用，不过人们就是想得到它。这些东西包括贵金属、珠宝、钻石、奢侈品牌的包、虎皮、熊掌等。人们想得到这些难得之货，很大一部分原因是社会抬高了这个物品的价值，拥有这些东西的人会有一种虚幻的高贵感。东西有了好坏贵贱之后，人们就会绞尽脑汁去得到这些不容易得到的“珍贵”东西，一旦正常途径得不到，歪主意就来了。所以只有不过分看重这些难得之货，人心就不会失衡，也就不会有成为盗贼的可能。</p>\n<p>人们看到美食佳肴，就有吃的欲望；听到婉转悠扬的歌曲，就有听的欲望；看到名车宝马，就有占有的欲望。现代都市社会，充斥着各种诱惑，几乎每一条广告都在劝你及时享乐。但中国有个成语叫“欲壑难填”，人这种生物，永远不会满足，好了还想更好。比如当年秦始皇以六合为家，崤函为宫，不可谓不极尽人间之奢华，但在得到了这一切之后，还想要长生不老、子孙万世继承帝业。欲望可怕的地方在于，在欲望面前，人最容易迷失自我。很多贪官的落马，都是被欲望诱惑，从而走上不归路的。三国人物我最佩服的是刘备，其中有一点就是因为他能把控住自己的欲望。他在吴国的那段时间，尽管面对各种美酒佳肴宫殿美女的诱惑，他仍然没有忘掉自己要匡扶汉室的志向。从种种细节可以看出他的志向不在小，所以曹操才会认为天下英雄，唯使君与操耳。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-30-2","url":"/2020/07/21/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-30-2/","content":"<p><strong>原文：果而勿矜，果而勿伐，果而勿骄。果而不得已，果而勿强。物壮则老，是谓不道，不道早已。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十章的前半部分老子讲述了他对战争和冲突的看法。用强力争斗永远是解决问题最后的方案。如果不得已要进行反击，也要把握好分寸，达到自己的效果就要适可而止。接下来老子在后半部分继续讲述为什么他有这样的一个观点～</p>\n<p><strong>达到目的了却不自我矜大，达到目的了也不去夸耀骄傲，达到目的了也不要自以为是，达到目的却出于不得已，达到目的却不逞强。</strong></p>\n<p>国虽大，好战必亡；天下虽安，忘战必危。我们不主动发起战争，但却不能没有反击的实力。侥幸胜利之后也没有什么可骄傲自大的，因为用兵之道本就不是为了战胜敌人，而是为了保一方平安。用兵一定要到了不得已的时候才去采用，穷兵黩武，只能导致国家的迅速败亡。不得已而为之的事情，又有什么可值得夸耀的呢？相反，我们应该深刻反思为何会招致如此祸患？沾沾自喜、狂妄自大只能推着事情向相反的方向转化。得意忘形就又会给未来的失败埋下伏笔。</p>\n<p><strong>事物过去强大就会走向衰朽，这就说明它不符合于“道”，不符合于“道”的，就会很快死亡。</strong></p>\n<p>前面先讲了老子的结论，那么他是怎么得出这个结论的呢？这里就给出了答案。跟前面讲的所有的道理一样，他也是从自然中领悟而来。物壮则老，月盈则亏，任何事物强大到一定程度都会必然走向衰败和灭亡。这说明一味的追求强大和突出不符合我们这个世界的道。木秀于林，风必摧之；行高于人，人必非之。一个人过于把强大和优秀显露出来，就必然会招致灾祸。就像老子在第二十章说的：“俗人昭昭，我独若昏。俗人察察，我独闷闷”。所以我们要学会藏拙，学会和光同尘。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-33","url":"/2020/07/26/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-33/","content":"<p><strong>原文：</strong></p>\n<p><strong>知人者智，自知者明。胜人者有力，自胜者强。知足者富。强行者有志。不失其所者久。死而不亡者寿。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十二章中老子讲了道无名无形却无处不在、无所不能。并且指出，人应该向道学习无为而无不为的管理理念。接下来我们一起学习第三十三章看看老子又讲了什么样的人生哲理吧～</p>\n<p><strong>能了解别人叫做智，能了解自己叫做明。</strong></p>\n<p>老子在这里给出了智和明的定义：一个能够看透他人的人可以称为智，能够了解自己的优缺点的人可以称为明。我们身边的“智者”可能很多，但其中却少有真正的可以称之为“明”的人。如果要挑他人的缺点，我们每个人都仿佛都是个明白人，都能一针见血。可是轮到自己头上的时候，却又不知道自己哪里出了差错，觉得一切的问题都来自他人。</p>\n<p>三国时期的杨修是一个聪明绝顶的人，他25岁就已经举了孝廉，当了丞相府的书记，知识非常渊博，常常能一语道破他人的心思。曹操让人造一座花园，造好后，曹操去看了一下，然后在门上写上了个“活”字就走了，结果是“人皆不晓其意”，杨修却说：“‘门’内添‘活’字，乃阔字也。丞相嫌园门阔耳。” 大家都不明白曹操在想什么，只有杨修看明白了门上的字的含意。并且很得意的把它告诉了别人。还有，曹操为了防止别人暗害自己，便对别人说自己梦中好杀人，让大家不要在自己睡着时接近自己，并装模作样的杀死了一个替自己盖被子的近待。结果是“人皆以为操果梦中杀人”，而又只有杨修了解曹操的意图，并对别人说：“丞相非在梦中，君乃在梦中耳”。还有一次，曹操故意让曹丕、曹植出城，却在暗中吩咐门吏不让两人出城。结果，曹丕老老实实地退回来了，而曹植却在杨修的指点之下，杀了门吏。杨修又一次的料到了曹操的意图。可怜杨修看穿了曹操这么多次，却始终没有看出曹操早已经对自己起了杀心，还是一如既往地将四处传播曹操的各种意图想法，最终导致自己被杀。于是，当杨修再一次从一根“鸡胁”中看出曹操退兵意图，并毫不顾忌的将之告诉夏侯敦时，曹操终于对杨修忍无可忍，他以“乱我军心”为名，将之杀死。杨修完全看透了他人的想法，但却没有了解到自己的危险将临。可谓是智有余，而明不足。</p>\n<p><strong>能战胜别人可以称之为有力，能克制自己的弱点才是真正强大。</strong></p>\n<p>能够战胜别人的人可以说是个有力量的人，但真正的强大永远不是战胜别人，而是战胜自己。一个人所遇到的种种不幸，诚然有他人的原因，但归根结底还是自己的原因。虽然每次都把过失归咎于他人，可以让自己心里更加舒服，但却永远不可能变得真正强大。走入困境的时候觉得没办法摆脱，往往是因为无法克服内心的恐惧和贪婪。其实我们每个人在任何时候都有选择，遇到困难的时候需要的只是勇敢的走出舒适区，克服自己内心的各种痴心妄想。</p>\n<p><strong>知道满足才是真正富有，坚持不懈地身体力行说明志向远大。</strong></p>\n<p>富有不是一个人有多少钱，而是内心知道满足的状态。理想远大也不是把口号喊的响亮就可以的，而是需要用实际行动坚持不懈地身体力行。所以说，智慧、强大、富有、志向远大等等都与外界的环境没有太大关系，都只与一个人的内心有关系。一个人的内心世界改变了，他的整个世界都会跟着发生变化。每个人都要经历从他求到自求的过程。他求的时候，希望获得他人的认同和羡慕；而自我内求的时候，更多的关注的是有没有成为更好的自己。</p>\n<p><strong>不离失本分能够长久不衰，身虽死而“道”仍存的，才算真正的长寿。</strong></p>\n<p>不失去本分可以长久不衰，但更加的长久是，肉身虽死，思想却能穿透时空的阻隔。一个国家、民族、公司、家庭以及个人，如果能够保住自己的根本，那么基本可以保持长久不衰。但如果想要达到真正的长寿，做到这些还不足够。那就需要将他们特有的价值观和文化经久不衰的发展传承下去。这样，即使组织和个人外在的看得到的形象不存在了，他还活在人们心中，不算真正消亡。</p>\n<p>《寻梦环游记》里面有一个情节，我至今还印象深刻。讲的是人有三次死亡，第一次的死亡是呼吸停止心脏停跳，在生物学上死了。第二次的死亡是在葬礼上，认识你的人都来祭奠，来怀念你的一生，在社会上你死了，不再有你的位置。第三次的终极死亡是最后一个记得你的人也死了，你彻底被这个世界遗忘了。如果一个人死了，几千年以后人们还在怀念这个人，那么这个人就可以称之为真正的长寿了。孔子、老子、释加牟尼、耶稣、默罕默德、尧舜禹等等这些人都可以说是真正的长寿之人。因为他们思想的光辉已经照耀了人类几千年，而且还将会继续照耀下去。</p>\n<hr>\n","categories":["哲学思考","道德经"]},{"title":"《道德经》-30-1","url":"/2020/07/19/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-30-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>以道佐人主者，不以兵强天下。其事好还。师之所处，荆棘生焉。大军之后，必有凶年。善有果而已，不敢以取强。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第二十九章中老子讲了天下神器不可为之，不可执之，所以圣人治理天下的秘诀在于去甚，去奢，去泰。接下来我们一起来学习一下第三十章老子又讲了什么样的人生哲理吧～</p>\n<p><strong>以“道”自辅的君主，不以兵力逞强于天下。穷兵黩武这种事必然会得到报应。军队所到的地方，荆棘横生，大战之后，一定会出现荒年。</strong></p>\n<p>武力永远是要作为最后的解决问题的手段。原子弹最大的威力在于未发射的时候的震慑作用，法律的最大作用在于对未违法的人的警戒作用。卢梭在他的自传《忏悔录》中记录了一件他小时候的故事。故事是讲他小时候偷东西被抓到，被惩戒之前内心害怕到了极点，但是当真正被惩罚的时候，他反而心中不再恐惧，觉得不过如此，并且惩戒抵消了他内心的罪恶感。《孙子兵法·谋攻篇》里讲: “上兵伐谋，其次伐交，其次伐兵，其下攻城；攻城之法为不得已。” 所以真正的军事家不是攻城略地，而是不战而屈人之兵。</p>\n<p>军事离我们生活比较遥远，那么这句话对我们一般人有什么借鉴意义呢？其实，我们跟他人之间的冲突就跟国与国之间的战争一样，也不可轻易发起争端。一个人最大的震慑力在于不怒自威。平时有力有理有节的与人交往，他人就不敢轻易冒犯。</p>\n<p>与他国发生战争或者与他人发生冲突，除了降低了自己的威慑力，还有另外一个副作用：那就是损耗太大。杀敌一万自损八千，敌人是消除了，但自身也空虚了，这就给自己带来了灭亡的危险。汉武帝曾经武力征战四方，在奠定了汉朝无上的影响力的同时，也导致了国力空虚，从此由盛转衰，为王朝的灭亡埋下了种子。</p>\n<p>动用武力的危害这么大，那么是不是我们就不能动用武力呢？也不是的。如果他人都欺负到头上了，就必须强有力的反击。我们没事不应找事，但来事也不应怕事，这是我们与人交往的一个准则。</p>\n<p><strong>善于用兵的人，只要达到用兵的目的也就可以了，并不以兵力强大而逞强好斗。</strong></p>\n<p>对于不得已的情况，我们必须反击。但应该把这种力量控制在哪种程度比较合适呢？老子在这里给了答案：只要达到目的就可以了。国家之间发生不可调和的冲突的时候，就会发生战争。只要一方服软，矛盾得以解决，签订了和平条约，那么就没必要把对方逼上绝路。同样的，如果一个人冒犯了你，那么你的反击让对方从此不敢再冒犯你，那么就算是到达目的了，就没必要再进一步的逼迫对方了。这也是上一章讲的去甚，去奢，去泰的一个延伸，凡事都要有度，把握好度就能把握好人生。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-32","url":"/2020/07/24/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-32/","content":"<p><strong>原文：</strong></p>\n<p><strong>道常无名，朴虽小，天下莫能臣也。侯王若能守之，万物将自宾。天地相合，以降甘露，民莫之令而自均。始制有名，名亦既有，夫亦将知止，知止所以不殆。譬道之在天下，犹川谷之与江海。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十和第三十一章中老子讲了对待战争和冲突的看法。接下来我们一起来学习第三十二章中老子又讲了哪些人生哲理吧～</p>\n<p><strong>“道”永远是无名的，它虽然很小不可见，天下没有谁能使它服从自己。侯王如果能够依照“道”的原则治理天下，百姓们将会自然地归从于它。天地间阴阳之气相合，就会降下甘露，人们不必给它指令而会自然均匀。</strong></p>\n<p>这一章又开始讲“道”。道虽无名无形，但却用处无穷。道很小，小到在我们的指甲缝里，在头发丝里。但它又可以很大，大到宇宙万物都必须遵循这个规律。《庄子》里有一篇讲东郭子向庄子问道。东郭子问：“道在哪里呢？”庄子回答道：“无所不在，道在蝼蚁，在稊稗，在瓦壁，在屎溺。”为什么庄子会说道在这些卑下污秽的地方呢？因为从道的角度来看，物无贵贱。只要存在的，即是道的一部分。</p>\n<p>道虽然小，但却没有谁能够驱使它。道虽然不能够被驱使，但我们却可以了解、利用道的规律，来为我们的生活服务。尤其是在管理方面，道可谓是世界上最高境界的管理，尤其值得我们学习借鉴。道不用指挥天地哪里该下雨，哪里该施肥，自然界的一切都在井井有条的自我管理。我们管理国家也好，公司也也罢，甚至是管理我们自身，都应该像道学习。学习它的无为而治，学习它的大制不割。道只需要制定好一套行之有效、符合自然的规则，就可以让万物自行运转。所以，管理最重要的应当是制定一个符合天道人心的法则。当法则制定好之后，就可以让所有人都井井有条的在忙碌自己该做的事情，然后一切就可以正常运转。当领导的不需要去到处彰显自己的能力和美德，也不需要去撸袖子上阵瞎忙活。放到个人身上来说，我们应当在生活中处处自律，培养自己良好的习惯，从而让身体自行按照这个习惯运转。这样呢，就会为无为则无不治，在没有感受到巨大的阻力中，我们就把事情办圆满了。</p>\n<p><strong>治理天下就要建立一种管理体制，制定各种制度确定各种名分。名分既然有了，就要有所制约，适可而止，知道制约、适可而止，就没有什么危险了。“道”与天下的关系，就像川谷与江海一样。</strong></p>\n<p>道虽无名，但却不是每个人都可以深刻理解，所以难以具体实施。所以我们就要把道形象具体化，给我们的制度以具体的形名，这些形名具体包括各种等级、规定、指责、章程等等。有了这些东西，人们就能知道哪些是不能做，哪里应当停止。只有知道了什么该做和不该做，人们才能不会有危险。放到个人来说，我们也应自律，当给自己设定一些限制。比如平时给自己制定一些计划（读书计划、健身计划、饮食计划、工作计划等等），还有给自己设置完成任务的截止时间，这些都有助于我们更好的完成一些我们想要做的事情，有助于我们提高和成为更好的自己。</p>\n<p>道和天下的关系就像川谷和江海的关系。那么川谷和江海有什么样的关系呢？水汇聚入川谷并且能够按照川谷的走向来流动。川谷做到这些靠的不是它的号召和驱使，而是靠的把自己放低，从而水自动汇聚而来。有道者也是如此，他们都会把自己的位置放的很低，与众人和光同尘，从来不把自己放到一个很高的位置，更不会对人民颐指气使。放低自己，人心自然汇聚。同样的，承认自己的无知，就会有机会让自己变得更渊博。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-31","url":"/2020/07/23/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-31/","content":"<p><strong>原文：</strong></p>\n<p><strong>夫佳兵者，不祥之器，物或恶之，故有道者不处。君子居则贵左，用兵则贵右。兵者不祥之器，非君子之器，不得已而用之，恬淡为上。胜而不美，而美之者，是乐杀人。夫乐杀人者，则不可以得志于天下矣。吉事尚左，凶事尚右。偏将军居左，上将军居右，言以丧礼处之。杀人之众，以哀悲泣之，战胜，以丧礼处之。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十章中老子讲述了自己的对待战争的看法。战争手段应该是慎之又慎的解决问题的最后不得已而为之的方案。国虽大，好战必亡，知止方能不殆。所以，在采用战争手段的时候也要适可而止，善有果而已。第三十一章还是在继续讲述战争，是对上一章的延伸，我们一起来学习一下吧～</p>\n<p><strong>兵器是不祥的东西，万物无不都厌恶它，所以有“道”的人不使用它。君子平时居处就以左边为贵而用兵打仗时就以右边为贵。兵器这个不善的东西，不是君子所使用的东西，万不得已而使用它，最好淡然处之。</strong></p>\n<p>就像上一章中讲的“师之所处，荆棘生焉；大军之后，必有凶年”。兵动则物有所害，所以万物莫不厌恶争斗打仗。真正顺应天道人心的君子都不会轻易使用它。</p>\n<p>古人以左为阳以右为阴，阳生而阴杀。上天有好生之德，君子也都喜欢鲜活有生命的东西。而战争却反其道而行之，却是以杀戮和毁坏为目的。所以用兵打仗是一件非常不吉利的事情。虽然战争不是不可以使用，但君子千万不可以倚重于杀戮带来的震慑力来进行管理。</p>\n<p>靠强力镇压统治的系统是不可以持久的，靠霸权来建立的领导地位是不稳固的。因为盛衰都是在不断转化，在强大之时这种系统尚可以稳固，一旦柔弱的时候，整个系统就非常容易坍塌。周朝以王道治天下，虽然在春秋战国时期，周朝的统治已经渐渐衰落，但却在长达将近五百年的时间里没有灭亡。秦朝以霸道统治天下，虽然盛极一时，可是短短的十来年时间就不复存在。靠“柔”来治理，是生之道；靠“刚强”来治理，是死之道。</p>\n<p><strong>胜利了也不要自鸣得意，如果自以为了不起，那就是喜欢杀人。凡是喜欢杀人的人，就不可能得志于天下。</strong></p>\n<p>一个喜欢杀戮和毁灭的人是不可能得到民心和天下的，更不可能被衷心的拥护和爱戴。人性本善，都会有同情弱者的一面。只有顺应天道人心的事业才能吸引一大批仁人志士，并且甘愿为此赴汤蹈火。而一个以杀戮为乐的人，周围必然聚集的是想从他身上得到好处的小人。以人心聚在一起的力量要远远大于以利益聚集在一起的组织和团体。</p>\n<p><strong>吉庆的事情以左边为上，凶丧的事情以右方为上，偏将军居于左边，上将军居于右边，这就是说要以丧礼仪式来处理用兵打仗的事情。战争中杀人众多，要用哀痛的心情参加，打了胜仗，也要以丧礼的仪式去对待战死的人。</strong></p>\n<p>战争是一件极其不吉利的事情，要用对待丧礼的形式来对待它。打了胜仗，不应该高兴，而应该为死去的人感到悲哀。战争是由于人心的贪婪、无知所造成的， 它给人类带来了巨大的灾祸。虽然人类为此付出了巨大的代价，但这个世界却永远没有真正和平过。</p>\n<p>从整体来看，每个国家、组织、个人都是我们人类社会的一部分，就像我们的手、脚、各种器官是我们身体的一部分一样。人类社会的战争就如同我们身体的不同部分在争夺养料，每个器官都希望自己能够更强大。但是一个人的心脏再强大，肾脏不行了，人最终的命运也是死亡。还有的书中提到，人类就像是地球的癌细胞。癌细胞最终会死于自己拼命的生长繁殖中，人类社会最终的命运是不是如此呢？这完全看人类有没有控制自身行为的能力。现在社会问题也是越来越突出，比如人口增长、环境污染、全球变暖、食品安全隐患、战争、病毒、核威胁。其中的任何一个问题都可能导致人类社会的文明被终结。无论是整个人类群体，还是一个国家、组织、个体，最大的敌人永远都是自己，真正的强大永远都是战胜自己。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经","战争"]},{"title":"《道德经》-34","url":"/2020/07/27/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-34/","content":"<p><strong>原文：</strong></p>\n<p><strong>大道泛兮，其可左右。万物恃之而生而不辞，功成不名有。衣养万物而不为主，常无欲，可名于小；万物归焉，而不为主，可名为大。以其终不自为大，故能成其大。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十三章中老子讲了什么是智，什么是明；什么是有力，什么是强；什么叫做富足，什么叫做有志；什么是长久，什么又是真正的长寿。接下来我们一起学习一下第三十四章中老子又讲了什么道理吧～</p>\n<p><strong>大道泛泛，可左可右，无所不宜。万物依赖它生长而不推辞，完成了功业而不居功。</strong></p>\n<p>道的一个很大的特性就是“生而不有，为而不恃，长而不宰”，<a href=\"https://zhuanlan.zhihu.com/p/148580762\">第十章</a>中已经提及过，这里再次提及，也说明了这种特质的重要性。在前面的章节中，老子把这种特质形容为玄德，也就是深远玄妙的德行。如果能够拥有这样的德行，就与道很接近了。用更通俗的话来说，这种德行就是无我利他。做父母的不求回报，只是给小孩一个温暖的家，希望他以后生活的好。做老板的不为自己的私利，只是给员工提供了一个养家糊口并且提升自我的平台，希望每一个员工都可以收获一些东西。做国家领袖的不为自己的名望，只是给百姓创造一个幸福安乐的社会环境，希望所有人都可以安居乐业。例子在第十章中举了很多，这里就不再重复了。有兴趣的可以回到<a href=\"https://zhuanlan.zhihu.com/p/148580762\">第十章</a>再去看一看。</p>\n<p><strong>它养育万物而不自以为主，可以称它为“小”，万物归附而不自以为主宰，可以称它为“大”。正因为他不自以为伟大，所以才能成就它的伟大、完成它的伟大。</strong></p>\n<p>有道之人，不以自我为中心，不自大，不为自己塑造光辉伟岸的形象，所以可以说很“渺小”。但万物都向他靠拢，主动向他归附，所以又可以说很“伟大”。一切伟大中都蕴涵着渺小，也正是因为把自己放得低，所以才成就了他的伟大。“江海所以能为百谷王者，以其善下之，故能为百谷王。”</p>\n<p>不像现在社会上一些人稍微有点名气就讲排场、摆架子，国学大师季羡林，为人一直非常朴实、谦逊，从没有人见他拿过架子。他在北大朗润园的住所是一直敞开的，任何人都可以轻轻敲开他的家门。他朴实和宽容的作风深深赢得了同事、学生甚至校内司机的尊敬。每年大年初一，季羡林一推开窗门，面前白皑皑的雪地上，就会有北大各系学生用树枝画满的各种各样的问候、祝福，布满方圆几百米。即使如今季羡林先生已经不在了，每逢雪花飘零，门口还会写满这样的问候。那扇空着的门，还将继续装载着季先生的人格魅力和大家对他的爱戴。</p>\n<p>如果一个人西装革履的穿戴，各种华丽的头衔加身，基本上就可以判定这个人不是真正的自信。因为内心真正自信的人是不需要这些外在的东西来标榜和装饰的，真正有料的人都是接地气的。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-36","url":"/2020/07/30/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-36/","content":"<p><strong>原文：</strong></p>\n<p><strong>将欲歙之，必固张之；将欲弱之，必固强之；将欲废之，必固兴之；将欲夺之，必固与之。是谓微明。柔弱胜刚强。鱼不可脱于渊，国之利器不可以示人。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十五章中老子讲了道虽然不像美食和音乐一样让人流连忘返，但却无处不在，功用无穷。执大道，就可天下归附；归附而不伤害，就可天下太平。接下来我们一起继续学习第三十六章，看看老子又讲了什么人生哲理吧～</p>\n<p><strong>想要收敛它，必先扩张它，想要削弱它，必先加强它，想要废去它，必先抬举它，想要夺取它，必先给予它。</strong></p>\n<p>西方也有句类似的谚语“上帝欲使人灭亡,必先使其疯狂”。事物的兴衰交替自有其发展的规律，看起来的强大，很可能只是灭亡前的征兆。二战时候的德国和日本在前期疯狂的扩张，迅速占领了很多国家，简直不可一世。但没疯狂没多久，就被其他国家联合起来打趴下了。国民党在二战胜利的时候，也是各种光环加身，尤其是蒋本人在国内获得了极大的个人声望。但在这之后，却迅速败亡，逃到了台湾。所以说，最强大的时候，往往也是最危险的时候，这时候我们应该格外小心注意。</p>\n<p>目前来说，全球政治经济开始趋于走向保守，各国的民粹势力有所抬头。这也是几十年的全球化所导致的必然结果，因为任何事物都不可能一直高歌猛进。在几十年的全球化的过程中，全球经济迅速发展，但同时也产生和积累了很多问题，这些问题又会必然导致人们对全球化进一步发展的担忧。这就像股市一样，有起有落才是必然规律。张的过了，就要有所收敛。收敛之后，必然会迎来进一步更大的扩张。也正如《三国演义》开篇中所说：“天下大势合久必分，分久必合”，分分合合最终的结果带来的是更大的融合。</p>\n<p>另外，老子在这里也告诉了我们几条阳谋。想要去削弱对方，就要先让对方感觉自己强大；想要废掉对方，就先要让对方感觉自己兴盛；想要获得一样东西，就得先付出一些东西。我们平时对一个人不满意，就要骂一个人，不断的指出对方的缺点，但这其实是在帮助对方进步。历史上很多城府特别深的人，越是对一个人充满敌意，越是会表现的和蔼可亲、人畜无害，然后在关键时刻给敌人致命一击。比如越王勾践复国的故事，他在被吴王拘禁的时候连对方的粪便都肯尝，表现的非常恭顺。等到取得了吴王的信任之后，回到越国卧薪尝胆，最终把吴国灭掉。讲到这里，突然想到人性和天道真的是背道而驰。想要把国家治理的安定，就要亲近魏征一样的诤臣，而诤臣却又往往让人浑身不自在。想要让生活过的美好，就不能过度享受当下的快乐。想要身体健康，就又得控制饮食和忍受运动的劳累。所以说天道平衡，任何收获都得有付出。对于治国齐家修身来说，这个付出最艰难的地方来自于跟自身的人性作斗争的过程。</p>\n<p><strong>这就叫做虽然微妙而又显明，柔弱战胜刚强。鱼的生存不可以脱离池渊，国家的利器不可以向人炫耀。</strong></p>\n<p>前面讲了这么多，老子得出了一个结论：“柔弱胜刚强”。直来直往的去索取或者是争夺自己想要的东西，不一定可以得到，就算勉强得到了，效果也不会很好。最好的销售策略，不是喋喋不休的推销自己的产品，而是处处为客户着想，为对方提供最好的服务。追求心爱的人的最好方式，不是死缠烂打，而是处处为对方考虑，让对方最大程度地感到舒适和快乐。想不丢掉工作和饭碗的最好的方式，不是跪舔老板，求他大发慈悲，而是努力提高自己，让老板觉得如果自己离开了这里可以立刻找到更好的平台。削弱对手的最好方式，不是斗个你死我活，而是让他迷失在他自己编织的幻想当中。要做到这些，就得韬光养晦，不可以锋芒毕露，不可以处处轻易向他人展示自己要干什么。</p>\n<p>鱼想活的长久，就不能经常跳出水面，让捕鱼者知道它的存在。国家想要国祚长久，就不能轻易的把自己的力量展示出来。整天叫呱呱的都是傻子，闷声发大财的才是聪明人。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-37","url":"/2020/08/01/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-37/","content":"<p><strong>原文：</strong></p>\n<p><strong>道常无为而无不为。侯王若能守之，万物将自化。化而欲作，吾将镇之以无名之朴。无名之朴，夫亦将无欲。不欲以静，天下将自定。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>三十六章中老子讲了柔弱胜刚强的智慧。接下来我们继续学习第三十七章，看看老子又教给我们什么样的人生哲理吧～</p>\n<p><strong>道永远是顺任自然而无所作为的，却又没有什么事情不是它所作为的。侯王如果能按照“道”的原则为政治民，万事万物就会自我化育而得以充分发展。</strong></p>\n<p>道最大的特点是“无为而无不为”，这也正是老子无为而治的核心思想的来源。无为不是不作为，而是不任意干涉，通过制定好一套顺应天道人心的规则，让万物来自然运转。如果领导和管理人员能够按照这个原则来管理和做事，那么万物都会“自化”。通俗来说，就是人民不需要管教而自我成才，百姓不需要教化而自然仁义。好的规则和法律可以引导人向善，可以起到规范社会活动、调动人民积极性的作用，而不好的规则和法律会引导人走向堕落，沦落为镇压和剥削人民的工具。就像前文提到的管理的最高境界是“太上，下知有之”，效仿天道制定一套好的规则将是最高的管理智慧。</p>\n<p><strong>自生自长而产生贪欲时，我就要用“道”来镇住它。用“道”的真朴来镇服它，就不会产生贪欲之心了，万事万物没有贪欲之心了，天下便自然而然达到稳定、安宁。</strong></p>\n<p>在道的规则下，万物将会自我发展，自我管理。那么在这个发展过程中肯定会产生一些贪欲，受到很多诱惑。那么这时候应当怎么办呢？老子说这时候就要用“道”和“德”来镇抚，通俗来说也就是划定一个人的行为和思想的边界。“道”和“德”来镇抚将会消除人们的贪欲之心，使人民重新回到无欲无求的静的状态，这时候天下将会自我安定。</p>\n<p>“道”和“德”大家可能会觉得比较虚幻，不容易理解。我们可以理解为他们是一种普世的价值观，一种大家都认同的世间真理。佛教里说这个“道”是“不二法门”，孔子说“道”是“一”，其实都是一个意思。都是众生平等，是己所不欲勿施于人，是公平公正，是将心比心。这个“一”到了曾子那里就引申为“忠恕”二字。“忠”就是内心中正，尽心做事，无愧于己，无愧于人。“恕”拆开就是如心，意思是如同他人之心，是推己及人、将心比心的意思。给自己捞好处的时候，想到他人也想要得到好处，那么就会抑制贪心。给他人上刑法的时候，想到自己也不愿接受刑法，就会给他人施以仁慈。如果社会上每个人都能这么替他人着想，都能克制自己的贪嗔痴慢疑等各种人性的弱点，那么这个社会必将成为一片人间乐土。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-39-1","url":"/2020/08/05/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-39-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>昔之得一者：天得一以清；地得一以宁；神得一以灵；谷得一以盈；万物得一以生；侯王得一以为天下贞。其致之，天无以清，将恐裂；地无以宁，将恐发；神无以灵，将恐歇；谷无以盈，将恐竭；万物无以生，将恐灭；侯王无以贵高将恐蹶。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十八章中老子讲了道、德、仁、义、礼之间的关系，并得出一个结论：失道而后德，失德而后仁，失仁而后义，失义而后礼。最大的美德往往不是彰显自我德行的仁、义、礼，而是不外在表现出来的道和上德。老子不反对仁义，相反他认为这是一种非常好的美德，但是仁义却比不露声色为社会、为他人奉献自我的道和上德的境界差了一线。相比于儒家的提倡仁义，老子更进一步，直接提倡让人们返璞归真，回归到最初的道的状态。接下来我们一起来进入第三十九章的学习，看看老子又带给我们什么样的人生智慧吧～</p>\n<p><strong>往昔曾得到过道的：天得到道而清明；地得到道而宁静；神得到道而英灵；河谷得到道而充盈；万物得到道而生长；侯王得到道而成为天下的首领。</strong></p>\n<p>根据后文第四十二章中提到的：“道生一，一生二，二生三，三生万物”，我们可以知道“一”是道之子，在这里指无为。曾经得到过道的都有什么呢？老子认为有天、地、神、谷、万物和侯王。</p>\n<p>天得到道就会清明，地得到道就会宁静。要知道在宇宙中并不是所有的星球都像我们生活的地球一样风和日丽，适合人类居住。比如火星中的大气以二氧化碳为主的，空气既稀薄又寒冷，沙尘悬浮其中，每年常有尘暴发生。正因为如此，火星上的风速可以达到每秒180多米，是我们通常所说的12级台风的6倍之多。而且火星沙尘暴一旦刮起来可持续三个多月，从地球上望去，就像一个暗红色的灯笼。另外在宇宙中，地也不总是宁静的。比如磁星的星震爆发的能量可以横一大片广袤的宇宙空间。2004年时，科学家们曾经监测到地球遭遇了巨型“耀斑”袭击，而这次耀斑就来自于一次距离我们有5万光年的磁星的星震，这次耀斑在不到一秒钟的时间内发出的能量相当于太阳在50万年内发出的总能量。与星震爆发的威能相比，我们在地球上所见到的地震简直就不值一提了。所以我们能够生活在一个可以让万物繁衍的星球上是一件非常幸运的事情，也是造物主给我们的恩赐。天清地宁是因为天地得到了“道”，这个“道”就是无私无欲默默奉献，是衣养万物而不为主，是用自己的厚重来承载众生。</p>\n<p>神得到道就会英灵，河谷得到道就会充盈。神之所以灵，是因为他们按道的规律行事。他们无私无欲、无我利他，便可得到无上的大智慧。拥有这种大智慧便可以看到一切的前因后果，所以才能够英灵。而河谷懂得放低自己，有博大的胸怀，所以才能够百川汇聚而成其大。</p>\n<p>万物得到道而生长；侯王得到道而成为天下的首领。万物之所以能够繁茂生长是因为懂得圆润柔和的智慧。坚强者死之徒，柔弱者生之徒。万物如果不懂得柔韧，那么一阵大风刮来，草木都会折断。万物如果不懂得退让，突出冒尖，必然会被自然摧毁。木秀于林，风必摧之；堆出于岸，流必湍之；行高于人，众必非之。古代的圣人明君之所以能让百姓安居乐业，把国家治理的井井有条，是因为他们懂得无为的智慧。把一切规则都按照天道人心制定好之后，就不再用自己的权威对社会活动强加干涉，然后就可以垂拱而治，无为而无不为。</p>\n<p><strong>推而言之，天不得清明，恐怕要崩裂；地不得安宁，恐怕要震溃；神不能保持灵性，恐怕要灭绝；河谷不能保持流水，恐怕要干涸；万物不能保持生长，恐怕要消灭；侯王不能保持天下首领的地位，恐怕要倾覆。</strong></p>\n<p>从上面的解释就可以推出这么一个结论：如果天地不按照道的原则来做事，那么就要崩裂；神灵如果不按照道的原则来做事，那么将不能称之为神灵，就会被灭绝。河谷如果不按照道的原则来做事，那么水将不会汇聚，就会干涸。万物不按照道的原则来做事，就会遭到杀戮和灭绝。侯王如果不按照道的原则来做事，国家将会一片混乱，他的高位也不可能得以保全。所以世间万物都需要学习道、效仿道。而我们想要生活幸福、安居乐业则更要把道的原则作为自己在社会中安身立命的根本原则。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-39-2","url":"/2020/08/08/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-39-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>故贵以贱为本，高以下为基。是以侯王自称孤、寡、不谷。此非以贱为本耶？非乎？故致数誉无誉。不欲琭琭如玉，珞珞如石。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在第三十九章上半节中，老子讲了道的重要性。“天得一以清；地得一以宁；神得一以灵；谷得一以盈；万物得一以生；侯王得一以为天下贞”。如果失去了道会怎么样呢？“天无以清，将恐裂；地无以宁，将恐发；神无以灵，将恐歇；谷无以盈，将恐竭；万物无以生，将恐灭；侯王无以贵高将恐蹶”。这些都是老子观察到的现象，那么透过这些现象，老子又能得出什么结论呢？接下来的后半章内容，老子给出了他的一些看法。我们一起来学习一下吧～</p>\n<p><strong>所以贵以贱为根本，高以下为基础，因此侯王们自称为“孤”、“寡”、“不谷”，这不就是以贱为根本吗？不是吗？所以最高的荣誉无须赞美称誉。不要求琭琭晶莹像宝玉，而宁愿珞珞坚硬像山石。</strong></p>\n<p>“道”是什么？道是知雄守雌，知白守黑，知荣守辱；道是不自见，不自彰，不自伐，不自矜；道是善利万物而不争；道是把自己位置放低，生而不有为而不恃。所有的这一切都告诉我们，要保持一颗平常心、宽容心、仁慈心。这也告诉了我们世界的本质，万物其实本无分别，高下美丑、善恶荣辱，只不过是人们心中的分别心在现实世界的映射。“一”代表的就是物我两忘、心无杂念的一种境界。没有了分别心，也就不会有争夺得失，从而也就没有了烦恼和痛苦。这时候，人生就达到了无欲无求的大圆满境界，这就是个人与大道的和谐统一。</p>\n<p>高贵者如果自视高贵，忘记自己的根基，那么将是十分危险的。因为贵贱都是相对的，贵是以贱为根本的，高是以下为基础的。没有人民群众，那么高贵也将不复存在。如果我们喜欢看古装剧都知道以前的侯王都喜欢自称孤家寡人，孤和寡都是非常凄惨的，为什么这些高高在上的侯王要这么自己称呼自己呢？其实这是一种自我告诫，时刻警醒自己不要让自己脱离群众，要不然自己就真的是孤家寡人了。</p>\n<p>《庄子·逍遥游》里有句话我特别喜欢：“至人无己，神人无功，圣人无名。”至人忘掉自己，毫无私心；神人没有有意的作为，无意求功于世间；圣人再无形名的区分，与万物化而为一。至人、神人、圣人都是修养极高的人物，他们无一不是无我利他，心与道合。他们奉献了一切，却并不彰显自我。他们不觉得自己付出了，也没有让被帮助的人心中觉得亏欠。所以最高的赞誉就是没有赞誉。相反，充满外在赞誉的人，境界上反倒差了一筹。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-38","url":"/2020/08/03/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-38/","content":"<p><strong>原文：</strong></p>\n<p><strong>上德不德，是以有德；下德不失德，是以无德。上德无为而无以为；下德为之而有以为。上仁为之而无以为；上义为之而有以为。上礼为之而莫之应，则攘臂而扔之。故失道而后德，失德而后仁，失仁而后义，失义而后礼。夫礼者，忠信之薄，而乱之首。前识者，道之华，而愚之始。是以大丈夫处其厚，不居其薄；处其实，不居其华。故去彼取此。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十七章中老子再次提出了他的无为而治的思想。最上乘的管理就像道一样应当是无为而无不为，制定好了规则之后，剩下的就是让一切自然运转，不强加干涉。当一些不好的现象出现的时候，这个制定好的规则给人们以适当的引导和规范，从而让秩序保持的井然有序。接下来我们一起学习第三十八章，看看老子又教给我们什么样的人生智慧吧～</p>\n<p><strong>具备“上德”的人不表现为外在的有德，因此实际上是有“德”；具备“下德”的人表现为外在的不离失“德”，因此实际是没有“德”的。“上德”之人无所施为，并且不故意表现他的“德”，“下德”之人有所施为，并故意表现他的“德”。</strong></p>\n<p>这里讲了什么是德、仁、义、礼，并且告诉我们同样的“德”也有高下的境界之分。真正的有上德的人是有德但不表现的有德。具有这种德行的人不用道德说教来教化他人，他们因循自然规律，行不言之教，处无为之事。他们的德行不表现在嘴上，而是以身作则，养人性命，默默奉献而不求回报。而有下德的人刚好相反，这类人把德行表现出来，喜欢用道德说教和政令法规来教化他人，处处彰显自己不失德，而这种表现恰好是没有真正的德行的表现。</p>\n<p><strong>“上仁”之人有所表现，但非故意表现他的“仁”。“上义”之人有所表现，并故意表现他的“义”。“上礼”之人要有所作为却没有回应他，于是就伸出胳膊强引别人来响应。</strong></p>\n<p>“上仁”是指践行仁的人。仁者爱人，而上仁之人更是对他人处处施以恩仁。这种人的境界和水平也是非常高的，但跟上德之人相比，境界却是略输一筹。因为他们虽然处处施以恩仁，内心充满了真善美，所行善事也别无他求，但却是着了痕迹。</p>\n<p>“上义”是指践行义的人。义的繁体字是“義”，说文解字中解释为：“己之威仪也。从我、羊。”所以跟仁相比，义更偏重自我的威仪，而仁更偏重于对待他人的态度。上义之人跟上仁之人相比，境界又要差了一筹，这种人会注重自己威仪，为人处事处处无不考虑是否合宜。但总的来说，这种境界也是比较好的境界，我们身边的一般人也没有几个可以达到这种境界。</p>\n<p>“上礼”是指践行礼仪的人。这种人的境界跟“上义”之人又差了一筹，他们只注重了外在表现的“礼”的形式，而形式中包含的内核“义”都已经被抛弃了。老子在这里举了一个特别生动的例子，说是这样的人到处呼喊却很少有人来响应，所以他们就伸出胳膊强拉着他人来响应。礼应当是从内到外，发自内心的一种表现形式。比如古代磕头是想表达对一个人的最高程度的感激和敬意，但如果这种形式沦为身处高位者对低位者人格的践踏，这种礼还有存在的必要吗？</p>\n<p>另外，德有上下，为什么仁、义、礼却没有上下呢？因为下德在仁义之间，而仁义以下的境界老子认为是不足为道的。</p>\n<p><strong>所以，失去了“道”而后才有“德”，失去了“德”而后才有“仁”，失去了“仁”而后才有“义”，失去了“义”而后才有“礼”。“礼”这个东西，是忠信不足的产物，而且是祸乱的开端。</strong></p>\n<p>上文中提到了德、仁、义、礼之间的关系，那么我们就可以得出一个结论：失去了“道”而后才有“德”，失去了“德”而后才有“仁”，失去了“仁”而后才有“义”，失去了“义”而后才有“礼”。“礼”的盛行和出现正是因为道、德、仁、义的缺失，是人与人之间失去基本的信任和仁爱之后的产物。“礼”的盛行和出现，已经代表了人心散乱，而人心散乱必然将是祸乱的开端。</p>\n<p><strong>所谓“先知”，不过是“道”的虚华，由此愚昧开始产生。所以大丈夫立身敦厚，不居于浇薄；存心朴实，不居于虚华。所以要舍弃浇薄虚华而采取朴实敦厚。</strong></p>\n<p>圣人玄览万物，是非得失都尽收眼底，怎么会有前识、后识之分呢？这是因为世人视止于目，听止于耳，思止于心，妄图用智力来求的知识，偶有所见，就自以为明，而不知道这其实是愚昧的开始。</p>\n<p>老子经常说“大智若愚”、“大音希声”、“大方无隅”、“大象无形”，也是在告诉我们人类的认识是有局限性的。我们普通人所赏识的有智慧、为人善良、懂礼节等等的一些优点，可能从某一个更高的角度来看其实是一种非常肤浅的停留在表面的一种表现。可能这些小智、小仁、小义正是束缚住我们的内心，让我们不能接近于道，不能获得终极智慧的最大的阻碍。</p>\n<p>所以大丈夫立身处世应当“处其厚，不居其薄；处其实，不居其华”。“厚”和“实”就是落实到实处的东西，“薄”和“华”就是外在的一些浮光掠影。比如社会交往中，“厚”和“实”就是为人处事无我利他，人与人之间发自内心的仁义和信任；“薄”和“华”就是人与人之间貌似彬彬有礼，有仁有义，但真正的却是人心隔肚皮，皮笑肉不笑的交情。再比如我们求学，“厚”和“实”就是要实实在在的在学习中学到东西，提高自我；而“薄”和“华”就是打着学习的名义，而目的却只是镀一层金或者拿到一个证。对于现代的中国社会，这几句话显得尤为令人警醒。因为在社会中，到处都充斥着浮躁、虚荣和短视，人们太看重形式而忽略内在，太看重结果而忽略过程。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-35","url":"/2020/07/28/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-35/","content":"<p><strong>原文：</strong></p>\n<p><strong>执大象，天下往。往而不害，安平太。乐与饵，过客止。道之出口，淡乎其无味，视之不足见，听之不足闻，用之不足既。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十四章中老子再次指出了道的生而不有、为而不恃的特点，正因为如此所以道才能海纳百川、万物归附。我们治国齐家修身都要学习道的这种无我利他的精神，只有这样我们才能在各个方面真正有所成就。接下来我们一起来学习《道德经》的第三十五章，看看老子又讲了什么样的人生哲理吧～</p>\n<p><strong>谁掌握了那伟大的“道”，则天下万民归附，心向往之，万民归往而不伤害，则国家安宁而致太平。</strong></p>\n<p>接着第三十四章，继续讲道的功用无穷。有道之人，天下万民归附，而民心者便可得天下。三国时期的刘备就深深懂得这个道理。在被曹操五路大军追杀之时，刘备却要带着十万老百姓一起逃亡，身边的文臣武将莫不劝他放弃百姓，轻车快马迅速逃亡，否则必将被曹操所擒。可是刘备不为所动，扶老携幼，终于带领百姓逃到安全地带。这件事为刘备真正赢得了民心，也赢得了以后三分天下的基础。</p>\n<p>在万民归附之后，也不要放松警惕。要常保慈悲之心、平等之心。对于归附的百姓，要做到不伤害他们。历史上很多帝王依靠穷苦老百姓打下天下，可是一朝做了王侯将相，就把当年豁出性命跟他们一起打天下的百姓忘到了脑后。从而继续重复前朝旧事，灭亡又将是迟早的事情。公司管理中也是如此，很多老板在招聘员工的时候，急需人才，什么条件都敢答应，许诺的特别好。可是等一切工作都走向正轨，员工不再被急需的时候，老板就换了一副嘴脸，之前答应的条件也都大打折扣。还有很多小伙子，在追求心爱的姑娘的时候，上刀山下火海都愿意，可是真追到手了，就不知道珍惜了。所以，人心永远是一个动态的过程，心怀他人，付出真心，人心自然汇聚。抬高自己，自私自利，人心自然消散。</p>\n<p><strong>音乐和美好的食物，使过路的人都为之停步。用言语来表述大道，是平淡而无味儿的，看它，看也看不见，听它，听也听不见，而它的作用，却是无穷无尽的，无限制的。</strong></p>\n<p>道不像美好的音乐和食物，他们可以发出美好的音声，散发出诱人的香味，让过路之人都为之流连忘返。道是平淡无奇的，看不到、摸不到，也听不到。第一眼看过去一点也不吸引人，但如果真正了解它的无穷的用处，就会深深被它的魅力所折服。就像上一章提到的“大道泛兮，其可左右”，道几乎是无所不包、无所不能。用来治国，则国家安定；用来治家，则家庭和乐；用来修身，则精神饱满、心安体健。所以我们学道修身就应当像一日三餐一般应当融入我们的生活当中，一举一动都应该效仿天道。假以时日，必将有所成就。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-4","url":"/2020/06/04/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-4/","content":"<p><strong>原文：</strong></p>\n<p><strong>道冲而用之或不盈，渊兮似万物之宗。挫其锐，解其纷，和其光，同其尘。湛兮似或存。吾不知谁之子，象帝之先。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前文讲了自然界本质并无无美丑善恶，都是相生相克的道理，然后接着讲了这样的道理体现在修身齐家治国中应该怎么运用。这一章笔锋一转，又开始讲起了自然中道是什么样子的。</p>\n<p><strong>道是不可见的虚无之体，虽空虚无形，但它的作用却无穷无尽，道的渊深不可估量，好像是万物的宗祖。</strong></p>\n<p>这一句讲了道是什么样子的，它不可琢磨但又意味深远功用无穷。“冲”是理解这一句的关键所在，在河上公的注解中解释为：“冲，中也。道匿名藏誉，其用在中”。“冲”是虚无而没有形状的状态。“冲”字是“水”加“中”字，所以冲是要剧中守中，在万事万物之中平衡之中。道虽然没有具体形状，摸不到看不到，但却功用无穷，一切事物中都包含了道。道同时又是深远的不可估量，没有人可以说自己完全掌握了道，道的体现在生活中无处不在，小到微尘颗粒，大到宇宙荒洪，处处都有道在起作用。因为万事万物都有道的影子，所以老子就说这个道可能就是世界的本源，孕育了一切世间万物，是万物的宗祖。</p>\n<p><strong>挫掉锐气，解开纠纷，与众人和光同尘。</strong></p>\n<p>同样的这句话在后面的第五十六章中也出现过：“知者不言，言者不知。塞其兑，闭其门，挫其锐，解其纷，和其光，同其尘，是谓玄同。” 有一种说法认为这句话应该是被误抄到了第四章，因为根据行文来分析，放到第五十六章会更加顺畅。但我觉得，其实放到这里也是可以解释通的，后面的再次重复是对这个观点的再次强调。</p>\n<p>锐，可以理解为尖锐的东西。另外还包含了一切有尖锐特性的品格，比如锐意进取功名的那种状态。我们观察自然就可以发现，凡是锋利冒尖的东西都会被自然给打磨光滑，失去锋芒。比如河中的石头，在河水的冲刷下，都会变成鹅卵型的。还有森林中冒尖的树木，都会首先被雷电击到，或者被风刮倒。所以这里就告诉了我们道的一个特质，挫掉尖锐的东西。</p>\n<p>纷，河上公解释为结恨。但个人认为“纷”还有更广的含义，应该包含了世间一切纷繁复杂的事物。从“纷”这个源头说起，左边“糸”指线丝。“分”意为“一分为二”、“由一而多”。 “糸”与“分”联合起来表示“绳线由一股变成多股，由一根变成多根，由一头变成多头。同样的观察自然，我们可以看到留长头发的人系的辫子，在平时的活动中，它们自己会慢慢松散开。还有以前人们挫的麻绳，时间久了也会断开变成一股一股的。所以这里其实是在告诉我们道的另一个特质，善于化繁为简，善于解开纷繁复杂的局面。</p>\n<p>和光同尘，我估计老子也是同样由观察自然界总结得出的道理。太耀眼的明珠，自然的冲刷会让它暗淡下来；太干净的地方，自然会给它蒙上一层灰尘。</p>\n<p>这几句话告诉了我们自然界中道的几种特质。道不喜欢太尖锐、太复杂、并且太过突出的东西。其实人世间何尝又不是如此？在社会中历练过一段时间的年轻人一般都会迅速收敛锋芒，变得圆润无碍。如果太过于个性化，就不太容易融入周围的世界，会被大家所排挤。这里也不是说鼓励我们变得圆滑世故。圆润无碍跟圆滑世故完全不同，圆润无碍是一种能与大家和谐相处的智慧，但圆滑世故是与社会同流合污，失去了自我。做人应该像铜钱一样，外圆而内方。心中方正，有自己的原则和认知，但并不与他人争辩，与众人合流但不同污。老子后面也提到“大方无隅，大智不割”。讲的就是大的方正是没有棱角的，大的智慧是不让人觉得难受的。</p>\n<p><strong>道清晰明了、湛然安静，但好像存在又仿佛不存在。我不知道它产生于何处，似乎在天帝出现之前它就存在了。</strong></p>\n<p>道好像清楚明白、安安静静地一直在那里摆着，可是钻研进去，却好像又什么也发现不了，说不出道不明，只可意会不可言传。看到这里，我就觉得对“道”的描述，先贤圣哲都是如此惊人的一致。《金刚经》中讲到如来是这样讲的：“如来者，无所从来亦无所去”。好像来了，又好像没有来，既不曾来，那又何谈去。</p>\n<p>道的存在似乎是永恒的，在天地之前就出现了。从古到今，从人到物，从地球到外太空，道似乎支配着一切，又孕育了一切。我想人类所有文化中的造物主都是指这个不可描述的“道”吧，只不过“道”又太虚无，所以在某些文化中被赋予了实体。</p>\n<hr>\n<p>总结一下，这一章讲了道的几个特质：1）道虚无不可见，但却无处不在、功用无穷；2）尖锐、复杂的事物会被道磨平、简化；3）道亘古长存，似乎是一切的本源，孕育一切、包含一切。</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-40","url":"/2020/08/09/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-40/","content":"<p><strong>原文：</strong></p>\n<p><strong>反者道之动；弱者道之用。天下万物生于有，有生于无。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第三十九章中老子讲述了得道的重要性。得“一”便可天清地宁、国泰民安，失去“一‘便会天崩地裂、国无宁日。这个“一”我们可以理解为道之子，或者道的核心。其中“一”最重要的一个体现就是没有分别心、私心和妄念。这一条对于管理和修身来说非常重要。比如将军如果没有私心，能够在战火中身先士卒，士兵们则都愿意赴汤蹈火，死不旋踵。接下来我们继续学习第四十章，看看老子又教给我们什么样的人生智慧吧～</p>\n<p><strong>循环往复的运动变化，是道的运动，道的作用是微妙、柔弱的。天下的万物产生于看得见的有形质，有形质又产生于不可见的无形质。</strong></p>\n<p>这一章非常简短，但这短短的21个字却道尽了天地间各股力量互动及成长的现象。就像四季的冬夏轮回，人的生老病死，月的阴晴圆缺，世间一切都是在循环往复的变化和运动。《易经》中否卦是非常不好的卦相，天地不交是为否。天地不交，则云雨不施，云雨不施，则万物不长。但否卦之后却是非常好的泰卦，天地交和是为泰。天地交合，则天降甘霖，天降甘霖则万物生长。非常有意思的是这两个卦相是连在一起的，所以才有了我们平时所说的“否极泰来”的成语。逆境达到极点，就会向顺境转化。同样的，寒冬中孕育着酷暑，死亡中包含着新生，圆满之中也包含着缺憾。所以老子提倡“曲则全，枉则直，洼则盈，敝则新”，指出“贵以贱为本，高以下为基”。</p>\n<p>人们都想追求富有、强大、高贵、圆满，那么怎么才能拥有和保持住这些呢？老子认为守弱、居下是秘诀。世界是平衡的，想要保持住荣，就得守得住辱；想要保持在高位，就要懂得谦卑；想要保持强大，就得懂得示弱。柔弱者所以能胜刚强，在于弱者较容易“存活”下去，显现柔弱面，使其更易于保存生机，这也便是所谓“柔弱生之徒，刚强死之徒”的道理。学会守弱是一种大智慧。乔布斯就是一个懂得“守弱”智慧的人，他有一句名言“stay hungry stay foolish（保持饥饿和愚蠢）”，就是在时刻提醒自己不要自大和自满。他的不断的找出自己的弱点，不断的谦卑的学习和进步，让他建立了苹果这种伟大的公司。曾国藩为了时刻提醒自己保持谦虚，他把自己的书房命名为“求缺宅”。在努力的寻找自己的缺点并不断改进中，他保持了圆满，被誉为近代第一完人。</p>\n<p>一个害怕失败的人，永远不可能有成功的时候。在失败中不断尝试，不断改进才有可能找到那个成功的点。相反，不去尝试，不去摔跤，就只能把自己的生活圈子过的越来越小。看起来好走的路，一定会是越走越窄。相反，看起来不好走的路，往往越走越宽。因为那条不好走的路，本来就是唯一的坦途。“大道甚夷而民好径”，人们都在寻找快速致富、快速成名的各种方法，但世界上哪里有捷径。所谓的捷径都是某些别有用心的人用来收割智商税的手段。“九层之台，起于累土；合抱之木，生于毫末“，一步一个脚印的积累，才是最正确最快捷的打开成功的方式。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-42","url":"/2020/08/17/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-42/","content":"<p><strong>原文：</strong></p>\n<p><strong>道生一，一生二，二生三，三生万物。万物负阴而抱阳，冲气以为和。人之所恶，唯孤、寡、不谷，而王公以为称。故物或损之而益，或益之而损。人之所教，我亦教之。强梁者不得其死，吾将以为教父。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>不知不觉《道德经》的学习已经过半，自己在讲解过程中学习收获了很多。跟着我一起学习的朋友，一定也有了很多收获。相信在学习完全文八十一章之后，你一定会对周围的世界产生一个全新的认知。首先回忆一下上一讲中的内容，在第四十一章中，老子主要讲了人都有认知的局限性。超出人们感官认知范围的东西往往不容易被人们所理解，所以会看起来行道之人似乎愚钝顽痴。但要知道不笑不足以为道，我们不要被外界的声音所干扰，要坚持自己的原则，知行合一来践行真理，必然会成就不一样的人生。接下来我们继续学习第四十二章，看看老子又教给我们什么样的人生哲理吧～</p>\n<p><strong>道生一，一生二，二生三，三生万物。万物背阴而向阳，并且在阴阳二气的互相激荡而成新的和谐体。</strong></p>\n<p>道的本体生出的是“一”，这个“一”就是我们物质世界的本源，所有的东西都是由这个“一”来组成。现代科学已经告诉我们，无论是无生命的山和水，还是有生命的动植物，基本组成的物质都是相同的，他们都是由基本的颗粒以不同的排列组合方式而形成的。人其实并没有什么特殊，只不过组织形式更为复杂一些，大脑也相比于其他动物发达一些。</p>\n<p>“一”又变化出了“二”，这个“二”就是将事物进行了二元分割，从而有了高下美丑大小之分。整个世界可以分为有生命的和无生命的，这就是一种二元分割。有生命的世界又可以分为动物和植物，这又是一种二分。具体到人，又可以分为男人和女人，可以分为有钱人和穷人等等。</p>\n<p>有了“二”就有了变化的转化的可能性，从而就又生出了“三”，这个“三”就是前面说的“二”的变化和融合。比如男人和女人可以生出小孩，这个小孩就兼有男人和女人身上的特点，并且每次融合都会有所不同。</p>\n<p>“三”再进一步的融合和衍化，就生出了万事万物。就像世间所有生命都是由那最开始的草履虫发展而来。说到底，我们跟猴子恐龙都有共同的祖先。亿万年来，有些物种灭绝了，而另一些物种又在形成。所以可能未来人类这个物种还会再次衍化分裂，形成不同的物种。无时无刻的变化，是我们这个世界的本质规律。</p>\n<p>阴和阳就是事物的两面性，我们任何人身上都有阴的一面，也有阳的一面。阴和阳都是实物的两个极端，都不可长久，所以需要冲气以为和。中国人最讲究中和和，所以故宫中最重要的三座大殿就是以太和、中和、保和来命名。和意味着万物交泰，意味着有生机。月球等没有大气的星球为什么不适合生命居住呢？就是因为被太阳晒到的地方太过炎热，而没有被太阳照到的地方又太过寒冷，没有大气来进行中和。地球正是因为有大气和海洋，所以冷和热都不会太过，昼夜温差就不会太大，从而适合生命居住。</p>\n<p><strong>人们最厌恶的就是“孤”、“寡”、“不谷”，但王公却用这些字来称呼自己。所以一切事物，如果减损它却反而得到增加；如果增加它却反而得到减损。别人这样教导我，我也这样去教导别人。强梁的人死无其所。我把这句话当作施教的宗旨。</strong></p>\n<p>所以万事万物都是在相互转化，追求平衡的。阴多了就要增加阳，阳多了就要加一些阴，这样才能保持平衡。王公贵族永远都有一大批人服侍，并且从来不愁衣食，但他们却以“孤”、“寡”、“不谷”来作为自己的称谓，这也是一种平衡和中和的智慧。</p>\n<p>刻意的减少一些自己的利益，反而能够获得更多的利益。如果刻意增加自己的利益，最终反而是损害了自己的利益。一个朋友在Costco买了一部苹果手表，结果不知什么原因，最终没有收到。朋友在联系Costco之后，他们也没有做很多调查，就给返还了现金。在这件事情上，Costco似乎是亏掉了一些钱，但是我们听说这件事之后，都更加相信了Costco的售后品质，我们反而花了更多的钱在他们身上。</p>\n<p>“Stay hungry. Stay Foolish”，保持饥饿和愚蠢，会让自己更加的充满进取精神和充满智慧。我们要时刻提醒自己，自满和骄傲只能让自己走向平庸。固执的相信自己的强大和崇拜绝对的力量，最终都不会有好的结果。老子认为最强大的力量是守弱，是柔中带刚，是在无数个困难和挫折面前站起来的坚韧。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-41-2","url":"/2020/08/13/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-41-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>故建言有之：明道若昧；进道若退；夷道若纇；上德若谷；太白若辱；广德若不足；建德若偷。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四十一章第一部分老子讲了三种不同的人听到真理（道）之后的不同反应：“上士闻道，勤而行之；中士闻道，若存若亡；下士闻道，大笑之。”接下来我们继续学习《道德经》第四十一章的第二部分，看看老子又教给我们什么样的人生智慧吧～</p>\n<p><strong>因此古时立言的人说过这样的话：光明的道好似暗昧；前进的道好似后退；平坦的道好似崎岖；崇高的德好似峡谷；洁白的东西反而含有污垢；广大的德好像不足；建设德行的人好似偷惰。</strong></p>\n<p>老子是当时周朝国家图书档案馆的馆长，因此在那个书籍并不常见的年代，他有机会接触到了很多更加远古的典籍文献。老子的智慧不是生而有之，也是站在巨人的肩膀上得来的。他博览群书、善于思考，因此他的智慧才得以穿越时空，给我们留下了简洁明了而又充满智慧的《道德经》一书。其实，在更加久远的古代，人们就发现了人类自身认知的局限性，并且总结和发现了一些不断应验的真理。</p>\n<p>最有智慧的真理，看起来总是模糊不清，仿佛隔着一层窗户纸没有捅破。如果看过孔子、老子、释迦摩尼、耶稣的语录或者著作，我们就会发现这些人类历史上最有智慧的人说出来的话，总有一股禅的韵味，可以让人反复琢磨和思考，却又不直接给人道破。不是他们不想讲清楚，而是真理就是模糊不清的，不是可以明明白白讲清楚的。科学是现代人类文明的基础，我们会觉得，科学可以用非常明白的方式来告诉人们真理。可是事实却不是这个样子的，科学正是在不断的推翻前人认为的真理的基础上发展起来的。当牛顿发现了三大定律的时候，我们以为人类已经掌握了物理世界的真理。可是量子力学的发现却证明了牛顿力学只适用于宏观物体，微观物体必须用更加复杂的模型来进行计算。当哥白尼通过观测发现太阳是宇宙的中心的时候，我们以为我们终于了解了宇宙。可是当我们有了更先进的观测仪器的时候，我们才发现太阳远不是宇宙的中心。我们对科学了解的越多，就会越发现他的局限性，我们总结出来的公式、定理，总有他适用的地方，可又会找到他不适用的例子。科学的不断发展正是在不断的修正我们的现有认知，让我们挖得更深，更加接近于真相。但人类永远不可能了解全部的真相，我们只能无限接近于它。</p>\n<p>往前走的路，看起来又仿佛像是在往后走。最容易走的路坦途，总是看起来好像有些崎岖不平。世界的发展规律就像我们看到的股票价格波动一样，是在波动中前进的。每一次的混乱和低迷都是在酝酿着新的秩序和繁荣。比如当一个人决定打破现有的生活状态，准备创业的时候，必然要经历一个开创期。这时候可能不但不赚钱，还需要使劲往里面砸钱。这时候的生活状态可能还不如安心当一个小职员过的舒服，然后大部分人就会觉得没有希望放弃了。但殊不知，这就是事情发展的必然规律，可能再坚持一下，就能熬过黎明前的黑暗，迎来自己的曙光。刘备四十多岁的时候，依然只能寄人篱下，甚至都没有一块真正属于自己的地盘。他失败了一次又一次，奋斗了二十多年，也漂泊了二十多年，可是梦想离自己还是很遥远。但他最让人佩服的地方就是，他没有放弃，心中的理想没有动摇。是幸运也是必然，他遇到奇才诸葛亮，开始有了自己的地盘，最终开创了自己的帝国。学习的过程哪有不摔跤的，摔的跤越多，我们就会变得愈加强大。</p>\n<p>崇高的美德好似峡谷。有崇高美德的贤能之士，总是虚怀若谷，把自己放得很低，放佛一点都不耀眼。我在参加一些国际学术会议的时候，就发现那些真正的学术界大佬们，穿着打扮都很随意，表现的也都非常谦卑。而往往光彩照人、不可一世的都是刚有些小名气的年轻教授们。</p>\n<p>洁白的东西反而含有污垢，广大的德行好像有不足。这里可以用一个故事来举例说明，老和尚携小和尚游方，途遇一条河；见一女子正想过河，却又不敢过。老和尚便主动背该女子趟过了河，然后放下女子，与小和尚继续赶路。小和尚不禁一路嘀咕：师父怎么了？竟敢背一女子过河？一路走，一路想，最后终于忍不住了，说：师父，你犯戒了？怎么背了女人？老和尚叹道：我早已放下，你却还放不下！这个故事中，老和尚看起来好像德行不足，但却是内心非常善良和单纯。</p>\n<p>真正在搞建设的人，别人不一定能够看到，就好似在偷惰一样。第一层意思是说，看起来整天在忙碌的人不一定在做事，真正在做事的人看起来不一定有多忙。这里就想到我一个朋友的故事。朋友博士毕业之后进入一家国有研究所，入职之后领导就分配给他一项研发任务。这个朋友每天就坐在电脑前较劲脑汁查文献和思考原理。结果领导却以为他在偷懒，就跟他说你得多去去试验现场，不要每天玩电脑。还有很多公司有加班文化，领导以为大家多加班，就能多处一些成果。可是真正有创造性的工作不是表面可以看出来的，而是需要不断学习，不断思考。很多人的表面的忙碌，往往是为了掩盖他的懒惰。这句话的另一层意思是说，积善行德的事情也需要偷偷来做。帮助人而不求名利，不求回报，才是真正的德行。那些去基层慰问了一下群众，就找来媒体大张旗鼓的报道的，都是假德行。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-41-3","url":"/2020/08/15/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-41-3/","content":"<p><strong>原文：</strong></p>\n<p><strong>质真若渝；大方无隅；大器晚成；大音希声；大象无形；道隐无名。夫唯道，善贷且成。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一讲我们讲了“明道若昧；进道若退；夷道若纇；上德若谷；太白若辱；广德若不足；建德若偷”的道理。接下来我们继续讲解第四十一章的最后一部分，看看老子又带给我们什么样的人生智慧吧～</p>\n<p><strong>最质朴真实的东西，仿佛没那么真实；最方正的东西，反而没有棱角；</strong>最优秀的器皿，反而需要长时间的锤炼；<strong>最大的声响，反而听来无声无息；最大的形象，反而没有形状。道幽隐而没有名称，无名无声。只有“道”，才能使万物善始善终。</strong></p>\n<p>渝是本意是改变违背的意思，这里也有人解释为假的意思。最质朴真实的东西，看起来好像没那么真实。比如，我们身边有一些真正的好人，他们心地特别善良，处处帮助他人。但在不了解他的人看来，会不禁胡思乱想这个人是不是别有用心，这个人是不是装出来的。</p>\n<p>最方正的东西，反而没有棱角。如果画一个小的方形，我们可以直接看到他的棱角。可是如果把这个方形无限扩大呢？扩大到地球那么大或者太阳系那么大，我们还能看到这个方形的棱角吗？我们就不会看到条条框框了，我们感受到的只是无尽的包容。这条法则同样适用于人，内心最方正的人，外表有时候看起来反而有几分圆滑。因为这些人为了可以做成有利于人民的事情，自己的一些名声反而没有那么在乎，因为他的方正太大，所以一般人也就看不到他为自己画的棱角和界限了。</p>\n<p>大器之才并非短期能够造就，需要数十年坚持不懈地修养锻炼。这就要再次提到刘邦和刘备了，他们都是到了四五十岁事业才开始有点起色。前面所受的各种挫折是成功路上必然的一些磨刀石，只有经过试炼，他们的心性才能够变得更加坚忍。承受常人所不能承受之辛苦，才能超出于常人。这就是我们现在的富二代官二代接班困难的原因。一代都是经受过时代洗礼的人，他们经历的各种困苦，让他们有着超出一般常人坚忍的心性，有着丰富的斗争经验。而正因为他们经历了很多苦难，所以他们不想自己的子女重新经历这些，从小给予了他们子女优越的物质生活条件。这些生长在蜜罐里的二代们，又怎么可能理解创业的艰难，又怎么能再现他们父辈的光荣呢？</p>\n<p>在一定条件下，人们的声音越大，我们就会越注意到这个人的观点。可是真正好的观点，不需要声音很大，也可以让人们折服。同样在一定条件下，产品的广告做的越显眼，我们就会越注意到这个产品。而真正好的产品，不需要刻意宣传，也能让人主动找上门来。还有在一定条件下，越是动听的音乐，越需要多种乐器的配合。可是真正动听的音乐，却是无声胜有声的自然之美。</p>\n<p>最大的形体，反而看不到他的形象。就像一些城市的地标建筑很是高大，我们可以看到他的形象，并且还会很显眼。但是大到一定程度，超出人们的认知范围，比如像地球一般的高大，我们反而就看不到它的具体形象了。盲人摸象的故事中，有人说大象像萝卜，有人说像柱子，有人说像蒲扇，还有人说像草绳。这就是因为大象超出了他们的感知范围，所以他们只能看到一部分。虽然我们一般人眼睛都是完好的，可以比盲人看到更加具体的一些形象。可是我们也有局限性，一旦超出我们的五官感受范围，我们就只能看到非常片面的一部分了。“朝菌不知晦朔，蟪蛄不知春秋。”地球乃至宇宙间的任何生物，都有其自身认知的局限性。即使人类掌握了科学这一认识世界的强有力的工具，但同样也有其局限性。比如因为科学强调客观和可重复性，这就导致科学无法研究主观和精神世界的东西。再比如，我们生活在三维世界中，是无论如何也不能理解更高维度的生命是什么样子的。</p>\n<p>道因为它太过于大，大到无所不包，所以我们只能看到非常小的一个方面。但我们不要以为这就是道，我们看到的永远只是道的一部分。所以说，道因为太大，所以反而变得隐而无名。但我们知道一点，道永远是善于给予万物并且辅助万物，凡事符合这一点的，都包含了道的影子。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-44","url":"/2020/08/22/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-44/","content":"<p><strong>原文：</strong></p>\n<p><strong>名与身孰亲？身与货孰多？得与亡孰病？是故甚爱必大费；多藏必厚亡。知足不辱，知止不殆，可以长久。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四十三章中，老子再次提起了守柔的智慧。无为而为实为无所不为，无言之教实为无所不教。接下来我们继续学习第四十四章，看看老子又教给我们什么样的人生智慧吧～</p>\n<p><strong>声名和生命相比哪一样更为亲切？生命和货利比起来哪一样更为贵重？获取和丢失相比，哪一个更有害？</strong></p>\n<p>这里老子连用三个问句：声名和生命相比哪一样更为亲切？生命和货利比起来哪一样更为贵重？获取和丢失相比，哪一个更有害？他没有直接给出我们答案，或许也根本没有正确答案。所以我们每个人都要自己问自己，到底什么对自己才是最重要的。如果自己认为生命更重要，那么为什么还要费尽心机要博得名声而不去认真享受生命呢？如果生命更加重要，为什么又要通宵加班和陪领导抽烟喝酒来伤害身体呢？还有，得到一些东西真的就会让自己更加幸福吗？</p>\n<p>名利也有其有利的一面，有了名望和地位就可以发挥更大的能量，也可以为社会做出更大的贡献。所以不是一点名利也不要追求，只是凡事要有度，过度的追求名利而忽视了一些其他生命中也很重要的东西就不值得了。这又是前面我反复提到的中庸之道，如果一个人生活中能够个方面获得平衡，那么这个人是有极大智慧的。</p>\n<p><strong>过分的爱一样东西就必定要付出很多代价；过于积敛财富，必定会遭致惨重的损失。所以说，懂得满足，就不会受到屈辱；懂得适可而止，就不会遇见危险；这样才可以保持住长久的平安。</strong> </p>\n<p>过度的喜爱一样东西，就必定要付出代价。太过于爱财，则会贪欲过甚，往往会遭受无妄之灾。太过于贪恋美色，则会大费精神，耽误事业。太过于珍惜名声，则会给自己划定太多限制，有失于洒脱。</p>\n<blockquote>\n<p>明熹宗时，外有金兵侵扰，内有明末起义，正是国难当头，内忧外患的时期。明熹宗却不务正业，不听先贤教诲去“祖法尧舜，宪章文武”，而是对木匠活有着浓厚的兴趣，整天与斧子、锯子、刨子打交道，只知道制作木器，盖小宫殿，将国家大事抛在脑后不顾，成了名副其实的“木匠皇帝”。</p>\n</blockquote>\n<p>有一些个人兴趣爱好是极好的，可以舒缓压力，颐养性情。但如果因为过于沉溺于此，则会辜负自己身上所担负的使命，对个人、家庭、甚至国家都有可能会造成巨大损失。</p>\n<blockquote>\n<p>还有和珅可以说是史上第一贪官，中国第一历史档案馆收藏了一本《和珅犯罪全案档》，其中记载和珅家产已估价的部分（金银、人参、绸缎、玉器库、当铺、古玩铺、田地等）价值为两亿多两白银。其中单单两座玉器库就估价白银七千万两，相当于乾隆时期全国岁入。</p>\n</blockquote>\n<p>一个人能够吃几两饭？能住几间房？家有黄金万两，食不过一日三餐；家有广厦千间，卧不过一榻之地。不懂得控制自己的欲望，就会给自己带来耻辱和祸患。我们的老祖宗几千年前就告诉我们“穷则独善其身，达则兼济天下”。穷富有时候不是我们所能左右的，但无论贫穷还是富裕，我们怎么为人处事确是我们可以决定的。在贫穷困苦之时，能够保持自己不丧失底线和尊严；在通达之时，能够做到不耽于享乐，心怀天下，就可以称得上是君子。挣钱多少能够体现一个人的能力，怎么花钱则能够体现一个人的修养。</p>\n<blockquote>\n<p>洛克菲勒一直认为上帝只是委托自己管理而非拥有财富。所以他将亿万财产几乎全部回馈社会，只留下2600万美元遗产。他相信上帝会赞同并褒扬这个出色的“管家”，所以去世前信心十足地与亨利·福特约定：“再见，咱们到天堂后再相会。”</p>\n</blockquote>\n<p>最后附上《红楼梦》中的《好了歌》，希望大家能够有所收获，找到属于自己的幸福。</p>\n<blockquote>\n<p>世人都晓神仙好，惟有功名忘不了！<br>古今将相在何方？荒冢一堆草没了。<br>世人都晓神仙好，只有金银忘不了！<br>终朝只恨聚无多，及到多时眼闭了。<br>世人都晓神仙好，只有姣妻忘不了！<br>君生日日说恩情，君死又随人去了。<br>世人都晓神仙好，只有儿孙忘不了！<br>痴心父母古来多，孝顺儿孙谁见了？</p>\n</blockquote>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-46","url":"/2020/08/26/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-46/","content":"<p><strong>原文：</strong></p>\n<p><strong>天下有道，却走马以粪。天下无道，戎马生于郊。祸莫大于不知足；咎莫大于欲得。故知足之足，常足矣。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四十五章中老子讲述了大成若缺，大盈若冲的道理。人类因为有其自身的局限性，往往不能看到事物的全貌。只有提高自身修养，认识到自身局限性，并且做到无私无欲、无我利他，方能突破自身限制，生出一些智慧。接下来我们继续学习第四十六章，看看老子又带给我们什么样的人生智慧吧～</p>\n<p><strong>治理天下合乎“道”，就可以作到太平安定，把战马退还到田间给农夫用来耕种。治理天下不合乎“道”，连怀胎的母马也要送上战场，在战场的郊外生下马驹子。</strong></p>\n<p>这里描述了两幅不同的场景：第一幅是战士解甲归田，战马回到农田用来耕种；第二幅是天下动荡不安，怀胎的母马也要被送上战场，只能在战场的郊外生产。这两种截然不同的场景完全取决于管理天下的领导者有没有按道来行事。如果治理天下合乎天道人心则国泰民安，如果治理天下逆天无道则兵荒马乱。下面举两则例子，来说明治理天下合乎道跟不合乎道的区别。</p>\n<p>第一则例子是“文景之治”：</p>\n<blockquote>\n<p>汉朝建立之初，经过数百年的动乱，国家百废待兴。朝廷推崇黄老之术，采取“轻徭薄赋”、“与民休息”的政策。同时，对周边敌对国家也不轻易出兵，维持和平，以免消耗国力。<br>汉文帝生活十分节俭，宫室内衣服没有增添，衣不曳地，车类也没有添，帷帐不施文绣，更下诏禁止郡国贡献奇珍异物。因此，国家的开支有所节制，贵族官僚不敢奢侈无度，从而减轻了人民的负担。<br>经过文景两朝的休养生息，生产日渐得到了恢复和发展，出现了多年未有的稳定富裕的景象。史称：「京师之钱累巨万，贯朽而不可校。太仓之粟陈陈相因，充溢露积于外，至腐败不可食。」人民的生活水平得到了很大程度的提升，同时汉王朝的物质基础大大增强，是中国历史上的第一个盛世。</p>\n</blockquote>\n<p>另一则例子是“国人暴动”：</p>\n<blockquote>\n<p>周厉王贪财好利，千方百计地搜刮人民。宠臣荣夷公教唆厉王对山林川泽的物产实行“专利”（国营垄断），由天子直接控制，不准平民（国人）进山林川泽谋生。周厉王听了很中意，置大臣的规劝和平民的反对于不顾，推行了“专利”政策。<br>平民被断了生路，怨声四起，纷纷咒骂。周厉王又派了一个佞臣卫巫监视百姓，将许多不满“专利”的平民捕来杀死。后来连不少没有发过怨言的平民也被杀死。厉王的高压政策，使得亲友熟人在路上遇到了都不敢互相招呼，只能以眼神示意（道路以目），使都城变得死气沉沉。周厉王却还自以为得计，得意洋洋地说：“我自有办法叫百姓不敢诽谤我。”大臣召穆公劝戒说：“这样堵住人民的嘴，就像堵住了一条河。河一旦决口，要造成灭顶之灾；人民的嘴被堵住了，带来的危害远甚于河水（防民之口甚于防川）。治水要采用疏导的办法，治民要让天下人畅所欲言，然后采纳其中好的建议。这样，天子处理国政就少差错了。”周厉王听了不以为然地说：“我是堂堂天子，那些无知的愚民只能遵从我的命令，怎么能让他们随便议论！”仍然一意孤行，实行暴政。<br>周厉王的暴政使得国人忍无可忍，前841年的一天，都城四郊的国人自发地集结起来，手持木棍、农具作武器，从四面八方扑向都城的王宫，要向周厉王讨还血债。周厉王听到由远而近的愤怒的呼喊声，忙命令调兵镇压。可是竟然没有士兵肯听从他的命令。臣下回答说：“我们周朝寓兵于农，所有的士兵出身都是农民，而且周朝的士兵也是由农民供养的。现在连农民都已经暴动了，您还能有谁可以被调集呢？”周厉王这才知道大祸临头，匆忙带着宫眷步行逃出都城，沿渭水朝东北方向日夜不停地逃到远离都城的彘，筑室居住了下来。</p>\n</blockquote>\n<p><strong>最大的祸害是不知足，最大的过失是贪得的欲望。知道到什么地步就该满足了的人，永远是满足的。</strong></p>\n<p>“国人暴动”的例子中，造成周厉王仓皇逃窜的最根本原因就是他的贪欲过盛。只顾满足自己，而忽略了他人。在他人有不满和反对意见的时候，试图采取高压政策来平息众怒，最后弄的反而自取其辱。而“文景之治”的例子中，文帝景帝不与民争利。自己的生活十分节俭，也懂得节制国家开支，用各种方式减轻人民负担。从而出现了前所未有的盛世。</p>\n<p>老子在第四十四章中也提到“**<em>知足不辱，知止不殆，可以长久</em>**”。这里再次提醒人们，尤其是当政领导者，要懂得克制自己的私欲，从而才可不辱、不殆。</p>\n<p>不但我们东方有这种智慧，西方同样有着类似的智慧。比如，叔本华有一句话我觉得说的特别好：</p>\n<blockquote>\n<p>幸福不过是欲望的暂时停止。——叔本华</p>\n</blockquote>\n<p>美国著名经济学家保罗萨缪尔森(PaulA.Samuelson)从经济学的角度给出了一个关于幸福的方程式:<strong>幸福&#x3D;效用&#x2F;欲望</strong>。这个公式说明，幸福程度与效用成正比，与欲望成反比。所以在效用一定时，欲望越小，人们感到越幸福，反之则不会感到幸福；在欲望一定的情况下，效用越大，人们感到越幸福，否则会感到痛苦。效用的增加需要依赖于很多外界因素，比如社会的经济状况，个人的机遇等等，往往具有不可控性。但我们的欲望却是我们自己可以主动控制的，所以增加幸福的最快捷的方式就是降低个人欲望。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-48","url":"/2020/09/02/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-48/","content":"<p><strong>原文：</strong></p>\n<p><strong>为学日益，为道日损。损之又损，以至于无为。无为而无不为。取天下常以无事，及其有事，不足以取天下。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四十七章中老子讲了“不出户知天下；不窥牖见天道。其出弥远，其知弥少”的道理。我们应当从外求转为内求，从而拥有真正的智慧，这样才能“不行而知，不见而名，不为而成”。第四十八章是第四十七章的延伸，这里继续再讲这个道理。让我们一起来学习吧～</p>\n<p><strong>求学的人，其情欲文饰一天比一天增加；求道的人，其情欲文饰则一天比一天减少。减少又减少，到最后以至于“无为”的境地。</strong></p>\n<p>我们日常所学都是在不断的增加知识，使我们的大脑中储存的信息量更加的丰富。而求道则不同，求道是不断的净化我们的心灵，使我们内心的私欲杂念越来越少。就像上一章说的“其出弥远，其知弥少”，我们越是外求，越是希望获得他人的尊重和认同，我们内心反而更加容易失衡。求道的最终境界是“少之又少，以至于无为”，内心无我人众生寿者的区别，无念想也无私欲。这样的人，做事情不再以自己得到多少而为行动标准，只想这件事应不应当做。这样的人不是以他人为中心，更不是以自己为中心，而是以亘古不变的原则为中心。</p>\n<p><strong>如果能够做到无为，任何事情都可以有所作为。治理国家的人，要经常以不骚扰人民为治国之本，如果经常以繁苛之政扰害民众，那就不足以治理国家了。</strong></p>\n<p>一旦做到了不以自己的主观意志而有所作为，就可以从一个更加客观的角度去看待事情，从而做出更为正确的有利于管理的决定。尤其是对于治理国家来说，领导起的作用是非常巨大的。往往一个重大决策就可以引导国家和人民走向完全不同的方向。如果秦始皇不焚书坑儒，如果立公子扶苏为二世，那么秦帝国的历史可能就会改写。但历史不可以假设，秦始皇也不会做出我们假设的这个决定，但我们可以从历史中吸取教训。汉朝建立之后，处处以秦为鉴。秦好苛政，汉则与民休养生息；秦焚书坑儒，汉则独尊儒术。在吸取秦的教训的基础上，汉朝社会一片繁荣，出现了有史以来第一个盛世，汉朝的国运也远远长于秦朝。</p>\n<p>一个好的制度，不是给人民戴上枷锁，而是解放人民的双手，激励人们更加勤勉的工作。天地已经给了我们最好的例子让我们来效仿，可是人们总是视而不见。天地大部分时间总是默不作声，默默付出和贡献，但如果环境破坏过度，就会引起一些自然灾害，从而给人们以警醒。我们的律法也应当如此，给人民以更大的活动空间，发挥出他们的创造力，只有在事情超出一定范围的时候，才要给予适当的纠正和警告，从而引导人们回到正路。</p>\n<p>“无事”的状态是每个人都没有私心杂念，活的充实而有意义，所有人都在朝着相同的目标在前进。这个状态是管理的最佳状态，取天下犹如探囊取物。“有事”的状态则是每个人都各怀心事，内心压抑且看不到希望，所有人都在努力挣脱目前的命运。这个状态的时候，说明管理非常糟糕，是不可能获得天下人的认同的。这里虽然是在说国家，但对于公司、家庭、个人的管理来说都是一样的道理。希望每个人都可以拥有“无为”的智慧，达到“无事”的状态吧～</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-43","url":"/2020/08/19/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-43/","content":"<p><strong>原文：</strong></p>\n<p><strong>天下之至柔，驰骋天下之至坚。无有入无间，吾是以知无为之有益。不言之教，无为之益，天下希及之。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四十二章讲述了万物的起源都是由道而来。万物负阴抱阳，冲气以为和。万事万物都趋向于平衡，追求阴阳平和的状态，所以损益都是相对的也是相互转化的。接下来我们继续学习第四十三章，看看老子又教给我们什么样的人生智慧吧～</p>\n<p><strong>天下最柔弱的东西，腾越穿行于最坚硬的东西中。无形的力量可以穿透没有间隙的东西，我因此认识到“无为”的益处。“不言”的教导，“无为”的益下，普天下少有能赶上它的了。</strong></p>\n<p>水可以说是我们最常见到的有形的柔弱的东西，但水却能在坚硬的岩石上刻划出一条条沟壑。如果有东西挡住了它的去路，它就会选择绕过去。如果筑一道堤坝，它则慢慢等待和积累，等到水涨满了，又从堤坝上满过去。还有空气也是非常柔弱的，人们甚至感受不到它的存在，但空气却无所不入，充满了整个空间。空气和水看似柔弱，但他们调和阴阳并为地球的一切生命的繁衍生长提供了保障。老子看到了这些自然现象，就得出了一个结论：无形的力量虽然看起来柔弱但却更为强大。</p>\n<p>“处无为之事，行不言之教”，虽然看起来和风细雨，润物无声，但却是普天之下最高等的管理智慧。无为不是不作为，不言不是不说话。无为和不言是指不妄为和不妄言。事必躬亲，处处彰显自己的能力，不如制定好清晰明了的规章制度，让一切自然运转，让所有人都从中受益。喋喋不休的说教，倒不如以身作则，给大家做一个表率。</p>\n<p>石油大王-洛克菲勒就是一个懂得这个道理的人。他在收购其他石油公司的时候，采取的策略往往不是硬碰硬的斗争，而是共赢的合作。尽量善意的同对方谈话，让对方了解自己是想实现双赢，甚至是让整个行业共同得利。如果对方充满敌意，他就采取迂回措施，从对手的朋友入手，让他们的朋友再来进行劝说和游说，从而降低对方的敌对心理。在这样的思想的指导下，他最终掌握了整个石油行业，在让整个石油行业获得巨大利益的同时，也成就了他世界首富的地位。</p>\n<hr>\n","categories":["哲学思考","道德经"]},{"title":"《道德经》-47","url":"/2020/08/30/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-47/","content":"<p><strong>原文：</strong></p>\n<p><strong>不出户知天下；不窥牖见天道。其出弥远，其知弥少。是以圣人不行而知，不见而名，不为而成。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四十六章中老子讲了按道行事跟不按道行事之间的区别，并且告诫人们最大的祸患都是来自于自身的欲望。想要获得真正长久的幸福就要学会控制欲望，懂得知足。接下来我们继续学习第四十七章，看看老子又带给我们什么样的人生智慧吧～</p>\n<p><strong>不出门户，就能够推知天下的事理；不望窗外，就可以认识天道。</strong></p>\n<p>我们现在对于获得知识的途径的比较流行的说法是要“读万卷书，行万里路”。而这里却刚好相反，圣人不用出门，就可以了解天下的事物；不用往窗外望，就能推知天道。这是因为宇宙万物都有其自身的发展规律，虽然形态万千，但却殊途同归。就像人类世界真正的新鲜事真不多，基本上我们身边每天发生的事情，在人类历史上都在一遍一遍的上演。读史可以使人明智，是因为历史都是人类历史上曾经真实发生过的事情。聪慧的人能从历史中吸取经验和教训，从而站在巨人的肩膀上，可以走的更远，看得更加深邃和明白。</p>\n<p>虽然世界各国都有不同的风土人情和地理文化，但人这种动物的本性都是一样的。无论哪种文化都喜欢真善美，都讨厌假丑恶。真理并不会因为人们相信什么或者不相信什么而会有所不同，历史上或许存在过不遵照世间这个唯一的真理来做事的人或者民族，或许他们甚至也曾繁荣兴盛过，但肯定也不过是昙花一现，最终还是会消失在历史的长河中。孔子总结与人交往的准则应当是“己所不欲，勿施于人”，这个准则不仅仅适应于中国古人，也同样适应于现代人，适应于不同的文化背景的外国人，如果延伸下去，甚至还同样适应于不同的物种。</p>\n<p>最近看了一部讲述十岁的小女孩和狐狸交朋友的故事的电影《狐狸与我》。故事情节大概是这样的：</p>\n<blockquote>\n<p>小女孩在上学路上碰见了一只正抓田鼠的狐狸。女孩被漂亮的狐狸迷住，下学后回到森林原地希望再见到那只狐狸。从秋天到冬天，女孩在厚雪地里沿着狐狸的脚印寻找，却失足摔断了腿，整个冬天只好在室内度过，读了很多关于狐狸的书。春天是猎狐的季节，为狐狸忧心忡忡的小女孩欣喜若狂的发现了狐狸的洞穴和它的三只小狐狸，却没想到狐狸嗅出人的气味，连夜转移了幼崽。女孩决定不去打扰狐狸，而是坐到山毛榉树上等它主动出现。就这样，经过一个夏天，在生疏、猜疑、熟稔、捉弄、闹别扭中，小狐狸渐渐靠近她，不再与她保持距离，并与她一同玩耍。但在获得狐狸的信任之后，小女孩给狐狸带上绳索，并且关进自己的房间，企图驯养狐狸。但狐狸在受到惊吓之后，选择了跳窗自杀。但信任一旦失去，却是很难再重新获得，从此他失去了狐狸这个朋友。很久之后，他才慢慢敞开心扉，并且反省自身的行为，明白了爱不是占有的道理。</p>\n</blockquote>\n<p>动物和人一样，都需要付出真心，对能获得对方真正的尊重和友谊。如果知道了这个基本的出发点，那么自然可以收获真正的友谊。</p>\n<p><strong>向外奔逐得越远，所知道的道理就越少。所以，有“道”的圣人不出行却能够推知事理，不窥见而能明了“天道”，不妄为而可以有所成就。</strong></p>\n<p>狡诈、计谋、机智或许可以给人带来一时想要的结果，但失去的却是他人的信任，这在长远看来是非常得不偿失的。大智若愚、大巧若拙，古人明白这个道理，到了文明的现代社会，很多人反而迷茫了。多少人只想着速成，坐着一夜暴富的美梦？多少人费尽心机，想要在智谋上胜过他人？《红楼梦》中的王熙凤，可以说是聪明人的代表。但她的结局却是“机关算尽太聪明，反误了卿卿性命”。</p>\n<p>所以老子提倡我们从外求转向内求，从钻营机巧转到修身养性。整日流连于外物他求，非常容易迷失自我，对于天道人心的感悟也会越来越少。致虚极守静笃，在安静中时常反省自身，参悟天道，则可以修得大智慧，看透世间的种种相。《金刚经》中说的“若菩萨有我相、人相、众生相、寿者相，即非菩萨。”也是在说不要被世间的种种相所迷惑。甚至如果执着于“法相”，即使念了再多经书，拜了再多菩萨，也是没有真正领悟佛法，也就不可能获得无上正等正觉的心。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-41-1","url":"/2020/08/11/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-41-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>上士闻道，勤而行之；中士闻道，若存若亡；下士闻道，大笑之。不笑不足以为道。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在上一章中老子讲了有无、强弱相互转化的道理。要做到持盈保泰，就得放空、放低自己。接下来我们继续学习《道德经》的第四十一章，看看老子又讲了哪些人生哲理～</p>\n<p><strong>上士听了道的理论，努力去实行；中士听了道的理论，将信将疑；下士听了道的理论，哈哈大笑。不被嘲笑，那就不足以成其为道了。</strong></p>\n<p>这几句话非常容易理解，描述了不同的人在听到真理之后的不同反应。最上等的人是有慧根的人，一听就能明白。他们没有否定再否定的过程，他们会非常笃定自己听到的就是真理，然后立刻就能把领悟到的真理应用到实践中。《三国演义》中有一段曹操和袁绍抢天子的故事。在接到天子要回东都洛阳消息的时候，曹操和袁绍手底下都有谋臣建议将天子接到自己的地盘，挟天子以令诸侯。当时袁绍的实力比曹操强大，势力范围也离天子更近。按理说袁绍应该更能夺得先机，但他却反复思量，拿不定主意。而曹操相反，一有谋臣提出这个建议，他立刻就接受了，然后快马加鞭把天子截了下来。在曹操迎接天子之后，挟天子以令诸侯，占据了道义制高点，从而人才纷纷汇聚，势力迅速壮大。</p>\n<p>大多数人并没有这种大智慧，基本上都属于第二类人，听到之后将信将疑，并不能立刻辨别是非。这其中有一些人，在经历过一些事情之后，或许会有所反思和感悟，从而慢慢领会到这些真理的含义。另一些不喜欢思考的人，可能在头破血流之后也不能想明白为什么，一生都活在混沌之中。</p>\n<p>第三类人属于慧根比较浅，跟道无缘的人。他们听到真理之后的反应是哈哈大笑，觉得说出这个道理，或者按照道德原则做事的人非常傻，非常可笑。但他们哪里能够明白大智若愚、大象无形的道理。这样的人有一个常见的特点，那就是他们目光非常短视，只能看得到眼前的利益。你告诉他们诚信经营、踏实积累才能走得长远，他们笑你傻，觉得这年头有快钱不挣，有油水不捞，肯定是脑子进水了。你告诉他们人活着要有更高的理想，要造福社会，帮助他人，他们笑你傻，觉得放着权情名利不去追求和享受，肯定是读书读傻了。</p>\n<p>面对第三类人的一些负面评价，老子告诉我们，不用疑惑，不用烦恼，这非常正常。因为“道之出口，淡乎其无味，视之不足见，听之不足闻”，道不像音乐和美食一样，可以让人立刻有感官上的刺激，让人立刻感到满足。但道却是“用之不足既”，道是一种无相无形，却功用无穷的东西。短期来看，感官刺激，会让人立刻有幸福感。长期来看，遵循道的原则做事，会让人受用无穷。就像我昨天提到的：“看起来好走的路，会越走越困难，而看起来不好走的路，却会越走越宽敞”。</p>\n<p>写到这里，我就想到，人生最重要的事情就是做决定。我们无时无刻都在做决定，比如晚上吃炸鸡还是青菜？周末休息去跑步锻炼还是在家打游戏？喝一杯可乐还是白开水？等等的各种决定。如果每天坚持锻炼，并且控制饮食，那么这个人肯定能收获健康的身体。如果每天吃炸鸡喝啤酒，并且经常窝在家打游戏，那么这个人过不了多久就会身材走样，精神萎靡。这是小的生活习惯的决定，还有稍微大一些的决定。比如是去离家远但却有发展的公司，还是在家找一个安稳但收入不高的工作？大学毕业是继续读书深造还是参加工作？这种决定我们就会发现，我们没有一个所谓的正确答案，这就要考虑到每个人身处的环境，个人状况和意愿来综合考量。如果担任一定的职位，就会需要做出影响跟多人的决定。比如国家是不要要提高税率？怎么处理国际关系？要不要进行改革？这些决定就更需要大的智慧。做出正确的决定，并不是一件谁都可以做到的事情。我们身在庐山，就会被眼前的各种幻象所迷惑。只有无私无欲，不被自己的情绪和得失心理牵着走，把思维跳出来，从更高的角度去审视，才有可能会做出正确的决定。而《道德经》就是一门教会我们拥有这种思维的学问。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经","老子"]},{"title":"《道德经》-50","url":"/2020/09/15/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-50/","content":"<p><strong>原文：</strong></p>\n<p><strong>出生入死。生之徒，十有三；死之徒，十有三；人之生，动之死地，亦十有三。夫何故？以其生生之厚。盖闻善摄生者，陆行不遇兕虎，入军不被甲兵；兕无所投其角，虎无所措其爪，兵无所容其刃。夫何故？以其无死地。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四十九章中老子讲了圣人无常心的道理。我们平常人都有自己的各种私心杂念，而圣人却抛却了个人私欲，以百姓心为心。一个人的心怀有多大，就能有多高的成就。圣人心怀天下，自然可以得天下民心。接下来我们继续学习第五十章，看看老子又讲了什么样的人生哲理吧～</p>\n<p><strong>人始出于世而生，最终入于地而死。属于长寿的人有十分之三；属于短命而亡的人有十分之三；人本来可以活得长久些，却自己走向死亡之路，也占十分之三。为什么会这样呢？因为奉养太过度了。</strong></p>\n<p>人从出生到死亡是一个自然规律，是谁都无法摆脱的规律。无论贫穷或者富有，无论高贵还是低贱，生命的终点都是一样的。死亡或许又是一种新生，但世间活着的人没有谁曾经到达过那里，所以我们谁都不敢保证死亡之后的世界是什么样子。死亡不可避免，死后又充满未知，而唯有现在活着的生命是可以把握的，所以我们要珍惜时间，保养好自己的生命，努力做出一些有意义的事情。</p>\n<p>人的身体就好比一部汽车，有的车出厂的时候用料实在质量较好，而有的车出厂的时候偷工减料质量较差。前者就属于天生长寿的那十分之三，而后者就属于天生短命的十分之三。但稍微懂一些车的人都知道，车的使用寿命也不完全是由出厂的时候的做工和材料来决定的。决定使用时长的还有平时的保养和爱护程度。如果平时能够按时保养，那么就可以让普通的车子跑到更长久一些。而一部好车，如果不保养，开不了多久也会报废。但保养过度也不行，懂车的人都知道，如果车子长时间不用，也不要一直放在车库不动，也要注意时不时打着火，稍微跑一跑。还有保养车子也不能太过于频繁，比如频繁的洗车反而会伤害车漆。这就是过犹不及的道理。</p>\n<p>如果懂得了车子保养的道理，那么就懂了人身体保养的道理了。如果生下来属于长寿的那三分之一，不要忙着高兴；如果生下来属于短命的那三分之一，也不要忙着气馁。一切皆还有变数，一切都还有机会。身体这部机器可以运行多久，还是要看自己怎么保养和照顾。如果保养得当，使用合理，还是有机会把命运掌控在自己手中的。</p>\n<p>那么这总共加起来才十分之九啊，剩下的十分之一是什么呢？有学者认为剩下的这十分之一是不生不死，不减不灭的得道之人。不生不死，则《易》所谓寂然不动者。可能这也正是《道德经》的魅力所在吧，给人留有一丝余地，让人无限遐想。</p>\n<p><strong>据说，善于养护自己生命的人，在陆地上行走，不会遇到凶恶的犀牛和猛虎，在战争中也受不到武器的伤害。犀牛于其身无处投角，老虎对其身无处伸爪，武器对其身无处刺击锋刃。为什么会这样呢？因为他没有死地。</strong></p>\n<p>这里说的就比较神乎其神了，善于养护生命的人，为什么陆地行走不会遭遇到凶恶的犀牛和猛虎，战争中也不会被武器伤害。而且就算遭遇到了猛兽，猛兽也无从下手，兵器无处可刺。首先说为什么他们不会遭遇到猛兽的袭击呢？第一种解释是君子不立于危墙之下，他们有超高的智慧，善于观察生活并且能够看到危险所在，所以能够躲避危险。第二种解释是圣人就像孩童一样，有着一颗赤诚之心，猛虎和恶人因为感受到不到他的威胁，所以就不会伤害他们。就像后面的第五十五章中所说：“含德之厚，比于赤子。蜂虿虺蛇不螫，猛兽不据，攫鸟不搏。” 潭中之鱼之所以被人钓到，是因为贪恋鱼饵，人之所以有危险是因为有贪欲。人们为了满足自己的欲望，想尽各种办法，犹如火中取栗，焉能不烫伤自己。这里说的死地，就是指自身的弱点，尤其是指自身的贪欲。修身的意义就在于此，修身是让我们正身形，去贪欲，从而心清神明，而入无死之地。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-45","url":"/2020/08/24/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-45/","content":"<p><strong>原文：</strong></p>\n<p><strong>大成若缺，其用不弊。大盈若冲，其用不穷。大直若屈，大巧若拙，大辩若讷。躁胜寒静胜热。清静为天下正。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四十四章中老子直指人心，连问三个问题：“名与身孰亲？身与货孰多？得与亡孰病？”我们扪心自问或许就可以了解自己内心最重要的是什么。对于那些浮名俗利，我们要懂得知足，这样才能幸福和不危殆。接下来我们继续学习《道德经》的第四十五章，看看老子又带给我们什么样的人生智慧吧～</p>\n<p><strong>最完满的东西，好似有残缺一样，但它的作用永远不会衰竭；最充盈的东西，好似是空虚一样，但是它的作用是不会穷尽的。</strong></p>\n<p>在第四十一章中提到：“大方无隅；大器晚成；大音希声；大象无形”。这里的行文有些类似，还是再讲浅层次的智慧大家都还尚可理解，但人类的认知有其局限性，更大的智慧反而不容易识别。</p>\n<p>道德大成者反而灭名藏誉，就好像毁缺不备。功成名遂身退天之道。做出最大贡献的人，不一定是站在人前被人歌功颂德之人，可能是一个在背后默默付出却并不为人所知道的人。最好的文学和艺术作品也不一定都是完整无缺憾的。《红楼梦》和断臂的维纳斯正是因为他们的不完整和缺憾却引来人们无限的遐想，赋予了作品更多的艺术想象空间。</p>\n<p><strong>最正直的东西，好似有弯曲一样；最灵巧的东西，好似最笨拙的；最卓越的辩才，好似不善言辞一样。</strong></p>\n<p>我们知道刚正不阿是一种正直，反倒不知圆润无碍更是一种有智慧的正直。刚正不阿之人只是圆了自己的刚正之名，对于所作所为的结果倒是不一定有什么担待。而圆润无碍外圆内方之人则用自己的智慧，努力调和阴阳，引导事情走向正轨。他们更加看重的是事情本身，而不太在意他人对于自己的看法。</p>\n<p>第二十七章也曾说过：“善行无辙迹，善言无瑕讁；善数不用筹策；善闭无关楗而不可开，善结无绳约而不可解。” 最巧妙的机变是以不变应万变，最高明的辩论是无言之辩。</p>\n<blockquote>\n<p>洛克菲勒每次面对气势汹汹来他办公室讨说法讲道理的人就有一套应对的策略。对方来了他办公室，洛克菲勒只说自己在忙，让对方稍等片刻。如果对方火气很大，一直大声说些什么，他也就任凭对方随便说，自己只是埋头做自己手上的工作，并不辩解和理睬对方。直到对方讲完，气焰少歇，他才抬起头，笑眯眯的跟对方说：“不好意思，因为太忙没有听到刚才您跟我讲了什么，可以再跟我细细说来吗？”这时候对方就像泄了气的皮球，再也没办法理直气壮的跟他叫嚷了。</p>\n</blockquote>\n<p><strong>清静克服扰动，寒冷克服暑热。清静无为才能为天下之长。</strong></p>\n<p>我们经常听到两个成语，一个是“急中生智”，另一个是“静能生慧”。这两个成语就告诉了我们智和慧的不同。我们生活中说一个人机灵，随机应变能力强，说的就是他有“智”。但有“智”的人不一定有“慧”。“慧”是我前面说到的大智慧，是需要清静无为，无欲无求，灭了一切分别心而生出来的。有“智”的人还是活在梦中，但有“慧”的人是已经觉醒之人。他们知晓了世事的无常，所他们顺应潮流、接受变化。他们了悟了感官享受带来的只是无尽的空虚，所以也并不贪图这些享受。只有拥有了大智慧才能超脱于自己的欲望，才能一览众山小，做出有利于人民的决定，所以才能成为天下之长。</p>\n<p>《高效能人士的七个习惯》中说到：“_<strong>在生命的长河中，个人或企业想要保持成功，唯一的方法就是以原则为中心的生活。</strong><em>” 这个以原则为中心的生活就可以理解为按照道的原则生活，而不是被自己的情绪所左右。在电影《十诫》中也提到：“</em><strong>我们不可能打破法则，只能在违背法则的时候让自己头破血流。</strong>_” 清静无为的时候是最接近于自己内心的时候，是最接近于道的时候，最能感受这个无上的法则的时候。</p>\n<p>今天就先解说到这里，愿你时刻都拥有“_<strong>宠辱不惊，看庭前花开花落；去留无意，望天上云卷云舒</strong>_”的心态。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-49","url":"/2020/09/11/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-49/","content":"<p><strong>原文：</strong></p>\n<p><strong>圣人无常心，以百姓心为心。善者，吾善之；不善者，吾亦善之；德善。信者，吾信之；不信者，吾亦信之；德信。圣人在天下，歙歙为天下浑其心，百姓皆注其耳目，圣人皆孩之。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四十八章中老子讲了“为学日益，为道日损”的道理。减损到心中不再有分别心，不再有私欲的时候，就可以做到无为。当不再为一己私利而为的时候，就可以无为而无所不为。接下来我们继续学习第四十九章，看看老子又带给我们什么样的人生智慧吧～</p>\n<p><strong>圣人常常是没有私心的，以百姓的心为自己的心。对于善良的人，我善待于他；对于不善良的人，我也善待他，这样就可以得到善良。对于守信的人，我信任他；对不守信的人，我也信任他，这样可以得到诚信。</strong></p>\n<p>圣人为道日损，损之又损以至于无为。所以他们早已没有了小我的概念，没有了分别心。所以他们做事只因循自然之道，而自然之道在管理中就是百姓之心。无论他人善良与否，无论我们得到什么样的反馈，我们如果都能善待对方，不以外界条件的改变而改变自己的初心，则可以说是发自内心的真正的善良。同样的，无论他人诚信与否，如果我们都能诚心待人，不以外界的改变而改变自己的行为，则可以说是发自内心的诚信。发自内心的善良和诚信，自然也会获得世界的善意和信用。</p>\n<blockquote>\n<p>雍齿作为刘邦的沛县同乡，在秦末跟随刘邦一同起义反秦。但雍齿素来轻视刘邦，第二年在刘邦最困难的时候，雍齿献出了他们的丰县大本营，投靠了魏国周市。刘邦大怒，数次攻打丰邑而不下，无奈之下，只好投靠项梁。靠着借来的军队，刘邦攻下了丰邑，俘获了雍齿还有跟随雍齿叛乱的老部下。刘邦本想杀掉雍齿以及叛乱的部下以泄愤，但最终还是选择了不计前嫌，释放了所有人。从此刘邦真正赢得了百姓的心，赢得了跟随他打天下的部下的心。跟暴秦相比，他总能施之以仁厚，所以他才能获得众多的支持，所以才能逐渐壮大最终可以与项羽争锋。</p>\n</blockquote>\n<p><strong>有道的圣人在其位，收敛自己的欲意，使天下的心思归于浑朴。百姓们都专注于自己的耳目聪明，有道的人都回到婴孩般纯朴的状态。</strong></p>\n<p>有道的圣人当政的时候，总是把自己的私欲放到后面，而把天下人的心放在前面。普通的老百姓都喜欢感官刺激和享受，并且以此为乐。而圣人呢，却像小孩一样，淳朴自然。他们没有善恶、美丑、高下、信伪的分别，都是以一而待之。所以对为善而不夸耀，对为恶者也不愤怒，无所喜，也无所恶。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-52","url":"/2020/10/06/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-52/","content":"<p><strong>原文：</strong></p>\n<p><strong>天下有始，以为天下母。既得其母，以知其子，既知其子，复守其母，没身不殆。塞其兑，闭其门，终身不勤。开其兑，济其事，终身不救。见小曰明，守柔曰强。用其光，复归其明，无遗身殃；是为习常。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在第五十一章中老子讲了为什么要尊道而贵德。道和德最重要的品质是什么？是生而不有，为而不恃，所以这也被称为最为深远的德行（玄德）。接下来我们继续学习第五十二章，看看老子又讲了什么样的人生哲理吧～</p>\n<p><strong>天地万物本身都有起始，这个始作为天地万物的根源。如果知道根源，就能认识万物，如果认识了万事万物，又把握着万物的根本，那么终身都不会有危险。</strong></p>\n<p>万事万物都是由道演变而来，而万变不离其宗，所以只要把握住了最为核心的道，或者说是天地之理，那么我们生活中面临的很多问题都会迎刃而解。《大学》开宗明义指出：“_大学之道，在明明德，在亲民，在止于至善。知止而后有定，定而后能静，静而后能安，安而后能虑，虑而后能得。物有本末，事有终始。知所先后，则近道矣。_”所谓物有本末，这个本就是核心问题，也是道层面的东西。想要治理好一方百姓，必然要提高自身的修养和智慧。如果身不修，则何以齐家，家不齐又何以治国。</p>\n<p><strong>塞住欲念的孔穴，闭起欲念的门径，终身都不会有烦扰之事。如果打开欲念的孔穴，就会增添纷杂的事件，终身都不可救治。</strong></p>\n<p>那么我们怎么才能提高自身修养和智慧呢？道家的方法简单而又非常有效，那就是“致虚极，守静笃”。烦恼都是源自于自身想要得到某样东西，然而现实中又得不到。如能致虚极，守静笃，则无所求，无所取，烦恼便成了无源之水、无本之木，自然也就消散了。一切烦恼痛苦顽痴都来自于本心不明。佛家讲明心见性，如果能够将内心修炼的透彻明亮，那么这个真我，或者说道也就能了悟了。</p>\n<p><strong>能够察见到细微的，叫做“明”；能够持守柔弱的，叫做“强”。</strong></p>\n<p>在修身过程中有非常重要的两点需要注意，那就是“明”和“强”。“明”是指修身要讲究慎独，“勿以恶小而为之，勿以善小而不为”。能够从细小处着手，时时自省审查自己的内心，从而让自己不出大的差错。在对待事物的判断上，要时刻保持清晰敏锐的判断力。在事情发端之始，就要看到它可能会造成的后果。</p>\n<p>老子认为真正的“强”是什么？不是我们通常可以看出来的强大，而是柔弱中带有韧性，温柔中带有坚定，就像水一样的处下和守柔的强大。在后文中也会学到“坚强者死之徒，柔弱者生之徒”。只有枯死的树木才是强硬的，而活着的树木都是有韧性的。当大风刮来，充满生机的树木随风摇曳，甚至弯曲匍匐到地上；但是当大风退去，他们又重新恢复到正常状态，仿佛大风从没有来过一样。</p>\n<p><strong>运用其光芒，返照内在的明，不会给自己带来灾难，这就叫做万世不绝的“常道”。</strong></p>\n<p>光向外照射，明向内透亮。发光体本身为“明”，照向外物为光。因世人都绞尽脑汁来寻求外物，所以不能明心见性。如能把智慧用在反省自身，照见自身的心性，使其恢复我们本来就有的光明，那么就不会有疏漏，也就掌握了真正的修习之道。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-53","url":"/2020/10/23/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-53/","content":"<p><strong>原文：</strong></p>\n<p><strong>使我介然有知，行于大道，唯施是畏。大道甚夷，而民好径。朝甚除，田甚芜，仓甚虚；服文彩，带利剑，厌饮食，财货有馀；是谓盗夸。非道也哉！</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第五十二章中老子讲了大道和修身之间的联系，接下来我们继续学习第五十三章，看看老子又讲了什么样的人生智慧吧～</p>\n<p><strong>假如我稍微地有了认识，在大道上行走，唯一担心的是害怕有所施为。</strong></p>\n<p>老子认为“罪莫大于可欲，祸莫大于不知足，咎莫大于欲得”，所有的灾祸的根源都是人们内心的私欲和妄念。私欲妄念一起，则行为有所偏差，就会有所施为，就要为自己谋利益。所以在修身治国平天下过程中，最重要的是保持一颗中正之心，淳朴之心。 </p>\n<p>《礼记》中对于大同社会的描述是“大道之行也，天下为公”。在这样的社会中，人们不单单爱护自己的亲友，也发自内心的爱护社会上的所有人。社会中所有人都各尽其能，各尽其职，阴谋诡计没有兜售的市场，从而出现夜不闭户、路不拾遗的太平景象。而小康社会则是“大道既隐，天下为家”的社会背景下，统治者用各种礼仪道德来规范和制约社会上的种种行为，从而可以保护既得利益者的财产和亲友。所以才会有“大道废，有仁义”和“失道而后德，失德而后仁，失仁而后义，失义而后礼”的说法。</p>\n<p>有所施为则会从大道的层面落到仁义的层面。社会中就会有投机取巧者，巧立名目，披上礼义的外衣而为自己攫取利益。河上公对此的注解是“独畏有所施为，恐失道意。欲赏善，恐伪善生；欲信忠恐诈忠起。”</p>\n<p><strong>大道虽然平坦，但人君却喜欢走小径。</strong></p>\n<p>这几句话非常形象的指出了社会上的种种乱象。大路平平就摆在面前，可人们偏偏喜欢走小路。最有效最直接的方法摆在面前，可是人们总是想取巧走捷径。可是哪里又有真正的捷径？比如说提高英语水平最有效的方法就是打牢基础，认真背单词，研读长难句，多听多说多读多写。可是各种辅导机构一打出速成的幌子，就让所有人都趋之若鹜。但那些眼花缭乱的各种解题方法，又有多少能够真正帮助到人们呢？</p>\n<p><strong>朝政腐败已极，弄得农田荒芜，仓库十分空虚，而人君仍穿着锦绣的衣服，佩带着锋利的宝剑，饱餐精美的饮食，搜刮占有富余的财货，这就叫做强盗头子。这是多么无道啊！</strong></p>\n<p>另外一个社会乱象是人们爱慕虚荣。明明已经民不聊生、仓廪空虚，可是人君仍然穿着华服、带着宝剑、饱餐美食、搜刮财货。这不正是跟现代很多年轻人的生活消费方式非常相似吗？明明没有多少收入，却贷款或者花着父母的血汗钱来买一些不必要的奢侈品来满足自己的虚荣心。</p>\n<p>一个人成熟的很重要的标志就是开始从外求转向内求，开始不在乎他人怎么看待自己，而是有一个自己内在的标准，真正知道自己想要什么。“_唯之与阿，相去几何？_”他人的称赞跟贬低，又有多大的区别呢？“_宠为下，得之若惊，失之若惊，是谓宠辱若惊。_”外界给予的宠跟辱，又有多大区别呢？一切不过是自己的内心在作怪。对于这些古怪的行为，老子很不客气的说，这是非常无道的表现。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-51","url":"/2020/09/25/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-51/","content":"<p><strong>原文：</strong></p>\n<p><strong>道生之，德畜之，物形之，势成之。是以万物莫不尊道而贵德。道之尊，德之贵，夫莫之命常自然。故道生之，德畜之；长之育之；亭之毒之；养之覆之。生而不有，为而不恃，长而不宰，是谓玄德。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第五十章中老子讲了生死之道。圣人之所以能够不遇兕虎、不被甲兵，就是因为他们懂得长生久视之道，返璞归真而无死地。接下来我们继续学习第五十一章，看看老子又带给我们什么样的人生智慧吧～</p>\n<p><strong>道生成万事万物，德养育万事万物。万事万物虽现出各种各样的形态，环境使万事万物成长起来。故此，万事万物莫不尊崇道而珍贵德。</strong></p>\n<p>道是万物之母，是一切的本源。德者得也，是道的外在体现。物生而后畜，畜而后形，形而后成。这个形和成，用佛家的话来说就是：一切相皆是因缘和合而生。现代物理也证明，我们物质世界的基础都是由相同的微观粒子来组成。万物属性不同，皆是由于分子尺寸上的排列组合不同。虽然精神世界的东西，科学未曾触及，但我相信最终的组成基础应该是相同的，只是我们还未曾用一种严谨且直接的方式呈现给世人。一切事物皆由“道”而来，所以万事万物莫不尊道而贵德。</p>\n<p><strong>道之所以被尊崇，德所以被珍贵，就是由于道生长万物而不加以干涉，德畜养万物而不加以主宰，顺其自然。因而，道生长万物，德养育万物，使万物生长发展，成熟结果，使其受到抚养、保护。生长万物而不居为己有，抚育万物而不自恃有功，导引万物而不主宰，这就是奥妙玄远的德。</strong></p>\n<p>道和德的珍贵之处在于它从不施加命令，而是用润物细无声的方式来影响和感化周围的一切，从不显露痕迹，而常呈自然之态。所以，道和德不但生养万物，并且使万物成长、覆育，全其性命。在做完这一切之后，却生而不有、为而不恃、长而不宰。《金刚经》中也曾说到：“善男子、善女人，发阿耨多罗三藐三菩提者，当生如是心，我应灭度一切众生。灭度一切众生已，而无有一众生实灭度者。”两者互相印证，都是来说明同一个道理，那就是要让我们但行好事莫问前程。心中有了相，哪怕是法相，那还是不曾领悟道的真谛。老子把这种为而不恃境界称为“玄德”，意思是深远幽深的德行。如果拥有玄德，那必然是已经去掉了贪嗔好恶等各种不良习性，个人修养达到了很高的水准。拥有这种德行的人，不再被各种情绪所左右，从而拥有无上智慧，生活中也不再有纠结和烦恼。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-55","url":"/2020/11/26/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-55/","content":"<p><strong>原文：****含德之厚，比于赤子。蜂虿虺蛇不螫，猛兽不据，攫鸟不搏。骨弱筋柔而握固。未知牝牡之合而全作，精之至也。终日号而不嗄，和之至也。知和曰常，知常曰明，益生曰祥。心使气曰强。物壮则老，谓之不道，不道早已。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第五十四章中老子再次讲了修身的重要意义以及观照的修身方法。接下来我们继续学习第五十五章看看老子又讲了什么样的人生哲理吧～<strong>道德涵养浑厚的人，就好比初生的婴孩。毒虫不螫他，猛兽不伤害他，凶恶的鸟不搏击他。他的筋骨柔弱，但拳头却握得很牢固。他虽然不知道男女的交合之事，但他的小生殖器却勃然举起，这是因为精气充沛的缘故。他整天啼哭，但嗓子却不会沙哑，这是因为和气纯厚的缘故。</strong>真正有德行的人是什么样子的呢？老子认为这样的人就像刚出生的婴孩一样。凶猛的野兽见到他们就不会生出嗔恨之心、暴戾之心，所以就不会伤害他们。就像第五十章中所描述的“盖闻善摄生者，陆行不遇兕虎，入军不被甲兵；兕无所投其角，虎无所措其爪，兵无所容其刃。” 我们自己可能也有一些经验，看到动物的幼崽，看到可爱的小孩子，都忍不住被他们清澈的眼神所感染，自然而生出怜爱之心。虽然外表看起来人畜无害，但却又很有力量。“骨弱筋强”中的骨是指具有强硬特质的东西，而筋是指具有柔韧特质的东西。老子也说过“坚强者死之徒，柔弱者生之徒”。这里再次表达了老子的崇尚柔弱的观点，认为守柔之道才是真正的强者之道。接下来就说了，骨弱筋强的后果是什么？是“握固”，是把事情牢牢把控住。所以真正的智者和强者不是靠蛮力来把控事情，靠的是柔弱的力量。另外，我们发现小孩子未知男女之事，有时却阴阳作怒。小孩子如此，不是因为欲望，而是因为精力充沛。反过来思考，小孩子为什么精力充沛呢？可能正是因为不被欲望所驱使，从而搞的身心俱疲。得道之人，也是如此，他们从容潇洒，不被欲望所驱使，不被世俗所羁绊，精气神也自然充盈。我们观察小孩子还会发现，小孩儿整天啼哭，嗓子却不会沙哑。这是为什么呢？是因为他们天然懂得怎么调动调和各种器官来配合发音，从而引起声音的共振。也就是这里老子说的懂得“和”的道理。得道之人也是如此，他们懂得怎么去调和阴阳，懂得怎么让一切圆润无碍的高效运作。<strong>认识和的道理叫做“常”，知道“常”的叫做“明”。贪生纵欲就会遭殃，欲念主使精气就叫做逞强。事物过于壮盛了就会变衰老，这就叫不合于“道”，不遵守常道就会很快地死亡。</strong>认识到了“和”的道理，那么就知道了世界那恒常不变的真理。这个真理是什么呢？万事万物都在周而复始的不断变化。唯有掌握了变化中那不变的一点，或者说感知到了平衡的那一点，那么就能调和阴阳，万事顺利。认识到了世界是在周而复始的不断变化就可以说一个人对世事明了了。万事万物都处在某个大循环的一个阶段。生老病死是人的一个循环，春夏秋冬是季节时令的一个循环。甚至我们的现在所处的时空，可能都只是宇宙周而复始的大爆炸中的某一次余波。人类本身可能并没有什么意义，所有的意义都是人类自我编织的故事，也可能只是我们的基因使然。就像《金刚经》所说：“一切有为法，如梦幻泡影，如露亦如电，应作如是观。”“益”通“溢”，是满的意思。“益生”就是过度的想生，或者说贪生。老子认为过度的想生会带来灾祸。这就跟前文五十章中所讲的“生之徒，十有三；死之徒，十有三；人之生，动之死地，十有三。夫何故？以其生生之厚。”古代帝王为什么贪生？大部分是因为贪图享受世间的各种权势、美色、声乐等等。而欲望过剩反而会减短生命的长度。心态平和、起居有常就是最好的养生。事物的规律就是循环往复、否极泰来。过于强大了，就会开始走向衰老。过于自满了，现实就会给予沉重的一击。满招损、谦受益。Stay Hungry, Stay Foolish.</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-5","url":"/2020/06/05/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-5/","content":"<p><strong>原文：</strong></p>\n<p><strong>天地不仁，以万物为刍狗；圣人不仁，以百姓为刍狗。天地之间，其犹橐龠乎？虚而不屈，动而愈出。多言数穷，不如守中。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第四章讲了道的几个特征：摸不着看不见但无处不在，无所不能，妙用无穷。了解了道之后，我们要向道学习，学习道的和光同尘和做人处事要学会外圆内方。这里第五章老子继续讲无为之道。</p>\n<p><strong>天地任自然，无为无造，不刻意施以仁恩，万物在天地眼里都刍草狗畜；圣人与天地合其德，同样也不刻意施以仁恩，百姓在圣人眼里也都是刍草狗畜。</strong></p>\n<p>刍狗是以前人们祭祀的时候用草扎成的狗。天地生养万物，但却生而不有，为而不恃，任其自然生长，不刻意施以仁恩。在道的规律下万物相生相克，自相治理。在天地眼里，人跟其他所有一切有生命的、无生命的万物都是一样的。天地不为人而生出鸡鸭牛羊，而人却以他们为食。天地不为鸡鸭牛羊生出谷物虫草，而鸡鸭牛羊却以他们为食。这个链条可以无限扩大包含一切，从而形成我们生活的这个世界。人只是这个链条中的一环，比如人在发明武器之前，会被野兽猛虎吃掉。现在人们有了更先进的武器，也同样还是逃脱不出这个链条。人会被无处不在的病毒细菌袭击，会被自身变异的癌细胞吞噬。就算没有疾病，人们也会被时间打倒，在全身器官衰竭中衰老而死。而死后，又会被细菌分解，从而进入这个循环。</p>\n<p>圣人看到了这个规律，知道一切都是在循环往复。所以圣人让百姓自行衍生发展，让社会的规律自然起作用，而不去强加干涉。在这个自然规律的支配下，百姓万物自然会各归其位，各司其职。</p>\n<p><strong>天地之间，不正像个中空的风箱一样吗？虽然空虚，但却永远没有屈竭的时候，越鼓动出的声气越多。多事害神，多言害身，不如守德于中，育养精神，爱气希言。</strong></p>\n<p>再次拿天地来做比喻来形容道。“橐龠”就是风箱的意思，如果见过风箱的可能都知道，风箱里面的气体永远鼓动不完，越是鼓动的厉害，跑出去的气越多，永远没有排尽的时候。风箱的特征就是无论人怎么鼓动，最后风箱里的气体还是那么多。所以说天地不去刻意施为，圣人也不去刻意仁恩。呼吁呐喊改革一通，社会还是会照着它本来的样子来运行。大炼钢铁并没有让钢铁产量真正增加，计划生育也并没有让人口问题彻底解决。社会自有其自己的发展规律，企图用人力政策来实现的跨越式发展并不现实。其实很多政策实施跟不实施的结果并没有什么两样。缩小到个人发展来说，我们就会发现同样的现象，是金子总能发光，不是金子就算被打磨光还是会自己暗淡掉。比如罗永浩也没上过大学，但这个人的性格就是敢闯敢做，有一股子不服输的精神，所以在社会中也闯出了自己的一片天地，找到了自己的位置。相反，某些人在父母或者老师的干预下，选择了某些令人羡慕专业或者工作，最后也不过是度日，不会做出什么突出的成绩。所以说，人成就的最根本来源是这个人内心的源动力，而不是外界的条件。对于个人修身养性来说，我们能够得到的启发是：多事害神，多言害身。多事多言，往往会使人自己陷入困境，然而对自身对他人其实并不会有什么改变。</p>\n<p>所以老子的结论是“不如守中”。对社会来说，不如以经济发展为中心，顺应时代社会的发展潮流，少一些政令，多一些顺应民心。对于个人发展来说，不如顺应自己内心的想法，少一些执念，做自己真正喜欢做的事情。对于个人修身来说，不如守德于中，育养精神，爱气希言。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-54","url":"/2020/11/04/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-54/","content":"<p><strong>原文：</strong></p>\n<p><strong>善建者不拔，善抱者不脱，子孙以祭祀不辍。修之于身，其德乃真；修之于家，其德乃馀；修之于乡，其德乃长；修之于国，其德乃丰；修之于天下，其德乃普。故以身观身，以家观家，以乡观乡，以国观国，以天下观天下。吾何以知天下然哉？以此。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第五十三章中老子批判了“大道甚夷，而民好径”的社会现象。他在上一章中告诉我们：想把事情做好没有捷径可走，只有一步一个脚印踏踏实实来做。我们不要被社会上的浮光掠影所吸引，而是要把握好最根本的东西。这些根本的东西包括：智慧、健康、美德、和才华，他们是靠自身修行而来的，是任何人都抢夺不走的。接下来我们继续学习第五十四章，看看老子又讲了什么样的人生哲理吧～</p>\n<p><strong>善于建树的不可能拔除，善于抱持的不可以脱掉，如果子孙能够遵循、守持这个道理，那么祖祖孙孙就不会断绝。</strong></p>\n<p>这一章承接前一章，还是要告诉我们把内功扎稳，踏踏实实做事情。把根深深扎进土壤的大树，不会轻易被狂风吹倒。不贪于多，善于抱持，而把事情做精做好的人，也不会轻易被社会所抛弃。如果能够把这个道理牢记于心，那么子子孙孙都会兴旺繁盛。</p>\n<p>历史上有数不胜数的大富豪或者是建立大功业的人，在人生得意之时，突然遭遇到危机，然后昙花一现就消失了。固然有历史的巧合因素，然而还有一个很大的原因是德不配位所带来的灾祸。如果自身的根基没有扎的足够坚实，那么这时候降临的财富和地位就会是一场灾难。</p>\n<p><strong>把这个道理付诸于自身，他的德性就会是真实纯正的；把这个道理付诸于自家，他的德性就会是丰盈有余的；把这个道理付诸于自乡，他的德性就会受到尊崇；把这个道理付诸于自邦，他的德性就会丰盛硕大；把这个道理付诸于天下，他的德性就会无限普及。</strong></p>\n<p>如果把这个道理付诸于修身、齐家、治国、平天下，那么就会身修、家齐、国治、天下平。一个人的德行和智慧不是突然而得来的，而是靠的扎扎实实的学习和训练而得来的。一个美满的家庭不是随随便便就能拥有的，而是靠的不断的对家人付出爱和理解而得来的。罗马也不是一天建成的，而是靠的几代人的心血和智慧不断完善而成的。</p>\n<p><strong>所以，用自身的修身之道来观察别身；以自家察看观照别家；以自乡察看观照别乡；以平天下之道察看观照天下。我怎么会知道天下的情况之所以如此呢？就是因为我用了以上的方法和道理。</strong></p>\n<p>怎么知道这个道理是正确的呢？老子这里告诉了我们一个方法。那就是用修道之身来观不修道之身，用修道之家来观不修道之家，用修道之乡来观不修道之乡，用修道之天下来观不修道之天下。一个人事业顺畅、家庭美满，那么必然有他成功的秘诀。而相反，另一个处处不顺心的人，也必然有他做的不够好的地方。两者对比，就可以知道差异在哪里。当然我们也可以反过来，观察一下历史上或者身边的人。看看他们按照道的原则来做事的人结果如何，不按道做事的人的结果又是如何。两者对比，我们也可以知道差异在哪里。比如，很多人深陷困境，只知道怨天尤人而不自我反省，最后也不能做出任何突破和改变。而又有一些人，在逆境中不断思考和改进，从而达到了新的人生高度。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-56","url":"/2020/12/11/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-56/","content":"<p><strong>原文：</strong></p>\n<p><strong>知者不言，言者不知。塞其兑，闭其门，挫其锐，解其分，和其光，同其尘，是谓玄同。故不可得而亲，不可得而疏；不可得而利，不可得而害；不可得而贵，不可得而贱。故为天下贵。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第五十五章中老子讲了得道之人是跟赤子一样的，“蜂虿虺蛇不螫，猛兽不据，攫鸟不搏”，一举一动蕴涵了天道。并且再次强调了物壮则老的天道法则，警醒世人要持盈满之戒。接下来我们继续学习第五十六章看看老子又讲了什么样的人生哲理吧～</p>\n<p><strong>聪明的智者不多说话，而到处说长论短的人就不是聪明的智者。</strong></p>\n<p>聪明的智者从来不多说一些无用之话，溜须拍马之话，或者是空许诺言之话。相反，不智之人却往往喜欢说长道短、夸夸其谈、空许诺言。为什么这么说呢？因为“轻诺必寡信，多易必多难”，夸夸其谈而不能落到实处的空话，只能降低自己的信用评分；溜须拍马、谄媚逢迎之话，只能降低自己的人格评分；家长李短、八卦绯闻之话，只能降低自己的人品的评分。君子要慎言慎行，因为我们的每一次待人接物，每一次做出决定，都是对自己诠释，都是在向社会和自己定义我们是谁。</p>\n<p>所以我们应当怎么做呢？答案是我们应当贵行不贵言。比如，在他人需要帮助的时候，伸出自己的双手，做一些力所能及的事情。在对美好生活向往的时候，踏踏实实耕耘付出，努力实现自己的目标。在评判和认识他人的时候也应当如此，我们应当更加注重这个人做了什么，而不是说了什么。</p>\n<p><strong>塞堵住嗜欲的孔窍，关闭住嗜欲的门径。挫掉锐气，解开纠纷，与众人和光同尘，这就是深奥的玄同。达到“玄同”境界的人，已经超脱亲疏、利害、贵贱的世俗范围，所以就为天下人所尊重。</strong></p>\n<p>人们为什么会没有智慧呢？为什么会做出偏离大道的愚蠢的行为呢？是因为人们有欲望，被纷纷扰扰的外部世界给迷惑了心性。“五色令人目盲；五音令人耳聋；五味令人口爽；驰骋田猎，令人心发狂；难得之货，令人行妨。” 所以老子说“圣人为腹不为目，故去彼取此”。也就是说，人们返璞归真、明心见性的关键在于远离和控制欲望。</p>\n<p>“挫其锐，解其分，和其光，同其尘”在<a href=\"https://shileilei.com/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-4/\">第四章</a>中已经出现并解释过。这里再稍微提一下，有兴趣的可以再翻回<a href=\"https://shileilei.com/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-4/\">第四章</a>去仔细品味。</p>\n<p>“锐”是指一切有尖锐特性的品格。木秀于林，风必摧之。自然界中，一切有棱角和突出的东西都会被打磨的圆润，这是天道的特性。就像意气风发的大学生，出了校园，很快棱角就会被磨平。这里不是在提倡平庸，而是在说圆润的智慧。事急则缓，事缓则圆。急风骤雨事的改革，不会有大的成效。坚定不移，一点一滴的解决遇到的困难，最后一定能够成功。 “纷”应该包含了世间一切纷繁复杂的事物。“解其纷”告诉了我们道的另一个特质：善于化繁为简，善于解开纷繁复杂的局面。在面对纷繁复杂情况的时候，我们要善于找到事情的本质，化繁就简。如果当下不能立马解决的问题，就交给时间来抽丝剥茧。做到这些，最后应当达到“和光同尘”的状态。和光同尘是一种圆润无碍地能够与大家和谐相处的智慧，圆润但并不圆滑的生活哲学。做人应该像铜钱一样，外圆而内方。心中方正，有自己的原则和认知，但并不与众人合流但不同污。“大方无隅，大智不割”，讲的就是大的方正是没有棱角的，大的智慧是不让人觉得难受的。</p>\n<p>达到以上所说的状态，就可以说是达到所谓的“玄同”。达到“玄同”境界的人，已经超脱亲疏、利害、贵贱的世俗范围，所以就为天下人所尊重。这时候已经超脱了我们世俗的认知，超脱了欲望和生物的本能，也同时拥有了无上的智慧。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-57","url":"/2020/12/19/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-57/","content":"<p><strong>原文：</strong></p>\n<p><strong>以正治国，以奇用兵，以无事取天下。吾何以知其然哉？以此：天下多忌讳，而民弥贫；民多利器，国家滋昏；人多伎巧，奇物滋起；法令滋彰，盗贼多有。故圣人云：我无为，而民自化；我好静，而民自正；我无事，而民自富；我无欲，而民自朴。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第五十六章中老子讲了得道之人“塞其兑，闭其门，挫其锐，解其分，和其光，同其尘”，最终达到了超脱亲疏、利害、贵贱的世俗范围的境界，所以为天下贵。接下来我们继续学习第五十七章，看看老子又讲了什么样的人生哲理吧～</p>\n<p><strong>以正道去治理国家，以奇道去用兵，以不扰害人民而取得天下。</strong></p>\n<p>治理国家和用兵打仗用的是完全不同的道。治国要用阳谋，要用仁义礼智信，用公平和信用来获得民众的支持。而用兵打仗却相反，打仗更多讲究的是出其不意，用阴谋诡计来打败敌人，获得胜利。那么怎么才能成为天下的共主呢？靠的既不是治理国家的那一套方法，也不是用兵打仗的那一套方法，而是“无为”。前文已经提及过很多次，无为不是什么都不做，而是设计制订好一个体制，所有人在这个体制下都可以发挥出自己的才能，也可以获得自己所需要的东西，最终这个体制的领导者实现的是“无为而无不为”。第十七章中老子说过管理有四重境界：“太上，下知有之；其次，亲而誉之；其次，畏之；其次，侮之。” 其中太上的管理境界就是无为而治“下知有之”的终极管理之道。</p>\n<p><strong>我怎么知道是这种情形呢？根据就在于此：天下的禁忌越多，而老百姓就越陷于贫穷；国家越是示人以国之利器，国家就越陷于混乱；人们的技巧越多，奇物就会滋起；法令越是森严，盗贼就越是不断地增加。</strong></p>\n<p>老子得出上面的结论是通过社会实践观察而得来的。老子首先发现天下的禁忌越多，老百姓就越是贫穷。如果稍微熟悉一点我们国家的近几十的历史的人都知道，在改革开放之前，我们的国家贫穷落后。造成这种现象的很重要的一个原因就是太过于强调社会的意识形态，只要是违反社会主义意识形态的任何行为都会被禁止，从而造成了人们的双手被束缚住，严重挫伤了劳动积极性。邓老等国家元老意识到了这个社会问题，在1978年的十一届三中全会上提出了“改革开放，实事求是”的八字方针。从而开始了轰轰烈烈的改革开放，不再走教条主义，彻底解放了人民的双手，在短短几十年间，彻底改变了人民的生活水平。</p>\n<p>第二点是国家越是示人以国之利器，国家就越陷于混乱。这里的“民多利器”不是人民掌握了利器，而是“利国器以示人”。老子在第三十六章中提到“鱼不可脱于渊，国之利器不可以示人”。对于一个国家来说，利器就是刑罚和军队这些国家力量。为什么不可以将国家利器轻易示之于人呢？因为天道好还。“木秀于林，风必摧之”，想要展示力量的国家，必然也会被这股力量所反噬。</p>\n<p>第三点是奇技淫巧越多，天下间的奇物就会滋起。上古代侯王追求奇货珍玩，大起宫殿是普遍现象。在生产力水平有限的前提下，人们花太多心思在奇技淫巧之上，老子认为是华而不实的。老子提倡的是“为腹不为目”，和“虚其心，实其腹，弱其志，强其骨”的理念。民多智则巧伪生，巧伪生则邪事起。庄子也说过：“达生之情者，不务生之所无所谓。” 意思是说，真正通达生命真相的人,不去追求生命中不必要的东西。这些奇物就是生命中无所谓的东西，花太多时间在这上面就是在浪费我们最宝贵的资源—时间。</p>\n<p>第四点是法令越是森严，盗贼就越是不断地增加。这一点看上去好像有点违反常理，但如果仔细思考就会发现这句话的合理性。盗贼是不可能被法令所消灭的。秦朝的法令可以说是非常严苛，可是盗贼并没有消失，江山也没有因此而稳固。杜绝邪恶的关键在于启发内心的真善美，在于去除欲望，和在于提高人们内心的精神文明，而不是简单粗暴的严厉惩罚。</p>\n<p>通过以上四点，老子就总结出“无为而治”才是解决一切乱象的根本。“王道”和“霸道”皆不可取。</p>\n<p><strong>所以有道的圣人说，我无为，人民就自我化育；我好静，人民就自然富足；我无欲，而人民就自然淳朴。</strong></p>\n<p>所以圣人采取的都是无为而治的方针。国家的高层能够做到无为、无欲，民众则会上行下校，自然而然的就会自我满足、淳朴自然。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-58","url":"/2021/01/08/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-58/","content":"<p><strong>原文：</strong></p>\n<p><strong>其政闷闷，其民淳淳；其政察察，其民缺缺。祸兮福之所倚，福兮祸之所伏。孰知其极？其无正。正复为奇，善复为妖。人之迷，其日固久。是以圣人方而不割，廉而不刿，直而不肆，光而不耀。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第五十七章中，老子讲了“以正治国，以奇用兵，以无事取天下”的观点，认为只有从个人出发做到无事、无为才能给天下以楷模，从而实现民众的自化、自正、自富和自朴。接下来我们继续学习第五十八章看看老子又讲了什么样的人生哲理吧～</p>\n<p><strong>政治宽厚清明，人民就醇醇富厚、相亲和睦；政治苛酷严厉，人民就民不聊生、心怀抱怨。</strong></p>\n<p>闷闷是形容昏昏昧昧的状态，有宽厚的意思在里面。而察察刚好相反，是用来形容严厉、苛刻的状态。我们知道有个成语叫做“察察为明”，意思是形容专在细枝末节上来显示精明。现在社会上有很多人都特别容易犯这种毛病，觉得挑了别人的错就可以彰显自己了。而这种锋利和比较的心态，却是老子非常不赞同的。他认为最大的智慧应该是和的智慧，应该是无为的智慧。</p>\n<p>作为一个普通老百姓，如果有这个毛病，人缘就会比较差，周围的人都会不愿意与这样的人打交道。作为一个组织的领导，如果有这个毛病，队伍就会没有向心力，下属会怨声载道，心怀不满。俗话说“水至清则无鱼，人至察则无徒”，做人治世怀三分宽厚仁慈之心，该糊涂的时候就装一把胡涂，往往事情反而会更加顺利。</p>\n<p><strong>灾祸啊，幸福依傍在它的里面；幸福啊，灾祸藏伏在它的里面。谁能知道究竟是灾祸呢还是幸福呢？它们并没有确定的标准。正忽然转变为邪的，善忽然转变为恶的。</strong></p>\n<p>我们这个世界一直处在不断的变化和运动当中，现在看起来好的事情，可能下一秒就会变成不好的了，而现在看起来不好的，说不准下一秒就变成好事了。任何事情都不是一成不变的，我们要学会用变化和发展的眼光来看待我们这个世界。</p>\n<p>在我们的语文课本中有一则塞翁失马的寓言故事，刚好讲的就是这个道理。这里再稍微复述一下这个故事：</p>\n<blockquote>\n<p>在靠近边塞的人中，有一位精通术数的人。他家的马自己跑到胡人那里去了，大家都来慰问他。这位父亲说：“为什么就知道不是福运呢？”过了几个月，他家的马带领着胡人的骏马回来了，大家都祝贺他。这位父亲说：“为什么就知道不是祸端呢？”家里有许多骏马，他的儿子喜欢骑马，有一次从马上摔下来折断了大腿骨。大家都慰问他，这位父亲说：“为什么就知道不是福运呢？”过了一年，胡人大举侵入边塞，男子健壮的都拿起弓箭参战，塞上参战的人，十个死九个，不死的都是重伤。唯独他的儿子因为腿摔断了的缘故，父子得以保全性命。所以福可变为祸，祸可变为福，这其中的变化难以捉摸，深不可测。</p>\n</blockquote>\n<p>塞翁失马，焉知非福。一时虽然受到损失，可能反而因此能得到好处。坏事在一定条件下可变为好事，反之也亦然。所以人们在失意时一定要乐观向上，在得意时一定要谦虚低调。任何事情都有二面性，不好的一面，有可能向好的一面转化，好的一面，也有可能向不好的一面转化。</p>\n<p><strong>人们的迷惑，由来已久了。因此，有道的圣人方正而不割截人，廉洁而不伤害人，直率而不放肆，光亮而不刺眼。</strong></p>\n<p>人们的迷惑来源于对事物的执念和偏见。觉得好的就一定是好的，而不好的就一定是不好的，但殊不知一切都在变化中。孔门提倡的中庸之道，释门所说的无我、人、众生、寿者相也是讲的同一个道理。过尤不及，凡事把握好度，不执迷、不过度，在纷繁复杂的世界中修炼好一颗如如不动的心，就能没有迷惑。</p>\n<p>所以有道之人是怎么做的呢？他们“方而不割，廉而不刿，直而不肆，光而不耀”。方正、廉洁、直率、光亮都是非常好的，但他们却懂得克制、不过分。方正廉洁但却并不会因此而割伤他人，他们心存宽厚，给他人留有余地。直率而不放肆，他们也懂得曲己从人，而不一味直率而显得放肆。另外，圣人虽有独见之明，却懂得让自己和光同尘，显得暗昧，不让人觉得刺眼。</p>\n<p>最后，附上一首《好了歌》来结束此章节。希望每个人都可以找到内心的平衡点，找到属于自己的道。</p>\n<blockquote>\n<p><strong>好了歌</strong><br>世人都晓神仙好，惟有功名忘不了！<br>古今将相在何方？荒冢一堆草没了。<br>世人都晓神仙好，只有金银忘不了！<br>终朝只恨聚无多，及到多时眼闭了。<br>世人都晓神仙好，只有姣妻忘不了！<br>君生日日说恩情，君死又随人去了。<br>世人都晓神仙好，只有儿孙忘不了！<br>痴心父母古来多，孝顺儿孙谁见了？</p>\n</blockquote>\n<hr>\n","categories":["哲学思考","道德经"]},{"title":"《道德经》-59","url":"/2021/01/19/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-59/","content":"<p><strong>原文：</strong></p>\n<p><strong>治人事天莫若啬。夫唯啬，是谓早服；早服谓之重积德；重积德则无不克；无不克则莫知其极；莫知其极，可以有国；有国之母，可以长久；是谓深根固柢，长生久视之道。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第五十八章中老子讲了福祸相依的道理，告诉我们不要执迷于我们所认为的“好”。所谓的好和坏只是事物的两个方面，也是非常主观的人为定义，它们相互依存、相互转换。接下来我们继续学习第五十九章，看看老子又给我们讲了什么样的人生哲理吧～</p>\n<p><strong>治理百姓和养护身心，没有比“啬”更为重要的了。只有做到“啬”，才能够得以做到先得天道。</strong></p>\n<p>这一章的重点在于一个“啬”字。“啬”在古书中解释为“不妄费”。这个“啬”字其实也就是“无为”，不胡乱而为。只在需要为的时候，顺势而为，起到四两拨千斤的效果。治理百姓如果能做到爱惜民力，不求奢泰则可以称之为“啬”。保养身体如果能够不骄奢淫逸，肆意放纵，也可称之为“啬”。做到了这个“啬”字，就可以保养民力，保养精力。在我们真正需要它的时候，才能发挥出真正的作用。</p>\n<p>国家的强大不是体现在政府有多富有，而是藏富于民、藏智于民，让整个社会都具有弹性。一个人精力充沛身体好，也不是体现在他多能熬夜多能造，而是善于保养、藏精于内，让身体充满了内在的能量。做到了这些，就能够早服（早早的得到天道）。这里的“服”不是衣服的服，而是跟我们平常说的服药的服有些类似。河上公的批注中，把“服”解释为“得”，我觉得解释的非常恰当。</p>\n<p><strong>先得天道，就是“重积德”；重积德，就没有什么不能攻克的；没有什么不能攻克，那就无法估量他的穷极。</strong></p>\n<p>早早的得到了天道，就是“重积德”。（这里我把重积德理解为一种非常好的德行，跟前面讲的玄德类似。也有把重积德解释为不断的积累德行，我觉得这样解释也说得通。）拥有了这种重积德就攻无不克了，就没有什么事情能够难倒他了。读到这里，你可能会问个为什么？这是因为，拥这种德行是一种对天道的深层次的理解，世间万物的运转规律都掌握了，当然也就可以做到攻无不克。达到这种境界的人，内心就像一潭深渊，就像浩瀚的宇宙，他人是无法看透他的极限在哪里。</p>\n<p><strong>具备了这种无法估量的力量，就可以担负治理国家的重任。有了治理国家的原则和道理，国家就可以长久维持。国运长久，就叫做根深祗固，符合长久维持之道。</strong></p>\n<p>老子认为只有拥有了这种攻无不克的力量，掌握了天道的运转规律，拥有了大的智慧，才能够担负起治理国家的重任。这样的智者治理的国家才可以根深祗固、长生久视<strong>。</strong>读到这里，不禁感叹，五千年中华文明史，出了无数王侯将相，而又有几人达到了这种境界。老子向往的社会是一个充满智慧和文化底蕴的和谐乐土，是一个每个人都可以安居乐业而不被打扰的大同社会。几千年过去了，我们还在不断做着尝试，但我们远远还没有到达。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-62","url":"/2022/02/13/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-62/","content":"<p><strong>原文：</strong></p>\n<p><strong>道者万物之奥。善人之宝，不善人之所保。美言可以市尊，美行可以加人。人之不善，何弃之有？故立天子，置三公。虽有拱璧以先驷马，不如坐进此道。古之所以贵此道者何？不曰：以求得，有罪以免耶？故为天下贵。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>由于去年的工作比较忙碌，《道德经》这个系列有将近一年时间没有更新了，还请大家多多谅解。现在忙完了上一阶段的工作，工作和家庭逐也渐步入正轨，准备继续更新完这个系列。一方面是自我的学习和修行，另一方面也是希望可以对大家有一些启发。闲话不多说，直接上干货。让我们继续《道德经》第六十二章的学习吧～</p>\n<p><strong>道是荫庇万物之所，善人把它当成宝贝珍惜它，不善的人也要保持它。</strong></p>\n<p>这一章老子继续宣扬“道”的好处和功用。道不但是善人的法宝，不善之人也必须保有它。这里就充分体现了道的平等性和一致性。天地不仁，以万物为刍狗；圣人不仁，以百姓为刍狗。无论出发点是善或者不善，大道的规律是不会有丝毫改变。你顺从这个规律，就可以事事顺遂。相反，如果你不遵循这个规律，事事就有可能受阻。见过很多好心办坏事的人，付出了很多却得不到认可，原因可能就是说话做事的时候没有遵循这个“道”的规律。打个比方，“道”就像是一个数学公式，你只要输入一个数值就会有相应的输出结果。把这个值输入的人的想法并不会改变这个输出的结果，真正重要的是这个输入的数值本身。</p>\n<p><strong>美好动听的言辞可以换来别人对你的尊重，良好高尚的品行可以见重于人。不善的人，又怎么能抛弃他们呢？这就是为什么立天子、设置三公。</strong></p>\n<p>这里继续阐述“道”的平等性。大道是包容的，是没有好恶的。大道的标准也不会因为人的主观的道德和价值观而有所改变。但大道又是公正的，严苛的。当一个人的言行合乎大道的德行时候，大道就会嘉奖他。而当一个人的言行不符合大道的德行时候，大道就会惩罚他。美言美行所对应的结果就是获得了他人的尊重，这就是我们之前说的大道的公式。得到的结果并不会因为是假意还是真心而有所改变。所以说即使不善之人，也应保有大道，这是他们得以保全的秘诀。</p>\n<p>上古时期的天子和三公都是有德者居之。这里提出之所以立天子、设三公，就是为了通过尊崇有德之人来遵行大道，彰显大道。而这里也不要忘了，彰显大道这个行为的本身也是大道的一部分。我们在管理公司和家庭的时候，也可以有所借鉴。善行得以嘉奖，可以推广善行；恶性得以惩罚，可以遏制恶性。惩恶扬善，赏罚分明正是管理者的不二法门。</p>\n<p><strong>虽然有拱璧之贵、驷马之良而进之，不如坐进此道。自古以来如此重视道是什么原因呢？不正是由于有求于它的就可以得到满足，犯了罪过的也可得到它的宽恕吗？就因为这个，天下人才如此珍视道。</strong></p>\n<p>美玉良马虽然稀有，却远远比不上道的珍贵。道无处不在，而人们却往往不能察觉。每个人都有慧根佛性，每个人都可以是如来，但却没有几个人修成正果，这是为什么呢？因为俗世的欲望和固有观念让我们的心蒙了尘。如果能祛除妄念，恢复本心，则可以拨开云雾，看见这个无处不在的道。对于这一段，苏辙说得好：“道本在我，人患不求，求则得之矣。道无功罪，人患不知，知则凡罪不能污也。”</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-6","url":"/2020/06/06/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-6/","content":"<p><strong>原文：</strong></p>\n<p><strong>谷神不死，是谓玄牝。玄牝之门，是谓天地根。绵绵若存，用之不勤。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前文讲了天地和圣人都是无为而治，不对施以仁恩，不强加干涉，而是让万物自行其事，互相治理。并且由天地就像一个风箱的例子，得出“多言数穷，不如守中”的道理。治理天下要少出政令来干扰百姓；对于自身发展要多问初心，少一些执着；对于修身养性，要少事少言，珍爱精气。接下来继续进入第六章的学习吧～</p>\n<p>第六章的文字比较晦涩难懂，各种解释都有。尤其是“谷神”二字，让人摸不着头绪。先说通常所为大家接受的解释版本：</p>\n<p>“谷”是指山谷。山谷的中央是空无的、空虚的。因为道跟山谷一样是空虚的，所以“谷神”指“道”。《道德真经注》对此的注解是“谷神，谷中央无。谷也，无形无影，无逆无违，处卑不动，守静不衰，谷以之成而不见其形，此至物也”。</p>\n<p>“玄”是幽远微妙之意。“牝”是母性、雌性生殖机能的代名词。合起来玄牝是指微妙化生的意思。</p>\n<p>所以<strong>“谷神不死，是谓玄牝”</strong>可以理解为：<strong>“空虚的大道永远没有穷尽，它孕育了万物，是一切的起源。”</strong></p>\n<p>接下来就理解起来比较容易了。</p>\n<p>“玄牝之门”是指道生万物的转化枢纽。寓意道生万物就像小孩从母亲的产道里出来一样。“天地根”是指“天地万物变化的根本”。</p>\n<p>合起来“<strong>玄牝之门，是谓天地根”</strong>就可以理解为<strong>：“道生万物转化的枢纽，是一切天地万物变化的根本”。</strong></p>\n<p><strong>“绵绵若存，用之不勤”</strong>比较容易理解，解释为<strong>：“延续不断恒久存在，怎么用也不会有穷尽”</strong>。总体来说，按照这种理解方式，这一章还是在讲道的特征：“空虚而用之不尽，且万物皆由此而出”。</p>\n<p>-———————————————————————————————————–</p>\n<p>再说河上公版本的解释，作为参考：</p>\n<p>河上公注解认为“谷”是“养”的意思。所以<strong>“谷神不死”</strong>的意思就是<strong>“人能养神则不死也”</strong>。其中养神是指养五脏之神：肝藏魂，肺藏魄，心藏神，肾藏精，脾藏志。如果五藏尽伤，则五神去矣。</p>\n<p>对于玄牝的解释，这里也不一样。他认为，玄，天也，于人为鼻。牝，地也，于人为口。放上注解的原文，大家自己品味一下，做为一种参考，这里就不过多解释了。</p>\n<p><strong>“天食人以五气，从鼻入藏于心。五气轻微，为精、神、聪、明、音声五性。其鬼曰魂，魂者雄也，主出入于人鼻，与天通，故鼻为玄也。地食人以五味，从口入藏于胃。五味浊辱，为形、骸、骨、肉、血、脉六情。其鬼曰魄，魄者雌也，主出入于人口，与地通，故口为牝也。”</strong></p>\n<p>接着，<strong>“玄牝之门，是谓天地根”</strong>就可以理解为<strong>“鼻口之门，是乃通天地元气的根本”。</strong></p>\n<p><strong>“绵绵若存，用之不勤”</strong>解释为<strong>：“鼻口呼噏喘息，当绵绵微妙，若有若无。用气当宽舒，不当急疾勤劳。”</strong></p>\n<p>所以根据河上公版本的理解，这一章完全是在告诉人们应该怎么养生。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-60","url":"/2021/01/23/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-60/","content":"<p><strong>原文：</strong></p>\n<p><strong>治大国若烹小鲜。以道莅天下，其鬼不神；非其鬼不神，其神不伤人；非其神不伤人，圣人亦不伤人。夫两不相伤，故德交归焉。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第五十九章中老子提出了一个很重要的概念“啬”。认为只有做到“啬”，才能够有足够的智慧去治理国家和长生久视。接下来我们继续学习第六十章，看看老子又给我们讲了什么样的人生哲理吧～</p>\n<p><strong>治理大国，好像煎烹小鱼。</strong></p>\n<p>煎烹小鱼的时候，不去肠、不刮鳞，不能用力搅拌，并且不可用大火烹调。因为如果我们一顿胡乱干预，鱼肉就糜烂了。治理一个大的国家，就应该跟煎烹小鱼一样，不急于求成，也不随意发布繁琐的政令来干预社会生活。而是要让一切慢慢发生，温和而又坚定的朝着更好的方向发展。欲速则不达，用力过猛可能会导致与我们预期相反的结果。做完该做的事情之后，要让子弹飞一会儿，自然就能水到渠成。</p>\n<p>治理自身也是如此。与其在躁动和胡思乱想中徒劳的浪费精力，不如精神内守，坚持不懈把一件事做好。很多长寿和成功的人，都有一个共同的秘诀，那就是沉浸在“心流”的状态中。这种“心流”的状态是指心无旁骛的沉浸在自己热爱的事业或者兴趣爱好中，完全忘记了与之无关的所有的事情，甚至感受不到时间的流逝。在这种状态中，人们能够极大的保持心态的平和和精神的内守，从而体会到一种无法言说的幸福。</p>\n<p><strong>用“道”治理天下，鬼神起不了作用，不是鬼不起作用，而是鬼怪的作用伤不了人。</strong></p>\n<p>这句话是来解释用道来治理天下，然后天下就会太平，牛马蛇神都不敢出来惹事。其实也可以用来解释我们生活中的为人处事的态度。如果用“正道”来面对我们所处的复杂的环境，就基本不会遇到一些特别奇葩的不幸遭遇。不是说这些奇葩的遭遇消失了，而是有道之人都选择躲开了这些可能会发生的麻烦事。到底如何“正道”行事，前文也已经解释的非常清楚。我们应当效仿水德，做到“<a href=\"https://zhuanlan.zhihu.com/p/147451460\">居善地，心善渊，与善仁，言善信，正善治，事善能，动善时</a>”。如果我们这些都做到了，人们怎么能不对你尊重和信服？那些奇葩的不幸遭遇怎么会不躲着你走？</p>\n<p>其实，牛鬼蛇神和霉运不幸都是非正不入。就像苍蝇不叮无缝的蛋一样，我们精神有了漏洞，所以才会心智失守，判断和应对失误，从而遭遇不幸。所以最好的护身符不是求来的，而是修心修来的。心与道齐，一切妖魔鬼怪都会远离你。</p>\n<p>说到这里，感觉又跟前面的第五十章的内容遥相呼应，前文提到：“盖闻善摄生者，陆行不遇兕虎，入军不被甲兵；兕无所投其角，虎无所措其爪，兵无所容其刃”。这里的善摄生的人不正是用道来治国修身的人吗？我相信守住一颗道心，用道的法则来应对世界，我们会更加少的遇到各种狗血，我们的世界也会变得更加美好。</p>\n<p><strong>不但鬼的作用伤害不了人，圣人有道也不会伤害人。这样，两不相伤，所以德交归之。</strong></p>\n<p>前面说了鬼怪的作用，另外还有一种可能性会使人民受到伤害。这种伤害是来自于当权者，当权者不恰当的使用权力，会使人们的手脚和思想戴上沉重的枷锁。如果当权者是一个深谙道的原则的圣人，那么这种可能对人民造成伤害的因素也就消除了。而人民从上到下都不再受到伤害的时候，就会构建出一个非常和谐的社会。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-64","url":"/2022/02/19/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-64/","content":"<p><strong>原文：</strong></p>\n<p><strong>其安易持，其未兆易谋。其脆易泮，其微易散。为之于未有，治之于未乱。合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下。为者败之，执者失之。是以圣人无为故无败；无执故无失。民之从事，常于几成而败之。慎终如始，则无败事。是以圣人欲不欲，不贵难得之货；学不学，复衆人之所过，以辅万物之自然，而不敢为。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在上一章中老子讲了他对于为人处事的一些独到见解。做人当要恬淡寡欲、以怨报德，做事当要精耕细作、无惧困难。伟大的事业不是靠整日空想得来的，而是靠着日复一日的辛勤耕耘和付出。伟大的人格不是靠自吹自擂得来的，靠的是言而有信的言行赢得他人尊重的。接下来我们继续学习第六十四章，看看老子又给我们讲了什么样的人生哲理吧～</p>\n<p><strong>局面安定时容易保持和维护，事变没有出现迹象时容易图谋；事物脆弱时容易消解；事物细微时容易散失；做事情要在它尚未发生以前就处理妥当；治理国政，要在祸乱没有产生以前就早做准备。</strong></p>\n<p>这里继续承接上一章的内容，继续讲解做人做事的哲学。这里告诉人们一个浅显易懂，却又十分容易忽略的道理：处理一件事情不要等到问题很严重的时候再去纠正它。因为等到事物发展到一定阶段的时候，再想要改变它原本的发展轨迹将会变得十分困难。从个人的身心健康，孩子教育，企业管理，到治理国家，防微杜渐、防患于未然都非常重要。比如在那个非常有名的《扁鹊见蔡恒公》的故事中，扁鹊看到蔡桓公有病在腠里，病势尚浅，不及时治疗将会加深，但桓公不听劝告。再次遇到蔡桓公，告诉他病在肌肤，并提出了治疗方法，但桓公仍不听劝。第三次遇到桓公的时候指出并已经入腑脏，还有治疗方法，但桓公还是不予理会。最后发现桓公已经病入骨髓，不久而亡。这个故事中，如果桓公可以在疾病的初期就采取积极治疗，怎么还会等到病入膏肓，不治身亡呢？任何事物都有它的发展规律，掌握了规律才能防止事物向不利的方向发展，做到防微杜渐。</p>\n<p><strong>合抱的大树，生长于细小的萌芽；九层的高台，筑起于每一堆泥土；千里的远行，是从脚下第一步开始走出来的。</strong></p>\n<p>冰冻三尺非一日之寒，滴水穿石非一日之功。任何事物都是慢慢演变而来，现在的果必然是之前的因造的业。一个人成功，那是由无数个岁月打拼而来的。一个人的失败，也是由不断的惰性消磨而来。每一个看似不起眼的小决定，其实都在塑造一个人。比如上学的时候，是选择认真把作业完成再去玩，还是先玩痛快再去想作业的事情？工资到手的时候，是选择先满足自己的欲望，还是选择延迟消费？吃饭的时候，是选择吃健康的蔬菜水果，还是选择撸串啤酒？这些都是我们生活中的一个个小的决定，在当时看来可能一点都不起眼。可是如果这些决定变成了一个不需要经过大脑的习惯之后，所带的力量却是巨大的。选择先把作业完成的，学习工作会做的有声有色。选择延迟消费的，经济状况会越来越好。选择健康饮食的，身体会十分健康。</p>\n<p>另外，这一章我个人觉得包含了“无为”的真谛。所谓无为是春风潜入夜般的不动声色的去作为，是在事物还在萌芽阶段的时候就介入干预已达到预期效果。这里再举一个扁鹊的故事来说明这个道理。《史记》中记载，扁鹊家有三兄弟，当魏王问及他们家三兄弟谁医术最高的时候，扁鹊回答说：“大哥医术最为高明，二哥其次，而我扁鹊是最差的一个。”魏王惊讶地问：“那为什么只有你名动天下，他们两个一点名气都没有？”扁鹊答曰：“我大哥的医术之高，可以防患于未然，一个人的病未起之时，他一望气色便知，然后用药将其调理好，所以天下人都以为他不会治病，他便一点名气都没有。我二哥的能耐，是能治病初起之时，防止别人酿成大病。病人刚开始感冒咳嗽时，他就用药将人治好了，所以我二哥的名气仅止于乡里，被人认为是治小病的医生。”扁鹊又答：“我呢，就因为医术最差。所以一定要等到这个人病入膏肓、奄奄一息，然后下虎狼之药，起死回生。这样，全世界便都以为我是神医。想想看，像我大哥这样治病，人的元气丝毫不伤，我二哥治病，这个人元气稍有破损就补回来了，像我这么治病呢，命是救回来了，可元气大伤，您说，我们家谁医术最高明？”</p>\n<p><strong>有所作为的将会招致失败，有所执着的将会遭受损害。因此圣人无所作为所以也不会招致失败，无所执着所以也不遭受损害。人们做事情，总是在快要成功时失败，所以当事情快要完成的时候，也要像开始时那样慎重，就没有办不成的事情。</strong></p>\n<p>做人做事要有一颗平常心，不要有过分索求的心态。这样就不会导致失败和遭遇损失。想要留住一把沙子的最好策略是张开双手，而不是攥紧拳头。抓的越紧，反而会走的越快。同样，抓住人心的最好方式是放开双手，让对方感觉到舒适，而不是方方面面的限制。在处理事情的时候，要学会因势利导、无为而治、没有执念，这样就不会遭遇失败和挫折。另外，还要做到始终如一，慎终如始。不能因为有了一点成就，就改变了初心。想要把一件事情完美做好，就要始终贯彻小心谨慎、心态平和、埋头苦干的精神。</p>\n<p><strong>因此，有道的圣人追求人所不追求的，不稀罕难以得到的货物，学习别人所不学习的，补救众人所经常犯的过错。这样遵循万物的自然本性而不会妄加干预。</strong></p>\n<p>从本章前面的几句话就可以看出来做一件事情，做重要的是有一颗稳如磐石的内心。具体说来就是，不惧困难，也不轻视小事，在细节处深耕，一步一个脚印的踏踏实实做事情，没有执念也不胡乱作为，心态平和、不骄不躁。这也是圣人的成功之道，圣人之所以为圣人是因为他们更加追求事物的本质，更加遵循这个世界运转的规律来做事，所以他们不被物质和常人所追求的名利所迷惑。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-63","url":"/2022/02/15/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-63/","content":"<p><strong>原文：</strong></p>\n<p><strong>为无为，事无事，味无味。大小多少，报怨以德。图难于其易，为大于其细；天下难事，必作于易，天下大事，必作于细。是以圣人终不为大，故能成其大。夫轻诺必寡信，多易必多难。是以圣人犹难之，故终无难矣。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一章讲了天之道，这一章又继续开始讲人之道。怎么为人处事这是一门学问，在某一方面有所成就的人也必然对为人处事有自己的一些独到的见解。那么我们就来看一看这一章中，老子的处事哲学吧。</p>\n<p><strong>以无为的态度去有所作为，以不滋事的方法去处理事物，以恬淡无味当作有味。</strong></p>\n<p>无为不是不作为，而是不乱作为，不刻意而为，却把事情解决的恰到好处。以不滋事的方式去处理事情是对无为在处理事务的时候的进一步解释。俗话说，世间本无事，庸人自扰之。有风轻云淡的心态，世间也就没有多少事情可以让人烦恼了。最后以无味做有味，意境更上一层，讲的是精神上的境界。其实这里也包含了以有味做无味的意思在里面。凡人所认为有味的事情，不过是吃喝玩乐，多巴胺的刺激而已。如能将无味当所有味，则是看破了在有味之下的无味。庄子也曾说过“至乐无乐，至誉无誉”，可以说是对于这句话的完美诠释。最高的快乐是一种无喜无乐无忧亦无愁的状态，是一种逃离尘世羁绊的洒脱，是一种无需外界评价的淡然。</p>\n<p>*<em><strong>以大为小，以多为少，以德报怨。</strong>处理问题要从容易的地方入手，实现远大要从细微的地方入手。天下的难事，一定从简易的地方做起；天下的大事，一定从微细的部分开端。</em>*</p>\n<p>这几句话在讲做人做事的具体方法。首先讲做人，大小、多少、德怨，看的都淡一些。在一定时空所谓的大，换了条件就变成了小。我们平时所谓的小仇小怨，也可能并不值得一提。就像两只蚂蚁为了一点点面包屑打得你死我活，但换我们看来会觉得没有必要也不值一提。当我们的精神境界足够高的时候，就会一览众山小，心境会开阔很多。其次讲做事，在处理问题的时候，最重要的是一步一步来做，从简单处、细小处入手，坚持不懈，必能成功。无论在什么行业，这几乎都是一个通用的成功法则。《劝学》篇中也曾反复强调用心专一的重要性，比如：“不积跬步，无以至千里；不积小流，无以成江海。骐骥一跃，不能十步；驽马十驾，功在不舍。锲而舍之，朽木不折；锲而不舍，金石可镂。”看似浅显易懂的道理，却是一语道破天机。知道易、行道难。如能把这几句话贯穿于生活工作中，必能收获良多。</p>\n<p><strong>因此，有“道”的圣人始终不贪图大贡献，所以才能做成大事。那些轻易发出诺言的，必定很少能够兑现的，把事情看得太容易，势必遭受很多困难。因此，有道的圣人总是看重困难，所以就终于没有困难了。</strong></p>\n<p>有成就的“圣人”之所以把大事做成了，就是因为他们一直在埋头苦干，一步一个脚印的来做事情。而那些整天想着要搞一个大新闻的人，因为飘在空中，脱离实际，很难真正做出什么成果。另外，我们做人也是一样，少许诺，少吹牛，多办实事，这样才能建立起靠谱的形象。面对困难，我们不能被困难吓倒，但也千万不能忽视困难。要有一颗平常心，把功夫做到细处，抽丝剥茧一样一点点把它解决掉。这就是为什么“圣人”做出了成就的关键点所在。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-65","url":"/2022/05/03/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-65/","content":"<p><strong>原文：</strong> </p>\n<p><strong>古之善为道者，非以明民，将以愚之。民之难治，以其智多。故以智治国，国之贼；不以智治国，国之福。知此两者，亦稽式。常知稽式，是谓玄德。玄德深矣，远矣，与物反矣，然后乃至大顺。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在前两章中老子讲述了他对于做人和做事的一些观点。踏踏实实做人，认认真真做事，天道就会给与相应的回馈。接下来我们继续学习第六十五章，看看老子又给我们带来了什么样的人生智慧吧~</p>\n<p><strong>古代善于为道的人，不是教导人民知晓智巧伪诈，而是教导人民淳厚朴实。人民之所以难于治理，乃是因为他们使用太多的智巧心机。所以用智巧心机治理国家，就必然会危害国家，不用智巧心机治理国家，才是国家的幸福。</strong></p>\n<p>这里老子讲述了他的治国理念。他认为国家难于治理的根源在于人民知晓太多的智巧和伪诈，从而导致不断地争权夺利，尔虞我诈，社会动荡不断，人民苦不堪言。老子从纷乱的社会现象中抽丝剥茧，认为一切动乱的根源是人们崇尚智巧。统治阶层不用大道治国，大德感人，反而喜欢玩弄权谋，从而导致人心不古，各怀鬼胎。</p>\n<p>很多人根据这句话认为老子提倡愚民的政策，又有很多人给老子洗白，认为老子所说的智和愚乃是诈伪和忠厚。至于谁是谁非，恐怕这样的争论永远也不会有结果。我认为对此也不必花太多时间用来解读他的真实意图是什么。一千个人心中有一千个哈姆雷特，可能每一个角度都有它正确的地方。但有一点可以肯定的是，老子提倡跟万物融为一体，回归人最初本性之善。</p>\n<p><strong>了解这两种治国方式的差别，就是一个法则，经常了解这个法则，就叫做“玄德”。玄德又深又远，和具体的事物复归到真朴，然后才能极大地顺乎于自然。</strong></p>\n<p>以智治国与不以智治国是两种截然不同的治国理念。深入来说，这两种治国理念的差别蕴含了天地之间的法则，也就是所谓的“玄德”。《道德经》在前面第十章中的解释过何为“玄德”：“生之、畜之，生而不有，为而不恃，长而不宰，是谓玄德。” 所以说，不以智治国是不以个人目的为导向的治国理念，是生而不有、 为而不恃、长而不宰、不求回报的大道境界，同时也是顺乎天地自然的可持续发展策略。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-66","url":"/2022/06/02/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-66/","content":"<p><strong>原文：</strong></p>\n<p><strong>江海之所以能为百谷王者，以其善下之，故能为百谷王。是以圣人欲上民，必以言下之；欲先民，必以身后之。是以圣人处上而民不重，处前而民不害。是以天下乐推而不厌。以其不争，故天下莫能与之争。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>我们继续学习《道德经》的第六十六章，看看老子又从大自然中领悟了什么样的人生道理吧~</p>\n<p><strong>江海所以能够成为百川河流所汇往的地方，乃是由于它善于处在低下的地方，所以能够成为百川之王。因此，圣人要领导人民，必须用言辞对人民表示谦下，要想领导人民，必须把自己的利益放在他们的后面。所以，有道的圣人虽然地位居于人民之上，而人民并不感到负担沉重；居于人民之前，而人民并不感到受害。天下的人民都乐意推戴而不感到厌倦。因为他不与人民相争，所以天下没有人能和他相争。</strong></p>\n<p>如果我们仔细观察我们周围的世界，我们就会发现一草一木，一花一树，乃至于一粒尘土，一滴水珠，莫不蕴含着世间的大道。大千世界看起来纷繁复杂，但背后却是至简的大道在不断推动事物在不断演变。著名的物理学家费曼先生曾经提出了一个非常有趣的提问：“一粒沙子和一块石头有什么不同？一块石头和一座大山又有什么不一样的地方？而一座大山和月球又有哪些本质不同？”这个三联问揭示了我们现代物理学研究的本质方法，也是老子道德经中一贯用的推理方法。那就是我们找出事物间相通的地方，然后进行归纳分类来大大简化工作量，从而揭示事物的本质。这也是我为什么作为一个理工科博士，这么推崇道德经的原因。现在我们回过头来再看费曼先生的问题，沙子、石头、大山、还有月球，本质来说都是石头或者更广义的来说是物质，所以我们是不是对沙子进行研究就可以了解月球乃至整个宇宙的真理？现代物理学正是沿着这条轨道在不断的突破寻求着世界的真相，研究极大时空尺度的天体物理正在与研究极小时空的粒子物理相互融合。超弦理论正在做着试图建立一个统一场理论的努力，从而揭示宇宙的秘密。</p>\n<p>回到主题，这个章节中老子通过观察江海发现所有的江河最终会汇入大海。那么江河为什么会汇入大海呢？首先，它把自己放低了。其次，它足够广博。这里面就包含了领导和管理的智慧。作为一个合格的领导人，想要对一个组织进行有效领导和管理，那么就要做到谦下，有肚量。管理的关键就在于此。想要带好一个团队，首先就要把团队的利益放在自身利益之前。如果自己和员工或者下属的利益不可兼得的时候，有魅力的领导人会选择自己受损失。这不仅仅是一种道德理论，也是很多管理学大师自己亲身体验和感悟后的心得。</p>\n<p>一花一世界，一叶一菩提。希望各位读者也可以从平凡的生活中感悟自己的道。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-61","url":"/2021/03/01/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-61/","content":"<p><strong>原文：</strong></p>\n<p><strong>大国者下流，天下之交，天下之牝。牝常以静胜牡，以静为下。故大国以下小国，则取小国；小国以下大国，则取大国。故或下以取，或下而取。大国不过欲兼畜人，小国不过欲入事人。夫两者各得其所欲，大者宜为下。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第六十章中老子讲了治大国若烹小鲜的道理。管理的最高境界是无为而治，是用大道来引导民众。接下来我们继续学习第六十一章，看看老子又讲了哪些人生哲理吧~</p>\n<p><strong>大国要像居于江河的下游那样，使自己处在低位，那么天下百川河流就会交汇在这里，从而处在天下雌柔的位置。</strong></p>\n<p>江海虽大却处在低位，然而百川却向它汇聚而来；同样，大国如果能居大而处下，则天下都会争相归附，人才尽收于囊中，所以说大国者下流也。牝，是指雌性，在这里蕴含静而不求，物自归之的意思。</p>\n<p><strong>雌柔常以安静守定而胜过雄强，这是因为它居于柔下的缘故。所以，大国对小国谦下忍让，就可以取得小国的信任和依赖；小国对大国谦下忍让，就可以见容于大国。</strong></p>\n<p>这里接着就解释了雌柔有什么特点，为什么老子这么推崇慈柔的力量。我们如果仔细观察就会发现，在自然界中，雌性动物往往比较安静。尤其在求偶过程中，雄性是非常躁动的主动出击，而雌性则刚好相反，它们则高冷得多，在慎重而又仔细的筛选之后才会做出选择。老子认为这就是慈柔力量的体现，在某种程度上也是一种无为而治。</p>\n<p>从这一条自然现象中，老子延伸出了他治国和管理的理念。如果大国处于高位而能够谦下忍让，则能够取得小国的信任和依附，从而万邦来朝。同样的规则也适用于小国，如果小国对大国谦下忍让，就可以在大国中间有自己的生存空间，见容于大国。所以说，无论国家大小，能持谦畜人，则无过失。</p>\n<p><strong>所以，或者大国对小国谦让而取得大国的信任，或者小国对大国谦让而见容于大国。小国修下，自全而已，不能令天下归之。大国修下，则天下归之。两方面各得所欲求的，大国特别应该谦下忍让。</strong></p>\n<p>小国处于下的位置是为了有自己的生存空间，不被大国过分榨取。大国处于下的位置是为了取信于小国，从而让天下归顺。如何能让它们两全其美，各得其所呢？在两者的关系平衡中，大国就应该特别注意要保持谦下忍让的态度。</p>\n<p>如果觉得国家这个概念离我们普通人太过于遥远，可以换成公司，家庭，和个人，这些道理也是同样适用的。比如在公司领导想要让下属敬服，那么就要谦下忍让，虚怀若谷，包容属下的一些棱角。如果员工想要有自己的位置和尊严，就要谦下低调，认真听取他人尤其是领导的建议，保持开放和学习的姿态。在这两者关系中，如果想要两全其美，各取所需，领导的态度就尤其关键。所以说，跟一个好的领导，可以让你收获很多东西，并且获得更多的尊严和自由。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-7-1","url":"/2020/06/07/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-7-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>天长地久。天地所以能长且久者，以其不自生，故能长生。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前文第六章再次提到道是恒久存在、孕育一切的世界本源。第七章，继续探讨道为什么可以恒久存在。</p>\n<p><strong>天地是恒久存在的。天地之所以能够恒久存在的原因是因为它们不自生，所以才能长生</strong>。</p>\n<p>自从有人类开始，天地就一直存在。天降甘露，地长万物。万事万物都在按照其自然规律在有条不紊的生存繁衍。上天从不轻易轻易展示自己的力量，来告诉万物空气阳光雨水都是它的功劳。大地也从不轻易展示自己的威力，来告诉万物，你们生长繁衍都是我的恩惠。这就是前文提到的“生而不有，为而不恃”的道理。</p>\n<p>我们甚至觉得世间的万事万物都是理所应当的存在的，从来没想过阳光、空气、雨水、土壤都是大自然的恩赐。天地也从来不奢求万物的回报，都任其自然发展，哪怕是人类对自然进行了破坏，也不会强加干涉对此进行制止和惩罚。因为在自然中一切自有其规律，人类破坏生态环境，自然会有相应的后果。就像前面章节提到的“天地不仁，以万物为刍狗”，天地从不刻意施以恩仁，同样的也不刻意施以束缚，都是任其自然发展。</p>\n<p>那么为什么天地刻意长久存在呢？老子认为这个关键点就在于天地不自生。不自生就是不为自己而生，没有意识到自己在生。天地没有意识、没有思想，不知道自己在生，没有生的概念也就无所谓死了。也正是因为没有生的概念，天地也就不会有为了自己谋私利的想法，从而也就不为自己而生。</p>\n<p>所以说，一个国家、一个组织、甚至一个个体想要长久存在就要效法天地。不为自己而生，要利益大众，不求回报。如果一个组织中高层领导所做的一切都是为了老百姓，老百姓哪会有不拥护这个组织和领导高层的的呢？父母全身心的为了孩子，孩子哪能不知恩图报，让爸妈过得安心幸福的呢？一个人养生也是如此，如果一个人没有口腹之欲，怎么会伤害身体喝酒撸串呢？所以说无论什么组织形式想要长久存在，就要控制自身的欲望，要多想想他人，少想想自己。不自生，故能长生。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-8-1","url":"/2020/06/09/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-8-1/","content":"<p><strong>原文：</strong></p>\n<p><strong>上善若水。水善利万物而不争，处衆人之所恶，故几于道。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第七章中老子从观察天地中得到启发，从而得出了一个结论：“天地所以能长久者，以其不自生，故能长生”。所以圣人效法天地，无我无私，最终以其无私而成其私。第八章，老子继续观察自然界中的现象，来体会道的特征。</p>\n<p><strong>最美好的事物就像水一样。水善于利益万物但却不争，处在众人都不喜欢的地方，所以非常接近于道。</strong></p>\n<p>老子非常推崇水的德行，后文章也会反复提及。那么老子为什么这个推崇水德呢？</p>\n<p>首先，水善于利益万物，但却从不为自己而争。世间万物没有可以离开水而存活的，无论动物、植物、还是微生物都离不开水。人们可以几天不吃饭还可以活下来，但如果没有水，很快就不行了。可以说，水几乎是生命存在的根本。但水却从来没有表彰过自己的功劳，也没有向万物索要过一分回报。永远都在地球上周而复始的循环，默默付出，从来不为自己而争。</p>\n<p>第二，水可以随物就形，容器是什么样，它就变成什么形状。但只要去除外界束缚，水又回变回原来的状态。顺从外界环境，但却从不被外界环境真正影响改变。也许这就是和光同尘、外圆内方、通流而不合污的体现吧。</p>\n<p>第三，水处在众人都不喜欢的地方。观察就可以发现，水最喜欢往低处流，而且从不躲避污垢。水避高趋下，除污纳垢，体现的是一种谦虚，一种伟大。普通人都争相往上走，去获得功名利禄。而圣人却走向老百姓，去了解并且解决他们的疾苦，不为自己而谋私利。</p>\n<p>第四，水是刚柔并济的。滴水可以穿石，洪水可以决堤，说明水不是一味的柔弱，而是柔中带刚，刚柔并济。小人为自己的利益相争，可以陷害无辜忠良。圣人不但不为自己争，而且可以为了万民而赴死。</p>\n<p>第五，水又是包容的。海不择细流，故能成其大。大海汇聚团结了一切可以汇聚的河流，从不高傲自大，从而会纳百川，壮大了自己。</p>\n<p>正是因为水有以上这些特点，所以老子非常推崇水的德行，认为水是世间万物最接近于道的事物了。</p>\n<hr>\n<p>下一篇文章会继续分析第七章的后半部分，来看看我们应该怎么效法水德。</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《道德经》-7-2","url":"/2020/06/08/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-7-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>是以圣人后其身而身先；外其身而身存。非以其无私耶？故能成其私。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第七章前半节分析了天地为什么能够恒久存在。老子得出的结论是，这是因为天地不自生，没有意识到自己是有生命的，也不为自己而生，所以才能够长生。那么这个道理，有什么用呢？老子接下来就把这个概念拓展到了人。</p>\n<p><strong>所以圣人都是把自己的利益放在最后考虑，反而却成为天下的楷模；把自己的危亡置之度外，反而得以生存。正因为他的无私，反而让他获益，成就了他的私。</strong></p>\n<p>天地不自生，反而能长久；圣人不为己，反而能成其私。这真是一种不争而争的大智慧，争是不争，不争是争，夫唯不争，天下莫能与之争。普通人的为名为利的争夺，是能让人看出来的争，其实是比较愚蠢的争夺方式。这里举一个可能不太恰当的例子，清朝康熙年间九子夺嫡，大部分阿哥们都对皇位表现出了浓厚兴趣，真是斗得你死我活，在利益面前上演了一部宫廷大戏。然而只有四皇子胤禛深谙“不争是争，争是不争”的道理，对皇位表现的毫不在意，只是一门心思替他父皇分忧解难，哪里有困难就去哪里。在忙碌之余，也只是耕田种地，作诗赏花。最终在白热化的皇子斗争中得以保全自身，并且让父皇感觉到了他是个可以托付大事的人，最终凭着这种不争取得了最终胜利，夺得了皇位。</p>\n<p>看到这里，有人说老子是个阴谋家。我觉得这是误会了老子的真实意思。老子在前面提到了，天地不自生，所以长生。天地不自生，不是假装不为自己考虑，而是完全没有自我意识，没有分别心，是非常纯粹的。圣人也是如此，圣人把自己的利益放在后面，不是因为自己想得到更大的利益，而是发自本心的一种做法，圣人无私这是圣人的行动，而成其私，这是事情发展的必然结果。这个成其私的结果，也不是圣人无私做事的目的。事实上，圣人对于这个私与不私的结果丝毫没有放在心上。</p>\n<p>为什么我说前面那个例子可能不太恰当呢，因为这可能会误导一些人，认为这是一种可以为自己谋取利益的手段。我只能说，这可以是道的一种运用，但老子更希望大家效法天地，做一个纯粹的没有分别心的人，一个不为己而谋利的圣贤之人。退一步讲就算是为了最终目的而委曲求全，不争而争，也不能算是个阴谋，这应该是一个堂堂正正的阳谋。有几个人在巨大利益面前可以保持这种不争而争的平稳心态呢？如果心里一直想着我要争，最后做出来的却是不争，又有几个人不会人格撕裂呢？所以说，就算胤禛为了得到皇位做出的不争而争的姿态，在康熙帝看来已经超出其他几位阿哥很多了。</p>\n<hr>\n<p>总结一下，第七章老子观察天地，得出他们可以长久存在的秘密在于不自生。所以圣人都效法天地，不在乎自己的利益得失，将自己的私利放在最后，然而结果却是因为圣人的无私，最终成就了他们的私。</p>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《金刚经》 第七品 无得无说分","url":"/2020/04/24/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%B8%83%E5%93%81-%E6%97%A0%E5%BE%97%E6%97%A0%E8%AF%B4%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！于意云何？如来得阿耨多罗三藐三菩提耶？如来有所说法耶？”须菩提言：“如我解佛所说义，无有定法名阿耨多罗三藐三菩提，亦无有定法，如来可说。何以故？如来所说法，皆不可取、不可说。非法、非非法。所以者何？一切圣贤，皆以无为法而有差别。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上文佛提到，众生不但不应该执迷于我、人、众生、寿者相，也不应取法相和非法相。在这一品继续对法和非法相进行了进一步阐释。</p>\n<p><strong>“须菩提，你说如来得到过无上正等正觉吗？如来说过法吗？”须菩提说：“根据我对佛法的理解，没有一个固定的‘法’被称作无上正等正觉，也没有固定的法，是佛可以说出来的。”</strong> 这里提到‘法’是不可说不可名的。认为吃斋念佛是佛法是不对的，认为好善乐施是佛法也是不对的。‘法’没有固定形式，会随着环境、对象的改变而发生变化。老子也说：<strong>“天下皆知美之为美，斯恶已;皆知善之为善，斯不善已</strong>” 。如果全天下都觉得施舍穷人、尊老爱幼是善，那么这种善就是一种不善之举了。因为由此而来的伪装可能会充斥天下，也有人会因此倚老卖老，不劳而获。所以说美善丑恶都是在特定条件的一种标准而已。佛所法也是同样道理，佛所说法是针对人性的缺点而指出的一条修行之路，从而克服自身弱点，得证佛法。但执迷于佛口中讲的法，佛经中记录的法，反倒不如没有法。有道是：“<strong>尽信书，不如无书</strong>”。佛所讲法只是一条通向大道的路，起的是引领作用。条条大路通罗马，不同的悟道之人，都有着自己独特的路，但得证佛法之人参透的又都是世界的本质规律。这里其实还是在告诉众生要透过现象看本质，不要迷于相。法相也是一种相。</p>\n<p><strong>“为什么呢？因为如来所说的法，都不可以执迷、不可以讲说。他们不是法、也不是非法。为什么这么说呢？因为一切圣贤，都只是因为无为法而有差别。”</strong> 佛所讲法不是‘法’，但同时也不是‘非法’。比如说帮助穷人是佛法吗？既是佛法又不是佛法。为什么呢？如果帮助的目的是为了得到回报，或者怀着施舍之心帮助他人，那么这就不是佛法。相反，心无所住的帮助别人，觉得这只是再平常不过的一件小事，这就又是佛法。佛所讲法是引导众生开悟、发现自己得证解脱之路的一座灯塔。学佛的过程是明心见性的过程，明心见性，就是明的自己的心，见的自己的性。一切不再执迷的时候，就会眼前开阔，得证无上正等正觉。一切的圣贤，包括不同的佛、甚至老子、孔子、耶稣、默罕默德，他们证得的果没有差别，只是因为他们得证的路不同而已。</p>\n","categories":["哲学思考","金刚经"],"tags":["无得无说分","金刚经","金刚经解说"]},{"title":"《道德经》-8-2","url":"/2020/06/10/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-8-2/","content":"<p><strong>原文：</strong></p>\n<p><strong>居善地，心善渊，与善仁，言善信，正善治，事善能，动善时。夫唯不争，故无尤。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第八章前半节老子高度赞扬了水的德行，说水是世界上最接近于道的东西了。在前面我们分析了水有什么样的特性，接下来我们再来看看老子对此的看法，然后分析下应该从哪些方面向水学习。</p>\n<p><strong>居所善于选择地方，心善于像深渊一样静默深远，与人交往善于给予仁爱，说话善于信守诺言，管理善于疏导，做事善于发挥才能，行动善于把握时机。这是因为他不争，所以没有怨咎。</strong></p>\n<p>水避高趋下，善于选择低地，不争奢华。水向下，圣人亦向下，不求荣华富贵而求内心清净，不求声名远播，只求踏实做事，不求仁爱贤德之名，只求问心无愧。</p>\n<p>胸怀大志者，不逞口舌之快，内心就像一潭深水一样古井不波，深不可测。对于外界的批判或是褒奖，不在意，也不争辩。保持独立思考的能力，保持克制情绪的能力，内心对人对事自有评判。</p>\n<p>水利泽万物，不求回报。仁者爱人，与人交往也应不失仁爱之心。“老吾老以及人之老，幼吾幼以及人之幼”，天下大同，福泽天下。多一些仁爱，少一些争夺，哪会有搞不好的各种社会关系。</p>\n<p>水静则明烛须眉，平中准，大匠取法焉。水可为天地之鉴，万物之镜，就是因为它的诚信，它的真实不虚。诚信是一个人立身处世的根本。对于不能做到的事情，不可贸然答应。对于答应了的事情，就一定要做到。“轻诺必寡信，多易必多难”，轻易许诺的后果就是失去个人信用。一个无信之人，必然不为社会所认可。另外还要对自己诚信，不自卑不自傲，也不自欺欺人，认清自己的真实状态，认清自己的真实需求。</p>\n<p>水善于洗涤污垢，平准高下，以柔克刚。治，从水从台（胎的本字）。自水的初始处、基础、细小处开始，以水的特征为法，进行的修整、疏通，是为治。治理国家、公司、家庭，甚至管理个人情绪，应该善于疏而不要堵，善于柔而不要刚，善于公平公正而不要厚此薄彼，善于洗涤污垢而不要藏污纳垢。</p>\n<p>水随物赋形，善于适应不同的环境，功用也无穷。水可以用来饮用，用来游泳嬉戏，用来交通运输，用来洗涤污渍，用来降温，甚至可以用来切割物体。子曰：“君子不器”，说的也是君子不能像一个器皿一样，只有一种用途。人要善于学习，善于应对各种复杂问题。在家是丈夫，是父亲，也是儿子，在外面是员工，是同事，也是上司，马桶家电坏了是维修工，管理家庭账目的时候是理财师，看书的时候是学者，写个人博客的时候是作家。人要对生活保持好奇心，不要被自己的身份给限制住，要敢于尝试新鲜事物，做一个多功能的人。</p>\n<p>水冬凝春泮，涸溢不失节，懂得把握时机。孟子讲天时地利人和是成功的先决条件。其中天时又是第一位的，只有时机合适，才能把握住机会。四季轮回有时，五谷生长有时，禽兽繁衍有时，市场荣衰也有时，同样，人的性情心性也有其发展的阶段性。善于把握时机，在合适的时间做该做的事情。一个典型的例子就是股神巴菲特，他就特别善于把握时机，在股价被严重低估的时候买入，在股价被高估的时候卖出，从而成为了一个股市传奇人物。</p>\n<p>等到“七善”具备，那么就“夫唯不争，故无尤”了。因为人们已经像水一样非常接近于道的状态，所以一举一动莫不合于道，成就上善，而没有怨咎，从而随心所欲而不逾矩。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道德经"]},{"title":"《道德经》-9","url":"/2020/06/11/%E3%80%8A%E9%81%93%E5%BE%B7%E7%BB%8F%E3%80%8B-9/","content":"<p><strong>原文：</strong></p>\n<p><strong>持而盈之，不如其已；揣而锐之，不可长保。金玉满堂，莫之能守；富贵而骄，自遗其咎。功遂身退天之道。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>第八章老子通过观察水的一些特性，得出了为人处事应该遵循的几个原则。做好“居善地，心善渊，与善仁，言善信，正善治，事善能，动善时” 就能够没有差错，与道接近。第九章老子继续探究道的特征。</p>\n<p><strong>保持盈满，不如适时停止；把铁器磨得又尖又利，锐势难以保持长久。</strong></p>\n<p>事物旺盛到了极点，必然走向衰落；人快乐至极，就会产生悲哀；太阳到了正中，就会向西偏移；月亮过了中秋，就开始走向残缺。所以人一定要持满戒盈，成功得意之时，一定要有所克制。曾国藩就很懂得这个道理，他虽然被誉为晚清“中兴第一名臣”，但偏偏给自己的书房起名为“求缺宅”。目的就是要时时警醒自己，凡事不可苛求圆满。只要没有圆满，就有改进的空间，人生就有追求。一旦到达圆满，就没有了进步的余地，就只能开始走下坡路。满招损，谦受益。老子在后面章节也提到：“大成若缺，其用不弊”，其意思是最大的成功、最完美的东西，好像也有缺陷，但它的作用永远不会衰竭。</p>\n<p>太过尖锐，锋芒过盛的事物总会遭到打压。比如太过挺拔的树木，大风第一个把它刮倒，太过锋利的针尖，最是容易折断。这里还是在告诫我们不要过分追求卓越，一旦做过了，有可能就会自身受到伤害。想到了现在的学生课业压力非常大，家长老师社会把重重压力和希望施加在了孩子身上。在这样的环境下，有些孩子只追求第一名，一旦失败，就会特别容易出现心理问题。追求卓越是好事，但不能把自己压榨到极限。事缓则成，事情都是一点点积累，最终把事情做好的。拔苗助长、急功近利只能把事情往坏的方向推进。</p>\n<p><strong>金玉满堂，无法守藏；由于富贵而生出骄横，那是自己留下的祸根。</strong></p>\n<p>再讲讲财富，一个人能够获得多少财富靠的可能是幸运，也可能是聪明才智。但一个人能守住多少财富，就靠的是修养和智慧。不懂得持满戒盈的人，就算获得了一笔财富，也很难真正守住。如果财富过多，不知收敛，反而会给自己招来祸患。匹夫无罪，怀璧其罪。拥有很多财富，本身就是一件令人觊觎的事情。如果再因为有很多财富而产生一种高人一等、骄横跋扈的心理，那么离祸患就不远了。</p>\n<p><strong>一件事情做的圆满了，就要含藏收敛，这是符合自然规律的道理。</strong></p>\n<p>总结来说，一件事情如果做的圆满了，就要懂得收敛。范蠡与勾践灭吴国之后，选择了急流勇退。因为他知道“狡兔死，走狗烹；飞鸟尽，良弓藏”的道理。范蠡身为布衣，经商积攒了万贯家财，受到齐王赏识，他又将家财散尽，再次离开。而和范蠡同为开国元勋的文种，没有急流勇退，最后没过多久就被勾践赐死。所以说，越是春风得意、处于高位、拥有财富的时候，也越是离危险最近的时候，这个时候就要时刻警醒自己。</p>\n<hr>\n","categories":["哲学思考","道德经"],"tags":["道家","道德经"]},{"title":"《金刚经》 第九品 一相无相分","url":"/2020/04/24/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%B9%9D%E5%93%81-%E4%B8%80%E7%9B%B8%E6%97%A0%E7%9B%B8%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！于意云何？须陀洹能做是念：‘我得须陀洹果’不？”须菩提言：“不也，世尊！何以故？须陀洹名为入流，而无所入，不入色声香味触法，是名须陀洹。”“须菩提！于意云何？斯陀含能做是念：‘我得斯陀含果’不？”须菩提言：不也，世尊！何以故？斯陀含名一往来，而实无往来，是名斯陀含。”“须菩提！于意云何？阿那含能做是念：‘我得阿那含果’不？”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>须菩提言：“不也，世尊！何以故？阿那含名为不来，而实无不来，是名阿那含。”“须菩提！于意云何？阿罗汉能做是念，‘我得阿罗汉道’不？”须菩提言：”不也，世尊！何以故？实无有法名阿罗汉。世尊！若阿罗汉作是念：‘我得阿罗汉道’，即著我人众生寿者。世尊！佛说我得无诤三昧，人中最为第一，是第一离欲阿罗汉。我不作是念：‘我是离欲阿罗汉’。世尊！我若作是念：‘我得阿罗汉道’，世尊则不说须菩提是乐阿兰那行者！以须菩提实无所行，而名须菩提是乐阿兰那行。</strong></p>\n<p>这一品其实还是在讲菩萨、众生要不住于法，并且连着举了好几个例子。这一品的翻译起来比较简单，就不逐句翻译了，但有几个名词是梵语的音译，需要解释一下。小乘佛法有四圣果，“须陀洹”是初果罗汉，已经断掉我、人、众生、寿者相。“斯陀含”是二果罗汉，在断掉见惑的基础上，进而断除欲界思惑。但只断了九品思惑中的六品，仍有三品还未断尽。“阿那含”是三果罗汉，在“斯陀含”的基础上进而断除了后三品思惑。“阿罗汉”是四果罗汉，断掉了一切欲界、色戒、无色界的一切见惑和思惑。</p>\n<p>“须陀洹”翻译过来的意思是“入流”，也叫“预流”。“流”是指“圣人之流”。须陀洹是凡夫通过修行，断尽见惑，开始见到大道，进入圣人之流。“斯陀含”翻译过来是“一往来”，得此名是因为斯陀含还未断尽思惑，还需再来人间受生一次，故名一往来。“阿那含”翻译过来是“不来”，意思是阿那含已经断尽思惑，不需要再来人间受生。“阿罗汉”是佛陀十大称号之一。“乐阿兰那行”直接翻译过来是“喜欢到寂静无人的地方去修行”。</p>\n<p>这一品的意思很直白，无论是一果罗汉还是四果罗汉，都不能有“我得了道”的一丝念头。一旦有了这个念头，其实就是没有得了道。说起来很绕口，但却很是发人深省。这个道理在《道德经》中也是被反复提及，例如：“<strong>上德不德，是以有德；下德不失德，是以无德</strong>”。最好的德行是从没有觉得自己很有德行，每天德不离口的人，反倒没有德行。现代社会，在媒体的放大下，彷佛到处都是名师、大德，但其中真正胸中有丘壑的又有几位呢？孔子说的更要直白一点：“<strong>不患人之不己知，患不知人也</strong>”，还有：“<strong>不患人之不己知，患其不能也</strong>”。得了什么果位，有了什么名声和地位，这些都不重要，不应当是我们关注的重点，重点应当是我们自身。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","一相无相分"]},{"title":"《金刚经》 第二十一品 非说所说分","url":"/2020/05/08/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B8%80%E5%93%81-%E9%9D%9E%E8%AF%B4%E6%89%80%E8%AF%B4%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！汝勿谓如来作是念：‘我当有所说法。’莫作是念，何以故？若人言：如来有所说法，即为谤佛，不能解我所说故。须菩提！说法者，无法可说，是名说法。”尔时，慧命须菩提白佛言：“世尊！颇有众生，于未来世，闻说是法，生信心不？”佛言：“须菩提！彼非众生，非不众生。何以故？须菩提！众生众生者，如来说非众生，是名众生。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前文一直在讲不要着各种相。各种相着了实，就算诸相具足也不能见如来。这里接着前文继续讲法和佛也不可着实。先上翻译：</p>\n<p><strong>“须菩提，你不要以为佛有这样的念头：我应当有所说法。为什么不要有这样的想法呢？如有人说佛有所说法，那他就是在诽谤佛，就是不能理解佛法的缘故。须菩提，所谓说法，其实无法可说，只是称他在说法。” 这时，长老慧命须菩提问佛道：“世尊，可有这样的众生，在您寂灭后，听见此经，他还生不生信心呢？”佛说：“须菩提，那些众生，并非真正的众生，也非非众生。”“这是什么原因呢？”“须菩提，所谓众生，他之所以成为众生，也就是因为他们是非众生，只是叫他们为众生。”</strong></p>\n<p>这里讲到了佛法也不可以取实。释迦摩尼佛从未讲过一种叫做佛法的东西。如来所说之法只不过是给世人解去束缚、指明道路。但如果说他说出来的话就是法本身，这就完全错了。世尊说了，如果有人有这种想法，那么就是在诽谤佛。世尊这么讲，是要让世人去掉法执。尽信书，不如无书，尽信法，不如无法。不是说佛说之法就不重要了，而是说，要通过佛说之法去思考，去真正理解弦外之心、核心要义。如果执迷于文字中、语言中的佛法，就会陷入教条主义。佛说之法会根据对象不同、时机不同而采取不同的方式应机而说。对于一个人来说是法，换一个人可能就不是法。</p>\n<p>前文也有过对于众生能否能生信心的讨论。前文是这么回答的：“<strong>莫做是说。如来灭后，后五百岁，有持戒修福者，如此章句，能生信心，以此为实。当知是人，不于一佛二佛三四五佛而种善根，已于无量千万佛所，种诸善根</strong>。” 这里的回答略微有些不同，说的是“<strong>彼非众生，非不众生</strong>”。人人都有佛性，迷时是众生，悟了就是佛。众生成佛之后，还是社会的一份子，外在看来也还是众生，但内心已经超脱，所以又不是众生。所以前面也说过：“<strong>如是灭度无量无数无边众生，实无众生得灭度者</strong>。”也是在讲每个众生都有佛性，不执迷即可成佛。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","非说所说分"]},{"title":"《金刚经》 第二十七品 无断无灭分","url":"/2020/05/14/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B8%83%E5%93%81-%E6%97%A0%E6%96%AD%E6%97%A0%E7%81%AD%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！汝若作是念：‘如来不以具足相故，得阿耨多罗三藐三菩提。’须菩提！莫作是念，‘如来不以具足相故，得阿耨多罗三藐三菩提。’须菩提！汝若作是念，发阿耨多罗三藐三菩提心者，说诸法断灭。莫作是念！何以故？发阿耨多罗三藐三菩提心者，于法不说断灭相。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前面几品一直在讲不要着实相，也就是不要着“有”。不可着色声香味触法各种相，不可有我、人、众生、寿者的分别，不可以执着于定法，也不可以色相音声见如来。一切都不可着实相，那么我们是不是可以认为一切都是虚无的？从这一品开始呢，世尊就开始着手于讲“无”。</p>\n<p><strong>“须菩提，如果你有这种想法：‘如来不是因为具有圆满身相的缘故，而修得了无上正等正觉的大智慧。’须菩提，不要有这种想法。如果你有这种想法，发心要修成无上正等正觉的人，就会说一切法都是空的。不要这样想！为什么呢？发心要修成无上正等正觉的人，不会说一切法都是空的。”</strong></p>\n<p>前文说可以以三十二相而观如来吗？须菩提先说可以的，后面又说不可以的。两次回答佛都没有给予正面的回答。这是因为说可以通过三十二相观如来是对的，说不可以通过三十二相观如来以也是对的。都是事实的一部分，但又不是事实的全部。首先，不能执着于相，不是因为各种相就可以见到如来，这些相都是表相，不是根本。但又不可脱离一切相，因为这些相是如来本性的外显，相由心生，不修行心灵，又不可有这样的相。</p>\n<p>佛得证圆满，就要通过修行，不断断除各种欲念，修习福德和智慧，最终会在相上会有所显化，成就三十二相，八十种随形好。不圆满这些，就不能得证圆满。如果执着于空，认为一切都是虚无的，认为不需要以具足之相就能得证无上正等正觉的智慧，就是诸法断灭。这种诸法断灭，会导致发无上正等正觉之心之人，修行无所依靠，没有路径可循。甚至会导致行为放荡不羁，陷入欲海而无法自拔。这是比着有更危险的事情。</p>\n<p>如来前面也说过，菩萨于法，应无所住，行于布施。无所住是要将内心打扫干净，清澈透亮，无欲无求，不住于外界的种种相，但行为上还是在布施，在帮助众生，度化众生，慈悲为怀，以众生心为己心。也是道家所说的为无为而无不为。心无所为，而利益了一切众生。</p>\n<p>世界是无的，但同时也是有的。有无本就相生，何必要执着于区分彼此。如果一切空无，又何来的这个世界。世界的一切生生不息，无不显示了有一个隐藏在背后的规则在运转。但背后的看不见的手，又让我们感觉到生活如梦如幻。</p>\n<p>学佛的目的是离苦得乐，世间的生老病死，是每一个人无法摆脱的宿命。除却生老病死，还有种种执着妄想，让人深陷其中，看不清真相，各种情绪让人内心无法平静。着了实相，是深陷在各种苦中无法自拔，着了空相，是躲避现实的自欺欺人。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","无断无灭分"]},{"title":"《金刚经》 第二十三品 净心行善分","url":"/2020/05/10/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B8%89%E5%93%81-%E5%87%80%E5%BF%83%E8%A1%8C%E5%96%84%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>复次，须菩提！是法平等，无有高下，是名阿耨多罗三藐三菩提；以无我、无人、无众生、无寿者，修一切善法，即得阿耨多罗三藐三菩提。须菩提！所言善法者，如来说即非善法，是名善法。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品世尊说到他从来没有得到过一种叫做阿耨多罗三藐三菩提的法，佛法不可着实，不可着相。这一品再进一步讲为什么佛法无实无虚，不可着相。先上翻译：</p>\n<p><strong>“其次，须菩提，佛法讲究平等，没有高下之分，所以称其为无上正等正觉的智慧。用无我、无人、无众生、无寿者的心念，来修持一切善法，就能得到阿耨多罗三藐三菩提。须菩提，我们说的善法，也即非善法，只是称其为善法。”</strong></p>\n<p>这里讲为什么没有无上正等正觉呢？因为只要有了无上这种比较的词语出现，就代表了还有分别心，就有比这个差一些、低一些的法。但真正的佛法是没有高低美丑之分的，无任何分别心，所以才是无上正等正觉，也就只能姑且称之为无上正等正觉。</p>\n<p>凡夫所做的善事，都是源自于求福德，求回报。有了这种心，善行也是有为之善，就不会有真正的大福德。有了执著，内心就还不够清净，那么就无法修得无上的智慧。只有远离一切相，而出自本心的来修持善法，才能得到无上正等正觉的智慧。但这里说的善法，又不是刻意为之的善法，有了为善之心，就不是真正的善法。内心清净，没有为善之心，而行善行；行了善行，又无所觉所行之行为善行，才是善法，也就只能姑且称之为善法。“善法”其实就是人的本性中的自然的本性，而涤除杂垢，自见本性。这里的“善行”跟老子说到的“无为”意思很像，无为不是什么都不做，而是不刻意为之，正所谓无为而无不为。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","净心行善分"]},{"title":"《金刚经》 第二十九品 威仪寂净分","url":"/2020/05/16/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B9%9D%E5%93%81-%E5%A8%81%E4%BB%AA%E5%AF%82%E5%87%80%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！若有人言：如来若来若去、若坐若卧，是人不解我所说义。何以故？如来者，无所从来，亦无所去，故名如来。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品说到要心无所住，而行布施。居中而行，不着有，不着空，方可修成阿耨多罗三藐三菩提心，得无上福德。这一品继续承接上文，接着讲佛法的境界。</p>\n<p><strong>“须菩提，如果有人说：如来若来若去，若坐若卧，是人们不了解我所说的佛法的义理。为什么这么说呢？如来如来，就是没有所来，也没有所去，所以叫做如来。”</strong></p>\n<p>题目中的“威仪”是指，佛的三十二相，八十种好，万德庄严之相。“寂静”是非动非静，寂然之体。威仪寂静就是一切威仪都是非动非静，无来无去。如果看如来还有来去坐卧，就是还有着相。如来本性就是无来无去，是世界的本源和本质规律，一切外在的都在成坏毁空，唯有这个如来本性是如如不动。</p>\n<p>前文说如来不可观，但又非无相。不可执着于相，也不可说诸法断灭。要知道，相由心生，是法的外在体现，但又不可只凭相而观如来。佛法的境界就是心无所住，而行布施。菩萨利益众生而心中无有所求，才能得成于忍，参透诸法如意。也就是孔子说的随心所欲不踰己，一动一卧都蕴含着佛法。但这又只是佛法的外在体现，不是佛法，真正的佛法是那个真如本性，世界本质规律，无来又无去。</p>\n<hr>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","威仪寂净分","第二十九品"]},{"title":"《金刚经》第二十五品 化无所化分","url":"/2020/05/12/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%BA%94%E5%93%81-%E5%8C%96%E6%97%A0%E6%89%80%E5%8C%96%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！于意云何？汝等勿谓如来作是念：‘我当度众生。’须菩提！莫作是念。何以故？实无有众生如来度者。若有众生如来度者，如来则有我、人、众生、寿者。须菩提！如来说：‘有我者，则非有我，而凡夫之人以为有我。’须菩提！凡夫者，如来说即非凡夫。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>这一品继续讨论不要着相，不要执着。前面讲众生不要着佛像，这里讲佛也不要着众生相。先上翻译：</p>\n<p><strong>“须菩提，你想想，你们这些人不要说佛有这样的心念：‘我应当灭度众生。’须菩提，不要有这样的想法。”“为什么呢？”“实际上并没有众生需要佛来灭度的。 如说有众生需要佛来灭度，那么佛就着了我、人、众生、寿者的相。须菩提，佛说有我，即非有我，然而凡夫俗子却以为确实有我。须菩提，凡夫，就是佛所说的非凡夫，只不过名叫凡夫。”</strong></p>\n<p>先说题目“化”就是度化，化无所化就是度化了众生，其实并无众生可度化。无所化而化之，就是以平等心度众生，内心无我与他人的区别，无佛与众生的区别。</p>\n<p>另一个角度来说，度众生的过程也是在度己。老板开公司给员工创造了工作机会，员工努力工作让公司正常运转。在这过程中，双方是平等的，也都得到了自己想要的东西。老板既不需要怀着施舍之心给员工工资，员工也不需要怀着奉献精神给公司工作。大家都没有那么“伟大”，只是等价交换、社会协作中的一个环节。一个有朝气有希望的公司，总是会让所有人都得益。大家发自内心的朝着一个方向而努力，而不是被什么伟大的情怀而洗脑。只有这样才可以长久，才符合世界的本质属性。</p>\n<p>佛度众生也只是发自本心的一个过程，有度众生之实，而无度众生之心，才是佛度众生的精髓。真正的奉献，要看做的事情，而不要听喊的口号。佛非佛，凡夫非凡夫。佛和众生本质并无任何差别，佛只是少了妄想执著，而凡夫还在妄想执著中挣扎。佛心慈悲，出自本心地去帮助凡夫揭开事实的真相，从而让他们跳出妄想执著。这件事是佛出自本心愿意做的事情，而不是怀着要度人之心而去做的事情。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","化无所化分"]},{"title":"《金刚经》 第二十二品 无法可得分","url":"/2020/05/09/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%BA%8C%E5%93%81-%E6%97%A0%E6%B3%95%E5%8F%AF%E5%BE%97%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>须菩提白佛言：“世尊！佛得阿耨多罗三藐三菩提，为无所得耶？”佛言：“如是，如是。须菩提！我于阿耨多罗三藐三菩提乃至无有少法可得，是名阿耨多罗三藐三菩提。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品讲到了不要讲佛法看成某种固定的看得见或听得到的东西。无有定法叫做佛法。也不要把众生看成与佛是不同的两种人。佛迷时即是众生，众生觉悟即是佛。任何特定事物都可以在一定条件下相互转化，不可对某种形象过于执迷。这一品承接上一品，继续在讲同一个道理。先上翻译：</p>\n<p><strong>须菩提问佛说：“世尊，佛所得的无上正等正觉的大智慧，也就是什么也没得到吗？”佛回答道：“正是这样，正是这样！须菩提，我于无上正等正觉，是无所得，甚至一星半点的佛法都没得到，只是说我成就了无上正等正觉的大智慧。”</strong></p>\n<p>这一品对于实相否定的更为彻底，直接说无上正等正觉这种法的实体都是不存在的。没有一种法叫做无上正等正觉。正所谓，菩提本非树，明镜亦非台，本来无一物，何处惹尘埃。学世间之法都是在做加法。从一生下来就开始不断地学习各种各样的东西，仿佛人就像一个容器，各种好的坏的习性知识都一股脑的往里面灌。可是学习佛法就是一个做减法的过程，把多年学过的东西，抽丝剥茧，一样一样再扔出去，直到做到心中空无一物。心中既然空无一物，又哪里有什么无上正等正觉这种东西？</p>\n<p>生命只是一场心性的历练，是一个逝远而返的过程。刚出生时心灵纯净，空无一物，然后经过社会的历练，变得复杂而患得患失，最后再返璞归真，心灵就得到了升华。心中空无一物，无善亦无恶，无美亦无丑，就是无了我相、人相、众生相、寿者相。没有一切执迷，就得到了所谓的无上正等正觉。有了欲求，内心就会有倾向，就会有分别，自然无法准确判断事物，也就会迷失。不要觉得无上正等正觉是多么高深的智慧，其实很简单，每个人都可以做到。但同时又很难，就算知道途径，又有几人可以完全放下内心执着，去除一切欲求。壁立千仞，无欲则刚；海纳百川，有容乃大。无欲而有容，就是佛所说的无上正等正觉吧。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","无法可得分"]},{"title":"《金刚经》 第二十八品 不受不贪分","url":"/2020/05/15/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E5%85%AB%E5%93%81-%E4%B8%8D%E5%8F%97%E4%B8%8D%E8%B4%AA%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！若菩萨以满恒河沙等世界七宝布施；若复有人知一切法无我，得成于忍，此菩萨胜前菩萨所得功德。须菩提！以诸菩萨不受福德故。”须菩提白佛言：“世尊！云何菩萨不受福德？”“须菩提！菩萨所作福德，不应贪著，是故说不受福德。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前面讲到了不要着实相，也不要着空相。有无相生，空实一体。入世做事不可太执着，也不可太虚无飘渺。应该居中而行，不偏不倚。心无所住，而行于布施。踏踏实实做利益众生的事，但不生出任何妄想贪念之心。这一品接着上文，继续在解释这个概念。</p>\n<p><strong>“须菩提，假如有菩萨用装满恒河沙那么多世界的七宝来布施，另有人懂得一切的法都是无我的，从而得证无生法忍（无有生灭，诸法受忍），这个菩萨的功德胜过前面菩萨的功德。这是因为菩萨不受福德的缘故。”须菩提答佛道：“世尊，为什么菩萨不受福德？””须菩提，菩萨所做的福德，不应该贪著，所以说不受福德。”</strong></p>\n<p>这里再次用满恒河沙等世界七宝布施来进行比喻，说明不住相布施的功德。学佛不要以贪受福德为目的。读到这里我觉得《金刚经》跟《道德经》中所讲的智慧是非常相像的。就像前文提到的，一切圣贤，皆以有为法而有差别。这里的含义可以用《道德经》中的一句话来解释，“上德不德，是以有德，下德不失德，是以无德”。做了利益众生的事情，而不贪著功德，才是至高的功德。也可以用另一句来说明“夫唯不争，而天下莫能与之争”。不争的功德，是天下人都不可以比拟的功德。贪著福德而去布施，其实是没有福德的。佛的胸怀是广大的，同时看待众生又是平等的。所以，站在这样的高度看事物，是没有度化众生，也没有得到福德这种概念的。</p>\n<p>这里再讲一下无生法忍，字面解释是无有生灭，诸法受忍。《大智度论》里面说“无生法忍者，于无生灭诸法实相中，信受通达，无碍不退，是名无生忍。” 《华严经》中解释的更加详细 “若无生则无灭，若无灭则无尽，若无尽则离垢，若离垢则无差别，若无差别则无处所，若无处所则寂静，若寂静则离欲，若离欲则无作，若无作则无愿，若无愿则无住，若无住则无去无来。” 所以这样的境界可以概括为在无生无灭中，参透一切相，得证如来智慧。</p>\n<hr>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","不受不贪分"]},{"title":"《金刚经》 第二十六品 法身非相分","url":"/2020/05/13/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E5%85%AD%E5%93%81-%E6%B3%95%E8%BA%AB%E9%9D%9E%E7%9B%B8%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！于意云何？可以三十二相观如来不？”须菩提言：“如是！如是！以三十二相观如来。”佛言：“须菩提！若以三十二相观如来者，转轮圣王即是如来。”须菩提白佛言：“世尊！如我解佛所说义，不应以三十二相观如来。”尔时，世尊而说偈言：“若以色见我，以音声求我，是人行邪道，不能见如来。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品讲到凡夫非凡夫是名凡夫。但如来有三十二相异于凡人，可不可以以三十二相观见如来呢？</p>\n<p><strong>“须菩提，你说可以通过佛色身的三十二种相而观见如来吗？”须菩提说：“可以，可以，可以通过佛色身的三十二种相而观见如来。”</strong></p>\n<p>这里再次提到了观见佛的三十二相是不是可以见到如来？在第十三品也提了相似的问题，当时须菩提回答到：“不可以三十二相见如来，三十二相，即是非相，是名三十二相。”但绕了一圈之后，须菩提这里给出了一个颇为蹊跷的回答，说到可以通过三十二相来观如来。</p>\n<p>先解释一下这里的“观”的意思，这个词很关键。“观”是指通过观察虚妄的表相世界，而达到空谛的智慧。而第十三品中提到的是可不可以以三十二相“见”如来。这里只有一字之差，但意思又是很大不同。“观”是指用心来观想，而“见”是指用眼睛看。前面说不可以着了外在的色相，所以不可以用眼睛来见如来。但可不可通过内心观想来见如来本性呢？这里须菩提给出的是肯定的回答。到底佛对此如何评价呢？接着看后面佛的再次开示。</p>\n<p><strong>佛说：“须菩提，如果可以以三十二相观见如来，那么转轮圣王就是如来。”</strong></p>\n<p>佛没有直接给须菩提答案，而是说如果你说的对的话，那么转轮圣王也有跟如来一样的三十二相，那么转轮圣王就是如来了。转轮圣王是人间最有福报的圣王，以“十善法”来教化四大部洲的人们，使这个世间变成道德纯善的世间，因此他的国土中人心都向善。相由心生，因为在人间有莫大的福德，所以显示出的是最好的三十二相。释迦摩尼佛为了要教化在世间的众生，让众生知道他是真实不虚的存在，也要显示出一个相，所以显现出了跟转轮圣王一样的第一福德相，‘三十二相’。但如果凭借三十二相就可以观想如来，转轮圣王也有同样的三十二相，那么转轮圣王就是如来了。这种说法显然是错误的。转轮圣王只是世间最有福德的凡夫，还未成佛。</p>\n<p><strong>须菩提说到：“如果我理解您的话正确的话，不应该以三十二相观见如来。”当时，世尊说了一句偈颂：“如果以色见我，以音声求我，是人行邪道，不能见如来。”</strong></p>\n<p>须菩提听完之后立刻就改了口，说不应当以三十二相观如来。世尊也没有正面回答他，而说了一句四句偈。这就是世尊教导人的一种方式，循循诱导，但很少直接告诉你，你是对的还是错的。一切要让你自己去思考。如果以为眼睛看到的佛的色身就是佛，或者以为耳朵听到的佛的声音就是佛，是在走歪门邪道，不可能见到如来的。金刚经一直都在告诉我们不要着相，色声香味触法被称作“六尘”就是六种污染我们心灵的东西。着了相，心就被尘迷住了，就不能有一颗清净心来见如来真我了。三十二相，也是一种相，有所住，也是有所迷。凡夫大多以为求神拜佛上香祷告就是虔诚的信徒，就可以得福报，死后就可以去西天极乐世界。佛在这里就对这种想法进行了斥责，说这些人简直是在走邪道，完全没有理解佛法的含义，是不可能见到如来真意的。佛苦口婆心劝说世人，你们不要拜我，拜我也没用。学佛修的是自己的内心，心中无一物，晶莹透彻，无有任何妄想执念，就是把佛学到家了。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","法身非相分"]},{"title":"《金刚经》 第二十四品 福智无比分","url":"/2020/05/11/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E5%9B%9B%E5%93%81-%E7%A6%8F%E6%99%BA%E6%97%A0%E6%AF%94%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！若三千大千世界中所有诸须弥山王，如是等七宝聚，有人持用布施；若人以此《般若波罗蜜经》，乃至四句偈等，受持、为他人说，于前福德百分不及一，百千万亿分，乃至算数譬喻所不能及。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前面讲到了诸相非相，诸佛非佛，诸众生非众生，诸佛法非佛法，诸善行非善行。一切都不可着了实相，不可被固定的表相观念束缚住。一切事物都在相互依存，相互转化。有无相生，长短相形。至善无善，至德无德。心中如能空无一物，即能见到诸相非相。所见诸相非相，即见如来。这一品还是在继续讨论这个话题，福德也不可着了实相。先上翻译：</p>\n<p><strong>“须菩提，假如三千大千世界中，所有的像须弥山王这么多的七宝聚在一起，有人拿它用做布施。如有另有一个人对这部经，甚而至于只对其中的四句偈，来坚持接受，修持诵读，给他人讲解，那么前面作布施之人的福德，赶不上这个人的百分之一，百千万亿分之一，以至无法用数字来表达的几分之一。”</strong></p>\n<p>这里再次提到了受持读诵《金刚经》的福德，跟第八品、第十一品、第十五品、第十九品的意思很相近。再多的财宝布施不如法布施。给人钱财，不如教人解脱的智慧。</p>\n<p>如果把这个道理说的浅显一点，可以拿贫穷这个话题进行讨论。很多人很多书都在讨论这个话题，多年来争论不休。但有一点可以肯定的是，导致贫穷的原因有很大一部分是因为穷人和富人之间的思维的差异。研究发现，很多因中彩票而一夜暴富的穷人，往往两三年或者更短的时间就会把手里的钱财挥霍一空，然后日子过的比中彩票之前更加的困难。还有很多贫穷的人总是被各种事情推着走，每天陷于忙碌之中，却只够挣到勉强糊口的钱。其实这都是思维的问题，是没有掌握生活的智慧。如果掌握了更多的生活的智慧，可能这些人就会在有横财或者横祸的时候应对的更加得当。对于生活和自身的掌控会更加的有节奏。</p>\n<p>掌握了现世智慧都可以让人活的更加幸福，何况掌握了无上正等正觉的智慧呢？自己返璞归真，获得无上智慧，再去帮助他人明心见性，看破这世间的梦幻泡影，这样的福德跟七宝布施的福德相比，岂不是要大得多。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","福智无比分"]},{"title":"《金刚经》 第二十品 离色离相分","url":"/2020/05/07/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%8D%81%E5%93%81-%E7%A6%BB%E8%89%B2%E7%A6%BB%E7%9B%B8%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！于意云何？佛可以具足色身见不？”“不也，世尊！如来不应以具足色身见。何以故？如来说：具足色身，即非具足色身，是名具足色身。”“须菩提！于意云何？如来可以具足诸相见不？”“不也，世尊！如来不应以具足诸相见。何以故？如来说：诸相具足，即非具足，是名诸相具足。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品讲到诸相非相、诸心非心、诸法非法，诸福德非福德。佛法是非实非虚的，世人偏向于着实，所以佛陀给开示说不可以着实。一切相、一切法着了实相就如管中窥豹，无法窥探无上的智慧。这一品延续上一品，继续讨论种种诸相是不是实的。</p>\n<p><strong>“须菩提，我在问你，可以凭佛的圆满色身见到佛吗？”“不可以，世尊。不应该以圆满色身来见如来。为什么呢？因为如来说，圆满的色身，即非圆满色身，只是名为圆满色身。”“须菩提，你说可以以圆满的种种诸相见如来吗？”“不可以，世尊，不可以以圆满的种种诸相来见如来。为什么呢？如来说，种种诸相具足（圆满），即非诸相具足，只是叫做诸相具足。”</strong></p>\n<p>具足的意思是没有亏欠，也就是圆满。这一品与第五品和第十三品讲的差不多，都是在说诸相非相。佛反复强调，不要执着于眼睛看到的，耳朵听到的，鼻子闻到的，口中尝到的，触觉摸到的，脑袋里想到的。一切的相，在观察者角度变化或者是外部条件变化的时候，就都变了。诸相不过是因缘而生的幻像而已。</p>\n<p>圆满的色身为什么不能见到佛呢？因为如来色身不是如来。如来是无所去无所来，可以理解为世界的本源规律。这种规律是不会因为外部的变化而变化，是事情的真相，也就是佛教说的如来法身。以肉身之躯，是无法见如来的，因为看到肉身之躯的人还停留在被所见的物质界所迷惑的阶段，有所迷惑就不能得证大智慧，也就无法见如来。其他诸也是相同理，具足诸相还是诸相，所以无法见如来。只有见到诸相非相，即见如来。</p>\n<p>那么所见到的一切难道都是虚无的、自己想象的吗？恐怕很多人，看到这里就会产生疑惑。觉得这门哲学实在是太虚无飘渺，很多人也对此进行抨击。我觉得佛法不是一门让人逐字逐句来研究的书本哲学，而是一门教人解惑修得智慧的实用哲学。对于不同的对象，佛法也是不同对待的。佛法不是实的，但也不是虚的，佛法和诸相是非实非虚的。世人着有，所以世尊讲无。如果世人着空，世尊反倒应该讲有了。色即是空，空即是色。空色本一体，何必太过执着。就像我们看到的任何一个物体，看起来是实的，但如果用高倍显微镜观察，就会发现，原子中间充满了空隙。原子再放大观察，就会发现原子核只占了整个原子非常小的一部分，大部分都是空的。我想，如果再把实体部分的原子核再放大，结果也会是一样的。这又跟中庸的道理是一样的。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","离色离相分"]},{"title":"《金刚经》 第二品 善现启请分","url":"/2020/04/24/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%8C%E5%93%81-%E5%96%84%E7%8E%B0%E5%90%AF%E8%AF%B7%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>时，长老须菩提在大众中即从座起，偏袒右肩，右膝着地，合掌恭敬而白佛言：“希有！世尊，如来善护念诸菩萨，善付嘱诸菩萨。世尊！善男子、善女人，发阿耨多罗三藐三菩提心，云何应住，云何降伏其心？”佛言：“善哉，善哉。须菩提！如汝所说，如来善护念诸菩萨，善付嘱诸菩萨。汝今谛听！当为汝说：善男子、善女人，发阿耨多罗三藐三菩提心，应如是住，如是降伏其心。”“唯然，世尊！愿乐欲闻。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>这一品讲的是须菩提为大众请佛说法。虽然佛的一言一行中无不透漏着佛法，但凡夫俗子不能领悟，为使大众开悟，须菩提就在此为众生请佛说法。“善现”是须菩提的多种中文翻译中的一种，又有别称“空生”、“善吉”。因为梵语“须菩提”有这三种意思，本着多意不译的原则，大多数情况是直接称为须菩提。</p>\n<p><strong>这时名叫须菩提的长老，从众比丘中离座站起来，右肩袒露，右膝着地，合上手掌十分恭敬地对佛说：“举世稀有的世尊啊，您善于护持惦念各位菩萨，善于叮咛嘱咐诸菩萨。</strong>“</p>\n<p>须菩提先是赞美了世尊。世尊这样的尊者真是世间少有，在寻常生活中，穿衣乞食无不在说法，无不在行法。如来是佛的十种德号之一。如来者，无所从来，亦无所去，故名如来。如来善于护持惦念诸菩萨，善于叮咛嘱咐诸菩萨。对于众生、弟子，佛是博爱的无私的。佛唯欲于众生共成佛道。</p>\n<p>接下来须菩提开始请佛说法。<strong>“世尊，对于世上的发了阿耨多罗三藐三菩提心的善男子、善女人，他们的心应该在哪里安住？他们应该怎么样降服他们的心？”</strong></p>\n<p>阿耨多罗三藐三菩提是梵文，翻译过来的意思是无上正等正觉。正等即平等，对于世间万物真正的平等。对于人来说是：男女平等、老幼平等、肤色平等、人我平等。更大的角度来说是人与众生平等，无论人、有生命的动物、甚至无生命的物体一切皆平等。《道德经》里也曾提到：天地不仁，以万物为刍狗；圣人不仁，以百姓为刍狗。皆是此理。正觉即是真正的觉悟，是看破一切虚妄，参透一切世间法。佛度有缘人，佛讲法是讲给已经发了阿耨多罗三藐三菩提心的人听的。对于一心求道，但悟性不高的人，给予语言上的更加直接的启示。相对于方法来说，发心更重要。可谓是求仁才能得仁。再高明的导师也唤不醒一个装睡的人。只有发了心，才会孜孜不倦探求到彼岸的方法。</p>\n<p><strong>佛回答道：“好啊好啊，问得好！须菩提，就像你所说的，佛要求各位菩萨好好守护自己的心念，常常警示自己。现在你认真听着，我来告诉你。”</strong></p>\n<p>佛听完之后，连赞了两声“善哉”。是对须菩提能够在他日常的举动中体会到佛法感到欣喜，也是对须菩提对于挂念大众的赞美。然后世尊又对须菩提说，你说的对啊，如来善于护持惦念诸菩萨，善于叮咛嘱咐诸菩萨。世尊不但在讲佛法中护念众生，也在出入行走、一举一动中护念众生。说到此处，世尊开始讲法。</p>\n<p>“<strong>发了阿耨多罗三藐三菩提心的善男子、善女人应当这样安住其心，这样降伏其心。”</strong>佛法不可说，只可参。这里说了法但又等于没有说法。这里“如是” 有三种解释：“本来如此”、“真是如此”和“应该如此”。真实行事、本心行事、不妄求、去除后天带来的习气即可安住其心、降伏其心。</p>\n<p><strong>须菩提说：“是这个样子的，世尊，我很愿意听您再讲下去。”</strong></p>\n<p>须菩提听到这里，明白了世尊的意思。回应道：“是这个样子的”。但须菩提是为大众请法，希望世尊可以给大众细细道来，也希望自己可以再听的更透彻。接着回应一句“愿乐欲闻”。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","善现启请分"]},{"title":"《金刚经》 第八品 依法出生分","url":"/2020/04/24/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%85%AB%E5%93%81-%E4%BE%9D%E6%B3%95%E5%87%BA%E7%94%9F%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！于意云何？若人满三千大千世界七宝以用布施，是人所得福德，宁为多不？”须菩提言：“甚多，世尊！何以故？是福德即非福德性，是故如来说福德多。”“若复有人，于此经中受持，乃至四句偈等，为他人说，其福胜彼。何以故？须菩提！一切诸佛，及诸佛阿耨多罗三藐三菩提法，皆从此经出。须菩提！所谓佛法者，即非佛法。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前文提到诸菩萨、诸众生不应住法，也不应住非法。没有定法叫“阿耨多罗三藐三菩提”，也没有定法可说可讲。这一品继续讲如果理解了佛所讲的意思，并且为他人解说的福德。</p>\n<p><strong>“须菩提！你说，如果有一个人，他拿充满三千大千世界的财宝统统用来布施，这个人的福德多不多？”须菩提说：“非常多，世尊。为什么呢？因为这种布施得来的福德是世间有的福德，而不是不生不灭的福德实相，所以如来只能说福德很多。”</strong> 这里世尊用世人通常认为的用财宝布施的福德来揭示佛法。用财宝布施福德多不多呢？须菩提给出了答案，这种福德按照世人理解的福德来说是非常多的，如来随顺世俗来鼓励世人，所以只能说福德多。但要知道，真正的布施是不住相布施，哪里又有什么福德呢？所以这种七宝布施的福德还停留在没有真正理解佛法的基础上而生出的福德。</p>\n<p>佛接着说法：“<strong>如果有人，能够信奉受持此经，哪怕只受持其中的四句偈等，并且为他人解说，那么所得福德超过用七宝布施的福德。</strong>” “四句偈”一般解释为有四句所构成的偈颂，往往能涵盖经纶佛法的要义。根据这种说法，《金刚经》中的四句偈，有人就指出应当是指最后几句：“<strong>一切有为法，如梦幻泡影，如露亦如电，应作如是观</strong>”。还有说法，说四句偈是指：<strong>空身、空心、空性、空法</strong>。但因为在佛教经典中，从来没有详细解说什么是四句偈，所以谁也不能论断什么是四句偈。无论哪种解释，这里所说的意思是什么明了的，就是哪怕没有信奉受持整部经典，只是理解其中一部分，并且给他人解说，福德都要比之前所说的七宝布施要多。</p>\n<p><strong>“为什么呢？须菩提，一切诸佛，以及诸佛的得证无上正等正觉的法门，都是从这部经中讲的义理推演出来的。须菩提，大家普遍认为的所谓的佛法，其实不是真正的佛法。”</strong> 接着解释，为什么信奉受持这部经典并给他人解说的福德多。一切所谓佛法的源泉其实就是这部经的核心思想：“<strong>凡有所相，皆是虚妄”</strong>。看破这种相的虚妄，其实就不需要法了，因为已经真正理解世界的本质。《庄子》在外物篇中也说到：“<strong>筌者所以在鱼，得鱼而忘筌；蹄者所以在兔，得兔而忘蹄；言者所以在意，得意而忘言</strong>”。庄子在其他篇章中还有更加激烈的言辞，说：“<strong>君之所读者，古人之糟魄已夫</strong>”。所以说，“<strong>所谓佛法者，即非佛法”。</strong></p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","依法出生分"]},{"title":"《金刚经》 第十一品 无为福胜分","url":"/2020/04/26/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E4%B8%80%E5%93%81-%E6%97%A0%E4%B8%BA%E7%A6%8F%E8%83%9C%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！如恒河中所有沙数，如是沙等恒河，于意云何？是诸恒河沙宁为多不？”须菩提言：“甚多，世尊！但诸恒河尚多无数，何况其沙。”“须菩提！我今实言告汝：若有善男子、善女人，以七宝满尔所恒河沙数三千大千世界，以用布施，得福多不？”须菩提言：“甚多，世尊！”佛告须菩提：“若善男子、善女人，于此经中，乃至受持四句偈等，为他人说，而此福德胜前福德。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>接着<a href=\"https://shileilei.com/%e3%80%8a%e9%87%91%e5%88%9a%e7%bb%8f%e3%80%8b-%e7%ac%ac%e5%8d%81%e5%93%81-%e5%ba%84%e4%b8%a5%e5%87%80%e5%9c%9f%e5%88%86/\">上一品</a>，前文提到佛陀拿自身举例子，来说明不应该执着于法。并且告诉了诸菩萨们应该“应无所住，而生起心”，心中无所住、无所想，自然就能生出无上正等正觉的清净心。这一品重点在于开示善男子、善女人。跟<a href=\"https://shileilei.com/%e3%80%8a%e9%87%91%e5%88%9a%e7%bb%8f%e3%80%8b-%e7%ac%ac%e5%85%ab%e5%93%81-%e4%be%9d%e6%b3%95%e5%87%ba%e7%94%9f%e5%88%86/\">第八品“依法出生分”</a>意思上有很大重叠，有兴趣的可以回到第八品来细细品味。由于在前面几品中，有很多地方已经讲解过，这里没有太难理解的地方，先直接上翻译。</p>\n<p><strong>“须菩提，就如恒河中有无数的沙粒，每一颗沙粒再做一条恒河，你说，这样所有的恒河中的沙子多吗？”须菩提说：“非常多，世尊。这样的恒河数量都数不清，更何况里面的沙子呢。”“须菩提，我今天实话告诉你：如果有善男子、善女人，用可以装满我前面所说的沙子那样多的三千大千世界的七宝用来布施，得到的福德多吗？”须菩提回答到：“非常多，世尊。”佛告诉须菩提说：“如果善男子、善女人，受持这部经典，哪怕只有其中的四句偈，并给他人解说，这样所获的的福德远胜前面所说的七宝布施的福德。”</strong></p>\n<p>核心意思只有一个，再多的财宝布施不如法布施。财宝布施可以暂时解决人们生活中眼前的问题，但是如果没有法布施，没有看破虚妄的各种相，人们不可能从根本上幸福。幸福的本质是内心的平安喜乐，如果有一颗无上正等正觉的心，外界会很难影响到一个人，这样的人得到的是平静的无上法喜。</p>\n<p>世上的信男信女都喜欢用财货布施、喜欢修塔建庙，以期望获得福德、修得正果。但佛陀告诉我们真正的大智慧是“凡有所相，皆是虚妄”。修正果是修心，心能看破虚妄相，就能获得无上智慧。布施、持斋、诵经都是方法，是用来训练一个人的心性，如果被社会熏染太深，可以通过这些方法逐步摆脱一些固有习气。待习气已除、心灵清净，这些方法就都不需要了，因为有了清净心就不需要刻意控制自己了，就完全能够看清楚之前的执着其实是虚妄。如果自己拥有智慧之后，再去帮助他人得以解脱，这样才是真正的福德。而这部经典正是一把破除虚妄的利器，如果能够信奉受持并且说与他人听，将会使听经之人破除固有观念、解放心灵。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","无为福胜分"]},{"title":"《金刚经》 第六品 正信希有分","url":"/2020/04/24/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%85%AD%E5%93%81-%E6%AD%A3%E4%BF%A1%E5%B8%8C%E6%9C%89%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>须菩提白佛言：“世尊！颇有众生，得闻如是言说章句，生实信不？”佛告须菩提：“莫作是说。如来灭后，后五百岁，有持戒修福者，于此章句能生信心，以此为实，当知是人不于一佛二佛三四五佛而种善根，已于无量千万佛所种诸善根，闻是章句，乃至一念生净信者，须菩提！如来悉知悉见，是诸众生得如是无量福德。何以故？是诸众生无复我相、人相、众生相、寿者相；无法相，亦无非法相。何以故？是诸众生若心取相，则为著我人众生寿者。若取法相，即著我人众生寿者。何以故？若取非法相，即著我人众生寿者，是故不应取法，不应取非法。以是义故，如来常说：‘汝等比丘，知我说法，如筏喻者；法尚应舍，何况非法。’”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>这一品比较长，也比较难理解。我试着一说，姑且听之。</p>\n<p>前文提到了“凡所有相，皆是虚妄”。须菩提就提出疑问了：<strong>“世尊，众生听到这样的说法，他们能相信吗？”</strong> 世人都喜欢有形有质的东西。如果告诉世人，这一切都是虚妄的，难免让人难以置信。</p>\n<p><strong>佛对须菩提说：“别这样说。如来灭后五百岁，真正持戒修福的人，对此章句，能生出信心，会相信我说的是真实不虚的，你要知道这样的人不是在一个佛两个佛三四五个佛那里种的善根，而是在无数的佛那里种的善根。这样的人听到这样的章句，甚至是一念之间就能生出信念。须菩提，这样的人是如来本性的流露，具有无上的智慧，所以这样的人得到的是无量的福德。”</strong> 这里说到，只有真正持戒修福的人才能对此章句生出信心，理解这个世界真实的一面需要善根，而且需要大善根。老子也说过：‘<strong>上士闻道，勤而行之；中士闻道，若存若亡；下士闻道，大笑之。不笑不足以为道</strong>。’”世上真正的大道是只有真正的智者才能理解。上一等的人，听到这种真理就会立刻相信，并且按照这种真理立刻行动。差一点的人，就会感到疑惑，有时候觉得有道理，但有时候又会觉得好像哪里不太对。再差一点的人，就会哈哈大笑，觉得这些都纯粹是扯淡，傻子才会信。所以说，真正的道理在某些人眼里看来肯定是蠢不可及的。这也就是“大智若愚”的道理。如果一个道理，一说出来，大家都拍手称赞，觉得简直是真理，那么这肯定不是真正的道理。</p>\n<p><strong>“为什么呢？这样的人不再有我相、人、众生、寿者相；没有法相，也没有非法相。为什么这么说呢？因为如果众生心里有了相，看世间的一切就是我、人、众生、寿者，如果取了法相和非法相，也就有了我、人、众生、寿者各种相。如果取了非法相，就是著了各种相，所以不应该取法相，也不应该取非法相。”</strong> 我、人、众生、寿者相前面已经提过，是对这个世界的分别心，是通过感官对外界的认知，然后主观进行了分类。那么破除这些相，就可以了吗？还不够。如果心中有法，觉得这个法是无上法，是一切的真理，那么这个法相也要破除掉。老子也说：“<strong>道可道，非常道；名可名，非常名。</strong>”真正的“道”和“佛法”，是不能用语言说的，也不是恒久不变的。所谓的“佛法”和“道”，不过是得道者对这个世界规律的一种勉强的描述。这种描述会随着外界情况，随着听法之人而改变。如果听了法，只是看到表面，而不是理解实质精髓，那么只会偏离佛法。</p>\n<p>“<strong>根据这样的义理，如来常常说道：‘你们这些学佛的人，应当知道我所说的法就像度世人上岸的筏子，上了岸筏子就没用了，就应该舍弃。法都应当舍弃，更何况非法呢。’</strong>” 接着前文所说，佛法可以比喻成是度人从彼岸到此岸的工具，上了岸就应该抛弃这种工具。应该做到随心所欲不逾矩。得了道，成了佛，就进入了一种大洒脱，大智慧的状态。不再囿于所谓的佛法的条条框框。如果把刻意行善当成是法，刻意行恶当成是非法，那么这两种刻意都应当放弃，就会达到“无为而无不为”的大解脱大慈悲状态。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","正信希有分"]},{"title":"《金刚经》 第十七品 究竟无我分（下）","url":"/2020/05/04/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%93%81-%E7%A9%B6%E7%AB%9F%E6%97%A0%E6%88%91%E5%88%86%EF%BC%88%E4%B8%8B%EF%BC%89/","content":"<p><strong>原文：</strong></p>\n<p><strong>何以故？如来者，即诸法如义。若有人言：‘如来得阿耨多罗三藐三菩提’。须菩提！实无有法，佛得阿耨多罗三藐三菩提。须菩提！如来所得阿耨多罗三藐三菩提，于是中无实无虚。是故如来说：一切法皆是佛法。须菩提！所言一切法者，即非一切法，是故名一切法。须菩提！譬如人身长大。”须菩提言：“世尊！如来说：人身长大，即为非大身，是名大身。”“须菩提！菩萨亦如是。若作是言：‘我当灭度无量众生’，即不名菩萨。</strong></p>\n<p><strong>何以故？须菩提！实无有法名为菩萨。是故佛说：一切法无我、无人、无众生、无寿者。须菩提！若菩萨作是言，‘我当庄严佛土’，是不名菩萨。何以故？如来说：庄严佛土者，即非庄严，是名庄严。须菩提！若菩萨通达无我法者，如来说名真是菩萨。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>这一品的前半部分世尊对世人应当怎么生其心，怎么降伏其心进行了讨论。佛说：“要灭度一切众生，灭度完了，有认识到其实没有众生被灭度。” 其实还在说，心怀慈悲，但不要着相。人相、我相、众生相、寿者相是相，佛法也是相。上文说到，如果释迦摩尼佛得过一种叫做无上正等正觉的佛法，那么就不能成佛。这里接着上文继续对此进行讨论。</p>\n<p><strong>“为什么呢？如来的意思就是一切法都无法可得的意思。有人会说：‘如来得到了无上正等正觉’。须菩提，其实没有什么佛法能使佛开启无上的智慧。须菩提，如来修成的无上的智慧，其实即无实也无虚。所以我才说一切都是佛法。”</strong></p>\n<p>“诸法如义”里的“如“字，是圆融而无碍的一种不可说的通达。这里借用前人的注解：“凡义之有可言说者曰通达，而不可言说之通达，则假名曰如如，此表般若神妙之用，非凡见所可意测，且愈测而愈远，故曰不可思议，言无法思议，亦正不必思议耳。” 诸法如义，就是真正的法是不可得不可说的，要用心去体会。比如，如果让顶级拉面师傅去用语言来教授别人怎么拉出粗细均匀，筋道合适的面条来，恐怕很难用语言来描述出来，就算勉强用语言描述了出来，也需要学习的人自己摸索，自己求证，再加上多年的练习，才能达到神乎其技的水平。一切法，无论是出离世间法还是世间法，都需要用心来琢磨，动手来实践摸索，靠被动学习或他人讲述，很难去理解精髓。</p>\n<p>这里讲一切法都是佛法，首先什么是“法”？佛教对这个字的解释的是：“<strong>任持自性、轨生物解</strong>。”这就是说，每一事物必然保持它自己特有的性质和相状，有它一定轨则，使人看到便可以了解是何物。例如水，它保持著它的湿性，它有水的一定轨则，使人一见便生起水的了解；反过来说，如果一件东西没有湿性，它的轨则不同于水的轨则，便不能生起水的了解。所以佛教把一切事物都叫做“法”。所以说在你身边的一草一木都是佛法，各有各自身的特性，都包含了世间哲理的一部分。《道德经》讲“人法地、地法天、天法道、道法自然”。一切的事物都源自这个世界的本源，自然也就继承了本源的一部分属性。比如说看到水，可能就会想到水的一些属性。看到滴水可以穿石，我们就可以想到它蕴含的理。比如柔弱的力量是最坚强的，也可以说坚持不懈总能做成事情。看到水流汇聚到大海，我们就可以想到，把姿态放低，就会得到人心的汇聚，就可以承载众人，成就伟大。法无处不在，只要有一双善于观察的眼睛，一个善于思考的大脑，我们就可以在平时生活中求得所谓的佛法。</p>\n<p><strong>“须菩提，我说的一切法本质上来说也都不是法，只是被姑且称作一切法。须菩提，就好比说人的身材高大。”须菩提说：“世尊，如来说人的身材高大，其实也是身材不高大，只是称作身材高大。”</strong></p>\n<p>前面说了一切法都是佛法，这里又反过来说其实一切法本质上都不是法，只是被称作法。看到了水的特性，就想到了水这种东西。但水本质上来说，跟其他所有的有形的东西又有什么差别？其实还都是由电子、质子、中子等等的微粒组成的。对事物的认识要经历三个阶段，看山是山，看山不是山，最后看山还是山。本质相同，但又体现了不同的方面。身材高大这一段在第十品种讲须弥山王的时候也提到过，可以参考我发布在我<a href=\"https://shileilei.com/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E5%93%81-%E5%BA%84%E4%B8%A5%E5%87%80%E5%9C%9F%E5%88%86/#more-143\">前面的文章</a>。身材高大不高大，完全是由看的人心中的标准决定的。如果完全没有大小的标准，大即是小，小即是大。消灭了这些标准，就是消灭了分别心，当无一切分别心的时候，就得了无上智慧。另一个角度来说，人的肉身也是由微粒组成的，哪里又有什么高大与否的区别。</p>\n<p><strong>“须菩提，菩萨也是这样。如果菩萨这样说：‘我应当灭度无量众生’，那他就不能被称作菩萨了。为什么呢须菩提？没有一种人叫做菩萨。所以佛说：一切法都没有我、没有人、没有众生、没有寿者。须菩提，如果菩萨这样说：‘我应当庄严佛土’，就不可以被称为菩萨。为什么呢？如来说，所谓的庄严佛土，其实并不是庄严佛土，只是被称作庄严佛土。须菩提，如果菩萨通晓无自我相状的佛法，如来说这是真菩萨。”</strong></p>\n<p>菩萨一旦有了我灭度了众生，就不是菩萨。真正的菩萨是要没有分别心的。没有我、人、众生、寿者。一旦有丝毫的分别心，就落回了各种相的迷惑之中。</p>\n<p>媚上者必欺下，因为这样的人心中有等级观念，有分别心。所以在他眼里，世界就是有等级的，上级就应该被捧着，下级就应该顺从。但这样的人真的就高人一等了吗？可能只是一种虚妄的执念在作怪吧。《人类简史》中有一个观点是这样的，说人类社会的一切组织形式都是靠的一种想象共同体。国家、宗教、公司、家庭等等都是一个个想象出来的概念。就是靠着这样一个个的概念，人类互相协作，从而创造了人类文明。如果跳出平时各种观念的束缚，我们会发现我们生活的界限都是我们自己划出来的，各种概念其实只是人为划定或者人为想象的。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","究竟无我分"]},{"title":"《金刚经》 第五品 如理实见分","url":"/2020/04/24/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%BA%94%E5%93%81-%E5%A6%82%E7%90%86%E5%AE%9E%E8%A7%81%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！于意云何？可以身相见如来不？”“不也，世尊！不可以身相得见如来。何以故？如来所说身相，即非身相。”佛告须菩提：“凡所有相，皆是虚妄。若见诸相非相，即见如来。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品讲完菩萨要不住相布施，并且提到不住相布施的福德不可思量。</p>\n<p>佛继续承接上文的对话，接着说道：**”须菩提，你说，可以通过外表的身相来见如来吗？”须菩提答道：“不可以的世尊。为什么不可以用身相来见如来呢？如来所说的身相，其实不是真正的身相。”佛回答须菩提道：“凡是一切有形有相的东西，都是虚妄的。如果能够意识到一切的相都是虚妄的，就能够见到如来了。”**</p>\n<p>“如来”是佛的十大称号之一，也是指“无所从来，亦无所去”。“见如来”可以理解为见到如来佛，也可以说见到“无所从来，亦无所去”的那个真我和自性。众生皆可成佛，众生皆有佛性，见到如来本性，也就是打破一些虚妄，获得无上智慧。而这个“见如来”的过程，是不可以通过眼耳鼻舌身意来见到的，因为眼耳鼻舌身意来感官到的外部世界是虚妄不真实的，眼耳鼻舌身意都是有局限性的。“五色令人目盲，五音令人耳聋，五味令人口爽，驰骋畋猎令人心发狂，难得之货令人行妨”。如果想看到一切表象后面的真实的世界运转的规则，就得放下一切由感官带来的执念，用心来体会，回归自然。世间一切都在变化，都在不断的生成，而又不断的毁灭。唯有背后的法则或者说自性没有变化。如果见到一切相，都能看透本质规律，看到它从何来而又将到哪去，不被表象所迷惑，那么就见到“如来”了。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","如理实见分"]},{"title":"《金刚经》 第十二品 尊重正教分","url":"/2020/04/27/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E4%BA%8C%E5%93%81-%E5%B0%8A%E9%87%8D%E6%AD%A3%E6%95%99%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“复次，须菩提！随说是经，乃至四句偈等，当知此处，一切世间、天人、阿修罗，皆应供养，如佛塔庙，何况有人尽能受持读诵。须菩提！当知是人成就最上第一希有之法，若是经典所在之处，则为有佛，若尊重弟子。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在<a href=\"https://shileilei.com/%e3%80%8a%e9%87%91%e5%88%9a%e7%bb%8f%e3%80%8b-%e7%ac%ac%e5%8d%81%e4%b8%80%e5%93%81-%e6%97%a0%e4%b8%ba%e7%a6%8f%e8%83%9c%e5%88%86/\">上一品</a>中，佛陀提到了受持《金刚经》的福德远胜财货布施。这一品继续讲到受持《金刚经》的重要意义。</p>\n<p><strong>“还有须菩提，随时随地只要一宣说此经，哪怕只有四句偈，应当知道说经之处，一切世间、天人、阿修罗都应当供应此地，就像供应佛塔所在地那样，更何况有人能够完全实践修持、读诵。”</strong> “复次”是前文已经说过，这里再次强调。“随”是不限定的意思，具体说来有：随人、随众、随文、随处、随时。“当知”包含警戒不可忽视的意思，是要告诉闻经者说经者，不可不存恭敬心。“天人”是天界生类的总称。“阿修罗”又名“无酒神、非天、无善神”，相貌丑陋、性格好斗，是“天龙八部”中的第五部。“天龙八部”是佛教术语，包括八种神道怪物，因为“天众”及“龙众”最为重要，所以称为“天龙八部”。这里的“世间”、“天人”、“阿修罗”包含了一切众生。</p>\n<p><strong>“须菩提，你应当知道，此人已经成就最上乘的第一希有法。“</strong> “第一希有之法”即“阿耨多罗三藐三菩提法”，此法无上正等正觉之法。成就此法，即是指成佛。</p>\n<p><strong>“经典所在的地方就是有佛的地方，就是有佛最尊贵的弟子的地方。”</strong> “经“有路径的意思，”典“有轨则的意思。明白经中所说之理，所依之轨，即可得证无上正等正觉之心。行此路、依此轨，就可以达到佛所做的地方。佛所在的地方，也就是一切圣贤所在的地方。是不是真有这么一个地方是佛所呢？里面住着一切佛神菩萨？我觉得不能着相。有可能只是一种比喻，是指精神到达的那种层次，那种大解脱、大智慧的逍遥态。</p>\n<p>这一品又再次强调了受持读诵此经的重要性。所谓的受持读诵、给他人讲说，也不要着相。受持读诵的是经中义理，而不是经文本身。与他人讲说，要随缘，需要听经的人打开心灵和耳朵，并且以对方能接受和理解的方式。一些所谓的佛教名词，也只是一些名词，不要整天“阿弥陀佛”挂在嘴边。给他人讲道理，也要用最贴切现实中的词语来讲解，这样人们才能真正接受。要记住前面所讲的“<strong>所谓佛法，即非佛法</strong>”。佛法即是世间法，是一门让人们生活更幸福的哲学。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","尊重正教分"]},{"title":"《金刚经》 第十三品 如法受持分","url":"/2020/04/28/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E4%B8%89%E5%93%81-%E5%A6%82%E6%B3%95%E5%8F%97%E6%8C%81%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>尔时，须菩提白佛言：“世尊！当何名此经，我等云何奉持？”佛告须菩提：“是经名为《金刚般若波罗蜜》，以是名字，汝当奉持。所以者何？须菩提！佛说般若波罗蜜，即非般若波罗蜜。须菩提！于意云何？如来有所说法不？”须菩提白佛言：“世尊！如来无所说。”“须菩提！于意云何？三千大千世界所有微尘是为多不？”须菩提言：“甚多，世尊！”“须菩提！诸微尘，如来说非微尘，是名微尘。如来说：世界，非世界，是名世界。须菩提！于意云何？可以三十二相见如来不？”“不也，世尊！何以故？如来说：三十二相，即是非相，是名三十二相。”“须菩提！若有善男子、善女人，以恒河沙等身命布施；若复有人，于此经中，乃至受持四句偈等，为他人说，其福甚多。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><a href=\"https://zhuanlan.zhihu.com/p/136835239\">上一品</a>中主要讲了金刚经的重要性。受持读诵并且依照经中义理行事思考就会得到无上智慧。这一品讲了此经的名字的由来，然后再次警醒世人不要着相，重点在于要真正理解经中的义理，而不要捧着一本书，或者是书中的文字奉为佛法。</p>\n<p><strong>此时，须菩提问佛：“世尊，应当给这部经取个什么名字呢？我们应该怎么供奉、修持这部经呢？”</strong> 前面几品一直在讲持修这部经的好处和重要性，但还没说这是部什么经？应该怎么去修持？这里须菩提就对这些问题提出了疑问。</p>\n<p><strong>佛跟须菩提讲：“这部经叫做《金刚般若波罗蜜》，就凭这个名字，你们都应供奉、修持。</strong>这里佛给这部经取了名字，金刚容易理解，金刚石是世界上最硬的材料，意为这部经可以无坚不摧，一切幻想、执着、顽痴，在这部经面前都可以被摧毁。“般若”是梵语的音译，这里读作bō rě，意思是终极智慧。为什么不直接翻译成智慧，而用音译呢？这是因为这里所说的智慧跟平常生活中所说的智慧不是一回事。这里的智慧是终极智慧，是觉悟一切的智慧。根据三藏法师的五不翻原则，这里就直接做音译。“波罗蜜”也是梵语，是度人到彼岸的意思。合起来这部经的名字意思就是像金刚一样摧毁一切相，用智慧度人到彼岸。佛说就凭这个名字，你们都应当奉持。为什么呢？因为只有智慧才能度人到彼岸，一切外道，一切外物依靠都不可以让人脱离颠倒梦想。这里又在警戒世人，人要看破幻像，要修习智慧，这才是修行的根本。</p>\n<p><strong>为什么要这么做呢？须菩提，佛说的般若波罗蜜，要按真谛来讲，就不是般若波罗蜜，只是个称谓而已。须菩提，我问你，我讲过佛法没有？须菩提对佛说：“世尊，如来没有说过法。”</strong> 这里佛陀又担心世人对这部经的表面意思过于执迷，又再次提醒，这部经不是佛法，佛陀从来没有说过一种叫佛法的东西。佛陀姑且给这部经起了个名字，但这部书只是一条指引到佛法的路。<strong>“道可道，非常道”</strong>，没有任何东西是亘古不变的，一切说出来的、写出来的、做出来的佛法，都是在特定时空条件下的佛法。如果过于教条、死守陈规，在条件变了的时候，虽按经行法，也不是在行佛法。</p>\n<p><strong>“须菩提，你说三千大千世界的所有微尘，多不多呢？”须菩提说：“很多，世尊。”“须菩提，各种微尘，其实本质来说，不是微尘，只是假借个名称叫做微尘。如来说的世界，本质来说，不是世界，只是假借个名称叫做世界。”</strong> 佛陀进一步解释为什么说前面说其实佛法本质不是佛法，只是叫做佛法。世间一切的名称，只是为了方便人们交流，而勉强给他赋予了一个称谓。有名有形的东西都是会变化的。物理角度来说，所有的东西都是由各种原子构成的，不同的排列组合组成了各种材料。所有的原子又都是由中子、电子、质子组成的。所以但本质来说，一切我们看到的有形的东西都是由相同的微粒组成的。山川是由一粒粒的土组成的，堆在一起，就被称作了山。把土移走，山就不能被称作山了，但组成山的土并没有消失，只是从一个地方到了另一个地方。</p>\n<p><strong>“须菩提，你再想想，你能凭借佛的三十二相来认识佛的本性吗？”“不能，世尊，我不能凭借佛的三十二相来认识佛的本性。”“为什么呢？”“因为你说的三十二相，其实不是相，只是称作三十二相。”</strong> “三十二相”是佛陀和转轮圣王有的三十二中外貌特征。佛陀说了，不能只凭藉这个外貌特征来确认是不是佛。人不可貌相，外貌特征只是一种虚像，不要被这种虚像所迷惑。多少道貌岸然的人，只是衣冠禽兽。认识佛的本性，要从本质入手，佛陀也说过“凡有所相，皆是虚妄，若见诸相非相，即见如来”。要认识佛的本性，就得破除一切相，去掉一切执着幻想。认识佛的本性，其实就是认识真正的自己。人人都是佛，只要去除执迷，即可觉悟成佛。</p>\n<p><strong>“须菩提，倘若有善男子、善女人用如恒河沙那样多的身体、生命来布施，又有另一个人修持这部经典，甚至只是受持其中的四句偈等，并且给他人解说，那么他的福德就比前面的善男善女的功德还要多。”</strong> 这里再次提到了修持《金刚经》，并且给他人解说的福德很多。帮助他人真正明晓道理，得到智慧，才是真正的从根本上帮助他人。比如说很多人贫穷，只是思想观念上的贫穷，给他再多钱，也不能真正帮助他摆脱贫困。只有真正在思想上解决问题的根源，才能真正帮助在各种苦恼中挣扎的人。所有的生活现状都是人的选择的结果。觉得自己没有选择，只能这样的人，只是被各种假设前提给困住了，被各种相给迷住了，让自己好像没有了选择。</p>\n<hr>\n<p>这里附上三藏的五不翻原则：“一、秘密故，如陀罗尼；二、含多义故，如薄伽梵具六义；三、此无故，如阎浮树，中夏实无此木；四、顺古故，如阿耨菩提，非不可翻，而摩腾以来常存梵音；五、生善故，如般若尊重，智慧轻浅。”</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","如法受持分"]},{"title":"《金刚经》 第十九品 法界通分分","url":"/2020/05/06/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E4%B9%9D%E5%93%81-%E6%B3%95%E7%95%8C%E9%80%9A%E5%88%86%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！于意云何？若有人满三千大千世界七宝以用布施，是人以是因缘，得福多不？”“如是，世尊！此人以是因缘，得福甚多。”“须菩提！若福德有实，如来不说得福德多；以福德无故，如来说得福德多。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品对各种相的根本来源进行了分析。世尊和须菩提对五种眼的问答和还有对诸心非心的讨论，让我们从侧面对事物本质进行了思考。这一品话锋一转又开始对福德进行了讨论。先上翻译：</p>\n<p><strong>“须菩提，我问你，倘若有人用装满三千大千世界的七宝用来布施，那么此人因为布施的因缘所修得的福德多不多？”“很多，世尊。此人因布施的因缘所得的福德很多。”“须菩提，假如福德是一个实体的话，如来便不可以说福德多了。因它没有实体，无可形容，如来才说他获得的福德多。”</strong></p>\n<p>上文提到过去心、现在心、未来心都不可得。所以说诸心非心，皆是世人的妄想执着。而法也一样，诸法非法，才可求得真法。佛法要旨在于不可以把一切的世间法当作是实实在在、一成不变的。那么福德呢？这里就进行了讨论。</p>\n<p>世尊先问了如果用很多财宝来布施，福德多不多？世尊回答说，如果是实实在在、看得见的福德，这样的福德就不能说多了。为什么这么说呢？实实在在的福德是有因有果的世间福德，获得的福德回报也是世间的俗物。这样的福德，在佛看来实在是太有限了。而如果布施而不在意世间的福德回报，有没有这种福德不重要，来了去了并无差别，这样的布施就有大福德。而这种福德，不是升职加薪，不是子孙满堂，也不是生活无忧。这种福德是菩提之果，是大智慧大圆满。当然，这也只是在没有得证无上智慧的人看来的福德而已，而得菩提之果之人，内心觉得自己与世人并无两样。得无上正等正觉的智慧的人，早已消除了我见人见众生见寿者见。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","法界通分分"]},{"title":"《金刚经》 第十六品 能净业障分","url":"/2020/05/02/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E5%85%AD%E5%93%81-%E8%83%BD%E5%87%80%E4%B8%9A%E9%9A%9C%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“复次，须菩提！若善男子、善女人，受持读诵此经，若为人轻贱，是人先世罪业，应堕恶道，以今世人轻贱故，先世罪业则为消灭，当得阿耨多罗三藐三菩提。”“须菩提！我念过去无量阿僧祗劫，于然灯佛前，得值八百四千万亿那由他诸佛，悉皆供养承事，无空过者，若复有人， 于后末世，能受持读诵此经，所得功德，于我所供养诸佛功德，百分不及一，千万亿分、乃至算数譬喻所不能及。须菩提！若善男子、善女人，于后末世，有受持读诵此经，所得功德，我若具说者，或有人闻，心即狂乱，狐疑不信。须菩提！当知是经义不可思议，果报亦不可思议。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>“再说，须菩提，如果有善男子、善女人受持读诵此经，但是还被别人轻视作贱，是由于这个人前世做下了罪业，应该现世遭受恶报。因为现世被人轻视作贱，前世的罪业就抵消了，就可以修得无上正等正觉的大智慧。”</strong></p>\n<p>前文提到受持读诵《金刚经》的福德非常巨大，但有些人就会产生疑问。自己或者自己所见到的某些人就每天积善行德，受持读诵《金刚经》，但是在社会中却被人轻视作贱，生活的很不如意。而有些人为非作歹，但却要什么有什么，日子过的很惬意。这里佛陀给出了解释，说那些受持读诵《金刚经》，但是在社会中却被人轻视作贱的人，是因为上辈子做了伤天害理的事情，有了罪业，现世就要遭受报应。这里就涉及到了佛教的一个基本的生死观。佛教认为人的生命是一个周而复始的轮回过程，人的死亡只是肉体的死亡，灵魂会在轮回中投胎，重新开始新的一世。行了善或者做了恶，有时候现世并不会受到报应，但这个人的业障会在来世继续影响这个人。有兴趣的可以看看电影《大只佬》，里面对轮回因果有一个不错的解读。</p>\n<p>要摆脱轮回，就要真正醒来，看清一切事物的真相。要能看到世间一切如梦幻泡影，都是因缘和合而生的幻像。就像人做梦的时候，在梦中人很难察觉到自己在做梦。但醒来之后，就会知道梦是假的。人的一生更像是一场大梦，每个人都沉浸在其中，不愿醒来。争名夺利，机关算尽，到头来不过是竹篮打水一场空。有的人把这个过程视为红尘炼心，在历练中找到真我，看清真相。然而有的人，却永远迷失了自己，不能自拔。是否能醒来，首先看你是不是愿意醒来。如果有这个发心和意愿，醒来又是件很容易的事情。</p>\n<p><strong>“须菩提，我回忆过去也曾受过无数的劫，在燃灯佛祖之前，我遇到过无数的佛，我全都恭敬的奉养伺候，没有落下一个，如果有人在后世能够受持读诵此经，其所得功德，比较我供养诸佛所得的功德，虽百分、千万亿分之一都不及此人。须菩提，如果有善男子、善女人，在后世能够受持读诵此经，所得的功德，如果我详细说来有多大，或许有人听了会心意狂乱，狐疑不信。须菩提，应当知道此《金刚经》的义理是不可思议的，受持读诵的果报也是不可思议的。”</strong></p>\n<p>佛陀再次强调受持读诵《金刚经》的福德之大。这次是用自己来供养诸佛的例子来比喻，相当于是又划了一次重点。</p>\n<p>佛教有三世佛的说法，燃灯佛是过去佛，释迦牟尼佛是现在佛，弥勒佛是未来佛。传说，燃灯佛是为释迦牟尼佛授记的佛陀。燃灯佛授记，对于释尊的历劫修行，是一关键性大事。因为燃灯佛授记时，‘释迦菩萨得无生法忍（无有生灭，诸法受忍）’。《心地观经》曰：“昔为摩纳仙人时，布发供养燃灯佛，以是精进因缘故，八劫超于生死海。” 。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","能净业障分"]},{"title":"《金刚经》 第十七品 究竟无我分（上）","url":"/2020/05/03/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%93%81-%E7%A9%B6%E7%AB%9F%E6%97%A0%E6%88%91%E5%88%86%EF%BC%88%E4%B8%8A%EF%BC%89/","content":"<p><strong>原文：</strong></p>\n<p><strong>尔时，须菩提白佛言：“世尊！善男子、善女人，发阿耨多罗三藐三菩提心，云何应住？云何降伏其心？”佛告须菩提：“善男子、善女人，发阿耨多罗三藐三菩提者，当生如是心，我应灭度一切众生。灭度一切众生已，而无有一众生实灭度者。何以故？须菩提！若菩萨有我相、人相、众生相、寿者相，即非菩萨。所以者何？须菩提！实无有法发阿耨多罗三藐三菩提者。”“须菩提！于意云何？如来于然灯佛所，有法得阿耨多罗三藐三菩提不？”“不也，世尊！如我解佛所说义，佛于然灯佛所，无有法得阿耨多罗三藐三菩提。”佛言：“如是！如是！须菩提！实无有法如来得阿耨多罗三藐三菩提。须菩提！若有法得阿耨多罗三藐三菩提，然灯佛则不与我授记：汝于来世，当得作佛，号释迦牟尼。以实无有法得阿耨多罗三藐三菩提，是故然灯佛与我授记，作是言：‘汝于来世，当得作佛，号释迦牟尼。’</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>此时，须菩提又问佛：“世尊，善男子、善女人，发心要修成无上正等正觉的大智慧，心应该住于何处？应该怎么降服他们被诸相干扰的心呢？”佛对须菩提讲：“善男子、善女人，发心要修成无上正等正觉的大智慧的人，应当生出这样的菩萨心，我应当灭度一切众生，灭度完一切众生，又认识到其实没有一个众生是自己所灭度的。”</strong></p>\n<p>这里须菩提再次提问最开始问到的问题“善男子、善女人，发阿耨多罗三藐三菩提心，云何应住，云何降伏其心。”在讲完前面那么多品之后，佛告诉须菩提，应当灭度完一切众生又不觉得有一个众生被自己灭度，这样来守住自己的心念。灭度又称做涅槃，又叫做入灭、灭惑，度生死的意思。不是永生，是非生非灭。首先，应该生起我应灭度众生的心，这是一个慈悲的发心，要有度世人离一切苦的心愿。然后，还有有灭度众生的能力，通过六度万行来度世人远离一切苦。最后，度完众生这件事就忘掉了，没有一个念想觉得我曾度过众生。《道德经》也提到：“上德不德，是以有德；下德不失德，是以无德。”。度众生这件事，完全是出自本心，而不是要有所回报。度完众生，这件事就是过去时了，就没有必要在留在心里了。功成名遂身退，天之道。</p>\n<p><strong>“为什么呢？须菩提，如果菩萨有我、人、众生、寿者相，就不再是菩萨了。这是为什么呢？须菩提，本质上来讲，没有一种法叫做无上正等正觉的佛法。须菩提，你说如来在燃灯佛那里，得到了一种叫做无上正等正觉的佛法吗？”“没有，世尊。按照我对佛法的理解，佛在燃灯佛那里，没有得到一种叫做无上正等正觉的佛法。”</strong></p>\n<p>这里接着解释为什么度了世人之后，又要认识到其实没有一个众生是自己所灭度的。如果有了灭度世人的心，就有了分别心，有了我是菩萨，他们是需要灭度的世人的我、人、众生、寿者相。着了这些相就不再菩萨了。不执着于世间的相，也不能执着于法相。着有不是佛法，着空也不是佛法。这就是中庸的道理，过犹不及。佛法是平和中正，不执着、不偏激的。后面这几句话也是前文提到过的，这里再次提起，再次强调重点。详细内容请参考我之前发布在我的<a href=\"https://shileilei.com/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E4%B8%83%E5%93%81-%E6%97%A0%E5%BE%97%E6%97%A0%E8%AF%B4%E5%88%86/#more-110\">个人网页</a>或者<a href=\"https://zhuanlan.zhihu.com/p/134758839\">知乎专栏</a>或者<a href=\"https://zhuanlan.zhihu.com/p/134758839\">知乎专栏</a>前面写过的文章。</p>\n<p><strong>佛说：“正是如此，正是如此。须菩提，实际上根本没有什么佛法能让人开启无上正等正觉的大彻大悟的大智慧。须菩提，如果我有得此法，那么佛就不会受记我，对我说：‘你在来世，将会成佛，号释伽牟尼’。正因为我并没有得到一个叫做无上正等正觉的佛法，所以燃灯佛才给我受记，对我说‘你在来世，将会成佛，号释伽牟尼’。”</strong></p>\n<p>世尊听完须菩提的回答，很是满意。接着用自己的例子，来解释其实没有一种叫做佛法的法。如果他曾经觉得自己得了无上的佛法，那么燃灯佛就不会给他受记，告诉他来世可成佛。正因为他觉得什么法也没得到，内心一片纯净，消除了所有的分别心，远离了一切相，所以燃灯佛才会给他受记，告诉他下世可成释迦摩尼佛。</p>\n<p>看到这里，我特别有感慨。现在动不动就会有人跳出来说自己得了道，开了悟，有了各种神通。真正开了悟，得了道的人，会是这个样子吗？释迦摩尼佛尚且从来没有觉得自己得证过无上的佛法，他们这些人会是得了无上智慧的人吗？真正厉害的人，往往都是在默默努力奉献，把精力放在自己所关注的事情本身上面。他们在意的是自己有没有提高，而不会在意这些外来的虚名。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","究竟无我分"]},{"title":"《金刚经》 第十五品 持经功德分","url":"/2020/05/01/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E4%BA%94%E5%93%81-%E6%8C%81%E7%BB%8F%E5%8A%9F%E5%BE%B7%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！若有善男子、善女人，初日分以恒河沙等身布施，中日分复以恒河沙等身布施，后日分亦以恒河沙等身布施，如是无量百千万亿劫以身布施；若复有人，闻此经典，信心不逆，其福胜彼，何况书写、受持、读诵、为人解说。须菩提！以要言之，是经有不可思议、不可称量、无边功德。如来为发大乘者说，为发最上乘者说。若有人能受持读诵，广为人说，如来悉知是人，悉见是人，皆得成就不可量、不可称、无有边、不可思议功德。如是人等，即为荷担如来阿耨多罗三藐三菩提。何以故？须菩提！若乐小法者，著我见、人见、众生见、寿者见，则于此经，不能听受读诵、为人解说。须菩提！在在处处，若有此经，一切世间、天、人、阿修罗，所应供养；当知此处则为是塔，皆应恭敬，作礼围绕，以诸华香而散其处。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>“须菩提，假如有善男子、善女人，早晨用恒河沙这么多的身命来布施，中午、下午又用恒河沙那么多的身命来布施，像这样用百千万亿劫那样长的时间，用身命来做布施；还有一个人，听到这部经，产生信心，毫不怀疑，那他的福德胜过前面那个人。何况还书写、受持、读诵、为他人解说此经。须菩提，概括来说，这部经有着难以想象、不可称量、无边无际的功德。”</strong></p>\n<p>人最宝贵的就是生命，所以佛陀用身命布施来比喻受持读诵《金刚经》的功德。这一次的比喻跟前文提到的用金银财宝布施的比喻相比给人的冲击感更加强烈。就是用无限时间无数身命来布施也不如理解真理来的福德大。方向永远比努力更重要。</p>\n<p>“劫”是佛教的一个时间长度的概念。“劫”分三等：小劫、中劫、大劫。根据《大智度论》的算法，一小劫约为1680万年，二十小劫为一中劫，约3.3亿年，四中劫为一大劫，约为13亿年。四个中劫包含了世界的成、住、坏、空的四个阶段。成是世界的形成期，住是世界的壮盛期，坏是世界的老死期，空是世界的毁灭期。世界有成住坏空，人也有生老病死。任何有形的东西都脱离不开这四个阶段。所以一切都是无常，唯有不断的变化才是唯一永恒不变的。</p>\n<p><strong>“如来是为发愿修习大乘的人来说这部经的。如果有人能够受持读诵这部经书，并且广泛为人解说，如来便能完全知道、完全看到这个人能够修成不可量、不可称、无边无际、不可思议的功德。这样的人，就可修成至无上正等正觉的无上佛法。”</strong></p>\n<p>对于修习大乘的人来说，修习的是菩萨道，菩萨的意思前文提过，就是上求佛法，下度众生，所以除了度己还要度人。自己得了无上智慧还不算，还要把这种智慧教给他人。在《金刚经》中反复提到，这部经给他人解说的功德是无边无量的，正是典型的大乘佛法风格。与之相对应的是“小乘佛法”，但“小乘佛法”是大乘对“南传上座部佛教”的一种贬称，修习者本人并不认同“小乘”这一说法。但本质来说这一派的根本还是在度己。我自己的观点来说，佛法并无高低，有了高低，就是着了相。有能者度人，无能者度己。达则兼济天下，穷则独善其身。</p>\n<p><strong>“为什么呢？须菩提。如果在小法中自得其乐的人，还是会执着于我、人、众生、寿者之见，那他就不能听受读诵、为他人解说这部经。须菩提，无论在什么地方，如果有此经，一切世间、天、人、阿修罗，都应该供养他。都应该把这里当作是佛塔，都应该恭敬，围绕他作礼，用各种香和花撒在这个地方。”</strong></p>\n<p>虽然佛法从根本来说无大乘小乘之分，但在小法中自得其乐的人，是还没有真正领悟佛法。大小乘只是不同状态，但有能力度人，而不去度人，却自得其乐，不可以说得了真法。既然自得其乐，说明还有我见，有了我见，就有了一切分别心。对于修得了无上智慧，并且还能够给他人解说，这样的人是一个高尚的人，纯粹的人，我们应该心怀敬意。</p>\n<p>世间、天、人、阿修罗在十二品中已经讲过，这里不再赘述。可以参考我的<a href=\"https://shileilei.com/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E4%BA%8C%E5%93%81-%E5%B0%8A%E9%87%8D%E6%AD%A3%E6%95%99%E5%88%86/\">之前的文章</a>。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","持经功德分"]},{"title":"《金刚经》 第十品 庄严净土分","url":"/2020/04/25/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E5%93%81-%E5%BA%84%E4%B8%A5%E5%87%80%E5%9C%9F%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>佛告须菩提：“于意云何？如来昔在然灯佛所，于法有所得不？”“不也，世尊！如来在然灯佛所，于法实无所得。”“须菩提！于意云何？菩萨庄严佛土不？”“不也，世尊！何以故？庄严佛土者，即非庄严，是名庄严。”“是故须菩提！诸菩萨摩诃萨应如是生清净心，不应住色生心，不应住声香味触法生心，应无所住而生其心。须菩提！譬如有人，身如须弥山王，于意云何？是身为大不？”须菩提言：“甚大，世尊！何以故？佛说非身，是名大身。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品中通过举出从一果罗汉到四果罗汉的例子来说明不应住于法。这一品接着上一品，世尊从自身来继续举例来论证这一观点。</p>\n<p><strong>佛问须菩提：“你说，如来以前在燃灯佛那里，对法有所证得吗？”“没有，世尊，如来在燃灯佛那里，没有证得任何法。”</strong> “然灯佛”即“燃灯佛”，有名定光佛，是释迦摩尼之前的佛。佛教说燃灯佛是过去佛，释迦摩尼是现在佛，弥勒佛是未来佛。</p>\n<p>佛接着说：<strong>“须菩提，你认为菩萨用六度万行来庄严佛土吗？”“没有，世尊，为什么这么说呢？所谓的庄严佛土，其实不是庄严，只是被称作庄严。”</strong> 在很多宗教中，都会提到有一个理想之地。比如，佛教中的极乐世界，西方的天堂。往往人们会把这个地方描绘的特别美好，喜爱财宝的人会把这个地方想象的珠宝遍地，喜爱山水的人把这里想象成有森林瀑布高山这样的美景的地方。但这种想象都是世俗之人心中的臆想，都是因心而生的幻象。佛在世间度世人，世间即是庄严佛土。佛下地狱救世人，地狱即是庄严佛土。所谓的佛土，不过是相，而这个相是由心生的。佛陀心中有庄严佛土，任何地方都是庄严佛土。这一点可能很多人在生活中也有类似的体悟，相同的事情，只要心态一转，之前觉得不好的事情，就变成好事了。所以说，一切事情的好坏，往往在于心中的判断标准。在生活中，很多人觉得自己生活在痛苦中，但也许只要转变心态，就可能就会乐在其中。</p>\n<p><strong>“所以说须菩提，一切菩萨、大菩萨应该这样生起清净之心：不应当因为外界的色声香味触法而有起心动念，心应当无所住，就会自然而然生起清净心。须菩提，如果有人有像须弥山王一样无量无边大的身体，你说他的身体大吗？”须菩提回答到：“非常大，世尊，为什么呢？因为佛说的不是真正的法身，所以只能说他很大。”</strong> 这里再次提到不应当着相，色声香味触法都是暂时的感官感受，不是真实不虚的、也不是永恒不变的。不着相，看破这些虚妄，清净心、无上正等正觉自然就生出来了。后面举的例子跟第八品提到的<strong>“若人满三千大千世界七宝以用布施，是人所得福德，宁为多不？”须菩提言：“甚多，世尊！何以故？是福德即非福德性，是故如来说福德多。”</strong>有异曲同工之妙。世人看到的身体，其实不是如来所说的真正的身体，所以只能说这个身体很大。这里就蕴含一个很深的哲学问题：什么是自我？我们的肉体就是自我吗？我们的思想就是自我吗？如果像刘慈欣在《时间移民》小说中说的一样，人大脑中的意识可以转移到计算机上，那么这个芯片中的意识还是自我吗？《楞严经》中有七处征心的故事，对这个自我有着更深刻更详细的论证，有兴趣的可以去看看具体章节。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","庄严净土分"]},{"title":"《金刚经》 第十八品 一体同观分","url":"/2020/05/05/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E5%85%AB%E5%93%81-%E4%B8%80%E4%BD%93%E5%90%8C%E8%A7%82%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！于意云何？如来有肉眼不？”“如是，世尊！如来有肉眼。”“须菩提！于意云何？如来有天眼不？”“如是，世尊！如来有天眼。”“须菩提！于意云何？如来有慧眼不？”“如是，世尊！如来有慧眼。”“须菩提！于意云何？如来有法眼不？”“如是，世尊！如来有法眼。”“须菩提！于意云何？如来有佛眼不？”“如是，世尊！如来有佛眼。”“须菩提！于意云何？恒河中所有沙，佛说是沙不？”“如是，世尊！如来说是沙。”“须菩提！于意云何？如一恒河中所有沙，有如是等恒河，是诸恒河所有沙数，佛世界如是，宁为多不？”“甚多，世尊！”佛告须菩提：“尔所国土中，所有众生，若干种心，如来悉知。何以故？如来说：诸心皆为非心，是名为心。所以者何？须菩提！过去心不可得，现在心不可得，未来心不可得。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>前面一直在讲不要着各种相，这一品突然话锋一转，开始讲起了宇宙观。这其实是更加深入在讨论各种相的由来。不同层次的人，看到的世界的深度和广度是不一样的。</p>\n<p><strong>“须菩提，你说，如来有肉眼吗？”“是的，世尊，如来有肉眼。”“须菩提，你说，如来有天眼吗？”“是的，世尊，如来有天眼。”“须菩提，你说，如来有慧眼吗？”“是的，世尊，如来有慧眼”。“须菩提，你说，如来有法眼吗？”“是的，世尊，如来有法眼”。“须菩提，你说，如来有佛眼吗？”“是的，世尊，如来有佛眼”。</strong></p>\n<p>什么叫做“肉眼”、“天眼”、“慧眼”、“法眼”、“佛眼”呢？这其实是一个比较深奥的几个名词。眼睛是心灵的窗户，不同的眼睛，代表了不同的内心，并且看到的世界都是不同的。</p>\n<p>首先，什么是“肉眼”？肉眼就是我们平时接触外界物理世界的眼睛，各种花花绿绿的颜色都是由这个肉眼看到的。但要知道，虽然我们每个人都有肉眼，但看到的世界也不尽相同。有近视的、远视的、色盲的、色弱的。看不清楚一个东西，并不代表这个东西是模糊的，这个我们所有人很容易理解。看到一个东西是红色的，这个东西不一定是红色的，这个色盲色弱的人也比较容易理解，但对于大部分人来说可能就不太容易理解。大部分人会觉得色盲是一种病，觉得如果百分之九十的人看一样东西是红色的，那这个东西就应该是红色的。但有没有可能只有那百分之十的人看到的才是真实的颜色？色盲人的眼睛对敏感度有更好的分辨能力，那么是不是其他百分之九十的人的眼睛是有缺陷的？如果再拓展到对其他动物的讨论，我们就会发现，动物的肉眼的观察范围又跟我们人类很不相同。比如猫头鹰，对光的敏感远超我们人类，可以在黑夜中看到我们看不到的东西。狗又都是天生的色盲，跟人类看到的东西的颜色有很大差别。我们就会发现，东西一直没有变，但我们有的肉眼有差别，就会产生不同的观察结果。</p>\n<p>我们能看到的光，只是宇宙电磁光谱中非常狭窄的一段电磁波。而颜色只是光照在物体上之后，能被反射出来的光的波长不同而产生的一种现象。除了可见光，还有微波、红外线、紫外线、X光、伽马射线等等。不同的生物，对于光的可见范围也是有区别的，有的动物可以看到红外线，有的则可以看到紫外线。</p>\n<p>其次，什么是“天眼”、“慧眼”、“法眼”、“佛眼”？普通人几乎是没有这几种眼的。我按照自己的理解这里姑且一谈。</p>\n<p>天眼的能力是超出一般肉眼能观测的范畴的，通俗的说天眼可以看到很多肉眼看不到的东西。比如不会受距离、大小、明暗等的限制。也不会被遮挡隐藏，比如可以透视。而且不受空间限制，比如可以看到其他维度的生物。</p>\n<p>慧眼识罗汉所证，见十二因缘、生死流转的象征，所以能出生死轮回，不受身心世界的束缚。所以慧眼是无我无执的。</p>\n<p>法眼是初地以上的菩萨所具，能见万法的本性。可以看到色即是空，空即是色。看到事物的本质属性，看到有又可以看到无。</p>\n<p>至于佛眼，可以说是可以看到一切，是智慧的全体，无所不包，无所不察。</p>\n<p><strong>“须菩提，你说恒河中的沙粒，佛说是沙粒吗？”“是的，世尊，如来说是沙粒。”“须菩提，你说，如果像恒河中的很多沙粒一样，大千世界中有像恒河沙粒那样多的恒河，如有像这多恒河中所有沙粒那样多的佛世界，你认为这佛世界是多还是不多？”“很多，世尊。”佛跟须菩提讲：“这么多佛土中所有众生的心念，如来都知道。这是为何呢？如来说：我所说的各种心念，都是非心念，只不过叫做心念。为什么呢？须菩提，过去心不可得，现在心不可得，未来心不可得。”</strong></p>\n<p>在讨论完物种眼之后，这里继续开始讨论大千世界。在两千多年前，佛就举例说有无数个世界，在当世可能很难被大家理解。现代科学的发展，我们已经知道宇宙是无限大的，有无限多个像地球一样的星球。在茫茫的宇宙中，我们就如同恒河中的一粒沙子。而一粒沙子，如果无限放大，其实里面也是无限大的世界，里面也有无数的“众生”。我们人类，太过于以自我为中心，以自身为参考。其实世界很大，人类很渺小。《庄子》也有类似的观点，“知天地之为稊米也，知毫末之为丘山也”，这刚好与《金刚经》不谋而合。</p>\n<p>这么多宇宙中的所有众生的心念，如来都知道。然后如来自问自答，说为什么知道。因为所有的这些心都是一样的，都是执着妄心，而众生自以为心。所有的这这些心都是因缘而生，因缘而生的就会随时变化而无本性，所以其实是非心，只是叫做心。这样的缘影之心，过去的已经过去了，现在的刹那之间也无法留住，而未来的心，还没有到，又如何能得？此三种缘影之心，皆不可得。既然不可得，又何必为此苦恼？</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","一体同观分"]},{"title":"《金刚经》 第十四品 离相寂灭分（上）","url":"/2020/04/29/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E5%9B%9B%E5%93%81-%E7%A6%BB%E7%9B%B8%E5%AF%82%E7%81%AD%E5%88%86%EF%BC%88%E4%B8%8A%EF%BC%89/","content":"<p><strong>原文：</strong></p>\n<p><strong>尔时，须菩提闻说是经，深解义趣，涕泪悲泣，而白佛言：“希有，世尊！佛说如是甚深经典，我从昔来所得慧眼，未曾得闻如是之经。世尊！若复有人得闻是经，信心清净，则生实相，当知是人，成就第一希有功德。世尊！是实相者，即是非相，是故如来说名实相。世尊！我今得闻如是经典，信解受持不足为难，若当来世，后五百岁，其有众生，得闻是经，信解受持，是人则为第一希有。何以故？此人无我相、人相、众生相、寿者相。”“所以者何？”“我相即是非相、人相、众生相、寿者相，即是非相。何以故？离一切诸相，则名诸佛。”佛告须菩提：“如是！如是！若复有人得闻是经，不惊、不怖、不畏，当知是人甚为希有。何以故？须菩提！如来说第一波罗蜜，非第一波罗蜜，是名第一波罗蜜。须菩提！忍辱波罗蜜，如来说非忍辱波罗蜜，是名忍辱波罗蜜。何以故？须菩提！如我昔为歌利王割截身体，我于尔时，无我相、无人相、无众生相、无寿者相。何以故？</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品中佛陀给这部经取名为《金刚经》，并且告诉了人们修持的方法。虽然这部经名称为《金刚经》，但不可执着于经文本身。警告世人，没有定法叫做佛法，要透过现象看本质，不要对名相太过看重，要去真正理解佛陀要表达的义理。这一品继续阐释不应着相的义理。但因为经文较长，就分为了两部分来讲解。</p>\n<p><strong>这时，须菩提听佛解说此经，深深的领悟了佛法的义理和境界，悲悯而泣，对佛说到：“真是少有的经文啊，世尊，您解说如此深刻的经文，我自从修习慧眼以来，从来没听倒过如此经文。世尊，如果有人听到此经能够对佛所说的义理产生信心，并且生出清净心，那么就能够看清楚真正的实相。应当知道这个人成就了，成就了世上第一的罕见的功德。”</strong> 这里讲到，须菩提听完之后，对此经大加赞赏。并且说到，如果有人能够真正听懂这篇经文所讲，就能够对佛法产生信心，生出无上平等心、智慧心、清净心。佛讲般若讲了二十二年，有经书600卷。般若部的所有经典浓缩到五千字，就是一部《金刚经》。所以《金刚经》在佛教经典中是十分重要的一部经。如果真正读懂《金刚经》那么就能够成就无上功德。所谓的功德，并不是世人所说的被人称赞的功德，而是能够看到实相，生出无上正等正觉的心的一种大机缘。</p>\n<p><strong>“世尊，这实相，就是看一切相都不是相，因此佛说它只是取名为实相。世尊，我现在有机会听您解说这部经典，由产生信心，理解义理，再进行修行，最后印证得果也就不难了。如果在五百年后，有众生听说此经，也会信解受持，这人也就成为世上第一少有的人。为什么呢？因为这个人没有人、我、众生、寿者相。”“这又是为什么呢？”“因为我、人、众生、寿者相其实就是非相。为什么呢？远离一切相，就叫做佛。”</strong></p>\n<p>这里提到了佛和众生的差别就在于有没有远离一切相，远离了一切相就可以称为佛。佛不是我们供起来的那个雕像，佛也不会因为给他献了花烧了香就会满足信徒的愿望。佛在每个人的内心深处，在于每个人的自明自觉。《道德经》里面说最接近道的是刚出生的小孩儿。如果观察小孩，就可以发现，他们没有我的概念，没有什么是好的的概念，没有虚荣心，没有分别心。饿了吃饭，困了睡觉。虽然这么没心没肺，但每个人都对小孩子充满了喜爱。人刚生出来的时候的那个状态，最接近实相，所以说，有时候我们得向小孩子学习。每个人在社会中成长，就是红尘炼心的过程，经历过社会上的各种挫折，各种诱惑，最后再返璞归真，这样得到的感悟就会是最深的，经过磨练，对于佛法义理也会更加有信心。</p>\n<p><strong>佛说：“是这样，是这样！如果有人听说此经，不惊讶、不恐怖、不害怕，应该知道这个人是相当罕有的人。为什么呢？须菩提，如来说的第一波罗蜜，其实本质来说不是第一波罗蜜，只是称作第一波罗蜜。须菩提，如来说的忍辱波罗蜜，其实本质来说不是忍辱波罗蜜，只是称作忍辱波罗蜜。须菩提，比如当初我被歌利王割截身体一事，就是因为我当时已没有了我相，没有了他人相， 没有了众生相和长寿者相。这又是为什么呢？”</strong></p>\n<p>如果看到此经，并且听佛解说之后，思考发现一切相都是虚妄，平时坚信的现实中的很多东西发现都只是假象。难免会产生惊讶、恐怖、害怕等的情绪。如果看完之后，觉得本应如此，那这个人真是少有之人。</p>\n<p>“波罗蜜”，前面的章节提到过，是梵文，意思是“度人到彼岸”的意思。波罗蜜有六种，包含“布施”、“持戒”、“忍辱”、“精进”、“禅定”、“般若”。六波罗蜜包含了修行的各种法门。这里的第一波罗蜜，是指“般若”。无上智慧也只是一种称谓，并不是说得了无上智慧，就跟别人不一样了，不要太在意这个名相。而且无上智慧不是文字可以完全表达的，更多的在于体悟。后面的忍辱波罗蜜，代表了其他的另外五种修行法门，也都只是名字暂且称作“忍辱”、“布施”等等的。这些方法都是为了训练自己的心性，万不可只做到表面功夫。</p>\n<p>歌利王割截身体是一个佛教故事。大意是说歌利王见到佛陀在给他的嫔妃讲法，很是恼怒，就用利剑割伤了佛陀的身体，就问他：“你既然能持戒，能生出嗔恨心吗？”佛陀答道：“如果有嗔恨，身体割伤之后不能复原。”说完，身体就复原了。这个故事太过传奇，就不做过多解释了。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","离相寂灭分"]},{"title":"《金刚经》 第十四品 离相寂灭分（下）","url":"/2020/04/30/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B-%E7%AC%AC%E5%8D%81%E5%9B%9B%E5%93%81-%E7%A6%BB%E7%9B%B8%E5%AF%82%E7%81%AD%E5%88%86%EF%BC%88%E4%B8%8B%EF%BC%89/","content":"<p><strong>原文：</strong></p>\n<p><strong>“我于往昔节节支解时，若有我相、人相、众生相、寿者相，应生嗔恨。须菩提！又念过去于五百世作忍辱仙人，于尔所世，无我相、无人相、无众生相、无寿者相。是故须菩提！菩萨应离一切相，发阿耨多罗三藐三菩提心，不应住色生心，不应住声香味触法生心，应生无所住心。若心有住，即为非住。是故佛说：‘菩萨心不应住色布施。’须菩提！菩萨为利益一切众生，应如是布施。如来说：一切诸相，即是非相。又说：一切众生，即非众生。须菩提！如来是真语者、实语者、如语者、不诳语者、不异语者。须菩提！如来所得法，此法无实无虚。须菩提，若菩萨心住于法而行布施，如人入暗，即无所见。若菩萨心不住法而行布施，如人有目，日光明照，见种种色。须菩提！当来之世，若有善男子、善女人，能于此经受持读诵，则为如来，以佛智慧，悉知是人，悉见是人，皆得成就无量无边功德。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>“倘若我当时被歌利王节节支解身体时，如果有我、人、众生、寿者相，就会生出嗔恨心。须菩提，再回想过去，在五百年前，做忍辱仙人的时候，那时我就没有我、人、众生、寿者相。”</strong> 歌利王的故事前面提到过了，如果歌利王在割伤佛的身体的时候，佛有一丝着相，就会生出嗔恨心，佛的身体也不会复原如初。因为当时释迦摩尼还没有成佛，所以在当时被称作忍辱仙人。</p>\n<p>这么传奇的故事，至于是不是真有其事，我也没有一个明确的答案。毕竟两千多年过去了，很多故事经过时间的洗礼，都会留下一些传奇色彩。对于比较传奇的故事，我的观点更切近于孔子。在《论语》里有这么一段：<strong>季路问事鬼神。子曰：‘未能事人，焉能事鬼？’‘敢问死。’曰：‘未知生，焉知死？’</strong> 活着的事情还没有弄清楚，怎么能知道死了之后的事情。因此怪力乱神的事情，自己没有经历过，就不敢胡言乱语。</p>\n<p><strong>所以说须菩提，菩萨应远离一切相，发无上正等正觉的心，不应该因为色、声、香、味、触、法而有起心动念，应该无所住而生其心。如果心中惦念着什么，就是没有守护好自己的心念。</strong>这里再次点题，佛不厌其烦的一遍又一遍的重复，要远离一切相，不要被外界的形形色色所迷惑，要生出清净心。无所念想，心不为外物所动，返璞归真，就修得了无上的智慧。</p>\n<p><strong>“所以佛说：‘菩萨心不应该执着于表象布施。’须菩提，菩萨为了一切众生的利益，应该这样布施。如来说：‘一切的相，本质上又都不是相’。又说：‘一切众生，本质上又都不是众生。’”</strong> 这里又提了前面反复提到的话，相即非相。表面看到的一切有形的物质，物理的本质上都是微粒组成的。如果再往深处挖，一切有形的物质，在一定条件下又都是无形的能量组成的。所以不要太在意这个眼前的暂时的有形世界的物质或意识形态。一切众生，又都不是众生。这句话怎么解释呢？首先，心中不应该有我、人、众生、寿者等等的概念。这是一种不平等心在作怪，众生即我、即人、即寿者。《道德经》里面有一句话，我觉得可以和这句话相互印证“<strong>天地不仁，以万物为刍狗；圣人不仁，以百姓为刍狗</strong>”。这里就是大仁不仁的概念，刍狗和百姓在圣人看来，又有什么区别呢？</p>\n<p><strong>“如来是说真话的人，说实话的人，实事求是的人，不说谎话的人，不会讲一些奇怪言论来获得关注的人。须菩提，如来所得之法，是没有实也没有虚的。须菩提，如果菩萨执着于法而去布施，就像人走进了一个特别黑暗的地方，什么也看不见。”</strong> 如来可以理解为自己的如来本性，也可以理解为佛陀，也可以理解为那个寻得了永恒不变的真理的人。找到自性的人，是不说谎话的人，是一个不需要迎合外界而去欺骗他人的人。这句话也可以用来判断什么是正信，什么是邪信。如果一个人用夸张的词藻、奇怪言论来煽动大家，获得大家关注，请不要相信这个人。这里特意又提醒道，菩萨不要执着于佛法而去布施，这样的布施是没有结果的。就像钻进了黑洞，永远看不到希望之光。不识庐山真面目，只缘身在此山中。想看得远，就要站得高。想看清世界，就要脱离一切相。</p>\n<p><strong>“如果菩萨不是因为佛法说要布施而去布施，就好像人有眼睛，明明亮亮像太阳朗照，可以见到各种东西。须菩提，如果以后，有善男子、善女人，能够受持、诵读这部经，他就将是佛。凭佛的智慧，完全了解此人的修行， 完全能看到他将来一定会修得无边无量的功德。”</strong> 如果菩萨不着相，完全依着自己的心而去布施、修行，这就会看到通向真理的路。没有违背任何内心，不因外界的任何东西而去做着完全符合佛法的事情。这样的人，就已经是得到了无上正等正觉。后面再次说到善男子、善女人如果能够修持读诵这部经典，将会有很大功德。这里佛陀不厌其烦的一次又一次说这种功德，就是希望世人可以按照他得证的路去修行。佛陀已经得证，他完全看清了世界，体验到了无上的快乐，这种快乐他也想分享给世人。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","离相寂灭分"]},{"title":"《金刚经》第一品 法会因由分","url":"/2020/04/24/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B%E7%AC%AC%E4%B8%80%E5%93%81-%E6%B3%95%E4%BC%9A%E5%9B%A0%E7%94%B1%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>如是我闻，一时，佛在舍卫国祗数给孤独园，与大比丘众千二百五十人俱。尔时，世尊食时，著衣持钵，入舍卫大城乞食。于其城中，次第乞已，还至本处。饭食讫，收衣钵，洗足已，敷座而坐。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>这一品讲的是佛在讲经之前的活动，叙述了时间、地点、人物。并且把释迦摩尼佛的状态讲的非常细腻。仔细品味发现佛的一举一动皆蕴含着佛法。</p>\n<p><strong>我听佛是这样说的。当时，佛祖释迦牟尼在舍卫国的祗树给孤独园，和大比丘众一千二百五十人居住在那里。那时，世尊到吃饭时身着法衣，捧着食钵，进入舍卫国都城化缘。在城内乞食，化缘完后，回到住处。吃完饭，收好法衣和食钵，洗完脚，铺好座垫就开始打坐。</strong></p>\n<p>比丘是受过具足戒律的出家人，“具足”就是圆满，佛所制定的每一条戒他都接受，他都能够依教奉行。大比丘有两种说法，一种是说大比丘是大乘比丘，是菩萨比丘。另外一种说法是修道将要证果的比丘。无论哪种说法，都说明不是一般的比丘，是悟性和觉知比较高的比丘。也说明了这次说法的对象是说给智慧比较高的人来听。</p>\n<p>世尊在当世已然家喻户晓，仍像个普通僧人一般，著衣持钵，入城乞食。乞食完毕，回到住处。吃完饭、收起衣钵，洗了洗脚，铺展开座垫坐下。一个个平凡的举动中透露着不平凡。从这些动作中彷佛看到了佛的如如不动的心，已然万缘放下，心无所著，外部的任何事情都不会对他造成干扰。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","法会因由分"]},{"title":"《金刚经》第三十二品 应化非真分","url":"/2020/05/19/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B%E7%AC%AC%E4%B8%89%E5%8D%81%E4%BA%8C%E5%93%81-%E5%BA%94%E5%8C%96%E9%9D%9E%E7%9C%9F%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！若有人以满无量阿僧祗世界七宝持用布施，若有善男子、善女人发菩提心者，持于此经，乃至四句偈等，受持读诵，为人演说，其福胜彼。云何为人演说，不取于相，如如不动。何以故？”“一切有为法，如梦幻泡影，如露亦如电，应作如是观”。佛说是经已，长老须菩提及诸比丘、比丘尼、优婆塞、优婆夷，一切世间、天、人、阿修罗，闻佛所说，皆大欢喜，信受奉行。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>这一品是《金刚经》的最后一品，继续对本经作了概括性总结。</p>\n<p><strong>“须菩提，如果有人用装满无数无量世界的七宝来行布施，另有发菩提心的善男子善女人，对此经甚至其中的四句偈来受持读诵，为他人解说，这个人的功德胜过前面那个人。如何为人演说呢？不要执着于相，如如不动。为什么呢？”</strong></p>\n<p>这里再次提到了为人解说金刚经的功德，前面已经多次提及，这里不再赘述。另外还提到了如何为人演说经中义理。佛陀用了八个字来概括“不取于相，如如不动”。意思是说没有固定的给人解说的方式，要根据演说对象的不同，采取不同的方式，能让对方接受和理解。而不是发泄自己的演说欲望，滔滔不绝的阿弥陀佛讲个不停。虽然方式会有改变，但那个佛法又是如如不动的，佛法的根本义理不会发生变化。</p>\n<p><strong>“一切有为法，就像梦幻泡影，像露珠又像闪电，应当这样来观看。”</strong></p>\n<p>这里是在解释为什么要“不取于相，如如不动”。因为一切的有为法，一切自然规律，生存法则，或者说人们认定的真理，就像梦境、幻觉、泡沫、影子、露珠和闪电一样，亦真亦幻、稍纵即逝、变化无常。对于一切法应当这样来观想。</p>\n<p>首先说梦观。人们在做梦的时候，会觉得一切是真实的。但醒来之后，发现一切都是虚幻的。人生也是如此，执着于什么的时候，就会觉得自己执着的事情是最正确的真理。一旦醒来，就会发现，这些所谓的真理也不过是像一场梦一样虚幻。还有一点，就像梦是现实的映射，我们执着的某种法，也是这个世界真理的一个方面，一种映射。比如，当年物理学界对光是粒子还是波争论不休，各个学派总能找到支持自己的观点各种证据。但最后的结果表明，光具有波粒二象性，波和颗粒性都只是真实的一个方面。对于梦境，我觉得电影《盗梦空间》给我的启发比较大，有兴趣的可以了解一下。</p>\n<p>其次说幻观。幻境也是不真实的，但在被幻境迷惑的人来看，这一切都是如此的真实。比如沙漠中会看到海市蜃楼、绿洲的幻境。还有一些精神方面的疾病，会幻想出各种不真实的存在。相对于梦境来说，幻更像是当下的执迷。这个可以参照电影《美丽心灵》，里面的主人公被精神疾病多年，总会幻想出不存在的人，最后认清了幻像，跟幻像达成和解。</p>\n<p>再次说泡观。我们小时候都吹过肥皂泡，就会发现泡泡是转瞬即逝的。真理也是如此，过去适用的真理，现在不一定还适用，所以不要墨守陈规。比如当年一纸文凭等于找到好工作，现在时代变了，只凭文凭很难找到好工作。所以就要紧跟时代潮流，努力打磨自身技能，让自己适应这个时代。</p>\n<p>然后说影观。影子是自身的映射，这跟前面说的梦是现实的映射一样。我们现在看到的真理，只是终极真理的一个投影，一个方面。而且影子还有一个特点，会随着光源变化发生变化。在不同的环境下，影子会有长短明暗的变化。这就跟我们看事物的角度一样，同一个事物，不同的角度来看，就会有不同的观点。就像前阵子有个话题特别火，说是学历重要还是能力重要。要我说，不同的角度来看就有不同的结果。如果对于一个刚好凭借着文凭，拿到了钱多事少离家近的工作机会的人来说，学历对他来说就特别重要。但对于一个没学历，但凭借自己本事，在社会中努力打拼，获得了成就的人来说，能力对他就更重要了。所以，事无绝对，角度不同，结论不同。</p>\n<p>再然后说露观。露水的最大特点就是转瞬即逝。前一分钟还真实不虚，后一分钟可能就消失的无影无踪，这个跟泡泡有点像。</p>\n<p>最后说电观。电就是闪电，跟泡泡、露水一样也是转瞬即逝。而且闪电的产生是两朵云碰到一起摩擦产生的偶然而又必然的结果。这就像世间万物一样，都是因缘而生转瞬既逝。只不过闪电的存在时间，对于我们人的感知来说更短。但我们人类的几十年生命，对于宇宙来说，也不过是白驹过隙，一晃就过去的事情。</p>\n<p><strong>佛说完这部经，长老须菩提、比丘、比丘尼和所有的优婆塞、优婆夷以及世上所有的天人、阿修罗，听罢此经，全都非常高兴，并且从此信仰、受持、遵守、修行这部经。</strong></p>\n<p>到这里这部经书就算是结尾了。一切因缘和合而生的事物，都有生灭。讲法有始就有终，人生有生就有死。讲法有终，但佛法无边。希望每个人在修行的路上不停歇，都可以得证无上正等正觉的智慧。</p>\n<hr>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","应化非真分","第三十二品"]},{"title":"《金刚经》第三十一品 知见不生分","url":"/2020/05/18/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B%E7%AC%AC%E4%B8%89%E5%8D%81%E4%B8%80%E5%93%81-%E7%9F%A5%E8%A7%81%E4%B8%8D%E7%94%9F%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>“须菩提！若人言：佛说我见、人见、众生见、寿者见。须菩提！于意云何？是人解我所说义不？”“不也，世尊！是人不解如来所说义。何以故？世尊说：我见、人见、众生见、寿者见，即非我见、人见、众生见、寿者见，是名我见、人见、众生见、寿者见。”“须菩提！发阿耨多罗三藐三菩提心者，于一切法，应如是知，如是见，如是信解，不生法相。须菩提！所言法相者，如来说即非法相，是名法相。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品佛陀揭示了这个世界的本来面貌，这个本来面貌也正解释了为什么不要着实相，也不要着空相。这一品是《金刚经》全文的倒数第二品。经书马上要接近尾声了，佛陀在最后两品中，对全文进行了简要的总结。</p>\n<p><strong>“须菩提，如果有人说：佛说我见、人见、众生见、寿者见。你说这个人理解了我所说的佛法的义理了吗？”“没有，世尊，这个人没有理解您所说的佛法的义理。为什么呢？世尊说：我见、人见、众生见、寿者见，其实不是我见、人见、众生见、寿者见，只是姑且称做我见、人见、众生见、寿者见。”</strong></p>\n<p>从须菩提开篇问的两个问题开始（即发菩提心的善男子、善女人，如何安住他们的心，如何降伏妄心?），世尊一直讲到现在，最大的一个观点就是告诉众生不要着四相（我相、人相、众生相、寿者相）。那么讲了这么多之后，如果心里对四相产生了固有形象，心中就会生起我见、人见、众生见、寿者见，那么这还是没有真正理解佛法在说什么。上一品讲到，整个世界都即是虚无也是实有的，执着于一点是不可能真正看清世界的本来面貌的。我、人、众生、寿者本源来讲其实都是相同的，又哪里有什么分别呢？我、人、众生、寿者都是一合相，由最基本的物质组成的现有的相貌，也只是和合而生的一个结果。这个合相姑且起了一个名字叫做了我、人、众生、寿者。</p>\n<p><strong>“须菩提，发无上正等正觉心的人，对于一切的法，应当这样觉知，这样看待，这样信奉和理解，即对法相不产生固定的执着。须菩提，我所说的法相，也不是法相，只是叫做法相。”</strong></p>\n<p>法相就是对于佛法或者真理有固定的形象，固定的看法。世界本来就没有对于所有人在所有情况下都适用的固定的真理。前面也说过，没有一种法叫做无上正等正觉的大智慧法门。真正的菩提心大智慧就是在内心无私欲，无杂念，众生平等的基础上生出的清净心。偏执于经书上面说的佛法，就是法执，这也是执念，不可能得到真正的智慧。偏执于相信任何写下来的固定道理，都不可能得到圆满大智慧，看清世界的真相。</p>\n<p>从生活中其实我们也可以发现，无知往往和偏执联系在一起，智慧和包容又往往联系在一起。哪有什么固定的好，哪有什么固定的真理。无论什么现实状态下都能转变心态，让自己舒心，就是一种很高的智慧。塞翁失马，焉知非福。再坏的一件事，总有它好的一面。所以生活中要有平常心，全面正确的看待事物的两面性。不要被自己主观的意愿和想法蒙蔽，如果总能看到现实生活中积极的一面，那么生活就能更加幸福。</p>\n<hr>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","知见不生分"]},{"title":"《金刚经》第三品 大乘正宗分","url":"/2020/04/24/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B%E7%AC%AC%E4%B8%89%E5%93%81-%E5%A4%A7%E4%B9%98%E6%AD%A3%E5%AE%97%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>佛告须菩提：“诸菩萨摩诃萨应如是降伏其心！所有一切众生之类：若卵生、若胎生、若湿生、若化生；若有色、若无色；若有想、若无想、若非有想非无想，我皆令入无余涅槃而灭度之。如是灭度无量无数无边众生，实无众生得灭度者。何以故？须菩提！若菩萨有我相、人相、众生相、寿者相，即非菩萨。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>在须菩提请佛进一步讲法之后，佛便开始更加深入细致的来讲法。</p>\n<p>佛说：”<strong>所有的菩萨大菩萨应该怎么样降服自己的心呢？所有的一切众生：无论是卵生、胎生、湿生、化生；有形的、无形的；有思想感觉的、没有思想感觉的、既不是有思想的又不是无思想的，我都让他们进入无余涅槃从而灭其烦恼、度脱生死</strong>。”</p>\n<p>“菩萨”就是“菩提萨埵”，梵语的音译，意为上求觉悟，下度众生。“摩诃”也是梵语，意思是“大”。”摩诃萨“就是”摩诃萨埵“，意为大菩萨。</p>\n<p>涅槃意思是不生不灭。一切万物都有成住坏空。比如身体会有生老病死、烦恼会有生灭。这些都不是涅盘。无余涅槃是相对于有余涅槃来讲的。有余涅槃是一种人为造成的寂灭境界，而无余涅槃是佛性本然，无生无灭，无成亦无坏。灭度就是灭其烦恼，度脱生死，不再受生死轮转。</p>\n<p>佛接着说：<strong>“像这样灭度了无量无数无边众生，其实并没有众生得以灭度。为什么呢？须菩提啊，如果菩萨内心有人、我、众生、寿者等等的区别，这就不是真正的菩萨。”</strong></p>\n<p>佛度众生但又不觉得有一个众生是自己度的。这是佛的一种境界、胸襟和智慧。佛是真正的平等主义者，在他眼里人、我、众生、寿者是无差别的。自己没有站在得道者的角度来度化没有得到的众生。众生是佛，佛也是众生。一旦菩萨心中有了分别心，境界就落了下乘，就有了尔虞我诈，争名夺利，也就不能称之为菩萨了。</p>\n<p>《道德经》也有类似的章句：“不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长。夫唯不争，故天下莫能与之争。”这里就有异曲同工之妙。觉得自己有功劳的人，其实没有功劳可言。</p>\n<p>大地、阳光、雨水从来没有说过万物生长是它们的功劳。人世间也是如此，每天告诉小孩自己有多辛苦，为了小孩自己放弃了很多东西的父母，往往小孩都叛逆。经常向自己的伴侣做一些感动对方的事情来展示自己很爱对方的人，往往最后总是很受伤。在生活中保持一颗慈悲心，平常心就是佛法。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","大乘正宗分"]},{"title":"《金刚经》第三十品 一合理相分","url":"/2020/05/17/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B%E7%AC%AC%E4%B8%89%E5%8D%81%E5%93%81-%E4%B8%80%E5%90%88%E7%90%86%E7%9B%B8%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>须菩提！若善男子、善女人，以三千大千世界碎为微尘，于意云何？是微尘众宁为多不？甚多，世尊！何以故？若是微尘众实有者，佛则不说是微尘。所以者何？佛说：微尘众，即非微尘众，是名微尘众。世尊！如来所说三千大千世界，即非世界，是名世界。何以故？若世界实有，即是一合相。如来说：‘一合相，即非一合相，是名一合相。’须菩提！一合相者，即是不可说，但凡夫之人贪著其事。</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p>上一品讲了什么是如来境界。如来者，无所从来，亦无所去。如来是如如不动的自性，是亘古不变的支配世界的真理。怎么见如来，前面也说过，若见诸相非相，即见如来。对于色声香味触法，不要太过执着，但又不可有诸法断灭的想法。一切事物都有实和虚，体和用的两面性。用一颗平常心，面对生活中纷繁复杂的事物，不骄不躁，不卑不亢，不气不馁，如果做到这些，就是在生活中践行佛法。在这一品，世尊继续破开迷雾，讲世界的本质到底是什么样的。</p>\n<p><strong>“须菩提，如果有善男子、善女人，把三千大千世界碎为微尘，你说那样的微尘数量多吗？”“非常多，世尊。”“为什么呢？如果把微尘看成实有的相，佛陀就不会说有很多微尘。佛说：我说的很多的微尘，其实不是很多的微尘，只是把他们叫做很多的微尘。”</strong></p>\n<p>世尊在这里又运用**即非**是名**这个句式，来说明我们这个世界的真实面貌。我们所说的一切东西，在某种程度上是存在的，但换个角度或者维度来看可能又不能说是真实存在的，所以姑且只能给他起一个大家能接受的名字。比如说国家这个实体，是由全国人民的共同思想认同加上一些办事机构而构建起来的。但我们不能说这些办事机构就是国家，也不能说某些人就可以代表国家。再比如说人身体是由各个器官构建起来的，我们不能说人身体的某一部分是自我，也不会说手术换掉了某些器官我就不是我了。所有的器官甚至细胞分工合作，才能有身体，才能有自我这个概念。但从细胞层次来说，这个自我又是不存在的，身体只是所有细胞的一个集合体。</p>\n<p><strong>“世尊，如来所说的三千大千世界，其实不是世界，只是叫做世界。</strong></p>\n<p><strong>”</strong>须菩提在这里理解了世尊的意思。我们所处的大千世界，每粒微尘，每个人，都是这个世界的一粒尘埃，从而构成了这个世界。但是这个世界又只是由各种不同层次的组合而集合而成的。不存在世界这么一个浑然一体的实体，只是这些实体通过一定方式组合到一起，我们姑且把这个集合体叫做世界。有机物组合到一起就形成了单细胞生命，单细胞生命组合到一起就形成了多细胞生命，多细胞生命组合到一起就形成了各种各样的高等智慧生命。高等智慧生命把生活思维方式相似的人组织到一起，就形成了宗教、种族、社会、国家。但归根到底，我们只是有机物，或者说可以再分，是分子、原子、夸克…</p>\n<p><strong>“为什么呢？如果世界的存在是一个实相，那么这个世界也只是一个实相的集合体。如来说：‘实相的集合体，其实也不是实相的集合体，只是叫做实相的集合体。’须菩提，这个实相的集合是不可说的，但凡夫都太执着这个实相的存在。”</strong></p>\n<p>这里世尊再次解释，说如果说我们的世界是个实体，也只能说是一个实体集合。再次强调，不要被集合体这个概念给迷惑了，这个集合体只在某种程度上是存在的。比如说一个宗教或者说一个家庭，如果大家思维上不再认同同一个理念，即使组成这个团体的人还在，这个团体实际上也就不能说存在了。</p>\n<hr>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","一合理相分"]},{"title":"《金刚经》第四品 妙行无住分","url":"/2020/04/24/%E3%80%8A%E9%87%91%E5%88%9A%E7%BB%8F%E3%80%8B%E7%AC%AC%E5%9B%9B%E5%93%81-%E5%A6%99%E8%A1%8C%E6%97%A0%E4%BD%8F%E5%88%86/","content":"<p><strong>原文：</strong></p>\n<p><strong>复次，须菩提！菩萨于法，应无所住，行于布施，所谓不住色布施，不住声香味触法布施。须菩提！菩萨应如是布施，不住于相。何以故？若菩萨不住相布施，其福德不可思量。须菩提！于意云何？东方虚空可思量不？”“不也，世尊！”“须菩提！南西北方四维上下虚空可思量不？”“不也，世尊！”“须菩提！菩萨无住相布施，福德亦复如是不可思量。须菩提！菩萨但应如所教住。”</strong></p>\n<span id=\"more\"></span>\n<hr>\n<p><strong>“其次，须菩提啊，菩萨既然没有我相人相众生相寿者相，所以在任何时候都不应有所住、不应有所执着和分别而布施。这就是不住色声香味触法布施。”</strong>这里的色声香味触法是对应着眼耳鼻舌身意的六尘。“色”是一切眼睛能看到的，“声”是一切耳朵能听到的，“香”是一切鼻子能闻到的，“味”是一切舌头能尝到的，“触”就是一切身体能感受到的，“法”是大脑中的一切意识活动。一旦着了这种种法相，就有了个人主观感受和个人喜好，就有了分别心。比如，秦始皇喜欢美女珍宝权力宫殿这些能刺激感官的东西，搜罗天下宝货美女为他一人的欲望服务。在这些东西的腐蚀下，他完全丧失了判断力，对危机视而不见，最终暴毙在途中，大好河山也二世而亡。相反，《史记》在谈到汉高祖刘邦的时候，他的表现是在进秦宫之后“财物无所取，妇女无所幸”。远离这些东西，从而使他时刻保持着清醒的头脑，最终推翻了秦的暴政，平息了多年战乱给老百姓带来的痛苦。从某种角度来讲，这就是一种应无所住，行于布施。《道德经》中也有类似的章句“<strong>五色令人目盲；五音令人耳聋；五味令人口爽；驰骋畋猎，令人心发狂；难得之货，令人行妨</strong>”。所以首先要意识到主观感受的虚妄，跟着主观的感受来走只能让我们偏离大道。《金刚经》又被称作《金刚般若波罗蜜经》，意思是就像金刚一样锋利，无坚不摧，用智慧来破除一切障碍，一切法相，从而度人到彼岸的一部经。</p>\n<p><strong>“须菩提，菩萨应该这样不住相布施，为什么呢？菩萨不住相布施的福德是不可思量的。须菩提，你说这是什么意思呢？东南西北上下的虚空可以思考度量吗？”“世尊，不可以思量。”“须菩提，菩萨不住相布施的福德跟东南西北上下的虚空一样是不可思量的。须菩提，菩萨应当按照我刚才所教的去做，住无所住。”</strong>这里提到了不住相布施的福德非常大。默默付出，不求回报，不计后果，甚至连付出这个念头都不曾产生，这样将会产生巨大的福报。当然，这只是一种自然结果，福报本身并不是布施者刻意追求的。</p>\n<p>从广义来说，人们平时所做的工作、对亲人朋友或是陌生人的关心都是一种布施。在工作和生活中，我们不应太执着于这件事情所带来的回报，而是关注事情本身。关心怎么把事情做好，事情做好了，回报自然就来了。比如说搞科研发文章，如果只想着要发表在影响因子多高的杂志，而不是扎实做事情，结果就是空中楼阁，基础不稳。相反，如果注意自己科研中的每一个细节，思考每一种可能并去认真验证，而不去想能发表在什么杂志上，最终的结果往往会超出预期。真正厉害的企业家往往也是不考虑自己能得到多少回报的人，稻盛和夫出任破产重组的日航CEO的时候，提出了两个条件：一是以零薪水出任日航CEO；二是他将不带团队去日航，因为他公司内部没有人懂航空运输。最终仅仅用了一年时间，日航就做到了三个第一，一个是利润世界第一，一个是准点率世界第一，一个是服务水平世界第一。</p>\n<p>还有就是在工作和生活中，也不应该掺杂太多的个人喜好。佛教讲究缘，生活中的万物都是因缘和合而生。随喜随缘是一种让我们与世界和平相处的智慧。如果有强烈的个人喜好，就会想要得到。想要得到而又因现实得不到，就会造成巨大的痛苦。《道德经》也说：“祸莫大于不知足；咎莫大于欲得”。这里不是说不要去追求自己的理想，而是要放下心中的分别心，放下自己的欲望。真正的理想不应是欲念作祟，而是做这件事的时候自己没有任何想从中获名获利的心思。没有了分别心，人自然就会去做自己想做的事情了。比如一个人就喜欢音乐创作，没有掺杂一点获名获利的心思，那么这个人在追求自己理想的路途中，就不会有患得患失的心态，无论结果如何，这个过程也是洒脱和喜乐的。相反，没有了分别心会更容易追求自己的理想，少了许多世俗的羁绊，就会认清自我，就更容易做出贴合自己内心的选择。佛陀就是舍弃了自己尊贵的王子身份，走上修行之路，终于在菩提树下觉悟求得正果。</p>\n","categories":["哲学思考","金刚经"],"tags":["金刚经","金刚经解说","妙行无住分"]},{"title":"人生如棋，一关一关过就是了（节选）","url":"/2021/06/26/%E4%BA%BA%E7%94%9F%E5%A6%82%E6%A3%8B%EF%BC%8C%E4%B8%80%E5%85%B3%E4%B8%80%E5%85%B3%E8%BF%87%E5%B0%B1%E6%98%AF%E4%BA%86%EF%BC%88%E8%8A%82%E9%80%89%EF%BC%89/","content":"<p>人生如棋，世事如棋，一关一关过就是了。经常会有一个人在独想，会想起一首诗：“春有百花秋有月，夏有凉风冬有雪，若无闲事挂心头，便是人间好时节，好来好往好聚首，春去秋来再团圆。苦尽甘来人自省，平平淡淡度一生”。</p>\n<span id=\"more\"></span>\n<p>谁说不是人海漂泊，边走边悟，边悟边省。年华似水，急急奔走。悟一生，一生悟。有人说，少年如溪，青年如河，中年如湖，老年如海。坎坷人生路，风雨几十载。历尽世事沧桑，阅尽人间百态。心量越活越大，心胸越活越阔，心境越活越淡，最后海纳百川，有容乃大。这当是人生的最高境界，也是生命最后的圆满。少年壮志不识愁，中年心静万事休。漫漫人生，跌跌撞撞，不知不觉已至中年。渐渐悟出，人活到最后，真正想要的，莫过于一份真真切切的安稳与踏实。心安，才身安。</p>\n<p>有时候，以为天快要塌下来了，其实是自己站歪了。有时候，总有无边落木萧萧下的落寞，其实是自己无可名状的情愫作祟。有时候，很容易感动的汹涌澎湃，很容易触景生情。有时候，却麻木的像根木头。终是明了心情不是人生的全部，却能左右人生的全部。细数流年，频频回眸。过往的千回百转，到最后都成了风轻云淡的念想。曾经的风烟往事，都成了茶余饭后的闲聊与闲话。人生聚散无常，生活充满变数。走过了，便从容了。放下了，就轻松了。没有经历，就没有体悟。没有领悟，就不会珍惜。那些看似浅显的道理，非要亲历过才能深悟，非要亲为过方可领会。那些看似清淡如水的寻常点滴，回头怀想才顿觉值得一生追忆、终生回味。</p>\n<p>人的一生，好多的事好多的人，错过就是一生。人生的棋子一步错，步步错。有时不由得感叹，生而为人，许多的经历真的与结果无关。很多的章节，只是人生故事里的小小插曲。无关初始，无关结局。走过小半生的光阴，终是懂得：一些东西放弃了，其实根本未曾拥有过；一些东西，得到了，其实也终将失去。时间总是这样，赠人阅历的同时，也将更无情的沧桑和省悟随手相赠。</p>\n<p>人是很奇怪的动物，思绪千变万化，心情百转千回。总有悲喜交集的时候，总有美丽与哀愁并肩的时刻。是谁说，待到老去，老到一无所有的时候，就慢慢咀嚼回忆。是的，人活一世，走到最后，留存心底的，无非就是那些或深或浅的前尘记忆。还有那些或浓或淡的温馨与感动。或许，岁月留给了我们太多的沧桑。但是，人要相信，生活给予我们最多的还是感动。人生之旅一路走来，你会发现生活于我们温暖，一直是一种牵引，感动一直都在心动处荡起波澜。踏浪于岁月之海洋，云帆尽头，处处回眸，处处别有洞天，风光无限。心在路上，路在心上，唯愿伴你日升与日落，伴你走过万水千山，边走边悟，且行且珍惜。</p>\n","categories":["随笔感想"]},{"title":"使用Hexo免费搭建个人博客","url":"/2022/07/13/%E4%BD%BF%E7%94%A8Hexo%E5%85%8D%E8%B4%B9%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","content":"<p>最近一直在倒腾我使用wordpress搭建的个人博客，因为各种插件导致的问题搞得很头大。所以就萌生了搭建一个非常简洁的原生态的个人博客的想法。在查阅了大量资料之后，发现GitHub+Hexo是一个非常好的方案，尤其是对于有编程基础并且爱倒腾的人来说，简直就是免费大礼包。下面我就分享一下，我使用Hexo搭建博客的过程吧~</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"一、什么是Hexo\"><a href=\"#一、什么是Hexo\" class=\"headerlink\" title=\"一、什么是Hexo?\"></a><strong>一、什么是Hexo?</strong></h1><p>Hexo 是一款基于Node.js运行的快速、简洁并且非常高效的博客框架。我们可以将我们撰写的Markdown文档在几秒内渲染为静态的HTML网站，从而可以是我们不用费尽心力去关注前端页面。<br>更多关于Hexo的介绍，请移步官方文档：<a href=\"https://hexo.io/zh-cn/docs/\">https://hexo.io/zh-cn/docs/</a><br>至于GitHub，相信每一个接触过编程的人都应该听说过这个神奇的网站吧，我在这里就不多赘述了。</p>\n<h1 id=\"二、搭建和配置环境\"><a href=\"#二、搭建和配置环境\" class=\"headerlink\" title=\"二、搭建和配置环境\"></a><strong>二、搭建和配置环境</strong></h1><h2 id=\"1-环境搭建-安装Git-amp-Node-js\"><a href=\"#1-环境搭建-安装Git-amp-Node-js\" class=\"headerlink\" title=\"1. 环境搭建-安装Git &amp; Node.js\"></a>1. 环境搭建-安装Git &amp; Node.js</h2><p>简单来说，Git就是一个版本控制工具，我们后期在搭建好网站之后，可以使用Git非常方便的将网页内容更新同步到GitHub上。<br>由于Git最开始设计用于Unix风格的命令环境中，而Windows系统使用的是Windows命令提示符，是一个非Unix的终端环境，所以我们需要在Windows环境中安装Git Bash。下面列出了Git的下载地址：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://git-scm.com/downloads</span><br></pre></td></tr></table></figure>\n<p>在选择相应的版本之后，选择默认安装。安装完成之后，可以在CMD命令行中输入git –version来测试是否成功。<br>由于Hexo是基于Node.js，所以我们还需要安装Node.js。下面是下载地址：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://nodejs.org/en</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-安装Hexo\"><a href=\"#2-安装Hexo\" class=\"headerlink\" title=\"2. 安装Hexo\"></a>2. 安装Hexo</h2><p>首先，在我们的电脑上新建一个文件夹，可以命名为MyHexoBlog用于存放Hexo框架以及我们自己的网页。在创建好的文件夹下，鼠标点击右键，选择Git Bash Here，然后输入以下命令来一键安装Hexo：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm install -g hexo-cl</span><br></pre></td></tr></table></figure>\n<p>安装完成后，我们可以输入以下指令，来初始化我们的个人博客：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">hexo init</span><br></pre></td></tr></table></figure>\n<p>然后安装Hexo所依赖的包，在Git Bash中输入：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm install</span><br></pre></td></tr></table></figure>\n<p>接下来在Git Bash中输入以下代码来运行本地hexo:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">hexo n Test</span><br><span class=\"line\">hexo g</span><br><span class=\"line\">hexo s</span><br></pre></td></tr></table></figure>\n<p>其中n、g和s分别是new、generate和server的命令缩写，用于新建文章、生成网页，以及启动服务预览。如果我们这时候在浏览器中打开localhost:4000的网页，就应该可以看到我们刚刚生成的名为Test的文章了。</p>\n<h1 id=\"三、配置GitHub\"><a href=\"#三、配置GitHub\" class=\"headerlink\" title=\"三、配置GitHub\"></a><strong>三、配置GitHub</strong></h1><h2 id=\"1-创建GitHub个人仓库\"><a href=\"#1-创建GitHub个人仓库\" class=\"headerlink\" title=\"1. 创建GitHub个人仓库\"></a>1. 创建GitHub个人仓库</h2><p>首先，要确保有一个GitHub的账户。如果您还没有账号，赶快使用邮箱申请一个免费账户吧。<br>在登陆GitHub之后，点击右上角的“+”，然后选择“New reposito”来新建一个仓库，仓库名为<em>username</em>.github.io，注意要将这里的username替换为你自己的用户名。比如我的GitHub账户为shilei165，那么我的仓库名应为shilei165.github.io。</p>\n<h2 id=\"2-配置GitHub\"><a href=\"#2-配置GitHub\" class=\"headerlink\" title=\"2. 配置GitHub\"></a>2. 配置GitHub</h2><p>接下来我们需要配置GitHub从而我们可以直接使用Git Bash来对我们的网页进行管理。在桌面点击右键，选择Git Bash Here。此时就会出现一个Git Bash的命令窗口，我们就可以在这里配置我们的GitHub信息了，具体配置如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">git config --global user.name &quot;username&quot; </span><br><span class=\"line\">git config --global user.email &quot;email address&quot; </span><br></pre></td></tr></table></figure>\n<p>注意要将上面的username和email address替换为你自己的GitHub用户名和邮箱地址。我在这一步的时候出现了找不到配置文件的error：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">error: could not lock config file G://.gitconfig: No such file or directory</span><br></pre></td></tr></table></figure>\n<p>这大概率是因为我们没有正确设置HOME文件夹的位置导致的。要解决这个bug，需要在环境变量中修改或添加一个变量HOME，它的值一般为C:\\Users\\username。这里需要把username替换为您自己的计算机用户名。当然如果你没有出现上面的错误提示，那么恭喜你，你已经成功在Git上配置好了GitHub。<br>接下来，我们需要创建SSH密钥。输入以下代码，然后一路回车：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh-keygen -t rsa -C &quot;email address&quot;</span><br></pre></td></tr></table></figure>\n<p>同样的，需要把email address替换为你自己的GitHub账户的邮箱地址。然后进入C:\\Users\\username.ssh的目录（username替换为你自己的用户名），记得要把隐藏目录显示出来，然后打开id_rsa.pub文件，将内容复制出来。<br>登录你的GitHub账户，点击右上角头像，选择Settings，然后在左侧一栏选择”SSH and GPG keys”，然后点击”New SSH key”。Title可任意填写，然后将刚才复制的密钥粘贴到key中。点击”Add SSH Key”完成添加。此时，我们就完成了将Git和你的GitHub账户的连接配置。我们可以通过在Git Bash中输入以下代码，来测试是否成功：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh git@github.com</span><br></pre></td></tr></table></figure>\n<p>如果出现You’ve successfully….说明配置已经成功。</p>\n<h1 id=\"四、推送网页\"><a href=\"#四、推送网页\" class=\"headerlink\" title=\"四、推送网页\"></a><strong>四、推送网页</strong></h1><p>上面的步骤只是在本地计算机生成了网页，我们只能在本地进行预览。接下来我们要做的就是将网页发布到网上，这样就可以让更多的人看到我们发布的东西了。这时候我们需要修改Hexo安装目录下的_config.yml文件。下拉至文件末尾，找到deploy，修改为如下格式：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repository: https://github.com/shilei165/shilei165.github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<p>然后搜索ulr，将url: <a href=\"http://example.com替换为https//shilei165.github.io%E3%80%82\">http://example.com替换为https://shilei165.github.io。</a><br>同样的搜索skip_render，将其改为skip_render: README.md。<br>这一步的目的是我们给hexo d这个命令做配置，这样hexo就能知道将我们的blog部署到哪个位置。<br>最后，我们安装Git部署插件，输入命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>\n<p>然后分别输入三条命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">hexo clean </span><br><span class=\"line\">hexo g </span><br><span class=\"line\">hexo d</span><br></pre></td></tr></table></figure>\n<p>完成后，稍等几分钟，在浏览器输入你的网址，例如shilei165.github.io。你就会发现你的博客已经上线了。</p>\n<hr>\n","categories":["技术杂谈","Cloud & Web"],"tags":["Hexo","博客","网页","GitHub","建站"]},{"title":"回首2021","url":"/2021/12/31/%E5%9B%9E%E9%A6%962021/","content":"<p>今天是2021年的最后一天，我的人生也正如现在的时刻一般处在一个新旧交替的特殊时期。前段时间的忙碌已经过去，下一阶段的工作还未开启，刚好有时间来总结一下今年的生活。</p>\n<span id=\"more\"></span>\n<p>2021年是忙碌的一年，收获的一年，也是充满变化的一年。</p>\n<p>这一年COVID疫情还在持续，但与2020年不同的是，美国这边人们早已经习惯了疫情，并且在感染人数不断攀升中重启了经济。我们学校和实验室也在重启经济的大潮中再次开放，学校虽然有一些非常敷衍的防疫政策，但说实话并没有对防控疫情有任何明显帮助。不出意外的，身边的很多同学，尤其是美国同学，相继感染了新冠。后果也没有想象和宣传中的那般严重，他们在发烧几天之后又生龙活虎的重返了实验室。但在疫苗推出之后，我跟我老婆还是第一时间接种了两针辉瑞的疫苗。打完疫苗之后心里有底多了，除了去公共场所要戴口罩之外，感觉跟疫情前的生活也没有太大的不同了。</p>\n<p>我的科研生活也几乎恢复到了疫情之前的状态。这里提到的“几乎”是因为老板刚好有一整年的学术休假，所以她搬去加州与家人团聚并且躲避疫情。而我，在这一年中就成了老板在学校的替身，学校和实验室有任何需要处理的事情，都是由我来处理。实验室新来的学生，也都交给我来培训。杂事不断，科研也不能停。每周的group metting，时不时的one-on-one meeting，再加上毕业的压力，科研上也不敢有一丝的松懈。无数日夜的绞尽脑汁也换来了一些成果和荣誉，其中包括被评选为student of the month 并刊登在学校网站公开表彰，两篇peer review文章的发表，当然还有拿到了Dr.的头衔。中间还有一个小插曲，由于疫情耽搁，再加上实验室缺人手接替我的项目，原本预定的暑期毕业的目标没能实现。在得知不能如期答辩之后，很是挫败了一阵子。但挫败和情绪不能改变任何事情，只能重新调整心态，并且积极面对挑战，终于在十一月初获得了committee的一致认可，拿到了博士学位。总结自己博士毕业的过程就像是一艘不断加速的火箭，速度越来越快，越来越快，直到最后一刻突破第一宇宙速度，逃逸出地球引力的束缚，走向更为广袤的宇宙.</p>\n<p>博士毕业，随之而来的是生活中比较大的变化。跟每一个在国外读书的人一样，我面临了工业界or学术界，回国or留美的艰难选择。深思熟虑之后，我最终接受了北卡的一所学校的offer。一辆U-Haul打包的不仅仅是我全部的家当，也是我五年半的记忆。对于待了五年多的城市、学校、还有蓝色小木屋充满了不舍和怀念。那里见证了我的成长，也留下很多美好的记忆。</p>\n<p>人生下一阶段即将来临，我也将要面临不一样的挑战和机遇。希望这个南方小城也可以带给我别样的生活体验吧。希望一切安好，平安喜乐。</p>\n","categories":["随笔感想"],"tags":["2021","新年感言","随笔"]},{"title":"使用SCHTASKS命令执行定时Windows任务","url":"/2022/07/10/%E4%BD%BF%E7%94%A8schtasks%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E5%AE%9A%E6%97%B6windows%E4%BB%BB%E5%8A%A1/","content":"<p><strong>这篇文章将会分享如何在Windows系统下使用SCHTASKS命令来定时执行任务（运行脚本）。</strong></p>\n<p>有时候我们需要定期执行一些常规任务，比如上传或者删除文，运行Python或者其他脚本来实现一些自动功能（自动发送邮件、爬取数据、及时交易等等）。这时候，我们就需要在本地的电脑或者服务器上设置一些定时任务。Windows提供了界面化和Command Line指令两种方式来实现设置定时任务。</p>\n<p>界面化的Task Scheduler 程序操作相对比较简单，可以满足大部分人的日常需求。但在某些特定条件下，比如脚本数量较多，需要管理多台电脑，或者没有显示接口的情况下，使用SCHTASKS 命令就会更加有效率。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"一、SCHTASKS基本参数\"><a href=\"#一、SCHTASKS基本参数\" class=\"headerlink\" title=\"一、SCHTASKS基本参数\"></a><strong>一、SCHTASKS基本参数</strong></h1><p>SCHTASKS 命令允许管理员创建、删除、查询、更改、运行和中止本地或远程系统上的计划任务，其常用参数包括：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">SCHTASKS /Create                创建新的计划任务</span><br><span class=\"line\">SCHTASKS /Delete                删除计划任务</span><br><span class=\"line\">SCHTASKS /Query                 显示所有计划任务</span><br><span class=\"line\">SCHTASKS /Change                更改计划任务的属性</span><br><span class=\"line\">SCHTASKS /Run                   根据需要运行计划任务</span><br><span class=\"line\">SCHTASKS /End                   终止当前正在运行的计划任务</span><br><span class=\"line\">SCHTASKS /ShowSID               显示与计划的任务名称相应的安全标识符</span><br></pre></td></tr></table></figure>\n\n<p>接下来我们会逐条解释这些参数的使用方法。</p>\n<h1 id=\"二-、创建新的本地计划任务\"><a href=\"#二-、创建新的本地计划任务\" class=\"headerlink\" title=\"二 、创建新的本地计划任务\"></a><strong>二</strong> <strong>、创建新的本地计划任务</strong></h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">SCHTASKS /Create [/S system [/U username [/P [password]]]]   </span><br><span class=\"line\">[/RU username [/RP password]] /SC schedule [/MO modifier] [/D day]   </span><br><span class=\"line\">[/M months] [/I idletime] /TN taskname /TR taskrun [/ST starttime]   </span><br><span class=\"line\">[/RI interval] [ &#123;/ET endtime  /DU duration&#125; [/K] [/XML xmlfile] [/V1]]   </span><br><span class=\"line\">[/SD startdate] [/ED enddate] [/IT  /NP] [/Z] [/F] [/HRESULT] [/?]</span><br></pre></td></tr></table></figure>\n\n<p>如果我们只是简单的使用本地计算机来执行定时任务，我们就可以省略掉 [&#x2F;S system [&#x2F;U username [&#x2F;P [password]]]] [&#x2F;RU username [&#x2F;RP password]] 以及 [&#x2F;IT &#x2F;NP] 这一块的代码设置。电脑将会自动默认使用本地电脑和当前用户。下面是其他一些重要参数的解释：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">/SC  schedule     指定计划频率:  MINUTE、 HOURLY、DAILY、WEEKLY、MONTHLY, ONCE, ONSTART, ONLOGON, ONIDLE, ONEVENT。</span><br><span class=\"line\">/MO  modifier     进一步改进计划类型以允许更好地控制计划重复周期。对于相应的计划频率，可以传递的数值如下</span><br><span class=\"line\">                  MINUTE:  1 - 1439 分钟.</span><br><span class=\"line\">                  HOURLY:  1 - 23 小时.</span><br><span class=\"line\">                  DAILY:   1 - 365 天.</span><br><span class=\"line\">                  WEEKLY:  1 - 52周.</span><br><span class=\"line\">                  MONTHLY: 1 - 12,或者FIRST, SECOND, THIRD, FOURTH, LAST, LASTDAY。</span><br><span class=\"line\">/I    idletime    指定运行一个已计划的 ONIDLE 任务之前要等待的空闲时间。有效值范围: 1 到 999 分钟。</span><br><span class=\"line\">/TN   taskname    指定唯一识别这个计划任务的名称。</span><br><span class=\"line\">/TR   taskrun     指定在这个计划时间运行的程序的路径和文件名。例如: C:\\windows\\system32\\calc.exe    </span><br><span class=\"line\">/ST   starttime   指定运行任务的开始时间。时间格式为 hh:mm (24 小时时间)，例如 14:30 表示2:30 PM。如果未指定 /ST，则默认值为当前时间。/SC ONCE 必需有此选项。</span><br><span class=\"line\">/RI   interval    用分钟指定重复间隔。这不适用于计划类型: MINUTE、HOURLY、ONSTART, ONLOGON, ONIDLE, ONEVENT。有效范围: 1 - 599940 分钟。如果已指定 /ET 或 /DU，则其默认值为10 分钟。      </span><br><span class=\"line\">/ET   endtime     指定运行任务的结束时间。时间格式为 hh:mm (24 小时时间)，例如，14:50 表示 2:50 PM。这不适用于计划类型: ONSTART、ONLOGON, ONIDLE, ONEVENT。</span><br><span class=\"line\">/DU   duration    指定运行任务的持续时间。 时间格式为 hh:mm。这不适用于 /ET 和计划类型: ONSTART, ONLOGON, ONIDLE, ONEVENT。 对于 /V1 任务，如果已指定 /RI，则持续时间默认值为1 小时。</span><br><span class=\"line\">/K                在结束时间或持续时间终止任务。这不适用于计划类型: ONSTART、ONLOGON, ONIDLE, ONEVENT。 必须指定 /ET 或 /DU。</span><br><span class=\"line\">/SD   startdate   指定运行任务的第一个日期。格式为 yyyy/mm/dd。默认值为当前日期。这不适用于计划类型: ONCE、ONSTART, ONLOGON, ONIDLE, ONEVENT。</span><br><span class=\"line\">/ED   enddate     指定此任务运行的最后一天的日期。格式是 yyyy/mm/dd。这不适用于计划类型:ONCE、ONSTART、ONLOGON、ONIDLE。</span><br><span class=\"line\">/Z                标记在最终运行完任务后删除任务。</span><br><span class=\"line\">/F                如果指定的任务已经存在，则强制创建任务并抑制警告。</span><br></pre></td></tr></table></figure>\n\n<p>接下来我们举一些实际例子来解释如何使用这些指令。</p>\n<p><strong>实例一：创建一个名字叫NotePad的计划任务，每天9点执行notepad.exe文件</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">SCHTASKS /Create /SC Daily /ST 09:00 /TN NotePad /TR c:\\windows\\system32\\notepad.exe /F</span><br></pre></td></tr></table></figure>\n\n<p><strong>实例二：创建一个名字叫SayHello的计划任务，首次运行时间为9点，然后每分钟执行一次hello.bat文件</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">SCHTASKS /Create /SC minute /MO 1 /TN &quot;SayHello&quot; /TR &quot;C:\\hello.bat&quot; /ST 09:00 /</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、查找计划任务\"><a href=\"#三、查找计划任务\" class=\"headerlink\" title=\"三、查找计划任务\"></a><strong>三、查找计划任务</strong></h1><p>当我们需要查找已创建计划任务的详细信息的时候，就会用到&#x2F;Query指令。其常用参数如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">/TN Taskname      指定要检索其信息的任务名称，否则会检索所有的任务名称。</span><br><span class=\"line\">/V                显示详细任务输出。</span><br></pre></td></tr></table></figure>\n\n<p>接下来我们举一个例子来熟悉如何使用这些指令。</p>\n<p><strong>实例一：查找名字叫NotePad的计划任务</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">SCHTASKS /Query /TN NotePad</span><br></pre></td></tr></table></figure>\n\n<p>其返回值（输出结果）如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">C:\\Users\\Leilei&gt;SCHTASKS /Query /TN notepad</span><br><span class=\"line\"></span><br><span class=\"line\">Folder: \\</span><br><span class=\"line\">TaskName                                 Next Run Time          Status</span><br><span class=\"line\">======================================== ====================== ===============</span><br><span class=\"line\">notepad                                  7/11/2022 9:00:00 AM   Ready</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"四、删除计划任务\"><a href=\"#四、删除计划任务\" class=\"headerlink\" title=\"四、删除计划任务\"></a><strong>四、删除计划任务</strong></h1><p>当我们需要删除一个已创建的计划任务的时候，就会用到&#x2F;Delete指令。其常用参数如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">/TN Taskname      指定需要删除任务名称。可以使用通配符“*”来删除所有任务。</span><br><span class=\"line\">/F                强制删除任务，并且抑制警告。</span><br></pre></td></tr></table></figure>\n\n<p>下面我们举一个例子来熟悉如何使用这些指令。</p>\n<p><strong>实例一：删除名字叫NotePad的计划任务</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">SCHTASKS /Delete /TN NotePad</span><br></pre></td></tr></table></figure>\n\n<p>其返回值（输出结果）如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">C:\\Users\\Leilei&gt;SCHTASKS /Delete /TN NotePad</span><br><span class=\"line\">WARNING: Are you sure you want to remove the task &quot;NotePad&quot; (Y/N)? y</span><br><span class=\"line\">SUCCESS: The scheduled task &quot;NotePad&quot; was successfully deleted.</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"五、批量安排计划任务-bat-file\"><a href=\"#五、批量安排计划任务-bat-file\" class=\"headerlink\" title=\"五、批量安排计划任务(.bat file)\"></a><strong>五、批量安排计划任务(.bat file)</strong></h1><p>相信上面所列举的SCHTASK指令可以满足我们绝大部分的日常需求。但对于同时管理多台电脑或多种程序的管理员来说，上面的代码并不具有可重复性。那么，我们就需要写一个bat程序来实现代码的可重复性。</p>\n<p>下面就给出了一个例子，可以同时安排多个任务执行，并且将执行结果输出到txt文件中进行记录。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">@ECHO off</span><br><span class=\"line\"></span><br><span class=\"line\">REM ****************************************************************</span><br><span class=\"line\">REM</span><br><span class=\"line\">REM Script Name: Task_Sch.bat</span><br><span class=\"line\">REM Author: Leilei Shi</span><br><span class=\"line\">REM Date: July 9th, 2022</span><br><span class=\"line\">REM</span><br><span class=\"line\">REM Description: This script demonstrate how to schedule scripts using</span><br><span class=\"line\">REM WSindows scheduler service and the Schtasks command.</span><br><span class=\"line\">REM</span><br><span class=\"line\"></span><br><span class=\"line\">REM ****************************************************************</span><br><span class=\"line\">REM ******** Script Initialization Section ****</span><br><span class=\"line\">REM Abort execution if OS is not Windows NT</span><br><span class=\"line\">IF NOT &quot;%os%&quot; == &quot;Windows_NT&quot; (</span><br><span class=\"line\">ECHO.</span><br><span class=\"line\">ECHO.</span><br><span class=\"line\">ECHO Unsupported Operating system</span><br><span class=\"line\">ECHO.</span><br><span class=\"line\">ECHO.</span><br><span class=\"line\">GOTO :EOF</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">REM Define a variable that specifies the location of this script log file.</span><br><span class=\"line\">SET ReportFile=C:\\SchtasksReport.txt</span><br><span class=\"line\"></span><br><span class=\"line\">REM ******** Main Processing Section ****</span><br><span class=\"line\">REM Call a procedure that logs this script&#x27;s execution.</span><br><span class=\"line\">CALL :SetUpSchedLog</span><br><span class=\"line\"></span><br><span class=\"line\">REM Call the procedure that sets up scheduled tasks.</span><br><span class=\"line\">CALL :SetUpSchedule</span><br><span class=\"line\"></span><br><span class=\"line\">GOTO :EOF</span><br><span class=\"line\"></span><br><span class=\"line\">REM ******** Procedure Section ****</span><br><span class=\"line\">REM This procedure writes a date and time entry to a report file</span><br><span class=\"line\">:SetUpSchedLog</span><br><span class=\"line\"></span><br><span class=\"line\">ECHO %date% %time% Task_Sch.bat - Now executing. &gt; %ReportFile%</span><br><span class=\"line\"></span><br><span class=\"line\">GOTO :EOF</span><br><span class=\"line\"></span><br><span class=\"line\">REM This procedure sets up the scheduled execution of other programs/scripts using the schtasks command.</span><br><span class=\"line\">:SetUpSchedule</span><br><span class=\"line\"></span><br><span class=\"line\">SCHTASKS /Create /SC minute /MO 1 /tn &quot;SayHello&quot; /tr &quot;C:\\hello.bat&quot; /ST 09:00 /F</span><br><span class=\"line\"></span><br><span class=\"line\">        SCHTASKS /Create /SC Daily /ST 09:00 /TN NotePad /TR c:\\windows\\system32\\notepad.exe /F</span><br><span class=\"line\"></span><br><span class=\"line\">GOTO :EOF</span><br></pre></td></tr></table></figure>\n\n<p>接下来只需要在command line执行这个bat脚本，所有的任务将都会被同时执行。注意Windows Shell Script并不区分大小写，所以不必对字母的大小写太过在意。</p>\n","categories":["技术杂谈","Windows"],"tags":["SCHTASKS","windows","定时任务"]},{"title":"如何使用Taskkill命令来定时关闭任务或程序","url":"/2022/07/19/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Taskkill%E5%91%BD%E4%BB%A4%E6%9D%A5%E5%AE%9A%E6%97%B6%E5%85%B3%E9%97%AD%E4%BB%BB%E5%8A%A1%E6%88%96%E7%A8%8B%E5%BA%8F/","content":"<p>前面我们讲解了如何使用SCHTASK来定时执行Windows的特定程序，但是我们还无法做到定时关闭。比如我们希望每天晚上9点开始定时打开迅雷来下载东西，然后每天上午9点来关闭迅雷，以免在使用网络的时候对网速产生影响。于是，我们就需要用到Taskkill指令，并且结合我们之前学过的Schetask来定时执行程序关闭任务。这篇文章，我们就来一起学习一下如何使用这个指令吧</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"一、TASKKILL基本参数\"><a href=\"#一、TASKKILL基本参数\" class=\"headerlink\" title=\"一、TASKKILL基本参数\"></a><strong>一、TASKKILL基本参数</strong></h1><p>TASKKILL这个命令可以用来结束一个或多个进程。可以通过进程id或者进程图像名来结束进程。其常用参数如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">/S    system           指定要连接到的远程系统。</span><br><span class=\"line\">/U    [domain\\]user    指定应该在哪个用户上下文执行这个命令。</span><br><span class=\"line\">/P    [password]       为提供的用户上下文指定密码。如果忽略，提示输入。</span><br><span class=\"line\">/F                     指定要强行终止进程。</span><br><span class=\"line\">/FI   filter           指定筛选进或筛选出查询的的任务。</span><br><span class=\"line\">/PID  process id       指定要终止的进程的PID。</span><br><span class=\"line\">/IM   image name       指定要终止的进程的影像名。通配符 &#x27;*&#x27;可用来指定所有图像名。</span><br><span class=\"line\">/T                     Tree kill: 终止指定的进程和任何由此启动的子进程。</span><br><span class=\"line\">/?                     显示帮助/用法。</span><br></pre></td></tr></table></figure>\n<h1 id=\"二、程序image-name和PID\"><a href=\"#二、程序image-name和PID\" class=\"headerlink\" title=\"二、程序image name和PID\"></a><strong>二、程序image name和PID</strong></h1><p>首先我们来了解一下什么是程序的image name和PID。简单来说，他们都是程序或进程的身份代码。image name是这个程序的名称，而PID (process identifier) 是这个程序所运行的进程的特有名称。一个程序可以对应多条进程。<br>比如迅雷的image name为’thunder.exe’，记事本的image name为’notepad.exe’。我们也可以通过Ctrl + Alt + Delete 键组合或者使用命令taskmgr来打开进程管理器去查看正在运行的进程。我们就可以在Details一栏中找到我们需要关闭的程序以及对应的PID。<br><img src=\"/images/taskmgr.png\" alt=\"Task Manager\"><br>对于我们日常使用来说，使用image name和PID来对特定程序进行关闭已经完全足够。下面我列举出几个例子来说明如何使用image name和PID来关闭程序或进程：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">taskkill /f /im QQ.exe           # 关闭QQ</span><br><span class=\"line\">taskkill /f /im thunder.exe /T   # 关闭迅雷和其所对应的所有子进程</span><br><span class=\"line\">taskkill /f /pid 4256            # 关闭chromdriver所对应的4256进程</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、筛选器的使用\"><a href=\"#三、筛选器的使用\" class=\"headerlink\" title=\"三、筛选器的使用\"></a><strong>三、筛选器的使用</strong></h1><p>如果我们需要关闭多个进程，可以使用筛选器来提高筛选效率。具体参数如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">筛选器名      有效运算符                  有效值</span><br><span class=\"line\">-----------   ---------------           --------------</span><br><span class=\"line\">STATUS        eq, ne                    运行 | 没有响应</span><br><span class=\"line\">IMAGENAME     eq, ne                    图像名</span><br><span class=\"line\">PID           eq, ne, gt, lt, ge, le    PID 值</span><br><span class=\"line\">SESSION       eq, ne, gt, lt, ge, le    会话编号</span><br><span class=\"line\">CPUTIME       eq, ne, gt, lt, ge, le    CPU 时间，格式为hh:mm:ss。</span><br><span class=\"line\">MEMUSAGE      eq, ne, gt, lt, ge, le    内存使用，单位为 KB</span><br><span class=\"line\">USERNAME      eq, ne                    用户名，格式为[domain\\]user</span><br><span class=\"line\">MODULES       eq, ne                    DLL 名</span><br><span class=\"line\">SERVICES      eq, ne                    服务名</span><br><span class=\"line\">WINDOWTITLE   eq, ne                    窗口标题</span><br></pre></td></tr></table></figure>\n<p>注意: 1. 只有带有筛选器的情况下，才能跟 &#x2F;IM 切换使用通配符 ‘*‘。<br>      2. 其中eq代表“equal”, ne代表”not equal”,gt代表”greater than”,lt代表”less than”, ge代表”greater than or equal to”,le代表”less than or equal to”。<br>      3. 注意: 远程进程总是要强行终止，不管是否指定了 &#x2F;F 选项。<br>举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">TASKKILL /F /FI &quot;PID ge 1000&quot; /FI &quot;WINDOWTITLE ne untitle*&quot;</span><br><span class=\"line\">TASKKILL /F /FI &quot;USERNAME eq NT AUTHORITY\\SYSTEM&quot; /IM notepad.exe</span><br><span class=\"line\">TASKKILL /S system /U domain\\username /FI &quot;USERNAME ne NT*&quot; /IM *</span><br><span class=\"line\">TASKKILL /S system /U username /P password /FI &quot;IMAGENAME eq note*&quot;</span><br></pre></td></tr></table></figure>\n<h1 id=\"四、结合SCHTASKS命令来定时关闭进程\"><a href=\"#四、结合SCHTASKS命令来定时关闭进程\" class=\"headerlink\" title=\"四、结合SCHTASKS命令来定时关闭进程\"></a><strong>四、结合SCHTASKS命令来定时关闭进程</strong></h1><p>在了解了TASKKILL的基本用法之后，我们就可以结合SCHTASKS命令来定时关闭进程。比如我们就可以使用一下命令来定时在每天的17：30来关闭Python程序。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">schtasks /create /sc daily /mo 1 /tn &quot;STOP_Python&quot; /tr &quot;TASKKILL /F /IM py.exe /T&quot; /st 17:30 /f</span><br></pre></td></tr></table></figure>","categories":["技术杂谈","Windows"],"tags":["编程","定时任务","Taskkill","Windows"]},{"title":"如何使用Python来操作Redis数据库","url":"/2022/08/10/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Python%E6%93%8D%E4%BD%9CRedis%E6%95%B0%E6%8D%AE%E5%BA%93/","content":"<p>这篇文章跟大家分享一下如何使用Python来操作Redis数据库。</p>\n<span id=\"more\"></span>\n<hr>\n<p>前面的文章中我们详细介绍了如何安装和使用Redis数据库，但这也仅仅是知道了如何利用数据库来储存数据。接下来，我们就来学习如何让数据库跟Python来进行交互，从而大大提高我们的工作效率。</p>\n<h1 id=\"redis-py模块\"><a href=\"#redis-py模块\" class=\"headerlink\" title=\"redis-py模块\"></a><strong>redis-py模块</strong></h1><h2 id=\"安装redis模块\"><a href=\"#安装redis模块\" class=\"headerlink\" title=\"安装redis模块\"></a>安装redis模块</h2><p>使用Python来与redis交互，首先我们需要安装redis-py这个模块。推荐使用pip安装，指令如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install redis</span><br></pre></td></tr></table></figure>\n<p>安装完成之后可以通过以下代码来测试是否安装成功：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; import redis</span><br><span class=\"line\">&gt;&gt;&gt; redis.VERSION</span><br><span class=\"line\">(4, 3, 4)</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>\n<p>如果成功显示了它的版本，说明已经安装成功了redis-py。</p>\n<h2 id=\"Redis和StrictRedis\"><a href=\"#Redis和StrictRedis\" class=\"headerlink\" title=\"Redis和StrictRedis\"></a>Redis和StrictRedis</h2><p>之前的版本中redis-py下面有两个类Redis和StrictRedis。Redis是StrictRedis的子类，用于向后兼容旧版本里的几个方法。但在redis-py 3.0版本以后，开发团队就放弃了原先”Redis”的支持，”StrictRedis”也更名为”Redis”。但是，”StrictRedis”的别名也可以继续使用。所以在现行版本中，使用Redis和StrictRedis是完全一致的。</p>\n<h2 id=\"连接和使用Redis\"><a href=\"#连接和使用Redis\" class=\"headerlink\" title=\"连接和使用Redis\"></a>连接和使用Redis</h2><p>在连接Redis之前，确保按照之前的文章的教程在本机安装了Redis数据库，并且运行在6379端口上。我们就可以仿照下面的示例来连接Redis：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import redis</span><br><span class=\"line\"></span><br><span class=\"line\">r = redis.Redis(host=&#x27;localhost&#x27;, port=6379, db=0, password = None)</span><br><span class=\"line\">r.set(&#x27;name&#x27;,&#x27;Leilei&#x27;)</span><br><span class=\"line\">print(r.get(&#x27;name&#x27;))</span><br></pre></td></tr></table></figure>\n<p>我们在上面的例子中传入了Redis的地址、运行端口和使用的数据库的信息。在没有改动数据库的默认设置的时候，这里不传入任何信息，也同样可以运行。因为传入的默认值为localhost、6379、0和None。</p>\n<p>运行结果如下:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">b&#x27;Leilei&#x27;</span><br></pre></td></tr></table></figure>\n<p>说明我们已经连接成功，并且执行了set()和get()的操作。如果我们希望输出结果直接将byte转换为string，可以在Redis的参数中加入<em>decode_responses&#x3D;True</em>,具体如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import redis</span><br><span class=\"line\"></span><br><span class=\"line\">r = redis.Redis(host=&#x27;localhost&#x27;, port=6379, db=0, password = None, decode_responses=True)</span><br><span class=\"line\">r.set(&#x27;name&#x27;,&#x27;Leilei&#x27;)</span><br><span class=\"line\">print(r.get(&#x27;name&#x27;))</span><br></pre></td></tr></table></figure>\n<p>运行结果如下:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Leilei</span><br></pre></td></tr></table></figure>\n<h2 id=\"连接池\"><a href=\"#连接池\" class=\"headerlink\" title=\"连接池\"></a>连接池</h2><p>redis-py使用connection pool来管理对一个redis server的所有连接，避免每次建立、释放连接的开销。</p>\n<p>默认每个Redis实例都会维护一个自己的连接池。我们可以直接建立一个连接池，然后作为参数传入Redis，这样就可以实现多个Redis实例共享一个连接池。具体示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">import redis</span><br><span class=\"line\"></span><br><span class=\"line\">pool = redis.ConnectionPool(host=&#x27;localhost&#x27;, port=6379, db=0, password = None)</span><br><span class=\"line\">r = redis.Redis(connection_pool = pool)</span><br><span class=\"line\">r.set(&#x27;name&#x27;,&#x27;Leilei&#x27;)</span><br><span class=\"line\">print(r.get(&#x27;name&#x27;))</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Redis数据导入和导出\"><a href=\"#Redis数据导入和导出\" class=\"headerlink\" title=\"Redis数据导入和导出\"></a><strong>Redis数据导入和导出</strong></h1><p>如果想要把Redis中的数据导入和导出，我们还需要安装一个名为RedisDump的工具。由于这个工具是基于Ruby实现的，所以我们还需要提前安装Ruby。</p>\n<h2 id=\"安装Ruby\"><a href=\"#安装Ruby\" class=\"headerlink\" title=\"安装Ruby\"></a>安装Ruby</h2><p>Ruby的安装可以参考： <a href=\"https://www.ruby-lang.org/zh_cn/documentation/installation/#rubyinstaller\">https://www.ruby-lang.org/zh_cn/documentation/installation/#rubyinstaller</a></p>\n<p>选择相应的平台，安装即可。注意需要安装带DEVKIT的版本。</p>\n<h2 id=\"安装RedisDump工具\"><a href=\"#安装RedisDump工具\" class=\"headerlink\" title=\"安装RedisDump工具\"></a>安装RedisDump工具</h2><p>安装完Ruby之后，我们就可以使用gem命令（类似于python的pip命令）来安装RedisDump了，具体如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">gem install redis-dump</span><br></pre></td></tr></table></figure>\n<p>执行完成之后，即可完成RedisDump的安装。</p>\n<h2 id=\"验证安装\"><a href=\"#验证安装\" class=\"headerlink\" title=\"验证安装\"></a>验证安装</h2><p>通过运行一下两个指令，可以测试是否安装成功：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-dump</span><br><span class=\"line\">redis-load</span><br></pre></td></tr></table></figure>\n<p>如果出现错误，可以尝试重新换一个Ruby版本重新安装，或者注释掉C:\\Ruby30-x64\\lib\\ruby\\gems\\3.0.0\\gems\\redis-dump-0.4.0\\lib\\redis 中的以下代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># `ps -o rss= -p #&#123;Process.pid&#125;`.to_i # in kb</span><br></pre></td></tr></table></figure>","categories":["技术杂谈","Python"],"tags":["计算机","Python","编程","数据读写","数据库"]},{"title":"配有LED音阶显示的Arduino蜂鸣奏乐器","url":"/2021/01/01/%E9%85%8D%E6%9C%89led%E9%9F%B3%E9%98%B6%E6%98%BE%E7%A4%BA%E7%9A%84%E8%9C%82%E9%B8%A3%E5%A5%8F%E4%B9%90%E5%99%A8/","content":"<p>本文将展示我最近用Arduino DIY的一个配有LED音阶显示小灯的蜂鸣奏乐器。</p>\n<span id=\"more\"></span>\n<h1 id=\"一、效果展示\"><a href=\"#一、效果展示\" class=\"headerlink\" title=\"一、效果展示\"></a><strong>一、效果展示</strong></h1><p><strong>-—————————————————————————————</strong></p>\n<p>知乎：</p>\n<p><a href=\"https://www.zhihu.com/zvideo/1325378495463915520\">月亮代表我的心</a></p>\n<p><a href=\"https://www.zhihu.com/zvideo/1325379476785008640\">DIY蜂鸣器演奏《牵手》</a> </p>\n<p>YouTube:</p>\n<p><a href=\"https://youtu.be/Up8Yi3Mj7tw\">https://youtu.be/Up8Yi3Mj7tw</a></p>\n<p><a href=\"https://youtu.be//_QSvo-1RP8g\">https://youtu.be/\\_QSvo-1RP8g</a></p>\n<h1 id=\"二、所需器材\"><a href=\"#二、所需器材\" class=\"headerlink\" title=\"二、所需器材\"></a><strong>二、所需器材</strong></h1><p><strong>-—————————————————————————————</strong></p>\n<ol>\n<li><strong>Arduino 板</strong></li>\n<li><strong>无源蜂鸣器</strong></li>\n<li><strong>LED灯7个</strong></li>\n<li><strong>串并行寄存器</strong></li>\n<li><strong>220欧姆电阻器7个</strong></li>\n<li><strong>杜邦线若干</strong></li>\n<li><strong>面包板1个</strong></li>\n</ol>\n<h1 id=\"三、插线连接\"><a href=\"#三、插线连接\" class=\"headerlink\" title=\"三、插线连接\"></a><strong>三、插线连接</strong></h1><p><strong>-—————————————————————————————</strong></p>\n<p><strong>连接示意图和真实连接图如下：</strong></p>\n<p><strong>注意：因为本实验中只用了7个LED灯来代表音阶中的1、2、3、4、5、6、7，所以第八个LED被划掉了。</strong></p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-148d2c9d95b10ff60f11ee8e14c3f7b0_1440w.jpg\"></p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-c73033343912c3c9c8e1b966b12e292e_1440w.jpg\"></p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-6dcd74bd881952e0a78a487db8e95510_1440w.jpg\"></p>\n<h1 id=\"四、蜂鸣器演奏音乐\"><a href=\"#四、蜂鸣器演奏音乐\" class=\"headerlink\" title=\"四、蜂鸣器演奏音乐\"></a><strong>四、蜂鸣器演奏音乐</strong></h1><p><strong>-—————————————————————————————</strong></p>\n<p>音乐的旋律是由声音的频率和节拍来决定的，如果我们能够控制好频率和节拍，那就有可能演奏出动听的音乐。因此，我们首先需要搞清楚各音调的频率，我从网上找到了这张对应的表格：</p>\n<p>低音：</p>\n<p><img src=\"https://pic2.zhimg.com/80/v2-a9abaa4b71fcde336b36ba0f9414f65d_1440w.jpg\"></p>\n<p>中音：</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-0765fb91c3eb7d8342be4826a94450b7_1440w.jpg\"></p>\n<p>高音：</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-89c5808cd3982cb6b8f18c5b850cf86f_1440w.jpg\"></p>\n<p>我们知道了音调的频率后，下一步就是控制音符的演奏时间。每个音符都会播放一定的时间，这样才能构成一首优美的曲子，而不是生硬的一个调的把所有的音符一股脑的都播放出来。音符节奏分为一拍、半拍、1&#x2F;4拍、1&#x2F;8拍，我们规定一拍音符的时间为1；半拍为0.5；1&#x2F;4拍为0.25；1&#x2F;8拍为0.125……，所以我们可以为每个音符赋予这样的拍子播放出来，音乐就成了。但具体的音阶根频率之间的关系，可能需要再进一步调节，我们后面会讲到。</p>\n<p>首先，我们看《月亮代表我的心》的简谱：</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-d428fb2fc1ca05b7a7998bbc05fcf783_1440w.jpg\"></p>\n<p>这里你可以选择C、D、E任意大调，然后在程序中定义相应的频率即可。另外，该音乐为四分之四拍，每个对应为1拍。几个特殊音符说明如下：</p>\n<p>1）普通音符，占1拍。</p>\n<p>2）带下划线音符，表示0.5拍。</p>\n<p>3）有的音符后带一个点，表示多加0.5拍。</p>\n<p>4）有的音符后带一个—，表示多加1拍。</p>\n<p>5）有的两个连续的音符上面带弧线，表示连音。如果后面那个音与前面的相同，可以只发一次音，然后将节拍相加。也可以稍微改下连音后面那个音的频率，比如减少或增加一些数值（需自己调试），这样表现会更流畅。</p>\n<h1 id=\"五、代码\"><a href=\"#五、代码\" class=\"headerlink\" title=\"五、代码\"></a><strong>五、代码</strong></h1><p><strong>-—————————————————————————————</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//定义音阶频率</span><br><span class=\"line\">#define NTE0 -1</span><br><span class=\"line\">#define NTE1 330</span><br><span class=\"line\">#define NTE2 370</span><br><span class=\"line\">#define NTE3 410</span><br><span class=\"line\">#define NTE4 441</span><br><span class=\"line\">#define NTE5 495</span><br><span class=\"line\">#define NTE6 556 </span><br><span class=\"line\">#define NTE7 624</span><br><span class=\"line\"></span><br><span class=\"line\">#define NTEL1 165</span><br><span class=\"line\">#define NTEL2 175</span><br><span class=\"line\">#define NTEL3 196</span><br><span class=\"line\">#define NTEL4 221</span><br><span class=\"line\">#define NTEL5 248</span><br><span class=\"line\">#define NTEL6 278</span><br><span class=\"line\">#define NTEL7 312</span><br><span class=\"line\"></span><br><span class=\"line\">#define NTEH1 661</span><br><span class=\"line\">#define NTEH2 740</span><br><span class=\"line\">#define NTEH3 820</span><br><span class=\"line\">#define NTEH4 882</span><br><span class=\"line\">#define NTEH5 990</span><br><span class=\"line\">#define NTEH6 1112</span><br><span class=\"line\">#define NTEH7 1248</span><br><span class=\"line\">  </span><br><span class=\"line\">  //根据简谱列出《月亮代表我的心》的各频率</span><br><span class=\"line\">int tune2[] = &#123;</span><br><span class=\"line\">  NTE5, NTE3, NTE2, NTE1,</span><br><span class=\"line\">  NTE3,</span><br><span class=\"line\">  NTE6,NTE4, NTE2, NTE1,</span><br><span class=\"line\">  NTEL7,NTE0, NTEL5, </span><br><span class=\"line\">  NTE1, NTE3, NTE5, NTE1,</span><br><span class=\"line\">  NTEL7, NTE3, NTE5, NTE0, NTE5,</span><br><span class=\"line\">  NTE6, NTE7, NTEH1,  </span><br><span class=\"line\">  NTE6, NTE5, NTE3, NTE2,</span><br><span class=\"line\">  NTE1, NTE1, NTE1, NTE3, NTE2,</span><br><span class=\"line\">  NTE1,NTE1, NTE1, NTE2, NTE3,</span><br><span class=\"line\">  NTE2, NTE1, NTEL6, NTE2, NTE3,</span><br><span class=\"line\">  NTE2, NTE0, NTEL5,</span><br><span class=\"line\">  </span><br><span class=\"line\">  NTE1, NTE3, NTE5, NTE1,</span><br><span class=\"line\">  NTEL7, NTE3, NTE5, NTE0, NTE5,</span><br><span class=\"line\">  NTE6, NTE7, NTEH1, </span><br><span class=\"line\">  NTE6, NTE5, NTE3, NTE2,</span><br><span class=\"line\">  NTE1, NTE1, NTE1, NTE3, NTE2,</span><br><span class=\"line\">  NTE1,NTE1, NTE1, NTE2, NTE3,</span><br><span class=\"line\">  </span><br><span class=\"line\">  NTE2, NTEL6, NTEL7, NTE1, NTE2,</span><br><span class=\"line\">  NTE1, NTE3, NTE5, </span><br><span class=\"line\">  NTE3, NTE2, NTE1, NTE5,</span><br><span class=\"line\">  NTEL7, NTEL6, NTEL7,</span><br><span class=\"line\">  NTEL6, NTEL7, NTEL6, NTEL5,</span><br><span class=\"line\">  NTE3, NTE5,</span><br><span class=\"line\">  NTE3, NTE2, NTE1, NTE5,</span><br><span class=\"line\">  NTEL7, NTEL6, NTEL7,</span><br><span class=\"line\">  </span><br><span class=\"line\">  NTE1, NTE1, NTE1, NTE2, NTE3, </span><br><span class=\"line\">  NTE2, NTE0, NTEL5,</span><br><span class=\"line\">  NTE1, NTE3, NTE5, NTE1,</span><br><span class=\"line\">  NTEL7, NTE3, NTE5, NTE5,</span><br><span class=\"line\">  NTE6, NTE7, NTEH1, </span><br><span class=\"line\">  NTE6, NTE5, NTE3, NTE2,</span><br><span class=\"line\">  NTE1, NTE1, NTE1, NTE3, NTE2,</span><br><span class=\"line\">  NTE1, NTE1, NTE1, NTE2, NTE3, </span><br><span class=\"line\">  NTE2, NTEL6, NTEL7, NTE1, NTE2,</span><br><span class=\"line\">  NTE1, NTE0</span><br><span class=\"line\">  </span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">  //根据简谱列出《月亮代表我的心》的各节拍</span><br><span class=\"line\">float durt2[]=&#123;</span><br><span class=\"line\">  1.5, 0.5, 0.5, 0.5,</span><br><span class=\"line\">  4,</span><br><span class=\"line\">  1.5, 0.5, 0.5, 0.5,</span><br><span class=\"line\">  3, 0.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, //问我爱你</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1.5,</span><br><span class=\"line\">  1, 1.5, 0.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,</span><br><span class=\"line\">  3, 0.5, 0.5,//心。你</span><br><span class=\"line\">  </span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, //问我爱你</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,//有多深，我</span><br><span class=\"line\">  1.5, 0.5, 1.5,//爱你有</span><br><span class=\"line\">  1, 1.5, 0.5, 0.5,//几分？我的</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,//情不移，我的</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,//爱不变，月亮</span><br><span class=\"line\">  </span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,//代表我的</span><br><span class=\"line\">  3, 0.5, 0.5,//心。轻</span><br><span class=\"line\">  1.5, 0.5, 1, 1, //轻的一个</span><br><span class=\"line\">  3, 0.5, 0.5,//吻，已经</span><br><span class=\"line\">  1.5, 0.5, 1.5,0.5,//打动我的</span><br><span class=\"line\">  3, 1,//心，深</span><br><span class=\"line\">  1.5,0.5, 1, 1,//深的一段</span><br><span class=\"line\">  3, 0.5, 0.5,//情，教我</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,//思念到如</span><br><span class=\"line\">  3, 0.5, 0.5,//</span><br><span class=\"line\">  1.5, 0.5, 1.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1.5,</span><br><span class=\"line\">  1, 1.5, 0.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,</span><br><span class=\"line\">  1.5, 0.5, 1, 0.5, 0.5,</span><br><span class=\"line\">  3, 1</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">int length2;</span><br><span class=\"line\">int tonePin = 6; //用6号接口</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int latchPin = 11;</span><br><span class=\"line\">int clockPin = 9;</span><br><span class=\"line\">int dataPin = 12;</span><br><span class=\"line\">//控制七个LED灯的排列组合来模拟七个音阶</span><br><span class=\"line\">byte LED1s = 0b11111110;</span><br><span class=\"line\">byte LED2s = 0b11111101;</span><br><span class=\"line\">byte LED3s = 0b11111011;</span><br><span class=\"line\">byte LED4s = 0b11110111;</span><br><span class=\"line\">byte LED5s = 0b11101111;</span><br><span class=\"line\">byte LED6s = 0b11011111;</span><br><span class=\"line\">byte LED7s = 0b10111111;</span><br><span class=\"line\">byte LED0s = 0b11111111;</span><br><span class=\"line\"></span><br><span class=\"line\">void setup() &#123;</span><br><span class=\"line\">  Serial.begin(9600);</span><br><span class=\"line\">  pinMode(tonePin, OUTPUT);</span><br><span class=\"line\">  pinMode(latchPin,OUTPUT);</span><br><span class=\"line\">  pinMode(dataPin,OUTPUT);</span><br><span class=\"line\">  pinMode(clockPin,OUTPUT);</span><br><span class=\"line\">  length2 = sizeof(tune2)/sizeof(tune2[0]); //计算长度</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void loop() &#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">  for (int x = 0; x&lt;length2; x++)&#123;</span><br><span class=\"line\">    tone(tonePin, tune2[x]);</span><br><span class=\"line\">    delay(300*durt2[x]);</span><br><span class=\"line\">    </span><br><span class=\"line\">    digitalWrite(latchPin, LOW);</span><br><span class=\"line\">    shiftOut(dataPin,clockPin,LSBFIRST,LED0s);</span><br><span class=\"line\">    digitalWrite(latchPin,HIGH);</span><br><span class=\"line\">    </span><br><span class=\"line\">    if(tune2[x] == NTE0)&#123;</span><br><span class=\"line\">      digitalWrite(latchPin, LOW);</span><br><span class=\"line\">      shiftOut(dataPin,clockPin,LSBFIRST,LED0s);</span><br><span class=\"line\">      digitalWrite(latchPin,HIGH);</span><br><span class=\"line\">      Serial.println(0);</span><br><span class=\"line\">      delay(200*durt2[x]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(tune2[x] == NTEH1  tune2[x] == NTE1  tune2[x] == NTEL1)&#123;</span><br><span class=\"line\">      digitalWrite(latchPin, LOW);</span><br><span class=\"line\">      shiftOut(dataPin,clockPin,LSBFIRST,LED1s);</span><br><span class=\"line\">      digitalWrite(latchPin,HIGH);</span><br><span class=\"line\">      Serial.println(1);</span><br><span class=\"line\">      delay(200*durt2[x]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(tune2[x] == NTEH2  tune2[x] == NTE2  tune2[x] == NTEL2)&#123;</span><br><span class=\"line\">      digitalWrite(latchPin, LOW);</span><br><span class=\"line\">      shiftOut(dataPin,clockPin,LSBFIRST,LED2s);</span><br><span class=\"line\">      digitalWrite(latchPin,HIGH);</span><br><span class=\"line\">      Serial.println(2);</span><br><span class=\"line\">      delay(200*durt2[x]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(tune2[x] == NTEH3  tune2[x] == NTE3  tune2[x] == NTEL3)&#123;</span><br><span class=\"line\">      digitalWrite(latchPin, LOW);</span><br><span class=\"line\">      shiftOut(dataPin,clockPin,LSBFIRST,LED3s);</span><br><span class=\"line\">      digitalWrite(latchPin,HIGH);</span><br><span class=\"line\">      Serial.println(3);</span><br><span class=\"line\">      delay(200*durt2[x]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(tune2[x] == NTEH4  tune2[x] == NTE4  tune2[x] == NTEL4)&#123;</span><br><span class=\"line\">      digitalWrite(latchPin, LOW);</span><br><span class=\"line\">      shiftOut(dataPin,clockPin,LSBFIRST,LED4s);</span><br><span class=\"line\">      digitalWrite(latchPin,HIGH);</span><br><span class=\"line\">      Serial.println(4);</span><br><span class=\"line\">      delay(200*durt2[x]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(tune2[x] == NTEH5  tune2[x] == NTE5  tune2[x] == NTEL5)&#123;</span><br><span class=\"line\">      digitalWrite(latchPin, LOW);</span><br><span class=\"line\">      shiftOut(dataPin,clockPin,LSBFIRST,LED5s);</span><br><span class=\"line\">      digitalWrite(latchPin,HIGH);</span><br><span class=\"line\">      Serial.println(5);</span><br><span class=\"line\">      delay(200*durt2[x]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(tune2[x] == NTEH6  tune2[x] == NTE6  tune2[x] == NTEL6)&#123;</span><br><span class=\"line\">      digitalWrite(latchPin, LOW);</span><br><span class=\"line\">      shiftOut(dataPin,clockPin,LSBFIRST,LED6s);</span><br><span class=\"line\">      digitalWrite(latchPin,HIGH);</span><br><span class=\"line\">      Serial.println(6);</span><br><span class=\"line\">      delay(200*durt2[x]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(tune2[x] == NTEH7  tune2[x] == NTE7  tune2[x] == NTEL7)&#123;</span><br><span class=\"line\">      digitalWrite(latchPin, LOW);</span><br><span class=\"line\">      shiftOut(dataPin,clockPin,LSBFIRST,LED7s);</span><br><span class=\"line\">      digitalWrite(latchPin,HIGH);</span><br><span class=\"line\">      Serial.println(7);</span><br><span class=\"line\">      delay(200*durt2[x]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    noTone(tonePin);</span><br><span class=\"line\">  &#125;  </span><br><span class=\"line\">  delay (2000);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>注意，代码中定义的音阶频率跟上表略有不同，因为不同的蜂鸣器可能振动频率略有差别，所以需要根据实际情况来进行一些调节。</p>\n<p>根据同样的原理，可以用蜂鸣器和LED灯来播放任意你喜欢的歌曲。</p>\n<hr>\n","categories":["技术杂谈","Raspberry Pi & Arduino"],"tags":["Arduino","DIY"]},{"title":"数据库--Redis的安装和使用","url":"/2022/08/02/%E6%95%B0%E6%8D%AE%E5%BA%93--Redis%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","content":"<p>这篇文章跟大家分享一下非关系型数据库Redis的安装和使用。</p>\n<span id=\"more\"></span>\n<hr>\n<h1 id=\"Redis简介\"><a href=\"#Redis简介\" class=\"headerlink\" title=\"Redis简介\"></a><strong>Redis简介</strong></h1><p>Redis全称”Remote Dictionary Server”是一个非常高效的开源数据存储系统。Redis支持多种数据结构，包括字符串(string), 哈希(hashes), 列表(lists), 集合(sets), 有序集合(sorted sets)等。</p>\n<p>我们可以通过Redis来对数据进行原子性操作，例如追加字符串;将元素嵌入到列表;计算集合的交集、并集和差集;或者给数据进行排序，并获取排名最高的数据。这里的原子性是指就像原子不可分割的属性一样，一个事务不能再被继续分割就是指执行事务的原子性。或者简单的理解成一个操作要么成功执行，要么失败完全不执行。</p>\n<p>我们可以使用多种计算机语言来对Redis进行操作，包括C, C++, C#, Python, Java, Node.js, Matlab, Perl, PHP, R等。</p>\n<p>如果想要了解更多可以参考Redis的官方网站： <a href=\"https://redis.io/\">https://redis.io/</a> </p>\n<h1 id=\"Redis的安装\"><a href=\"#Redis的安装\" class=\"headerlink\" title=\"Redis的安装\"></a><strong>Redis的安装</strong></h1><h2 id=\"Windows下安装\"><a href=\"#Windows下安装\" class=\"headerlink\" title=\"Windows下安装\"></a>Windows下安装</h2><p>下载地址：<a href=\"https://github.com/tporadowski/redis/releases\">https://github.com/tporadowski/redis/releases</a></p>\n<p>选择自己计算机支持的位数（32位或者64位），比如Redis-x64-5.0.14.1.msi，点击下载安装即可。在安装过程中最好选择把路径添加到环境变量以便于调取使用。</p>\n<p>安装完成之后，我们把目录切换到redis路径下，然后在终端(CMD)输入以下代码来启动并且测试Redis是否安装成功</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">C:\\Program Files\\Redis&gt;redis-server.exe redis.windows.conf</span><br></pre></td></tr></table></figure>\n<p>如果返回值如下所示，说明已经成功安装：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">C:\\Program Files\\Redis&gt;redis-server.exe redis.windows.conf</span><br><span class=\"line\">[45748] 01 Aug 22:10:16.074 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo</span><br><span class=\"line\">[45748] 01 Aug 22:10:16.074 # Redis version=5.0.14.1, bits=64, commit=ec77f72d, modified=0, pid=45748, just started</span><br><span class=\"line\">[45748] 01 Aug 22:10:16.074 # Configuration loaded</span><br><span class=\"line\">                _._</span><br><span class=\"line\">           _.-``__ &#x27;&#x27;-._</span><br><span class=\"line\">      _.-``    `.  `_.  &#x27;&#x27;-._           Redis 5.0.14.1 (ec77f72d/0) 64 bit</span><br><span class=\"line\">  .-`` .-```.  ```\\/    _.,_ &#x27;&#x27;-._</span><br><span class=\"line\"> (    &#x27;      ,       .-`  | `,    )     Running in standalone mode</span><br><span class=\"line\"> |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;|     Port: 6379</span><br><span class=\"line\"> |    `-._   `._    /     _.-&#x27;    |     PID: 45748</span><br><span class=\"line\">  `-._    `-._  `-./  _.-&#x27;    _.-&#x27;</span><br><span class=\"line\"> |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;|</span><br><span class=\"line\"> |    `-._`-._        _.-&#x27;_.-&#x27;    |           http://redis.io</span><br><span class=\"line\">  `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27;</span><br><span class=\"line\"> |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;|</span><br><span class=\"line\"> |    `-._`-._        _.-&#x27;_.-&#x27;    |</span><br><span class=\"line\">  `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27;</span><br><span class=\"line\">      `-._    `-.__.-&#x27;    _.-&#x27;</span><br><span class=\"line\">          `-._        _.-&#x27;</span><br><span class=\"line\">              `-.__.-&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\">[45748] 01 Aug 22:10:16.079 # Server initialized</span><br><span class=\"line\">[45748] 01 Aug 22:10:16.080 * DB loaded from disk: 0.001 seconds</span><br><span class=\"line\">[45748] 01 Aug 22:10:16.081 * Ready to accept connections</span><br></pre></td></tr></table></figure>\n<p>这时我们重新打开一个CMD窗口，输入Redis-cli就可以进入Redis命令行模式：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">C:\\Program Files\\Redis&gt;redis-cli</span><br><span class=\"line\">127.0.0.1:6379&gt; set &#x27;name&#x27; &#x27;Leilei&#x27;</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6379&gt; get &#x27;name&#x27;</span><br><span class=\"line\">&quot;Leilei&quot;</span><br></pre></td></tr></table></figure>\n<p>我们现在暂时还无法远程连接来使用Redis，如果需要远程连接，我们可以修改Redis安装文件下的redis.windows.conf配置文件。<br>首先，将下面的IP栏注释掉：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">bind 127.0.0.1</span><br></pre></td></tr></table></figure>\n<p>另外我们还可以通过取消注释并且修改下面这一行，来给Redis设置密码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">requirepass foobared</span><br></pre></td></tr></table></figure>\n<p>foodbared即当前的默认密码，我们需要修改为自己的密码。</p>\n<p>重启Redis服务之后，我们就可以使用密码远程连接Redis了。停止和重启Redis的服务命令如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">net stop redis</span><br><span class=\"line\">net start redis</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Mac下安装\"><a href=\"#Mac下安装\" class=\"headerlink\" title=\"Mac下安装\"></a>Mac下安装</h2><p>在Mac环境下使用Homebrew安装会比较简单，直接执行如下命令即可：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">brew install redis</span><br></pre></td></tr></table></figure>\n<p>可以使用如下命令来启动Redis服务：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">brew services start redis</span><br><span class=\"line\">redis-server /usr/local/ect/redis.conf</span><br></pre></td></tr></table></figure>\n<p>同样使用redis-cli进入Redis命令行模式。</p>\n<p>停止和重启Redis的服务命令如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">brew services stop redis</span><br><span class=\"line\">brew services restart redis</span><br></pre></td></tr></table></figure>\n<h1 id=\"全局命令\"><a href=\"#全局命令\" class=\"headerlink\" title=\"全局命令\"></a><strong>全局命令</strong></h1><h3 id=\"查询所有的key：\"><a href=\"#查询所有的key：\" class=\"headerlink\" title=\"查询所有的key：\"></a>查询所有的key：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">keys *</span><br></pre></td></tr></table></figure>\n<h3 id=\"查询key的总数：\"><a href=\"#查询key的总数：\" class=\"headerlink\" title=\"查询key的总数：\"></a>查询key的总数：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">dbsize</span><br></pre></td></tr></table></figure>\n<h3 id=\"检测key是否存在：\"><a href=\"#检测key是否存在：\" class=\"headerlink\" title=\"检测key是否存在：\"></a>检测key是否存在：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">exists key </span><br></pre></td></tr></table></figure>\n<h3 id=\"删除指定key：\"><a href=\"#删除指定key：\" class=\"headerlink\" title=\"删除指定key：\"></a>删除指定key：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">del key [key...] </span><br></pre></td></tr></table></figure>\n<h3 id=\"指定key过期时长：\"><a href=\"#指定key过期时长：\" class=\"headerlink\" title=\"指定key过期时长：\"></a>指定key过期时长：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">expire key seconds  # 当超过过期时间，会自动删除，key在seconds秒后过期</span><br><span class=\"line\">expireat key timestamp # key在秒级时间戳timestamp后过期</span><br><span class=\"line\">pexpire key milliseconds # 当超过过期时间，会自动删除，key在milliseconds毫秒后过期</span><br><span class=\"line\">pexpireat key milliseconds-timestamp # key在豪秒级时间戳timestamp后过期</span><br><span class=\"line\">ttl # 命令可以查看key的剩余过期时间，单位：秒（&gt;0剩余过期时间；-1没设置过期时间；-2键不存在）</span><br><span class=\"line\">pttl #与ttl类似，但单位是毫秒</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看key的数据结构类型\"><a href=\"#查看key的数据结构类型\" class=\"headerlink\" title=\"查看key的数据结构类型:\"></a>查看key的数据结构类型:</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">type key</span><br></pre></td></tr></table></figure>\n<h3 id=\"key重命名\"><a href=\"#key重命名\" class=\"headerlink\" title=\"key重命名\"></a>key重命名</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">rename key newkey</span><br></pre></td></tr></table></figure>\n<h3 id=\"随机返回一个key\"><a href=\"#随机返回一个key\" class=\"headerlink\" title=\"随机返回一个key\"></a>随机返回一个key</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">randomkey</span><br></pre></td></tr></table></figure>\n<h3 id=\"切换数据库\"><a href=\"#切换数据库\" class=\"headerlink\" title=\"切换数据库\"></a>切换数据库</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">select index # 默认16个数据库：0-15</span><br></pre></td></tr></table></figure>\n<h3 id=\"清除数据库\"><a href=\"#清除数据库\" class=\"headerlink\" title=\"清除数据库\"></a>清除数据库</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">flushdb # 清除当前数据库</span><br><span class=\"line\">flushall # 清除所有数据库</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Redis数据类型\"><a href=\"#Redis数据类型\" class=\"headerlink\" title=\"Redis数据类型\"></a><strong>Redis数据类型</strong></h1><p> Redis支持多种数据类型，包括strings, hashes, lists, sets, sorted sets, bitmaps, hyperloglogs, geospatial indexes, 以及streams。其中我们最常用到的为字符串(string), 哈希(hashes), 列表(lists), 集合(sets), 有序集合(sorted sets)，下面我们就来简单介绍下如何使用这几种数据类型。</p>\n<h2 id=\"String-字符串\"><a href=\"#String-字符串\" class=\"headerlink\" title=\"String(字符串)\"></a>String(字符串)</h2><p> String是Redis最基本的数据类型，该类型的最大储存空间为512M。</p>\n<p>常用的Redis字符串命令如下：</p>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>set key value</td>\n<td>设置key值</td>\n</tr>\n<tr>\n<td>get key</td>\n<td>获取key值</td>\n</tr>\n<tr>\n<td>mset key value [key value…]</td>\n<td>批量设置值</td>\n</tr>\n<tr>\n<td>mget key [key…]</td>\n<td>批量获取值</td>\n</tr>\n<tr>\n<td>incr key</td>\n<td>将key中储存的数字值增一</td>\n</tr>\n<tr>\n<td>decr key</td>\n<td>将key中储存的数字值减一</td>\n</tr>\n<tr>\n<td>strlen key</td>\n<td>字符串长度</td>\n</tr>\n<tr>\n<td>getset key value</td>\n<td>设置并返回原值</td>\n</tr>\n<tr>\n<td>setrange key offset</td>\n<td>设置指定位置的字符</td>\n</tr>\n<tr>\n<td>getrange key start end</td>\n<td>获取部分字符串，start和end分别为开始和结束的偏移量</td>\n</tr>\n</tbody></table>\n<p>最常用的存储和获取string的示例如下：<br> <figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6379&gt; set name leilei</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6379&gt; get name</span><br><span class=\"line\">&quot;leilei&quot;</span><br></pre></td></tr></table></figure></p>\n<p>相对来说稍微复杂的incr, setrange, getrange 举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">## incr &amp; decr</span><br><span class=\"line\">127.0.0.1:6379&gt; set age 20</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 21</span><br><span class=\"line\">127.0.0.1:6379&gt; decr age</span><br><span class=\"line\">(integer) 20</span><br><span class=\"line\"></span><br><span class=\"line\">## setrange</span><br><span class=\"line\">127.0.0.1:6379&gt; set name Leilei</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6379&gt; setrange name 0 M</span><br><span class=\"line\">(integer) 6</span><br><span class=\"line\">127.0.0.1:6379&gt; get name</span><br><span class=\"line\">&quot;Meilei&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">## getrange</span><br><span class=\"line\">127.0.0.1:6379&gt; set name Leilei</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6379&gt; getrange name 0 3</span><br><span class=\"line\">&quot;Leil&quot;</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"Hash-哈希\"><a href=\"#Hash-哈希\" class=\"headerlink\" title=\"Hash(哈希)\"></a>Hash(哈希)</h2><p>Redish Hash是一个键值对(key &#x3D;&gt; value)集合。</p>\n<p>常用的Redis哈希命令如下：</p>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>hset key field value</td>\n<td>设置值</td>\n</tr>\n<tr>\n<td>hget key field</td>\n<td>获取值</td>\n</tr>\n<tr>\n<td>hdel key field [field…]</td>\n<td>删除field</td>\n</tr>\n<tr>\n<td>hlen key</td>\n<td>field个数</td>\n</tr>\n<tr>\n<td>hmset key field value [field value…]</td>\n<td>批量设置field-value</td>\n</tr>\n<tr>\n<td>hmget key field [field…]</td>\n<td>批量获取field</td>\n</tr>\n<tr>\n<td>hexists key field</td>\n<td>判断field是否存在</td>\n</tr>\n<tr>\n<td>hkeys key</td>\n<td>获取所有field</td>\n</tr>\n<tr>\n<td>havls key</td>\n<td>获取所有value</td>\n</tr>\n<tr>\n<td>hincrby key field increment</td>\n<td>增加field所对应的value, increment必须为整数</td>\n</tr>\n<tr>\n<td>hidecrbyfloat key field increment</td>\n<td>增加field所对应的value()，increment为浮点型</td>\n</tr>\n<tr>\n<td>hstrlen key field</td>\n<td>计算value字符串长度</td>\n</tr>\n</tbody></table>\n<p>在创建单组数据时，我们即可以使用HMSET，也可使用HSET命令，创建时需要输入key field value示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6379&gt; hmset students stu1 &quot;Leilei&quot; stu2 &quot;Jason&quot; stu3 &quot;James&quot;</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6379&gt; hget students stu1</span><br><span class=\"line\">&quot;Leilei&quot;</span><br><span class=\"line\">127.0.0.1:6379&gt; hget students stu2</span><br><span class=\"line\">&quot;Jason&quot;</span><br></pre></td></tr></table></figure>\n<p>这里HMSET和HSET唯一的不同在于返回值不同，HMSET返回值为字符串(例如OK)，而HSET返回值为整数值(例如0, 1等)。</p>\n<h2 id=\"List-列表\"><a href=\"#List-列表\" class=\"headerlink\" title=\"List(列表)\"></a>List(列表)</h2><p>Redis列表是简单的字符串列表，字符串可以多次重复出现，可以按照插入顺序排序排列。</p>\n<p>列表有四种操作类型，归类如下：</p>\n<table>\n<thead>\n<tr>\n<th>操作类别</th>\n<th>操作</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>添加</td>\n<td>rpush, lpush, linsert</td>\n</tr>\n<tr>\n<td>查找</td>\n<td>lrange, lindex, llen</td>\n</tr>\n<tr>\n<td>删除</td>\n<td>lpop, rpop, lrem, ltrim</td>\n</tr>\n<tr>\n<td>修改</td>\n<td>lset</td>\n</tr>\n<tr>\n<td>阻塞操作</td>\n<td>blpop, brpop</td>\n</tr>\n</tbody></table>\n<p>常用的Redis列表命令如下：</p>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>lpush key value1 [value2]</td>\n<td>将一个或多个值插入到列表头部</td>\n</tr>\n<tr>\n<td>rpush key value1 [value2]</td>\n<td>在列表中添加一个或多个值到列表尾部</td>\n</tr>\n<tr>\n<td>linsert key before|after pivot value</td>\n<td>在列表的元素前或者后插入元素</td>\n</tr>\n<tr>\n<td>lrange key start stop</td>\n<td>获取列表指定范围内的元素</td>\n</tr>\n<tr>\n<td>lindex key index</td>\n<td>通过索引获取列表中的元素。</td>\n</tr>\n<tr>\n<td>llen key</td>\n<td>获取列表长度</td>\n</tr>\n<tr>\n<td>lpop key</td>\n<td>弹出并获取列表的第一个元素</td>\n</tr>\n<tr>\n<td>rpop key</td>\n<td>弹出并获取列表的最后一个元素</td>\n</tr>\n<tr>\n<td>lrem key count value</td>\n<td>移除列表元素。count &gt; 0 : 从表头开始向表尾搜索，移除与value相等的元素，数量为count。count &lt; 0 : 从表尾开始向表头搜索，移除与value 相等的元素，数量为count的绝对值。count &#x3D; 0 : 移除表中所有与value相等的值。</td>\n</tr>\n<tr>\n<td>ltrim key start stop</td>\n<td>对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。</td>\n</tr>\n<tr>\n<td>lset key index value</td>\n<td>通过索引设置列表元素的值</td>\n</tr>\n<tr>\n<td>blpop key1 [key2 …] timeout</td>\n<td>弹出并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</td>\n</tr>\n<tr>\n<td>brpop key1 [key2 …] timeout</td>\n<td>弹出并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</td>\n</tr>\n<tr>\n<td>brpoplpush source destination timeout</td>\n<td>弹出列表的最后一个元素，并将该元素添加到另一个列表并返回；如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</td>\n</tr>\n<tr>\n<td>rpoplpush source destination</td>\n<td>弹出列表的最后一个元素，并将该元素添加到另一个列表并返回</td>\n</tr>\n</tbody></table>\n<p>linsert key before|after pivot value举例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6379&gt; rpush newlist a b c d e f g</span><br><span class=\"line\">(integer) 7</span><br><span class=\"line\">127.0.0.1:6379&gt; linsert newlist after b a</span><br><span class=\"line\">(integer) 8</span><br><span class=\"line\">127.0.0.1:6379&gt; lrange newlist 0 -1</span><br><span class=\"line\">1) &quot;a&quot;</span><br><span class=\"line\">2) &quot;b&quot;</span><br><span class=\"line\">3) &quot;a&quot;</span><br><span class=\"line\">4) &quot;c&quot;</span><br><span class=\"line\">5) &quot;d&quot;</span><br><span class=\"line\">6) &quot;e&quot;</span><br><span class=\"line\">7) &quot;f&quot;</span><br><span class=\"line\">8) &quot;g&quot;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Set-集合\"><a href=\"#Set-集合\" class=\"headerlink\" title=\"Set(集合)\"></a>Set(集合)</h2><p>Redis的Set是string类型的无序集合，元素只能出现一次。</p>\n<p>常用的Redis集合命令如下：</p>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>sadd key element [element…]</td>\n<td>添加元素</td>\n</tr>\n<tr>\n<td>srem key element [element…]</td>\n<td>删除元素</td>\n</tr>\n<tr>\n<td>scard key</td>\n<td>计算元素个数</td>\n</tr>\n<tr>\n<td>sismember key element</td>\n<td>判断元素是否在集合中</td>\n</tr>\n<tr>\n<td>srandmember key [count]</td>\n<td>随机从集合返回指定个数元素</td>\n</tr>\n<tr>\n<td>smembers key</td>\n<td>获取所有元素</td>\n</tr>\n<tr>\n<td>sinter key [key…]</td>\n<td>求多个集合的交集</td>\n</tr>\n<tr>\n<td>sunion key [key…]</td>\n<td>求多个集合的并集</td>\n</tr>\n<tr>\n<td>sdiff key [key…]</td>\n<td>求多个集合的差集</td>\n</tr>\n<tr>\n<td>sinterstore destination key [key …]</td>\n<td>将多个集合的交集保存</td>\n</tr>\n<tr>\n<td>sunionstore destination key [key…]</td>\n<td>将多个集合的并集保存</td>\n</tr>\n<tr>\n<td>sdiffstore destination key [key…]</td>\n<td>将多个集合的差集保存</td>\n</tr>\n</tbody></table>\n<h2 id=\"Zset-有序集合\"><a href=\"#Zset-有序集合\" class=\"headerlink\" title=\"Zset(有序集合)\"></a>Zset(有序集合)</h2><p>Redis zset和set一样也是string类型元素的集合,且不允许成员重复。不同的是每个成员都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。</p>\n<p>常用的Redis有序集合命令如下：</p>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>zadd key score member</td>\n<td>添加成员</td>\n</tr>\n<tr>\n<td>zcard key</td>\n<td>计算成员个数</td>\n</tr>\n<tr>\n<td>zscore key member</td>\n<td>计算成员分数</td>\n</tr>\n<tr>\n<td>zrank key member</td>\n<td>计算成员排名</td>\n</tr>\n<tr>\n<td>zrem key member [member…]</td>\n<td>删除成员</td>\n</tr>\n<tr>\n<td>zincrby key increment member</td>\n<td>增加成员分数</td>\n</tr>\n<tr>\n<td>zrange key start end</td>\n<td>从低分到高分排列</td>\n</tr>\n<tr>\n<td>zrevrange key start end</td>\n<td>从高分到低分排列</td>\n</tr>\n<tr>\n<td>zrangebyscore key min max</td>\n<td>返回指定分数范围的成员，分数从低到高排列</td>\n</tr>\n<tr>\n<td>zrevrangebyscore key max min</td>\n<td>返回指定分数范围的成员，分数从高到低排列</td>\n</tr>\n<tr>\n<td>zcount key min max</td>\n<td>返回指定分数范围的成员个数</td>\n</tr>\n<tr>\n<td>zremrangebyrank key start end</td>\n<td>删除指定排名内的升序元素</td>\n</tr>\n<tr>\n<td>zremrangebyscore key min max</td>\n<td>删除指定分数范围的成员</td>\n</tr>\n<tr>\n<td>zinterstore destination key [key …]</td>\n<td>将多个集合的交集保存</td>\n</tr>\n<tr>\n<td>zunionstore destination key [key…]</td>\n<td>将多个集合的并集保存</td>\n</tr>\n</tbody></table>\n<p>zrange和zrangebyscore的区别，示例如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">27.0.0.1:6379&gt; zadd school 100 UC</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6379&gt; zadd school 90 UH</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6379&gt; zadd school 70 CU</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6379&gt; zrange school 0 -1</span><br><span class=\"line\">1) &quot;CU&quot;</span><br><span class=\"line\">2) &quot;UH&quot;</span><br><span class=\"line\">3) &quot;UC&quot;</span><br><span class=\"line\">127.0.0.1:6379&gt; zrangebyscore school 80 100</span><br><span class=\"line\">1) &quot;UH&quot;</span><br><span class=\"line\">2) &quot;UC&quot;</span><br></pre></td></tr></table></figure>\n","categories":["技术杂谈","Database"],"tags":["计算机","编程","数据读写","教程","数据库","Redis"]},{"title":"怎么设置Mac和树莓派(Raspberry Pi)之间的文件共享  AFP设置教程","url":"/2021/01/06/%E6%80%8E%E4%B9%88%E8%AE%BE%E7%BD%AEmac%E5%92%8C%E6%A0%91%E8%8E%93%E6%B4%BEraspberry-pi%E4%B9%8B%E9%97%B4%E7%9A%84%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB-afp%E8%AE%BE%E7%BD%AE%E6%95%99%E7%A8%8B/","content":"<p><strong>这篇文章将会分享怎么设置AFP (Apple Filing Protocol) 来实现Raspberry Pi 和苹果系统之间的文件共享。</strong></p>\n<span id=\"more\"></span>\n<p>最近我在树莓派(Raspberry Pi 4B)上设置AFP的时候踩了很多坑，希望分享出来，可以帮助到大家。通过这篇文章，我相信大家都可以非常轻松的设置AFP，从而实现树莓派和Mac之间的文件共享。</p>\n<h1 id=\"什么是AFP？\"><a href=\"#什么是AFP？\" class=\"headerlink\" title=\"什么是AFP？\"></a><strong>什么是AFP？</strong></h1><p>AFP是苹果专有的网络协议，这个协议是用来在不同电脑之间传输文件，实现文件共享。它是苹果对于SMB (<a href=\"https://pimylifeup.com/raspberry-pi-samba/\">Server Message Block)</a> 和 NFS (<a href=\"https://pimylifeup.com/raspberry-pi-nfs/\">Network File System)</a>协议的替代产品。</p>\n<h1 id=\"怎么下载所需文件？\"><a href=\"#怎么下载所需文件？\" class=\"headerlink\" title=\"怎么下载所需文件？\"></a><strong>怎么下载所需文件？</strong></h1><p>在你的树莓派上设置AFP之前，首先请确保你的系统是最新的。输入以下代码来更新Raspberry Pi 的系统：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo apt update</span><br><span class=\"line\">sudo apt upgrade</span><br></pre></td></tr></table></figure>\n\n<p>在确保系统已经更新的前提下，接下来我们要在Raspberry Pi 上需要下载一个叫做Netatalk的包。使用以下代码来下载和安装：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo apt install netatalk</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"怎么配置Netatalk\"><a href=\"#怎么配置Netatalk\" class=\"headerlink\" title=\"怎么配置Netatalk?\"></a><strong>怎么配置Netatalk?</strong></h1><p>在下载和安装好Netatalk之后，我们就要对它进行一些配置。所以请在Pi的Terminal输入以下代码对 “<strong>afp.conf</strong>” 文件进行修改：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo nano /etc/netatalk/afp.conf</span><br></pre></td></tr></table></figure>\n\n<p>打开之后，是这个样子的：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">;</span><br><span class=\"line\">; Netatalk 3.x configuration file</span><br><span class=\"line\">;</span><br><span class=\"line\"></span><br><span class=\"line\">[Global]</span><br><span class=\"line\">; Global server settings</span><br><span class=\"line\"></span><br><span class=\"line\">; [Homes]</span><br><span class=\"line\">; basedir regex = /xxxx</span><br><span class=\"line\"></span><br><span class=\"line\">; [My AFP Volume]</span><br><span class=\"line\">; path = /home/pi</span><br><span class=\"line\"></span><br><span class=\"line\">; [My Time Machine Volume]</span><br><span class=\"line\">; path = /path/to/backup</span><br><span class=\"line\">; time machine = yes</span><br></pre></td></tr></table></figure>\n\n<p>修改成如下的样子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">;</span><br><span class=\"line\">; Netatalk 3.x configuration file</span><br><span class=\"line\">;</span><br><span class=\"line\"></span><br><span class=\"line\">[Global]</span><br><span class=\"line\"> Global server settings</span><br><span class=\"line\"></span><br><span class=\"line\">[Homes]</span><br><span class=\"line\"> basedir regex = /home</span><br><span class=\"line\"></span><br><span class=\"line\">[My AFP Volume]</span><br><span class=\"line\"> path = /home/pi</span><br><span class=\"line\"></span><br><span class=\"line\">;[My Time Machine Volume]</span><br><span class=\"line\">; path = /path/to/backup</span><br><span class=\"line\">; time machine = yes</span><br><span class=\"line\"></span><br><span class=\"line\"> log file = /home/pi/afp.log</span><br></pre></td></tr></table></figure>\n\n<p>这里[Homes]是对home文件夹的路径进行设置；[my AFP Volume]是对要分享的文件夹进行设置；[My Time Machine Volume]是对Time Machine的备份进行设置；然后最后一行是设置log file的文件存放路径。</p>\n<p>设置完按Ctr+O 然后按Enter进行保存，然后Ctr+X退出。</p>\n<p>接下来使用以下代码重启服务器的Netatalk</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo systemctl restart netatalk</span><br></pre></td></tr></table></figure>\n\n<p>接下来的步骤需要用到Raspberry Pi的IP，可以通过如下命令来查看IP:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo hostname -I</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"怎么用Mac进行连接？\"><a href=\"#怎么用Mac进行连接？\" class=\"headerlink\" title=\"怎么用Mac进行连接？\"></a><strong>怎么用Mac进行连接？</strong></h1><p>在设置完成之后，我们就可以用mac来连接我们的Raspberry Pi来实现文件共享了。</p>\n<p>首先，进入Finder，然后Command+K来连接服务器。在地址栏输入afp:&#x2F;&#x2F;+刚才查找的IP，比如：<strong>afp:&#x2F;&#x2F;192.168.0.159</strong>。</p>\n<p>然后输入pi的用户名和密码，就可以实现文件共享了。这里一定要记得改用户名哦！</p>\n<hr>\n","categories":["技术杂谈","Raspberry Pi & Arduino"],"tags":["Linux","Raspberry Pi"]},{"title":"树莓派(Raspberry Pi) 在mac上做系统备份","url":"/2021/01/01/%E6%A0%91%E8%8E%93%E6%B4%BEraspberry-pi-%E5%9C%A8mac%E4%B8%8A%E5%81%9A%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/","content":"<p>树莓派Raspberry Pi 是一款基于 ARM 的单板计算机。默认运行一款称为 Raspbian 的操作系统。RaspbianOS 是一个基于 Debian 的 Linux 发行版，专门用于 Raspberry Pi，它是Raspberry 用户的完美通用操作系统。</p>\n<span id=\"more\"></span>\n<p>由于树莓派的系统是基于Linux而搭建的，所以是一款非常适合学习Linux语言的小机器。但由于Linux可操控性非常高，所以一些不当的操作往往会导致系统崩溃。所以按时备份系统将会非常有必要。</p>\n<h3 id=\"1-首先将装有树莓派系统的SD卡插入mac电脑。\"><a href=\"#1-首先将装有树莓派系统的SD卡插入mac电脑。\" class=\"headerlink\" title=\"1 . 首先将装有树莓派系统的SD卡插入mac电脑。\"></a>1 . 首先将装有树莓派系统的SD卡插入mac电脑。</h3><h3 id=\"2-打开mac的终端输入以下代码查询盘符\"><a href=\"#2-打开mac的终端输入以下代码查询盘符\" class=\"headerlink\" title=\"2. 打开mac的终端输入以下代码查询盘符\"></a>2. 打开mac的终端输入以下代码查询盘符</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">diskutil list </span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://upload-images.jianshu.io/upload_images/3870627-c1a0838ec76f1e92.png?imageMogr2/auto-orient/stripimageView2/2/w/754\"></p>\n<p>图片中的dev&#x2F;disk2既对应的树莓派的TF卡</p>\n<h3 id=\"3-使用dd命令进行备份\"><a href=\"#3-使用dd命令进行备份\" class=\"headerlink\" title=\"3. 使用dd命令进行备份\"></a>3. 使用dd命令进行备份</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo dd if=/dev/disk2 of=~/Desktop/PiSDCardBackup.dmg</span><br></pre></td></tr></table></figure>\n\n<p>这里注意，如果树莓派的盘符不是disk2，要将disk2改为自己的盘符名称。</p>\n<p>回车后，读卡器会显示在读取数据灯在闪烁，备份过程有点长，根据卡的大小，可能会在1小时左右。</p>\n<h3 id=\"4-在备份完成之后将会在桌面出现一个名为PiSDCARDBackup-dmg的镜像文件。接下来我们移除系统SD卡，插上将要备份的SD卡。\"><a href=\"#4-在备份完成之后将会在桌面出现一个名为PiSDCARDBackup-dmg的镜像文件。接下来我们移除系统SD卡，插上将要备份的SD卡。\" class=\"headerlink\" title=\"4. 在备份完成之后将会在桌面出现一个名为PiSDCARDBackup.dmg的镜像文件。接下来我们移除系统SD卡，插上将要备份的SD卡。\"></a>4. 在备份完成之后将会在桌面出现一个名为PiSDCARDBackup.dmg的镜像文件。接下来我们移除系统SD卡，插上将要备份的SD卡。</h3><h3 id=\"5-用etcher软件讲镜像文件烧录入新的SD卡。\"><a href=\"#5-用etcher软件讲镜像文件烧录入新的SD卡。\" class=\"headerlink\" title=\"5. 用etcher软件讲镜像文件烧录入新的SD卡。\"></a>5. 用etcher软件讲镜像文件烧录入新的SD卡。</h3><p>etcher软件下载地址：<a href=\"https://www.youtube.com/redirect?q=https://www.balena.io/etcher/&v=Nc3YyANoOeQ&event=video_description&redir_token=QUFFLUhqbTN4YWNnWWlrLUY5MTNqRl9MRG5WSXBEX2ktUXxBQ3Jtc0tsekNCNkYwRFhXNWNKNGFYelotcUo3a0h6RzJRVnlrSkFHdnlpQzNfX3o3NUtJT1RrUElQV0ROWG1hbTQxM0dUUnpCVjlPNjZPWDRDSVloM3d0V0J6SVJZbGxpVEVhUzFGalNqd3JJR3RJeUJDSGRJbw==\">https://www.balena.io/etcher/</a></p>\n<p>首先选择刚才的镜像文件</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-1-1024x614.png\"></p>\n<p>然后，选择新的SD卡。最后选择Flash进行烧录。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-3-1024x614.png\"></p>\n<hr>\n<p>参考资料：</p>\n<p>[1] <a href=\"https://oranwind.org/-raspberry-pi-bei-fen-raspbian-shi-yong-macos/\">https://oranwind.org/-raspberry-pi-bei-fen-raspbian-shi-yong-macos/</a></p>\n<p>[2] <a href=\"https://www.youtube.com/watch?v=Nc3YyANoOeQ&amp;t=448s\">https://www.youtube.com/watch?v=Nc3YyANoOeQ&amp;t=448s</a></p>\n<p>[3] <a href=\"https://my.oschina.net/u/186291/blog/4544977\">https://my.oschina.net/u/186291/blog/4544977</a></p>\n","categories":["技术杂谈","Raspberry Pi & Arduino"],"tags":["Linux","树莓派","Raspberry Pi"]},{"title":"黑群晖NAS保姆级安装教程：旧笔记本改造重生成NAS","url":"/2021/01/03/%E9%BB%91%E7%BE%A4%E6%99%96nas%E4%BF%9D%E5%A7%86%E7%BA%A7%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%EF%BC%9A%E6%97%A7%E7%AC%94%E8%AE%B0%E6%9C%AC%E6%94%B9%E9%80%A0%E9%87%8D%E7%94%9F%E6%88%90nas/","content":"<p>家里扔着一台旧电脑，闲置了很久卖不出去，扔了又觉得可惜？</p>\n<p>与其让它趴在墙角吃灰，不如动手把它改造成一台NAS，网络资源各种下下下，图片随便存。</p>\n<span id=\"more\"></span>\n<h2 id=\"不知道NAS是什么？\"><a href=\"#不知道NAS是什么？\" class=\"headerlink\" title=\"不知道NAS是什么？\"></a>不知道NAS是什么？</h2><p><img src=\"https://pic1.zhimg.com/72c1c39bd58d1e013be36436a9cd1e9a_r.jpg?source=1940ef5c\" alt=\"preview\"></p>\n<p><img src=\"https://pic4.zhimg.com/4d12fb6aeae4248cbead1154082f396f_r.jpg?source=1940ef5c\" alt=\"preview\"><img src=\"https://pic4.zhimg.com/8b077b1fb2239f751427fe5e222286ae_r.jpg?source=1940ef5c\" alt=\"preview\"></p>\n<p>怎么样？心动了没有？如果心动了，那么就跟我一起动手改造吧~</p>\n<ol>\n<li>首先，下载所需要的软件和镜像：</li>\n</ol>\n<p><strong>百度云盘</strong>: <a href=\"https://pan.baidu.com/s/1C1UPeboMiMO4QQulpaRpKA\">https://pan.baidu.com/s/1C1UPeboMiMO4QQulpaRpKA</a> 提取码：gi1p</p>\n<p><strong>Google Drive</strong>: <a href=\"https://www.youtube.com/redirect?redir_token=QUFFLUhqbG15cTZCLWhmZzFQb01SbHhnS0xzMVhWZHlPZ3xBQ3Jtc0tsN3FKMzVUSmxuNHhpbzJPdndOWDI4ZUxtVGlEMlJKaV92aXVWb0hRZDdoZmF2YVZBWWVwQjdHZ0hkbTNTZGVTVUhxS0FOdk5vbTJpQUlIeDFJMUZIeUJwNURhLWtCZlg5TGhWRHFBZUF3cUtELTlzYw==&v=3XwcqRwNQvw&q=https://bit.ly/2PgqCNh&event=video_description\">https://bit.ly/2PgqCNh</a></p>\n<p>下载完成后的文件如下图所示：</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-6.png\"></p>\n<p>2. 打开第三个文件，也就是win32diskimager，这个是windows的镜像烧录软件（如果是mac的话推荐使用Etcher）。然后安装win32diskimager。</p>\n<p>Etcher下载地址：<a href=\"https://www.balena.io/etcher/\">https://www.balena.io/etcher/</a></p>\n<p>3. 接下来我们要对群晖的系统进行烧录。这时候我们要准备一个U盘，然后格式化。然后点开win32diskimager把上图列出的最后一个文件烧录入U盘。如下图所示：</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/%E6%97%A7%E7%AC%94%E8%AE%B0%E6%9C%AC%E6%94%B9%E9%80%A0NAS-1.png\"></p>\n<p>4. 烧录完成之后将U盘插入旧笔记本电脑，并且用一根网线将电脑和路由器相连接。</p>\n<p>5. 启动旧笔记本电脑，进入bios设置，选择U盘启动。然后我们刚刚烧录的群晖系统就会被写入笔记本系统。<strong>注意：这一步的操作将会把电脑中所有文件删除，如果有重要文件，务必要提前保存。</strong></p>\n<p>6. 当旧笔记本显示出DiskStation login的时候，确保旧笔记本跟路由器用网线连接在了一起。然后我们打开另一台在同一个wifi下的另一台电脑，进行下一步操作。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-7-1024x533.png\"></p>\n<p>7. 下载并且安装Advance IP Scanner ( <a href=\"https://www.youtube.com/redirect?redir_token=QUFFLUhqbVZZbGU3VXZESjgtUzlYMVJfZWNhaGZfbWhIZ3xBQ3Jtc0tuRUdreU40NVF4bGlPUmdaZFZQM2lwRjZnc0pBWm5HZFZsME9QVHhzc2R1dkh0bU9ZamVlbEF6QzI4QTRVNHRjdVo4M08wZldJUUU0WDB5X2s0UlRkdktINFZndHpfV2d0bzY0Q1VhWVV3OEVSNEd4VQ==&v=3XwcqRwNQvw&q=https://www.advanced-ip-scanner.com/&event=video_description\">https://www.advanced-ip-scanner.com/</a>)。当安装完成之后，打开这个软件，将会看到如下图所示界面。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-8.png\"></p>\n<p>8. 接下来我们要设置要扫描的IP范围，然后进行IP扫描。windows电脑在命令提示符中输入ipconfig就会显示出当前wifi所处的IP范围。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-9.png\"></p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-10.png\"></p>\n<p>9. 将得到的IP地址复制到IP Scanner的IP地址搜索框，并且将最后一个小数点之后的数字改为1-254，然后点击Scan进行扫描。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-12-1024x724.png\"></p>\n<p>10. 这时候我们会看到一个显示有Synology Web Assistant的IP。点击下面的网页，我们就会进入账户设置页面。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-13-1024x536.png\"></p>\n<p>11. 点击设置(Set up)，然后我们会看到</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-14-1024x496.png\"></p>\n<p>12. 载入下载好的第一个文件(DSM开头)。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-15-1024x526.png\"></p>\n<p>13. 安装DiskStation Manager (DSM)。勾选选框，表示理解数据将会被清除。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-16-1024x476.png\"></p>\n<p>14. 接下来是大概几分钟的等待安装时间。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-17-1024x475.png\"></p>\n<p>15. 安装完成会自动重启旧笔记本电脑，然后出现如下界面</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-18-1024x487.png\"></p>\n<p>16. 点Next进行下一步设置。然后创建用户名和密码。注意不要勾选选框。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-20-1024x495.png\"></p>\n<p>17. DSM更新设置。选择第三个。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-21-1024x486.png\"></p>\n<p>18. 跳过QuickConnect设置。然后选择Yes。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-22-1024x488.png\"></p>\n<p>19. 然后进入下一个界面。不要勾选选框。然后点Go，就进入到了群晖页面。</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-24-1024x526.png\"></p>\n<p>20. 界面如图所示：</p>\n<p><img src=\"https://shileilei.com/wp-content/uploads/2021/01/image-25-1024x485.png\"></p>\n<p>21. 到这里我们的群晖NAS系统就安装好了。进行一些简单的设置就可以愉快的使用了。</p>\n<hr>\n","categories":["技术杂谈","Cloud & Web"],"tags":["DIY","NAS","群晖"]}]